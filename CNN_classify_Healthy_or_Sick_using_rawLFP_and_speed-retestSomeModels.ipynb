{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929a0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since noteboke doesn't work in jupiterlabs    %matplotlib notebook \n",
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2904af6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "# os.environ['PATH'] += os.pathsep + 'D:\\\\6OHDA\\\\'\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "from IO import *\n",
    "from utils import *\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Concatenate\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D,Conv2D, Conv1D,MaxPooling1D\n",
    "# from tensorflow.keras.layers.core import Lambda\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "# import png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651e941a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12470726627113544064\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10091102208\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5235607361765387142\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10091102208\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18410676439630112429\n",
      "physical_device_desc: \"device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dabf073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Files = ['FinalData_6OHDA.h5','FinalData_6OHDA_H.h5']\n",
    "#miceList.remove('1253')\n",
    "#miceList.remove('1231')\n",
    "def periodCalc(day):\n",
    "    if day== 0:\n",
    "        return 'Healthy'\n",
    "    elif day<13:\n",
    "        return 'Acute' #day 1-13\n",
    "    else:\n",
    "        return 'Chronic' #day 14-35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4874a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "I deleted session: 1208_day12\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "I deleted session: 2976_day4\n",
      "cleaning up speed data\n"
     ]
    }
   ],
   "source": [
    "data_train = getData(Files[0],['lfp','speed'],period ='Pre', mice=mTrain)\n",
    "# data_validate = getData(Files[0],['lfp','speed'],period ='Pre', mice=mValidate)\n",
    "data_test = getData(Files[0],['lfp','speed'],period ='Pre', mice=mTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5d1f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepData(segN,overlap,df):\n",
    "    df2 = df\n",
    "    df2['start'] = pd.Series([[]] * len(df2), index=df2.index)\n",
    "    df2['end'] = pd.Series([[]] * len(df2), index=df2.index)\n",
    "    for l in df.length.unique():\n",
    "        a = np.asarray([[i,i + segN] for i in range(0, l-(segN-overlap),int(segN-overlap))])\n",
    "        df2.loc[df2.length==l,'start'] = pd.Series([a[:,0]] * len(df2), index=df2.index)\n",
    "        df2.loc[df2.length==l,'end'] =  pd.Series([a[:,1]] * len(df2), index=df2.index)\n",
    "    lst_col = 'start'\n",
    "\n",
    "    lst_col = 'start'\n",
    "    lst_col2 = 'end'\n",
    "    df3 = pd.DataFrame({\n",
    "        col:np.repeat(df2[col].values, df2['start'].str.len())\n",
    "        for col in df2.columns.difference(['start','end'])\n",
    "    }).assign(**{'start':np.concatenate(df2['start'].values)}).assign(**{'end':np.concatenate(df2['end'].values)})[df2.columns.tolist()]\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e69ab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1231, 1253, 8815, 1208, 2981, 1222, 2976, 7909, 4539, 1793, 8803, 7584, 2980, 8430] [1236, 761]\n"
     ]
    }
   ],
   "source": [
    "miceList = getMiceList(Files[0])\n",
    "miceList.remove('1253')\n",
    "miceList.remove('1231')\n",
    "mOrder = np.random.permutation(len(miceList))\n",
    "\n",
    "mTrain = [1231, 1253]\n",
    "mTest =[int(miceList[i]) for i in mOrder[:2]]\n",
    "mTrain = mTrain+ [int(miceList[i]) for i in mOrder[2:]]\n",
    "\n",
    "print(mTrain,mTest)\n",
    "# print(miceList[mOrder[:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4b46370",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('availableData2.csv')  \n",
    "# try 30s with 20s overlab\n",
    "dtL = 0.0032768\n",
    "segN = int(np.ceil(15/dtL))\n",
    "overlap = int(np.ceil(3/dtL))\n",
    "dataSamples = prepData(segN,overlap,df)\n",
    "\n",
    "df = prepData(segN,overlap,df)\n",
    "testData = df[df.Mouse.isin(mTest)]\n",
    "trainData = df[df.Mouse.isin(mTrain)]\n",
    "validate = trainData.sample(frac=.1)\n",
    "trainData = trainData.drop(validate.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86256562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrain(data,sampleSize):\n",
    "    f = h5py.File('E:\\\\rawLFPData2.hdf5','r')\n",
    "    data['Period'] = data.Period.apply(lambda x: 'Healthy' if x=='Healthy' else  'sick' )\n",
    "    # sampleSize = batchSize/3\n",
    "    while True: \n",
    "        batch = data.groupby('Period').apply(lambda x: x.sample(sampleSize))\n",
    "        batch = batch.sample(frac=1)\n",
    "        labels = batch.Period.apply(lambda x: [1,0] if x=='Healthy' else  [0,1]  )\n",
    "        labels = np.stack(labels.values)\n",
    "        dataPoint = batch.apply(lambda row: f[row.Session][:,row.start:row.end].T, axis=1).values\n",
    "        try:\n",
    "            dataPoint = np.stack(dataPoint)\n",
    "        except:\n",
    "            continue\n",
    "        yield (dataPoint,labels)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08148584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTest(data):\n",
    "    f = h5py.File('E:\\\\rawLFPData2.hdf5','r')\n",
    "    # sampleSize = batchSize/3 \n",
    "    for i, g in data.groupby(np.arange(len(data)) // 9):\n",
    "        batch = g\n",
    "        labels = batch.Period.apply(lambda x: [1,0] if x=='Healthy' else  [0,1] )\n",
    "        labels = np.stack(labels.values)\n",
    "        dataPoint = batch.apply(lambda row: f[row.Session][:,row.start:row.end].T, axis=1).values\n",
    "        try:\n",
    "            dataPoint = np.stack(dataPoint)\n",
    "        except:\n",
    "            continue\n",
    "        yield (dataPoint,labels)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b492a969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78273906 0.28923555]\n",
      "[0.76908022 0.14689967]\n"
     ]
    }
   ],
   "source": [
    "for ind,(dataP,label) in enumerate(loadTest(testData)):\n",
    "    print(np.max(dataP[3,:,:],axis=0))\n",
    "    if ind == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b253be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2) (6, 4578, 2)\n",
      "(6, 2) (6, 4578, 2)\n",
      "(6, 2) (6, 4578, 2)\n",
      "(6, 2) (6, 4578, 2)\n"
     ]
    }
   ],
   "source": [
    "for ind,(dataP,label) in enumerate(loadTrain(trainData,3)):\n",
    "    print(label.shape,dataP.shape)\n",
    "    if ind == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2de8fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  tf.keras.models.load_model('E:\\\\rawLFP_v5n_tunning_binary')\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "# model.load_weights(\"E:\\\\rawLFP_v5n_tunning_binary_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d14483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 64\n",
    "sampleSize = batchSize//2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fb8411a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4526, 16)          1712      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2263, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2263, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2253, 4)           708       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1126, 4)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1126, 4)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1096, 64)          8000      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 548, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 548, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 548, 64)           110656    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 274, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 274, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 274, 16)           25616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 137, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 137, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 137, 64)           3136      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 68, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 68, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4352)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                43530     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 193,380\n",
      "Trainable params: 193,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4551229",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,\n",
    "    patience=50,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50b307a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "126/126 [==============================] - 6s 38ms/step - loss: 0.6155 - accuracy: 0.6487 - val_loss: 0.6287 - val_accuracy: 0.6150: 0.613\n",
      "Epoch 2/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6181 - accuracy: 0.6391 - val_loss: 0.6398 - val_accuracy: 0.5949\n",
      "Epoch 3/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6150 - accuracy: 0.6365 - val_loss: 0.6656 - val_accuracy: 0.5681\n",
      "Epoch 4/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6128 - accuracy: 0.6420 - val_loss: 0.6644 - val_accuracy: 0.5424\n",
      "Epoch 5/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6122 - accuracy: 0.6424 - val_loss: 0.5998 - val_accuracy: 0.6674\n",
      "Epoch 6/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6191 - accuracy: 0.6317 - val_loss: 0.6833 - val_accuracy: 0.5547\n",
      "Epoch 7/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6048 - accuracy: 0.6481 - val_loss: 0.6470 - val_accuracy: 0.5725\n",
      "Epoch 8/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6054 - accuracy: 0.6500 - val_loss: 0.6989 - val_accuracy: 0.5759\n",
      "Epoch 9/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6039 - accuracy: 0.6479 - val_loss: 0.6247 - val_accuracy: 0.6083\n",
      "Epoch 10/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6060 - accuracy: 0.6549 - val_loss: 0.6341 - val_accuracy: 0.5859\n",
      "Epoch 11/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6044 - accuracy: 0.6517 - val_loss: 0.6734 - val_accuracy: 0.5212\n",
      "Epoch 12/1200\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.6086 - accuracy: 0.6513 - val_loss: 0.6839 - val_accuracy: 0.5592\n",
      "Epoch 13/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5984 - accuracy: 0.6591 - val_loss: 0.6636 - val_accuracy: 0.5804\n",
      "Epoch 14/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6048 - accuracy: 0.6560 - val_loss: 0.6570 - val_accuracy: 0.6272\n",
      "Epoch 15/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5978 - accuracy: 0.6551 - val_loss: 0.6478 - val_accuracy: 0.5625\n",
      "Epoch 16/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6061 - accuracy: 0.6514 - val_loss: 0.6224 - val_accuracy: 0.5938\n",
      "Epoch 17/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.6100 - accuracy: 0.6489 - val_loss: 0.6437 - val_accuracy: 0.5312\n",
      "Epoch 18/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5949 - accuracy: 0.6688 - val_loss: 0.6316 - val_accuracy: 0.6797 0s -\n",
      "Epoch 19/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5873 - accuracy: 0.6654 - val_loss: 0.7285 - val_accuracy: 0.5413\n",
      "Epoch 20/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5957 - accuracy: 0.6741 - val_loss: 0.5989 - val_accuracy: 0.6685\n",
      "Epoch 21/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5964 - accuracy: 0.6577 - val_loss: 0.5700 - val_accuracy: 0.7087\n",
      "Epoch 22/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5907 - accuracy: 0.6731 - val_loss: 0.6811 - val_accuracy: 0.5491\n",
      "Epoch 23/1200\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.5954 - accuracy: 0.6603 - val_loss: 0.6520 - val_accuracy: 0.5480\n",
      "Epoch 24/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5885 - accuracy: 0.6700 - val_loss: 0.5965 - val_accuracy: 0.6373\n",
      "Epoch 25/1200\n",
      "126/126 [==============================] - 5s 40ms/step - loss: 0.5838 - accuracy: 0.6703 - val_loss: 0.5738 - val_accuracy: 0.6708\n",
      "Epoch 26/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5870 - accuracy: 0.6696 - val_loss: 0.6590 - val_accuracy: 0.5949\n",
      "Epoch 27/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5839 - accuracy: 0.6739 - val_loss: 0.5869 - val_accuracy: 0.6842\n",
      "Epoch 28/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5816 - accuracy: 0.6762 - val_loss: 0.6134 - val_accuracy: 0.6429\n",
      "Epoch 29/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5815 - accuracy: 0.6762 - val_loss: 0.5592 - val_accuracy: 0.7422\n",
      "Epoch 30/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5745 - accuracy: 0.6820 - val_loss: 0.5710 - val_accuracy: 0.6775\n",
      "Epoch 31/1200\n",
      "126/126 [==============================] - 5s 36ms/step - loss: 0.5762 - accuracy: 0.6724 - val_loss: 0.5760 - val_accuracy: 0.6975\n",
      "Epoch 32/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5789 - accuracy: 0.6856 - val_loss: 0.6086 - val_accuracy: 0.6473\n",
      "Epoch 33/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5629 - accuracy: 0.6928 - val_loss: 0.5835 - val_accuracy: 0.6719\n",
      "Epoch 34/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5654 - accuracy: 0.6925 - val_loss: 0.5909 - val_accuracy: 0.6763\n",
      "Epoch 35/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5691 - accuracy: 0.6811 - val_loss: 0.6228 - val_accuracy: 0.6618\n",
      "Epoch 36/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5605 - accuracy: 0.6923 - val_loss: 0.5950 - val_accuracy: 0.6228\n",
      "Epoch 37/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5772 - accuracy: 0.6730 - val_loss: 0.6031 - val_accuracy: 0.6384\n",
      "Epoch 38/1200\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.5683 - accuracy: 0.6913 - val_loss: 0.5342 - val_accuracy: 0.7522\n",
      "Epoch 39/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5609 - accuracy: 0.6881 - val_loss: 0.5680 - val_accuracy: 0.6786\n",
      "Epoch 40/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5599 - accuracy: 0.6911 - val_loss: 0.5948 - val_accuracy: 0.6562\n",
      "Epoch 41/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5447 - accuracy: 0.7034 - val_loss: 0.5632 - val_accuracy: 0.6964s - loss: 0.5\n",
      "Epoch 42/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5515 - accuracy: 0.6975 - val_loss: 0.5761 - val_accuracy: 0.6842\n",
      "Epoch 43/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5538 - accuracy: 0.6963 - val_loss: 0.5654 - val_accuracy: 0.6797\n",
      "Epoch 44/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5508 - accuracy: 0.7026 - val_loss: 0.6031 - val_accuracy: 0.6752\n",
      "Epoch 45/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5540 - accuracy: 0.6959 - val_loss: 0.5692 - val_accuracy: 0.6998\n",
      "Epoch 46/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5468 - accuracy: 0.6974 - val_loss: 0.5395 - val_accuracy: 0.6886\n",
      "Epoch 47/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5473 - accuracy: 0.7025 - val_loss: 0.5637 - val_accuracy: 0.7210\n",
      "Epoch 48/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5399 - accuracy: 0.7085 - val_loss: 0.6081 - val_accuracy: 0.6819\n",
      "Epoch 49/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5411 - accuracy: 0.7106 - val_loss: 0.6077 - val_accuracy: 0.6406\n",
      "Epoch 50/1200\n",
      "126/126 [==============================] - 5s 39ms/step - loss: 0.5371 - accuracy: 0.7080 - val_loss: 0.6029 - val_accuracy: 0.6696\n",
      "Epoch 51/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5290 - accuracy: 0.7137 - val_loss: 0.5343 - val_accuracy: 0.7031\n",
      "Epoch 52/1200\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.5430 - accuracy: 0.7063 - val_loss: 0.5309 - val_accuracy: 0.7076\n",
      "Epoch 53/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5402 - accuracy: 0.7093 - val_loss: 0.5402 - val_accuracy: 0.7065\n",
      "Epoch 54/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5306 - accuracy: 0.7154 - val_loss: 0.6205 - val_accuracy: 0.6283\n",
      "Epoch 55/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5296 - accuracy: 0.7092 - val_loss: 0.5485 - val_accuracy: 0.6998\n",
      "Epoch 56/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5330 - accuracy: 0.7039 - val_loss: 0.5983 - val_accuracy: 0.6473\n",
      "Epoch 57/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5308 - accuracy: 0.7135 - val_loss: 0.5573 - val_accuracy: 0.6931\n",
      "Epoch 58/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5406 - accuracy: 0.7041 - val_loss: 0.5850 - val_accuracy: 0.6562\n",
      "Epoch 59/1200\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.5147 - accuracy: 0.7233 - val_loss: 0.5442 - val_accuracy: 0.6864\n",
      "Epoch 60/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5315 - accuracy: 0.7075 - val_loss: 0.6439 - val_accuracy: 0.6083\n",
      "Epoch 61/1200\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.5234 - accuracy: 0.7199 - val_loss: 0.5102 - val_accuracy: 0.7277\n",
      "Epoch 62/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5174 - accuracy: 0.7206 - val_loss: 0.5726 - val_accuracy: 0.6797\n",
      "Epoch 63/1200\n",
      "126/126 [==============================] - 5s 36ms/step - loss: 0.5144 - accuracy: 0.7290 - val_loss: 0.5316 - val_accuracy: 0.7042\n",
      "Epoch 64/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5142 - accuracy: 0.7274 - val_loss: 0.5782 - val_accuracy: 0.6875\n",
      "Epoch 65/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5076 - accuracy: 0.7283 - val_loss: 0.5074 - val_accuracy: 0.7221\n",
      "Epoch 66/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5123 - accuracy: 0.7272 - val_loss: 0.5710 - val_accuracy: 0.6842\n",
      "Epoch 67/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5005 - accuracy: 0.7303 - val_loss: 0.5133 - val_accuracy: 0.7143\n",
      "Epoch 68/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5296 - accuracy: 0.7168 - val_loss: 0.5068 - val_accuracy: 0.71435318 - accuracy: 0. - ETA: 0s - loss: 0.5300 - accuracy: 0.\n",
      "Epoch 69/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5059 - accuracy: 0.7264 - val_loss: 0.6271 - val_accuracy: 0.6484\n",
      "Epoch 70/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4973 - accuracy: 0.7336 - val_loss: 0.5314 - val_accuracy: 0.7109\n",
      "Epoch 71/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5008 - accuracy: 0.7289 - val_loss: 0.5612 - val_accuracy: 0.6518\n",
      "Epoch 72/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4924 - accuracy: 0.7439 - val_loss: 0.4911 - val_accuracy: 0.7388\n",
      "Epoch 73/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5119 - accuracy: 0.7216 - val_loss: 0.5597 - val_accuracy: 0.6763\n",
      "Epoch 74/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4984 - accuracy: 0.7378 - val_loss: 0.5689 - val_accuracy: 0.6920\n",
      "Epoch 75/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4957 - accuracy: 0.7289 - val_loss: 0.4966 - val_accuracy: 0.7221\n",
      "Epoch 76/1200\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.4963 - accuracy: 0.7369 - val_loss: 0.5691 - val_accuracy: 0.6663\n",
      "Epoch 77/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5028 - accuracy: 0.7289 - val_loss: 0.5183 - val_accuracy: 0.6987\n",
      "Epoch 78/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4837 - accuracy: 0.7393 - val_loss: 0.5886 - val_accuracy: 0.6484\n",
      "Epoch 79/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.5022 - accuracy: 0.7287 - val_loss: 0.5054 - val_accuracy: 0.7522\n",
      "Epoch 80/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4893 - accuracy: 0.7325 - val_loss: 0.4953 - val_accuracy: 0.7065\n",
      "Epoch 81/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4802 - accuracy: 0.7464 - val_loss: 0.5453 - val_accuracy: 0.6931\n",
      "Epoch 82/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4967 - accuracy: 0.7338 - val_loss: 0.5573 - val_accuracy: 0.6629\n",
      "Epoch 83/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4960 - accuracy: 0.7366 - val_loss: 0.5309 - val_accuracy: 0.6853\n",
      "Epoch 84/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4879 - accuracy: 0.7346 - val_loss: 0.5125 - val_accuracy: 0.6920\n",
      "Epoch 85/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4871 - accuracy: 0.7398 - val_loss: 0.5258 - val_accuracy: 0.7109\n",
      "Epoch 86/1200\n",
      "126/126 [==============================] - 5s 36ms/step - loss: 0.4774 - accuracy: 0.7436 - val_loss: 0.4926 - val_accuracy: 0.7344\n",
      "Epoch 87/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4841 - accuracy: 0.7392 - val_loss: 0.5659 - val_accuracy: 0.6786\n",
      "Epoch 88/1200\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.4781 - accuracy: 0.7476 - val_loss: 0.5308 - val_accuracy: 0.6998\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00088: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelName = 'rawLFP_v5n_retesting'\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "stepTrain=len(trainData)//batchSize\n",
    "stepValidate=len(validate)//batchSize\n",
    "\n",
    "history = model.fit(loadTrain(trainData,sampleSize),\n",
    "                    steps_per_epoch=stepTrain,\n",
    "                    validation_data=loadTrain(validate,sampleSize),\n",
    "                    validation_steps=stepValidate,\n",
    "                    epochs=1200,callbacks=[early_stopping])#,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "a928aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e68cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'rawLFP_v5n_tunning_2nd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "b8471574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:\\rawLFP_v5n_tunning_binary\\assets\n"
     ]
    }
   ],
   "source": [
    "## Saving the model\n",
    "##\n",
    "model.save('E:\\\\'+modelName)\n",
    "model.save_weights('E:\\\\'+modelName+'_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b370f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])# history.history\n",
    "plt.savefig(\"E:\\\\NN\\\\\"+modelName+\"_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "910c795e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABeSElEQVR4nO29d3wcV7n//z676r3blmVL7jXuqU5zegipJKTAjxIgBEio4UIuF760SyeQACEXQkJPCCGEkB4SpzjFPe5Nlptsy2pW79L5/XHm7M7Ozu7Oyir2+rxfL79WOzuze3YsfeaZz3nO8wgpJQaDwWBIXHyjPQCDwWAwDC9G6A0GgyHBMUJvMBgMCY4ReoPBYEhwjNAbDAZDgpM02gNwo6ioSFZUVIz2MAwGg+GEYe3atfVSymK3145Loa+oqGDNmjWjPQyDwWA4YRBC7Iv0mrFuDAaDIcExQm8wGAwJjhF6g8FgSHCM0BsMBkOCY4TeYDAYEhwj9AaDwZDgGKE3GAyGBMcIfaKw/VloPjjaozAYDMchRugTgYEB+NsHYe3Doz0Sg8FwHGKEPhHo7QDZDz3toz0Sg8FwHGKEPhHQAt/bObrjMBgMxyVG6BOBXkvo+7pGdxwGg+G4xAh9ItBjhN5gMETGCH0iELBujNAbDIZwjNAnAoGI3nj0BoMhHCP0iYCJ6A0GQxSM0CcCJqI3GAxRMEKfCPS0qce+7tEdh8FgOC4xQp8I9HZYjyaiNxgM4RihTwRMeqXBYIiCEfpEwEzGGgyGKBihTwQCHr0ReoPBEI4R+kSgx/Lo+7tVJUuDwWCwYYQ+EbBXrTRRvcFgcGCEPhHQ1g0YoTcYDGEYoU8E7BG9SbE0GAwOjNAnAjqPHkxEbzAYwjBCnwj0tEFyhvrZCL3BYHDgSeiFEJcJIXYIISqFEF91ef3LQoh3rX+bhRD9QogCL8cahoCedsgoVD+bXHqDweAgptALIfzAr4DLgdnAzUKI2fZ9pJQ/llIukFIuAO4GXpNSNno51jAE9LRDRoH62RQ2MxgMDrxE9KcBlVLKKillD/AocHWU/W8GHhnkscc3A/3Q0TjaowhloF/ZNRlF6rmxbgwGgwMvQj8eOGB7Xm1tC0MIkQFcBvxjEMfeJoRYI4RYU1dX52FYo8C6P8J9C6CvZ7RHEkRn3GRaQm+sG4PB4MCL0AuXbTLCvlcCb0opddjr+Vgp5W+klEuklEuKi4s9DGsUqN8FXc3Q1TTaIwmihV579CaiNxgMDrwIfTUwwfa8DDgUYd+bCNo28R57/NNu3Wl0tYzuOOzo1Ert0Zs8eoPB4MCL0K8GpgkhJgkhUlBi/pRzJyFELnAe8K94jz1h6KhXj13NozsOO3pVrPHoDQZDBJJi7SCl7BNC3AG8APiBh6SUW4QQt1uvP2Dtei3wopSyPdaxQ/0lRgwd0XcfT0Lv8OiN0BsMBgcxhR5ASvks8Kxj2wOO578Hfu/l2BOWdh3RH0fWjdOjN5OxBoPBgVkZ6xUpbR79cRjRp+WB8Js8eoPBEIYReq90NcFAn/q5+ziM6FMyISnNRPQGgyEMI/Re0bYNHJ/WTUomJKcZj95gMIRhhN4r7bZFXMeVdWNl3aRkQlK6EXqDwRCGEXqv2IX+eLJuejtA+JRtk5xm8ugNBkMYRui9ooU+oyh+66a7FfavHPoxgbJuUrJACCX2JqI3GAwOjNA7qfwPPHwF9PeFbtcefcHk+K2bl74BD18+PAXR7LXojdAbDAYXjNA72b8S9q2AloOh29vrIL1AlRqIZ8FU51HY8CjIfji4dmjHClZEn6l+Tk6PnXUjJfR1D/04DAbDcYsReid6crP5QOj29nq1+jQ1Jz7r5t2/BuvRVK8emjHa6ekICn1SWuw8+nV/hJ/Nhf7eoR+LwWA4LjFC70RPtDbtD93eXg+ZxZCW6926GRiAVb+FCWfAmFOGSejblEcP1mRsjIj+6B5or4Wje4d+LAaD4bjECL2Tbiuib3JG9HUqok/LUZOrMlKlZhuVLylhPf02mHAqVK9V4j+U9LRDit2jjxHR66yc+l1DOw6DwXDcYoTeSXeremx2RvR1KqJPzVF+e097+LFOVv4fZI2FWVdB2anK26/fObTjtXv0SWmx/XdtIzUYoTcYThaM0DvRQm+3bvr7oLMxaN1AbPumvhJ2vwxLbgV/shJ6GHr7prfDZt2kx86j77GE3kT0BsNJgxF6Jz0u1k1Hg3rU1g3EXjS1+rfgS4bFH1HPC6aowmNDLfTxplfqC0FD5dCOw2AwHLcYoXeiI/qWg0E/XS+WyiyGVB3RRxF6KeHdR2D21ZA9Rm3z+aBsCVSvGdrxOtMr+7qizx9o62aoLSSDwXDcYoTeSXcr+FOhvwfajqhtdqH3Yt10NCg/vmxJ6PayU6F2a/Bicqz096pxausmKVU9RvPpdUTf0TA8C7gMBsNxhxF6O1IqES6erp5rn16vis0s9mbdNFerx5zxodvLlgASDq4bmvHaK1eCKmoG0TNvetvBn6J+NvaNwXBSYITeTm+nyqgpmaOe60VTgTo3hSrrBqJH9HpVba5D6McvVo9D5dMHhN7y6JPT1GO0XPreTiiZpX42E7IGw0mBEXo7eiJWC2Egoq8DX5KaTPVi3TRbQp9TFro9PR+Kpg+dTx8Qem3deInoO6F4lpooNimWBsNJgRF6O9o7zx6nRNku9BlFakI1OV2JfjTrpqVaCWlmcfhrZaeqiN7LgqtY9DqtG8ujjxrRdyj7qWCSiegNhpMET83BT3ikhD9dqyLgSeeqfxNOU6JtRwt9ajbkTQxaNx0NQdEWIna9m+aDkFOqLgxOypbAu39RJQgKJh3b93J69Pr7REux7OlQ+xVNNx69wXCScHJE9O11ULVcTZKu+Bn88Sq4d0F4Ya+A0GdB7oRgLr0uf6CJVe+m5RDklrm/Flg4NQT2jRb6ZNvKWIgs9AP90N+t8u4Lp0LD7vByzAaDIeE4OYS+dqt6vPYB+MpeOPMOaKtRJYTtuEX0UgbLH2jScmJbN86MG03xLFXuePWDSniPBXsbQQhG9JFWx+rtyelQNA0GeqFp37GNwWAwHPecJEK/TT2WzFYiXbpQPXcKfUA4LaHv7VC2ja5cqYlm3QwMQMthZd244U+CS78HB96BlQ8M/jtBsJxBiseIPiD0GVA4Tf1s7BuDIeE5SYR+q5pMzbLEOj1fPXY2he6no/TUbGXdgFpB2tPm3bppr1WRciTrBmD+TTD9cnj528c2IRqWRx9L6LXVk6EiejATsgbDScBJIvTbgimTAOl56jHMurEi+tRsyLOEXi9uCrFuciNbN4HUygjWDagJ3SvvVRbKk58avIUTZt3EyKO3WzcZBcpC8ppiue8teOqzQ5MtZDAYRpTEF/qBAUvoZwe3BSJ6F49eWCmUeRPVNt3+z6t102KtinUulnKSPQbe8xOVavnWL7x9Fyc97SrVU690jZVHr+vc6CJoRdNUlU0v7HwB1v0hdnVMg8Fw3JH4Qt98QEW+IRG9JfRdTaH7dreqaF4ItTgqJRsO6YjeYd30tLpH4pEWS7kx930w60pY/j2VqRMvvVYbQSHUc68RvV5JWzjNe3EzffcQb2N0g8Ew6iS+0NsnYjWpuYBwn4zVJQ6EUPaNbrkXIvRR6t20HFReeUZB7LEJAZd8Fwb6BhfV29sIgs2jjxB19zgj+qlqTsGLeHcboTcYTlROAqG3UitLZga3+XwqKg+zblpChVPbNxBu3YC7fdNspVbqKDsW+RUw70ZY8zC01Xk7RtPTHhRtsCwcEbl6ZcC6sSwenXnjxb7Rqaex6vAbDIbjDk9CL4S4TAixQwhRKYT4aoR9zhdCvCuE2CKEeM22fa8QYpP12hAXY/dA7TZlo+gaNZr0PJesmzZl3Wh05k1yRnDCE6LXu2k5GNufd3LOF1WmzDv3x3ecvRY9qItLtC5T9slYCGbeeJmQ7bGE3kT0BsMJR0yhF0L4gV8BlwOzgZuFELMd++QB9wNXSSnnADc43maZlHKBlNJRoH0EcGbcaNLz3SdjU+0RvSX0dtsGols3zQe9+fN2iqbBnGth1W/DxxSNno7QOxCI3mUqENFbF4f8SYCAxqrYn2WsG4PhhMVLRH8aUCmlrJJS9gCPAlc79rkFeEJKuR9ASlk7tMMcJP19UL/DXejT8iJPxmq0deMsThbJuunvUytu443oAc75koqaV/7G+zE9bcGJVU1yepTJWId1k5Si5hLaPVhG2rpxnjODwXDc40XoxwO2BqpUW9vsTAfyhRCvCiHWCiE+ZHtNAi9a22+L9CFCiNuEEGuEEGvq6uL0qiPRWKU6MJXMDn/NLaLvcVo3EYReWzfOiL6tBuRA9Bz6SIydCzPeo+wbrx2onNYNqAqWMVfG2oq5ZRQGe+JG/Swd0RuP3mA40fAi9G6zis5VM0nAYuAK4FLg60IIq00TS6WUi1DWz2eEEOe6fYiU8jdSyiVSyiXFxS7lfQdDYCI2DusmxR7RR7JuInj0OrUy2qrYaJxzl4qY1//F2/6uQp8e3brxJYM/ObgtowjaPQi9sW4MhhMWL0JfDUywPS8DnEnf1cDzUsp2KWU98DowH0BKech6rAX+ibKCRobabWoBVPGM8Nf0ZKxe6anbCNoj+sxiVZu+aHrosZGsG71YajARPUDZYmUXHVjpbf/e9nCPPjkt+mSs0+rJKIgd0Q8MmMlYg+EExovQrwamCSEmCSFSgJuApxz7/As4RwiRJITIAE4HtgkhMoUQ2QBCiEzgEmDz0A0/BrVboWByeN15UBG97A/aJD3tgAydjBUCPrMKzvhM6LFJKSpy7o4U0Q9S6EG1MdR3ItGQMjy9EqJH9G77ZxZBR330z9I1csAIvcFwAhJT6KWUfcAdwAvANuAxKeUWIcTtQojbrX22Ac8DG4FVwINSys3AGGCFEGKDtf0ZKeXzw/NVXIiUcQNqMhaCk4v2EsUh++WoipNhx+eEi17LQWX9OFM542HMbFVozC0X/j/fhP3vqJ/7e9RCK6d1kxwt66Yz/KKXUQgdjSpqj4S2bcDk0Sci25+Ff90x2qMwDCOeOkxJKZ8FnnVse8Dx/MfAjx3bqrAsnBGntwsad8Pc69xft9e7yZsYnGzUtkws3OrdNFdHLk/slZLZ6k6jfieMPSW4veWwappycC18+N/h/WI1SWnRSyA4I/qMIvV5XU2RV/PaJ4dNRJ947H4FNj4GV/9ytEdiGCYSd2Vs/Q6VARMponcWNtORqlM4I+FWwXIwi6WcjJmjHo847Btdc2fPG6rzlbNEsSYpLXpRszChL1SPHY2Rx6T9+aR0I/SJSE+76jwW7a7OcEKTuELvVuPGTqBUcZN6tJco9oKbddN8cPATsZrCqSozpnZL6PaD69TEMhI2PWYTemcefayI3mHdZGqhj+LT63OTO94IfSKi52D6I5TOMJzwJK7Q73hWRe0FU9xfD4vobf1iveC0bvq6VYGwwaZWavzJKstHX6g0B9eqaH/iWfDuI1Gsm/QoEb3LZGwgoo+SeaPPTY4R+oREF7szJagTlsQU+rZa2P4MLPiA+0QqeJ+MjYTTutFlho81ogc1IWu3bqRU1k3pIlhws6pNs/d19ZrrgqlIRc3cJmOtNQLtUSJ6PX+RW6YmeiO9v+HERAcN5v81YUlMoV//Z5WRsujDkfdJTgd/ajCij3cy1mndaKE/Vo8elN3UUh20lRqr1GeNXwyzr1Y+/JqH1GthWTdWUTO3TlCuefRxRvRgVscmGtq6iXQnaDjhSTyhHxhQnZDKz4bi6ZH3EyJ0dWy8k7GpuVZ026Oet8TRcCQWekJW2ze6neH4RepOYuYV0LRfbUt2mYxFqvRLJ26TsSkZapsXodcXMWPfJBYmok94Ek/oq5arZiFLPhp7X3up4u42NQmalOrtc5z1bo5sBsTQRfQQnJA9uFZ578VWBtH8m4P7ukX04O639nS4Lx6LVe+mpw2EH7LGqudG6BML49EnPIkn9Gt/r5pez7oy9r4hEb1VothrwxBdqrirWVkZa3+vIm2n8A6G3DJ1x6B9+kProHRBcL5h8jLILFE/u6VXQnh0NtCvsiqcET0ooY/m0Xe3qXMTuLgZoU8oTESf8CSW0LceUdk2C27xFpnbSxU769zEItUm9Gt/rx7P+WKcA46AECr/v3Yr9PfC4Q1qIlbjT1KTss6GKBC5nWCgcqWL0GcWxbZu7Ct+TUSfWBiPPuFJLKFf/yc1CbvYg20DVkTfpH6294v1gha99np4+1cw6Tw1WTpUjJmthL52q5oLGL8o9PVlX4NPvh5aiRIiNwh3K1GsySiMnkffY10EjdAnHn1WKQ0wEX0CkzhCrydhK85RTa+94JyM9ToRC0HrZuUDqg79UEXzmpLZSlC3P6OeO4U+KTXYCjBkuyXkYRG9FbW5WjdF0VfGBqwb212MITHosdUxMh59wpI4Qt/XqVIPz/i092PS89Qven/v4K2b3S8rW2XSeXENNyZ6Qnb9X9QFKX+St+MGFdEXqPMQaUVtd6u6CKZkqdW5Jr0ycdBdx2B0Inop4dUfQuOekf/sk4jEEfqUTLjkuzDzPd6PCayObQpGrV6xV6g854veJ3G9MsYS+pZqZQl5ff+AR+8UeusP2m2yWDdWieTT685bQqjvbSL6xKHHVoJ6NDz6jgZ49XuwzVn53DCUJI7QDwa9Orbz6CAiemvfohkw44ohHxrp+ZBtVcIsXRR9XzsRhT6GRw+RffpuW4tFI/SJRYjQj0JEr38v7eMwDDmeyhQnLDqi72qKfzLW54ez7oSpF4NvmK6XY2ZD66H4Jnkj5dHrXOlIHj1Ejui1dQOjJ/TN1arjl9d1DgZv2AV2NDx6I/Qjwskd0Wuh72hQQh/PZCwoq2jyEHvzdvQKWedEbDRiWTfRInq33rFSBrNuQF0MR7r5SG8X/Op0NfFtGFpG26PXdpF9Utgw5JzkEX2eemy2er3GY92MBKd/Stk2WSXej9FCHtG6iZBHD+7WTW+nquufaovoG6u8j2coaNqnhODQ+pH93OORlsOqKc1QBRij7dEHIvqO6PsZjgkT0UOwbkxqFp09/WyqPk486JxxMOea+I7R1kZY1k0U6yYtT2XTuFk3zqqeaXkjb93oC0vdzpH93OORd+6HR24auvcLsW4iZF0NJ8a6GRESVujfqqznnpd20trVG3knnTnTfEA9pmZz1+MbuOb+NznSMgq/9ENBxDz6KNaNz6fKRriVQdC31CmjOBmrU+8aKlUph5OZzqPq/3KoRFn/XvhTIvcaHk56jXUzEiSc0Nc0d3HHX9dxy4Mrue/lXVxx3wrW7T/qvrPPr2rKNCmhX1fTxzMbD9M/IHlp65ERHPUQkpQKiCh59C4RPUQubOZsyJKWY6096BuS4XpCR/T93apg3cmMnh8ZqoutFtj0gtER+j4T0Y8ECSP0vf0DPPhGFRf+9FVe3HqEz180jb9+/HQGpOSGB97mvpd30dfv0hMzPS9g3TzwTi0zx2ZTXpjBiyeq0Avh3je2t0NFbZEasUSqdxNm3Tiqdo4EjVVq7KD86ZMZ/f8xZELfoSqTpuWOckRvhH44SRih7+4b4LdvVHHqpAJe+sK5fP6i6Zw1tYhnP3cOV84bxz0v7eSye9/gX+8epH/A1pQjPU+1AASqO5L40fXzuGzOWN7eXU9LNNvneCY5LTyDwq27lJ2MAnehD1g3tslYGFn7prEKKs5WP9ftGLnPPR4ZcqFvV4voovUaHk6M0I8ICSP0WalJ/PuOs3n4I6dSXhhc/ZmTlszPb1rIAx9cjF8IPvfou1x8z2v86e29rN7bSHdycIXre0+dzryyPC6ePYbefsmrO+pG46scO0lpLnn0Lv1i7WQUuXv0zqbpbkJf+TL8/aPuXa2Olf5eNYdSukiVZjYRvXocKqHvtYQ+Kc149AlMwgg9QElOGiJCqYDL5o7luc+dwwMfXERqsp+v/2sLNzzwNi/tCUa+H102D4CFE/MpykrhxS01IzLuIcftjzZmRF8InY2qOJwdbdHY8+ghVGi2PKH+aREaSpoPqOqKBZOgeIaJ6ANC3zQ079djdR0bLaHXn2ki+mHlpMqj9/kEl80dx6VzxrKnvp39jR2UvjEBqlcCkJ6lolW/T3DRrDE8vfEw3X39pCb5R3PYARrauslNTybJH+P6rPvG2untDG87aCezSOXLdzUpG0cTybqxe/S129VjR32wwuVQoSdiCyZD0XTY9Hd15zDUtYVOFLTQD9UcSU+7aieZlDZ0F4940L+n/d1qgj/SHJLhmEioiN4rQggmF2dx/owSpldMVBv9qZCUEtjnkjljaOvu4+3dURpyxIHrRHAcPLGumjO+/zL3vVIZe+ckN48+QhtBTaQm4d1tgAgWQ3NaN1IGo2y3lbXHik6tLJisIvruFmg9Qe+0jpWBgWGybrJG36PXYzEMCyel0IegV8c6VsWeNaWIjBT/MWff9PUPcNffN3DmD16hqcOlYXcMpJT88pVdfPGxDfQPSJ7bdDj2Qa7WjUehd/r0utibjqCdQt9crUokQPTmJW6s/QPcOz96bnzjHmUtZI1RET1A/Qli3+xfCX/7/+Dfn4fl34M1DwX7HwyGnjbAmgcZysnYUbVubEJv7Jthwwi9Xh3rEPq0ZD/nzyjmpa1HGBgY3CRjT98Adz6ynsfXVlPX2s2jqw/EdXxv/wB3P7GJn7y4k2sXjue/LpvJrto2DjTGWC6e7DIZ29sRYzI2QkTf0xpaAyg1BxBBoanbHnwtWt9ZN/a/rfLio5VUaKxStfiFUBE9QP2u+D5ntNj0mGocs+3f8NqP4OkvwB+uGnw9f/scyFCmVx4Pk7FghH4YMUKvSxW71KK/ZPZY6lq7+fvaA/xzfTX3vbyLn7ywg7X7jgbEX0rJ8u213PSbtznlmy/wxb+9y4pd9XT09PHJP63huc01/M8VszhzciF/fGuvq4XTG8HW+dlLO3l09QHuWDaVe94/n0vnjAXgle210b9TUrr7ZGxKFKGPVO/GWaff51MXRS1WtduCr8Ub0Wtb5siWKPtUqYlYgOxxaoXuiTIh21qjLk7/tRu+Xg83PaJaQz56y+BskmER+uMk6wZM5s0wYmY+AhF9+CTishklJPsFX/nHpsA2v0/wy+WVjMtN48JZJaza08jOI22My03jgpklvLTtCE+sP0hqko+e/gG+d+0p3HL6RMoLM/nEH9fwwpYjXDFvXOD97nlxB39ZuZ+n7jyb8XlBa6WmuYvfrdjDNQtKuetSFclOKspkUlEmr2yv5cNnVUT+TsmDzLoBF4/epU6/vQxC3XZlq3S1xB/RH7WEvnare02fgQEV8U+/VD0XAoqnnzjWTWuNOjegJhlnvgeu+TU88Qn4x8fghj/EN/kYIvRDNBnba1k3x4NHbyL6YcPTb5kQ4jLgXsAPPCil/IHLPucDPweSgXop5Xlejx1VtNC7lCjOzUjm0dvOoKWrjwn5GZTlp9PdN8B/th7h2U2HeWx1NZOKMrnn/fN577xSUpJ8dPX2859tR3huUw2XzR3LlfNV85ALZpZQXpjBQ2/uCQj9O1UN/GJ5JVLC//xzEw995NRAeui9L+9kQEq+dMmMkDEtm1HCn1fuo6Onj4yUCP99Senhf7Sx8uiT01VWjnNC1a18s13oa7dB8UwVeUeqZ+9GTzu0WfMfkSL61kMqG0NH9KAavex+Jfi8v1dZIos+BBNO8/758bB/Jex8Di76ZnzHtdYE5xU0896v+vM+/xX174qfen8/nWmTnDE81k1/98hnNPV1qUSI/m4j9MNITOtGCOEHfgVcDswGbhZCzHbskwfcD1wlpZwD3OD12FEnwmSsZnF5ActmlDC1JIu0ZD+56cm8b3EZv/vIqWz59qU8//lzuG5RGSlJ6lSmJft577xSfvWBRQGRB3Un8OEzK1i77ygbDjTR0tXLlx7bQHlBBl+8eDrLd9Tx741qonV3XRuPranmA6eXM6EgVJwvnFVCT98Ab1ZGEdWkVJcSCDEienCvd2PvLqXRQj8woGyUklnq2Hgi+qP71KM/NbLQ21MrNcXTVTN2LXTr/gjr/wQ7n/f+2fGy8VFY8bPg4jEvDAyocWaPCX/tjNthwQdgzcPxLTLTEX1u2dAI/UC/+j3RQg8jb9/0dgRtQ2PdDBtePPrTgEopZZWUsgd4FLjasc8twBNSyv0AUsraOI4dXSJMxnoh2e+LuEDLjRuWlJGVmsTDb+7hW09t5XBzJ/fcuIDPLJvK/LJcvvXUFo629/CTF3aQluTjjgumhr3HqRUFZKUmRffpkx0R/UC/ipii5dEDZBa6ePQu1k1qDnQ3q8VMve0qos8sis+j17bNlAuUPeMmom5CX2Td4dTtVGN79fvqeWeT98+OF92voGmf92M6G9VCr+xx7q8XzwTZH98iMx3RD5XQ2/sIj5rQd9mE3kT0w4UXoR8P2NNFqq1tdqYD+UKIV4UQa4UQH4rjWACEELcJIdYIIdbU1Y1g6YHkDCVc+pdtGMlOS+aGJWU8teEQ/1hXzR3LprJoYj5+n+D7182jqbOXT/5pLc9truET506mKCu8bV5Kko+zpxaxfHstMlI0qIua6dej9Yu14xbRO7NuIBjR64ybkllWCYU4rBs9ETvzCkCGZu/Y9/ElQ47tVyaQebMD3voFtNcNrZXhhhb6eCpntlppsNlj3V/Xd5LxjHuoI3otrNqjh5H36fs6g60sTfORYcOL0LuFrE6FSQIWA1cAlwJfF0JM93is2ijlb6SUS6SUS4qLiz0Ma4gQAj76HJz5mRH5uI+cVYEE5pXlcueF0wLbZ5fm8MlzJ7NqbyOFmSl8/JzJEd/jglkl1LR0sfVwhAm5tBy1ylVHgNFq0dtxirWU4Vk3EBR6nXEz2Ig+LRcqlqrnbvZNYxXkV6hy0pq8clXJcs/rSujnXKvEfzhXdQaEPo6IvtWaf8iKIPSB9QhN3t9TC31OmRLIPse6jLV/gAcv9v5+WuhHNaLvVL2AwVg3w4iXydhqYILteRlwyGWfeillO9AuhHgdmO/x2NFn7NwR+6jywkz+/skzmVSUSbKjlMFnL5zGziNtXLtwPFmpkf9rzp+h/jCWb69lTmlu+A4FUwA4sGsjm5hK08Fd3ALRJ2MhPKLv64aB3ggefYsS+uxxKjrNKFAXlJ6O6GmcmsY9Kj8+r0JZSrVb3fcpcFzw/ElQOBU2/k1F+xd+A57+4vBF9J1NwQvmUEb0Oq033og+JStoN3a3QJLtTvTAKqhe5X5xdsMu9P1WpdbREPq0HPV/aaybYcNLRL8amCaEmCSESAFuAp5y7PMv4BwhRJIQIgM4Hdjm8diTjiUVBRS62DJpyX4e/PCSkPRLN0qy05hXlhvRp3+5Xon/PY88w6f/so6HX1ORdzuhn9nV28/3nt3G2n2NakPueOW5t1nWmbO7VGCgOYCE6tUqmofg7bfXqP7oHpVN4/Mp68cZ0Utp5dC73NnoTJZTP65eT8v15tH3daueq/Ggo3mIU+itMg1ZLpOxEIzo45lb6G5RF91IpaKtctuBi0ws7O0lRzOiT05XFxsj9MNGTKGXUvYBdwAvoMT7MSnlFiHE7UKI2619tgHPAxuBVag0ys2Rjh2er3JycfGsMaw/0MSWQ6F/7O3dfXzt1Tb68fHJOf08fefZ/PQaZRE9+M7hwEKv3n61avc3r1dxx1/Xq5aLY1X1Tmo2qEdndymNFprG3UqkITjH4SXzpr9PNXvJt9Imx8xWQm+fc2ivUxcde2qlZuIZ6nb/3C+r5+l53iLjN++F+0+PrzuWFvrscfFNxrbVqMhbe99OAh59k/f31BPjkWyfNkvoWzzeNAci+qzR8egHBlSSQJIR+uHG08pYKeWzUsrpUsopUsr/tbY9IKV8wLbPj6WUs6WUc6WUP492rOHY+dBZFeRnpPCtp7aGTMo+/OYeatoH6M0pZ2byEeaOz2VeSTIA7xzo5Nev7aZ/QHLX3zfw0tYjfOjMcmpauvjh89th7CnqTQ47hd7FutHoydFARO9hQralOlh6GGDMXJWlovPqwT3jRnP67fCFLSpLSI+nqyl2quLBdeqC0FIdfT87up9wxdkqoveaDtlaEznjBgZn3XTFiuiti2zcQj9KEX2fLUkgJdN49MOIKYFwgpKbnsxdl8xg1d5Gnrby75s6evi/16u4aNYY0sbODNaEsbJulkwdz09f3MGtv1/Nv949xH9dNoNvXz2Xj541iT+/s59VNQMqytZC7yxRrAkR+kFE9DrjRkf0JdbSiiObbftEEXohrN64ejx50N8TW6R0Zk+02jpOmqvV5G/Zqer97RejaNhXxbqhawbFZd04I3rbZLyUQeum5aC39xtt60bfPRjrZtgxQn8Cc+OpE5hTmsP3nt1GR08fv35tN23dfXz50hlQNBUadqsceusP+lOXzGNKcRav7azjM8um8OnzVZ7+XZdOpyw/na/+YyP9Y+fZInpHdymNa0SvSyh4EHqdQx+I6OeoxyO2Cdm9K9QEXe4EYuLF7+7pCHrs8Qp9zvjgBcdr5k2siN7nU3Md8U7GRorou5rVxQ68e/T2C/moCL0tGywlywj9MGKE/gTG7xP8vyvncLi5i+88vZXfv7mXaxaMZ8bYbCicpvzPpv2BiD4jI4s/3Hoa9928kLtspRUyUpL4wXXzqKpvZ0X7eCWInUfDu0tpdF2g7NKg15yWq4TZa0TvT1XHg8rYyR4XzLw5uBbe/SucdltIj4CIeMlJb9hFILNX31F4ofmAylvPK1fPvUzIRlsVa0dbTl7pboXU3GBzF/v3bbetPfFs3egFU6OUR68vKtqjH4169F3N8V34T1CM0J/gnDapgCvnl/LIqgP0D0i+cJGVkaIzUxoqQ27RS/PSuWp+adiK3rOnFXHD4jJ+V2mJSM2mMOsmUHlT+8slM4NvIISVnukxos8vV1GtpmS2sm4GBuDZL6vJ1vO/6u0keMlJ112wkjPij+hzJ0Ce1aDGi9DHWhWrScsbnHWTkgXCFyr0eiI2Kd27dWNfMBWI6Dsj7z/UhET0o2TdvP5j+P2VI/+5I4wR+gTg7stnkp2WxIfPqmBioZXDXmQtxqrf5XnB1LeunoN//HwAdm98M2DdNPal8PE/rGbhd17i8bXVyNRsJTTaW9dkelwd27hXLYSyM2aOKmuw9mEV0V/yHe9tCdOsvPJoEX3ddvAlqUlVr0Lf36tskNwyFfF6zbzR1kk0jx68ZwuBtXitJdgExl5YDoL+/Ni53lNIe9vVhcHntwl9d/RjhpKAR582ekLfcljdfQ1HY/vjCCP0CUBpXjpvfvUC/ueKWcGNGYUqYqzfaSuBEH0hU0ZKEj+/9WJqRTFb177BoVolHu/59Tpe31nPxIIM7vr7Bj751420XPMHOOtOxxt4iOiltCJ6R9rkmDnKanrhv2HimTDvRg/f3MKLR1+3XS20Kp6hrBtnE3Q3Wg+rFca5Zep5foW3iF6vio0Z0cdh3ejuUtpGcwq9Xvswbr4Sfeeq2aP7YMdzjve0LW7TQu9sWDOc6LuHpFH06Lua1d3XSF7gRgEj9AlCTlpyqB0jhLJvtHXjT/FU+zw3PZncyYuZ59/HC+sqaZepZKan8uRnlvLUHWfztffM4tUddSx7Kp2/7+gNbaSSWRTbo+9oUKLlzI/Xdwf9PfCeH8dXKteLR1+3XYl8wWR1QWn14GPrHPq4hT7GqlhNWp73iN6Z6pqWG9ogvL1O3WWNmRs6Bs2Kn8FjHwq9wOmmIzBKEb1LeuVIR9b6/MdTXO4ExAh9IlM0LRjRx6pzYyN1wiImyoNUpLYykJzF03eew+zSHPw+wSfOnczTnz2bsoIMvvz4Ri75+ev8e8MhtRAroyh2Hr0ztVJTPENNNJ5+ezCf3yuxPPreTvW5xbOC2TNe7Bst9NqfzytXE52xxDDWqliN1xW9EC70qTnh1k1GIeRZWUpOoa/bri6i9knb3vZgRVOfT02Qj6hHbxP65Ax19zTSK3MDQj9EjVyOU4zQJzKFU1Xed2tN7Do3dsbNRyBZlr6b7Nx80lP8IS9PH5PNk58+iwc+uJgkn+DOR9Zz5g9e5g8bWqG7hVt+/RpvVUaI7J2plZqkVPjcu3DJINbU+ZOVYEWKjuutjBsd0YNHobcWS+nqmfkV6n2aYvT+jbUqVpOeZxUn8xBFa6HXFzU36yazJJjJ5JyQ1e0X7dvtET1YVU9HK6LPCo5pJDERveGER2fe1GyMW+gBJQounbcAhBBcNncsz33uXO69aQFnTC4kKbsEgLajR/jc396lubM3/MDGPYAIpivaySgIzcSJh2jRsb2ccs54ZWN5SbFsOqCiZO1j6wnkWPZNa03kqpUhY85Tj17sG2eqq9P2aa+FrGLI0UJvs6ba61UmkHO7swCdW1P54STEo7cuOCO9OlbfBSb4qlwj9ImMzrxprIpP6LPHqugQYjZk8fsEVy8Yz703LeQDFywC4KdXlNHQ1s2PnnepMX90D+SUMuBP5dFV+/nh89sj19WPh/S8yNaNzrgpmKIyTPIrvFs32p8HlRIK0LQ3+nGtNbH9eQgKvRf7xs2jd6ZXZpao7cmZoZk39mbqIUJvs27A6kwWR0Q/0H9sefdOjx5GtiZ9b1fQKjIRveGEJX8SCMt2icOjR4hgVB9P5y2r3s20rC5uXTqJv6zcz+q9jaH7NO6hPXMC1/36Lb76xCZ+/epuquqP7XZ97b6j9KVEWWVau12JvF58VTDZW0Svc+g1WWOVj+0lovci9PE0H+lyRvS5KgrVBdra69TaAyFUVG+3aOzN1O2T0L1O6yY9Po/+rfvggaXe93cSUgJhFKwbuy9vhN5wwpKUErQb4hF6CAp9BOvGlUC9mwa+cPF0xuelc/cTm+ju6wdg15FWWg/v4pnqNKqPdnD35WrB1Ws7Bt9RrKGtm/f/39tsb/JFj+h1qQawhL4qNMOjcQ9sejz4XMrgqliNz6cmZqMJfWBVrJeIPo7mI24RPSix6m5TmVVZVgOPnHGhkXvdTnVHlzshunUTb0R/ZItVZsNDqqobvR3qTsufPDrWjf0Ca4TecEKj7Rt75OaFQEQfh9DbatJnpibx3WvmUlnbxhcf28B197/Jn+77Gtl9DaSXL+blL53PJ8+bwqSiTF7fNXihf2t3A/0Dkp3NPnrbj4bv0Nul7KIS2xqD/ElW3X1bPf+XvwX/+JgSRVAi0NMWXmsnvyJ6vRuvq2JhcNaN7g1gL4OgM2m03ZYzPjTrpn6H+j3ILQu3buwX8uT0+Dz61hpADj5jpa9L3UWATehHMKK3n3cj9IYTGi30g43o47Fu0vNVLreVS79sZgnvnTeOZzYeZm7rCr6V/Ee6p17Glbd+jdx0VTr53GlFvFPVQFdvf3zjs3izsp6s1CTaRBZ97U3hOzTsUml7zogegj59TzvsfEH9vOYh9ejModfoXPpI8wpeV8VCfDXpu1uUn67XQtgLm2mhz9JCX6rGMWCd07qdqqm63dKR0kqvPIaIXl8oB9vdq7cj+Hs5GkJvInpDwlA4SKHPm6hWp065wPsxPh+kF4Ssjv3JDfNZflMm3+q9BzF+ManvfzikB+x5M4rp6h1gzV6XaDwGUkre2FXP0qmFVIwvJX2gjb21juhS17gptkX0OrVTC/2O55ToFE5TxdR62oOplWERfbkS3c4I4/W6Khbit27sF1270GvB1b1Xs8epu4r2OmXrtFRD8XRL6A8pke/rUhfAEOvGxaPf9xa89iP3MbXVBMcwGHq7gimoo2LdNAV/Nlk3hhOaQEQfR9YNqEm9634Dk8+P7zjH6ti01v1MevFWRPY4uOVvYf1kz5hcSIrfNyj7Zl9DBwebOjl7ahELZ1QA8ODLG0N3qtuuJqQLpwS35U1U27TQb35C5Z9feS90NyuvPlpED5Fr3gRWxXqI6JNSlbh6Sq+MIPTdLcE6N1k26waUqNdbVlTRDLW9r0tdpAKVK23WjVtEv+nv8Or3w7ty9XYFx+02/saq8JILTvo6R9e60eP2p5iI3nCCo3Pp4xX6weJcHfvq91XdlQ88Hpyste+eksSSinxe3xm/0K+wFmUtnVpEdq567zc2VbKvwSYWdduVyNsblfiTldg3VimftvIlmHMtlJ8FJXNg9YOqvLM/JRgla2Ll0gdWxXqYjAXvq2N1QTP7cWBF9Na503Mk9lx6LfTFM2zbDwYjWPvvhZtH39GoIn9nwxX7czehf+fX8Pit0b+TfcW2HsdoCH3OeLMy1nCCk1Go6rpPv3RkPi+zMBjRdzXD1qfglOtVI5QInDu9mO01rRxpcc/JXrvvKOf+aDl/Xbk/ZPublfWU5qYxqSgz4HcX+Dr45SuVwZ2cGTcanXmz/RlVGmDu+9RdzKm3qgVm259RAuBcwBWrLr3XVbGaaPn/dpwRfap9MrZWTezq9FF7RF+3w1pDMDl0u65omhIjj15bVM4a9/aJbDeh72hQnxEtL94u9D6/EvvBWijv/hX+ebv7ayt/Aw9fEb69q0mly2YWBZvsJChG6BMdIVSRsPKzRubzMoqCHv2Wf6rb84UfjHrIudNU1OwW1T+5/iA3//Yd9jd28OMXttPWrSyE/gHJW7sbWDq1SBVzsyLca2Zl8o911Ww91KLuJBqroHhm2PsGcuk3P67Ee7xa7MW8G5Wd0bg73LYBle2SWayKxbnhdVVs4P3yBmfd6FaEejJW2zagLu6+ZJUzX79TfVd/siOidxN6F48+IPSOkgqxInp9XLTaR84aTCmZwQtQPPR0wItfV79vbhxaD/vfCk8D7WpWvzep2ca6MRjiIrNI/ZH398H6vyhvePziqIfMGpdNcXYqr+8KevsDA5J7XtzB5//2Losm5vGHW0/jaEcvD61QC522HGqmubOXs6dZdoWVqnj97CzyMlL4xr82M3B0v7Id3PrOFkxWfvzu5cFoHtQf/fyb1M+6mJmTwmkqf9wNr4ulNJ6tm9bQFo4+X7Cwma5zY39N59LXbQ/ad5klKiuq5bC7deMa0VtjcxZJ0xOxEF3oOxvDX9PY0yth8DXp1/1RBRd9Xe4rdbua1e+BcyzHg9DveH5E7iaM0BuGFu0TH1gJ1atg4QdilhwWQnDOtCLe2FVH/4Bk/f6j3Pibt7nvlUpuOnUCf7z1dM6bXszFs8fw29eraOroCfjzZ02xPs+ybjJlO1+9bCZr9h1lxZo16jVnkxOwib9UQm9nycfUY0ShnxI9oo9H6L02H3F69GCVQWgJ1rmxk2O1hGzcE7Su/EnqbiOSdZOcbmXj2FJHAzVynBF9LSDU3c+gI/oOR0Q/iJr0fT1qhS7W75ib167H114Xvj09T61NGA2hbz0Cj9wI7/5l2D/KCL1haMm0moS/9QuV2TLvJk+HnTe9mKaOXj744Equvf8t9tS388P3ncL3rzuFlCT1a/qlS6bT1tPHb9+oYsWuemaOVXcCQEjzkesXl7G4PJ8VqyyhdyugpoW+aEawOblmzGw1eXzqx90HWzhViYYzEo9nVazGS/MRKcOtm8CxOqJ3Cn0pHFwHsl99R/v2loNBQXV69BCM6vt6gpG/06NvrVGfmV7gPv6A0EeJ6O3plXos8Xr0Gx9V30ffhXW5CH23JfT2eQUIjehHI71SX0RHoGetEXrD0KIj+p3PwbSLvaUZAmdPLcLvE7x7oInPXjCVV7+8jBtPnRjSTGXm2BzeO6+Uh9/cy5p9R1k61ZbFk5KlLixdzfh8gu9cPZfC3sP0iWT3nPb8cmX3RLrjmHaxa5YQEExZddo3TftU/rrbhSUSaXlKnKKVEejtUNaDm9C3HVFCZrduwMqlt6qHFk8Pbte59K5Cb0XX2qe3C7jbZGz2mPDiaqAWaultUYW+I9Q6ite66e9TDVXGLYDZ11hjdrm7iBTRdzaFWjeDLeUwWPS4mvZH328IiN1yyGCIB7s4LviA58MKs1J54lNnMTY3jTE5kTNWPn/RNJ7ZeIgBqS4OAQJ9VJsAmF2agyxqZ39jEa++tY+zpxUxtTgLn88S9aRU+PzGYEmBeCi0MogaKqHMNv9wZLN6jKdxSnoegTICeqWsE2dBM01aDuyzPtPNutEUTQ/dvnt5aGNwjTOi11G5P9XFuqlRq3/t+fSB8dqeR7Nu+rqCna30WFpt3n9/Hzz9eTj9k+7ndOuTKhq+8c/RVxlHs2600GOtFI5nJfixov9fjdAbTjh0RJ9RCNMvi+vQ+RPyYu4zpTiL9y0q4+mNhzltUkHoiw6/e2ZqA+tSxvHtp7cCqk3iNQtK+eZVc0IydeImv0JNajp9+prNgAitqxML++rYSEIfKGjmaJZut32cEb3OsMmdEBq155RCT2twMtXp0UMwl15H4yUzoXabinh1umlbrWr/2NkUvnjMvmo4ktAPWN2kQiL6rFALpbEK1v9J2WxOoZcS3rhHZVTNuCLYc8Dp0Q8MBM+fXeiltAm9tWisu22Ehd76XT26T40nnvaZcWKsG8PQklGoarLMvzmY1z3EfOeauTz3uXPITHXEKY4MFn/zPpYsWMSrd53Pj6+fp7J33t7H7rpjXJSTlKomaht2hW4/sllN1MZTQM5L85FoQq/JiiD09mjevr2+0qocafs/ihTRj5mr1hpo0R6wFlBlRbBu7HMXkYRe14EP8+ht/zf6Qup2btrroHYLLPqQuvjYF5DZ6WlTtpc+RtPbqayttLzgeR3pCVk9d9DTGrmkxhBhhN4wtPiT4PY34MJvDNtHpCX7qShyEVN7TnrnUehqRuSXU1GUyQ1LJvDda1VUuHx7bfix8VI4zSWi3zT4frfRUiyd3aWcx4L7ZCyELxbTlk7DLnVBtkeRTo8+IPTWZLW2bzqPqrmIiEJvHedLipxeGRB6p0dvy6OPJvT6fOnicZGE3tlu0bk9YN0Qn9DvfgVe/4n3/d2wjy1SSY0hwgi9YehxlhwYKexWhi4lbEutHJ+Xzowx2bwyJEI/VU3G6lTErhb1xzpmbnzv46WCpbMWvSaa0GePU2mjepJSoy8AjVXhdx4RI3ot9NaErLZ99GRsd0uwUqb9uPyKyBG9Tu+0e/QpWeoio98rIPRN4cfrbfqOKCUzMBkfup+93aJd6PXxubamJ3EI/UvfCJb3GCz2DKFh9umN0BsSB7tHryMk3f7PYtnMElbvbaSly6WfrUfauvuQhVOUWOmFREe2qMe4I/o89ejJunEIvbYcUrLCisXh88P1D8HE00O36wykgb7wY5wefedRJZ46PVNH9HpVrI7oIdQb10JfMCVy1o29u5TGWdjMS0SvL5RCqMlpZ3qlHlfWmGDxN/t7Diair9ms7t4G+iKvp/BCV3PwLipaj4MhwAi9IXGwe/S6Fo1jsdSyGcX0DUjetK3CtdPV289DK/Zw0T2v8d//3BQouQCqLPJDK/aw6Nsv8bc9ViRab/n0NZvUY7wR/VBYN85oPhpJtkJtzkJ3gYjeEuHORlW3J6tE2TCBiF5XyxzjbplooS+MJvRWRD9YoQ8IdV5wm5uNpJ8XTg2pqhpyfLxCv+GR4M+1W70d40Z3i7rDSss9PiJ6IcRlQogdQohKIcRXXV4/XwjRLIR41/r3Ddtre4UQm6zta4Zy8AZDCGl50N9tdZXaq547MmsWl+eTk5YUZt/09A3wp7f3ct6Pl/Ptp7eS4vfxyKr9XPqz13lrdz0Nbd187A9r+PbTW8lJT+aXG6wDtRgd2aREUVsjXknNVhk8g4no9XdzTsTGQo/R2SYy4NFroT+qvpPPr+4E9N1LoEJnBKHvalJpq1klyopxK2ymPyPJsTIWlNB3tQTvHFyFvkk92v9/owq9dQemLyJ6e3qeTeg9LJrq74WNj8G0S9X/m872GQw66ydv4rALfcz0SiGEH/gVcDFQDawWQjwlpXReyt6QUr43wtssk1K6h1AGw1BhT1U8us+19EGS38e504tZvqOOgQEZyKv/nyc38diaapaU5/OzGxdw1pQi1u5r5EuPbeCW364kNz2Zzt5+vnXVHK6aX8pFP11O90AqKfWVavF9zWYVzcebIufI/3elu0VF3/5k9+8bT0QPakL28IZw60ZH9L0OoYfQ7lRttUqUU7PcG5zr49Kt9NeOhvDPihrRt0Fja/C7ud3teBZ6625Ir31oq1WNZ/R7hlg3HkoVV76sLKDFH1GF72q3xT4mEl0tym5KyTo2C8gDXiL604BKKWWVlLIHeBS4elhHZTAMBrvoHN3rXuMGuGBmCfVt3Ww5pP6w39hVx2NrqvnkuZP5++1nBurnLC4v4LnPnctHl1YwuTiTJz+9lA+fVUF+Zgp3XzGHqoExHK7apCYPa7fB2HmDG3daXgzrxqX8ARyD0OuI3jEZm+wS0WdYYp09LnQyVt9FuFlPnUfV/0WGVQ7DLfOm1y290laTXq86Hr/YKkrmaN3Y2aQufvYU3tSccLG2WzcQWkJbH5OU6r35yIa/qrUi0y5WOfxDEtGXq4g+UnvKIcCL0I8HDtieV1vbnJwphNgghHhOCGEvHiKBF4UQa4UQt0X6ECHEbUKINUKINXV1g28WbTiJ0aLT0aj+cBwTsZrzphcjBLyyvZaOnj7ufmITk4sy+cLF00NKLgCkp/j5f1fO4Z+fXsrs0mAe+/sWjacpo5zeul0cPbBNWRRj4/TnAx+SF9u6iSb0g7Vukp1ZN5boaqHvsEf044NtCNtqo6c16oheC71b5k0goncsmAJL6CsBAaULVb67syFKV1OoPw/uJZ+7mpQ9pL+znpDtagq9UKRkxRb6jkbVNeuUG9TdVckslb3kVjHTC90t6kKTN1Gdj/bhMz28CL3bvajz0rMOKJdSzgd+ATxpe22plHIRcDnwGSHEuW4fIqX8jZRyiZRySXFxnBGKwQCQZolS3TYlDhEi+sKsVOaX5fHKjlp++uJOqo928oP3zSMt2e+6vxtCCGbMWch4Wcufn3gSgK+/A+/9xRu8vO1I9IPDxh3Luokg9On5cM6XYM518X2ezqUPs24cQu+0bno71DhbazwKvbZuXCL6gEfvWDAFyrppqIS8CcGLmJv37lxJ7GbddLeo7fquR6dYdjWHXii8FDbb8oRaOLbgZvW8eKZajOVcOOcVHdHrgGQYfXovQl8N2DsklwEhFY6klC1Syjbr52eBZCFEkfX8kPVYC/wTZQUZDEOPFp3D1kxplOJiF8wsYWN1Ew+/uYcPnjExvJyCBwomzCZJDDDt6Gv04WdL7zga2nrCsnVijzsvekTf5VKiGJS/f+E3VImCeIhk3WjR7e1Sk449raFCD6qWvT2iT8km0ABF4ymityJ054IpUBeU+l3Kbom0EEoXJLOTlqPE2t7ftqs52CwGgoumtMhqUnNiR/TvPqJaTWqLTpe6qB2EfdPfq76nnowFaNob//t4xIvQrwamCSEmCSFSgJuAp+w7CCHGCuueVwhxmvW+DUKITCFEtrU9E7gE2DyUX8BgCKAjPC30ESJ6gGUzSpASxuSk8ZXL4hRKjVXF8tKUjSSVzOSJO5dx/wcWcaSlm1+8HEeUF6v5SHdrePmDY0FH9E7rxudTXnVfly1PPT/0mMbdaum+rkrq81n565YQS6mOTc+3ImbhHtEHhN6xYApU9kvDbofQN4Ue74zIwT2nXwt6Uiqk5toi+iaH0Mewbtob4OAaOMXWpKZwmko7rRvEhKyeJA4R+lGM6KWUfcAdwAvANuAxKeUWIcTtQgjdpPF6YLMQYgNwH3CTlFICY4AV1vZVwDNSyueH44sYDIE/3CNbAKEKekVgTmkOt5w+kZ/fuIDstOSI+0XFqmkv+roC/vzCifm8f0kZv1uxh8paj3nZum+sNRlX19rN8u21DAxYDmkk62aw5IxXEa5bH98kq/mInkANCL210OrQevWoI3oItUx62pVtlp6nymGk57lH9H1RIvqje9TdROG0oB3n5r2HRfRuqZ4ttrmMYod1Yxf6GM1HdGppwZTgtqQU9XwwEb2+cKXmqM9OLxhWofdUvdKyY551bHvA9vMvgV+6HFcFzD/GMRoM3vAnqyi1t12JfJSiaj6f4HvXxrmK1UlGgbInOhpCFkp95bKZPL+5hv/31Bb+/LHTwyZ4w0jLU95vXxckp/P957bxxLqDLCnP57vXzmWmnrQbKpLT4K5d7qmgSamW0FuLnrTQZ40FhGpmEniux28Teudx6QWRrRvhD00Z9aeoCFnfkRVOiWLdRPDonft2NQfv7DIdQm9vyJKaHbk9JAQncZ0T3yUzg4vl4qHbFtGDiuqHcXWsWRlrSCz0H04U22ZIKbSakNhKHxRmpXLXpTN4s7KBv6zcz+Nrq7njr+tY+oNXuOelnUhnGp0tRbG3f4D/bD3C3PE57K5r44r73mCgq5W+ZMfipjjZXdfGUxtsU2uRLj7Jacqjdwp2UooSuUBEbxM8ZzE5+3EZhZHTK+059HpMKZlB4Yzk0Q8MWJOseaHHB6pQulg3oHol2IXefqGIFdFrb99ZDrp4lmrX6MwKikVgZa415vzyUZ+MNRhOHPQfbzxdno4FnZ/tqHHzgdPLmT0uh/95cjN3/X0DK/c0UpqXxn0v7+LuJzbR12/rZmTL/3+nqoGWrj4+e8E0Xv7S+XxyjsRHP8sP9HMs3P2PTXzhb+/S1RvjfZLSQiP6DNskdU5p0HLI9hjR6zseJ85+sZpkq52gPxVyy9zz9LubARnbupEymHUDSqTbakNr0WuctfCd6Ije2XWsZKYaS/3OyMe60eUS0TftH7YuV6bxiCGxGOmIfv6NaiLPIQB+n+AXtyxk+fZazpxSyOxxKnK756Wd/OKVShrbe7jv5oUqpdM24fjCll7Sk/2cO72YtGQ//5X9Ir0ime/uncVpHb3kZsQ/n7B+/1FW7VVRdVVde8h6gDC00Hc4PHpQ3v6h9Wrpv86ogRhCXwA1G8M/p68rtPyBRvv0BZNV6QWfX/n49slYe/kCO06h7+tSlph9YVlnoxqjHAjPuuntUBk7fhdZbK9T1pLz4lJsy7wZF4dLbV+wBSow6e9WF5R4eg57xET0hsRC385HWCw15Ew6Fy7/oetLU4qz+Pg5k5lTmosQAiEEX7pkBt+8cjYvbj3Cx/6wWk24WhOOAx1HeXHLEc6foUSelkPw7l9pnXUz+3qy+fPKwXm4v32jiiSr1MPOIzEmiO0RvfCHzg3oypeZJUqANbGE3jXrJkJEr4W+0Dbp6cyPt5cvsOMUeqc9oi/GjXvCj9eT3ZFKFbfVqe/ttLwKp4AvOf7MmzCP3vp9HSaf3gi9IbEY6Yh+EHxk6SS+c81c3qxs4Ml3DwYi032HDlPb2s1lc62I7q1fApKCS77MudOLefjNPbGtFwf7Gtp5fnMNH11aQbJfsCOW0Ns9+vT8UGHTufTOCcm0PCWQ/X3ByNtu3bgVNuvtCk2t1OgUS92AHcKF3lmLXqPFWtsiAXskL3TceoGTM70SIhc2a68N78sLajK5cGr8mTddzYAIXkiHedGUEXpDYqFv549joQf4wGkTmTs+h5+8sIMuvxKZvVW7SPYLls0sUXnbax+GU94PeRO5/bzJ1Lf18I911XF9zu9W7CHJ5+MT50xmclEWO2viiOjttg0Ec+ntqZUQmr/eeVT56zpatxc2s9PbEV4mGWwRvS3107ly2F5L3o7PugMJi+gdNYF0ATHnyliIPCHbVhu5plDJzPjLFetFcLoHr04FHqZOU0boDYlF6SJVHyXeQl8jjM8n+O/3zOJQcxe/X9+MHDOXc6of4FvFy8lJTYKVv1aZHGd/HoAzJxcyvyyX375eRb/Or3fwTlUDv3h5Fw1tqkNUY3sPj605wDULSynJSWP62OzYEX1A6BtdhN6K6LMjCH1XU/gFItLq2L6u0PIHGlehz3O3btyaqdujf6cPrjNm6t0i+hhC314fnnGjKZmtBNre7zYWYZPBGep31gi9weCB+TfCba/GXy54FDhrShEXzCzhV6/uYdX5f+al/sXc0vQb+NsHYeVvYNaVgZ6vQghuP28Kexs6eH5zTcj7DAxIfrW8klt++w4/fWknZ/9wOd97dhu/fKWSrt4BPnGOWtg1Y0wW1Uc7w8oz1Ld1s26/5a1Hjei1dRNJ6JsjC70zxbK3K86I3pEbD+HWjd5X+9/dzoje8ugDEb1daKMIvZRqMtbNugFV8wagbof76264rY3QVSyHASP0BsMocvflM2nv6eNTj1fy6b7P03beN1WFxO5mOOeLIfteMmcsk4oy+eHz23nwjSo2HGiioa2bT/xxDT9+YQfvnVfK03eezWVzx/LgG1U89OYeLphZwrQxSsSmW4+7HFH9T17YwQ0PvM3uurZQj96eWgkq3XHMXJjgaE8YIvRNESJ6p9B3uHv0uRMgd2LkrB5Qdw7CH16rB6JbN2m5KnNGL4zyOhnbeVSt9o0Y0evMmzgmZJ0RPQzroimTXmkwjCLTxmRz46kTeWTVfpaUF5C17AswdanKyy5dGLKv3yf45lVz+PqTm/nuM0FRSfYLvnXVHD50ZjlCCH524wI+e+E0Hl21nxuWBMtAzBirxGznkVYWTlRiLKXkjV319A9Ifvz8Dh4otCL63o7wiD4pFT71ZviXcEb09jUMGeEe/b83HOLslhbyy12ybs7+Apz+ydA7Mi30UqrtnU3KtnG7a0vLhZbq4HggmHUjhLJHdAMVr9aNXmQVyQ4smKzq6FSvgoUfcN/HSVdzeDeySee43+UMAUboDYZR5gsXT+OFLTVct6hMbZhwmvrnwnnTi3n9v5ZR09zF6r2NbDnUwmVzx7JgQl7IfpOKMrn7PbNCtk3IzyAt2ceOmmBmyb6GDg42dTKlOJPnt9RQswTGBurVOIQ+Ek6hH7fA9loezsJmz246zNm9nXSRQlhMn5QSXroiLVflvXe3BguoOaNh+761VqP2rhZVUsEunplFSuhTc0JTRANZN1GEPpJ14/PDxDNg31vur7vR1Ry8E9AsuVX9GwaMdWMwjDIl2Wms/tpF3HL6RM/HjM1N48r5pXz18plhIh8Jn08wfUx2SC79ikrV7OK+mxdSkp3K61WtSuRhkELfFDpJ6lLYrKqunTR6aOj2WP/f2a7QrelIYCw5tvRK64Jgj/y1/eK8UAQ8epf0St0MPZJ1A1B+lroL06USYjHU9YtiYITeYDgO8PtGZvJ4+pjQzJs3K+sZn5fO7HE5fPHi6exttpdm8Cj0KVlqtWxbrSoo5zzOVtisf0Cyp6GNdNHDkU6P39ltIZRbxo3et7tFlRLoag4XU22/OIXeb0X+bn1jY1k3AOVL1eN+R1Tf3QYPXwH7Vwa3uZVgGGaM0BsMJxEzxmRT19pNY3sP/QOSt3Y3sHRqIUIIrl9cRnaWrXiaV6H3+ZSg6tRApwjbCpsdaupE9Kn0z0MxGjoFcAq9W9MR+75yQNWtsde50ejMG7fjIxU2a6u1yj5EaU4zbr4q6bDv7dDtO5+HfStg98vBbT1tVgkGE9EbDIZhYLptQnbroRaaO3tZOlWJX5Lfx7K5NvvIq9CDEk5dWsB5nK2w2e66NtJRQn+gzX09gOt7Q3DRVFTrxrZ4yy1qdjY1txOpsFl7nWoI7otiNSWlwIRTYZ9jsnrLP9Xj0b3Bbc6CZiOAEXqD4SRixpig0Gt//qwpwYJsM8qCP2856r2HLmm5wdTAMKEP1rvR/jxAdav0VtJBi7rOvIlme2irpqs52EbQTsC6yXM5NkJE317nrQF7+VJVYlnfeXS3wq6X1M/6IqjHZh/rCGCE3mA4iRiTk0pOWhI7alp5s7KemWOzKc5ODbwubIXGvvDv/TR19Hh74/S84AIlV6FXEX1VfRtFaWoeoG0ghcpaD/6N3brp7VQVKaN59HrfLjfrJoJHD9GtG2d5YjfKzwJk0I/f8byqSFk0PTSidxY0GwGM0BsMJxFCCGaMzWZjdTOr9jYGbJsAVlkCKfzsafNx1983hjdKccMuWm7WTV8X9HRQVdfO1Hx1p9BFClsOOTpHueGM0iG2dROI6B37xRR6N+umNnrGjWb8ElXJUts3W59UFT9Peb96D10iIVKtnmHECL3BcJIxfUw2mw4209M3wNkRhF6k53H35bP5z7Yj/G7FHpd3cRBL6AE6Gqiqa2dSriU7SelsPeSS5eLEn6TSHzubbJUro0zGWp9Fb3u4PaJrvdtX3mpSs8OzbqRUKZNerJuUDLXIbd9b6m5i10sw+xooVCUoAlG98egNBsNwM9OakE3yCU6b5Mgk0YXG0vP56NIKLp0zhu8+s42v/XMT7Y4aOSHoyNlZwx4CFSw7mmupaemiPEelVY4pzGPrYQ9CD1YD9eboBc0gKJ7N1aHPNVklcMtjqiaSEzfrpqddlVn2WiSv/Cw4tA62PKFsmznXBCupBoTe+g7GozcYDMOFrnmzcGIemamOxfG6/kx6AUII7r1pIbedO5m/rtrP5fe+weq9Lk1EILSejLM0gRU9HzmsetaWZanXS4sL2Xa4VTVfiYUugxDL9tDiqYuDue03/dLIWTdOoQ+0EPQq9EthoA+Wfx+yS6HsNMifpF7TQj8KHr0pgWAwnGTMGJtNkk9w7jQX8bJF9ABpyX7++z2zuHBmCXc9voH3/9/bFGWlkpbsIy3Jz/wJefzgulNI0qLllpJpCX1D/WFgPOOsWmTlYwpo29jFgaMdlBe6FCizExD6Jut5nvt+SSlq4VNA6OOImlOz1argvm5V1weCK129WDcAE08HBLTVwBmfVmsM0vNVLZxARN+siqu5FXUbJozQGwwnGXkZKfzrjqVMKc4Kf9Eh9JrTJxfy3OfO5Xdv7OFwcyddvf00dfby+NpqphRn8an8UKFv6+6jsa2HiYUZgYyV/potCDGeYivrZtK4YuAAWw+1eBP6pgO2frFRcvxTc6D5QPA4r+i7ge7WoNDHG9Gn5cLYuSrNcvY1apsQqoOUTrF0ywYaZox1YzCchMwpzVV9aZ0EOkOFC2lWahKfu2gaP3jfPH5+00Ie/sipXDZnLD97aSeHulICxzV19PC++9/i8ntfp7WrV6VXzrqKRQf/wrm5taQMdAFQMbYQv0948+l1lynLo+/wZbDsJ6/ywpYa930jefTRCBQ2s42nPc6IHmDmlaoZSdmpwW35FaERvRF6g8EwauiIPtpyfwshBN+9di5ZaUnc95aKfHtTc/nww6uprGujvaefZzcdVju/92e0kcm3+n8ZENK09EymFmexxUvmje4y1dUEKdmsr25jT307f13p0qgjLVf55BDfhGeqS2Ezbd1keMij15z/FfjUW8E2gQAFk1SJiIGBES9oBkboDQaDnbRcmPs+mHKBp92LslL59tVzWF+rJlRf3tvL5oPN3P+BRUwpzuTxtSqyHkgv5Ot9H6eitxLe+bU6ODmD2aU53lIsdbGyjkZIy2XtPtUR683Kepo7esP3dfs5Fm416dtr1UXGWTo5Fs4J6fwKtdCr9ZCJ6A0Gwyjj88P1D0HZEs+HvHdeKUtmVACwvdnPj943j0vnjOX6xRNYvfcoe+vbqWnp4uneRewuvRLajqgiYf5kZo/LoaalK9DnNiKBtMkDkJ7Hmn1HyUzx0zcgeWnbEce+OloW8UXObu0E22rjs20iYU+x7GoZ0YJmYITeYDAMAV+85iwaffksXLKU9y1WDVSuXTgen4B/rKumqk6tCq0/59sq7TA5A4RgdqkSvG2HYzQt10J/dB8yLZf1+45y1YJSxuel8/zmw+77puaE2iexCLQTtFk30ZqCx4M9xXIUInqTdWMwGI6Zwrxc+MZezrNtG5ubxtnTinli3UEKM5X1UTG+FG55FGo2AzCnNAefgFe213L2tCg+uF4g1XKQtoI5tHb3saS8gIyUJP709j5au3rJTktW+wRy+uOMmrXQ25qk0F6r+uQeK7llajFZ4x73OvnDjInoDQbDsHH94jIONnXy6OoDZKb4KclOVbXbrd6qeRkpXLuwjL+s3MeRlq7IbxSIgCW1vWrCeHF5Pu85ZSw9/QO8sr02fN94o+asMSry3vyP4Dav5Q9i4U9WYl+/U620jbQOYJjwJPRCiMuEEDuEEJVCiK+6vH6+EKJZCPGu9e8bXo81GAyJyyWzx5CdlsT2mlYmF2chXBp6f+7CafQPSO5fXhn5jWyiXd2ZQmFmCuWFGSyckM+YnNRgdg8Eo2UXoW/u7OXW368OTOaG4PNxcMaH4cBKqF4LvV2qIudQWDegMm9qNlpjO84ieiGEH/gVcDkwG7hZCDHbZdc3pJQLrH/fjvNYg8GQgKQl+7lyfikAk4vdF0VNLMzghiUT+Ouq/VQf7Qh57UBjhyqRYBPt3a1JLC7PRwiBzye4fO44Xt1RF6zFY/foHXzr31t4ZXst/3r3YNhrB5s6ufS1CXT7M+Gd+6FD1euP2BQ8Xuy59Mdh1s1pQKWUskpK2QM8Clzt8f2P5ViDwZAAXG9NzrquxLW484KpCAS/fEVF9f0Dkh+/sJ1zfrScn760I8Tq2NeRwuLy4IKuy+eOpbtvgOU7LPtG7+sQ0xe21PDEuoMk+wWr94ZH9CurGmiT6Tzluwi59Uk4vEG94HVVbCx05g0clx79eOCA7Xm1tc3JmUKIDUKI54QQc+I8FiHEbUKINUKINXV1HjupGwyG456FE/L44ftO4aZTJ0TcpzQvnVtOn8jf11azfv9RPvLwKn61fDdjc9L43Yo9HOlOUimZQIvMYElFUOiXVBRQlJXKMxst+8bFo29o6+Zr/9zEnNIcbjt3MjtqWmjpCs2/X7VHFWy7t+0C1dN1+ffVC0Nl3ejMG8fYRgIvQu/Wqt1Zbm4dUC6lnA/8AngyjmPVRil/I6VcIqVcUlw8RFdQg8Ew6gghuPHUiZTkRC/i9ellU0j2C6779VusrGrkB9edwmOfPJO+fsl9r+wORMHtvizmlAaF0u8TXDW/lOc213DnI+tp6LPq1Fg+uJSS/3lyMy2dffz0/fM5c3IRAxLW728K+fxVexpZNDGPGlHCjrzz4Mgm9cJQWjeaEfbovaRXVgP2S3EZcMi+g5Syxfbzs0KI+4UQRV6ONRgMBoCS7DTuvGAaj6+t5mc3LmDBhDwAbj5tIo+s2s83i3JI7mqiqKgkrE7Pf102g5z0JO5fvpvN25tZLmB7k4/XX9/N1kMtPLe5hq9cNpOZY3Noy+/D7xOs3dvIedOViNe1dlNV387dl88kJz2Zew9fxK9Zrt7cxbr53Yo9/Gp5JeWFGUwpzmL6mCxuOb2cLGfZZzshQn/85dGvBqYJISYBB4GbgFvsOwghxgJHpJRSCHEa6k6hAWiKdazBYDBoPrNsKp9ZNjVk250XTOXxtdUc6kqlHKgoC3d/05L9fP6i6Vy9YDzfeHIT39nzQZ5eNYEjbKcgM4VrF47ntnNVp6es1CRmjcsO8el1nf1TJykb6Es7Kmgvm0dmSxWkhE8i/2NtNenJftKS/Ly+s47H11az60gbP75hfuQvl56nisV1Hh1xjz6m0Esp+4QQdwAvAH7gISnlFiHE7dbrDwDXA58SQvQBncBNUjWadD12mL6LwWBIQEpy0rj17AqqV6RQ7odp5WUR951UlMkfP3Y66/ZP5yqfj4rCTHIzksP2W1JewN9WH6C3f4Bkv49VexpJT/YztzSXaSVZpPzTzx+LvsSnzgvvqlXf1s3Wwy18+dIZgYvS/z6zlQdX7OHWsycxa1wUEc+vUBU4j8PJWKSUz0opp0spp0gp/9fa9oAl8kgpfymlnCOlnC+lPENK+Va0Yw0GgyEebjt3Cp1+lbUzd8rEqPsKIVhcXsD8CXmuIg+wpCKfzt7+QEG1VXsaWTgxj5QkH9lpyVwwo4SHdmfRP+d9Yce+WanSLu39du9YNo2ctGS+/9z26F8kv0KtwI2nNMMQYFbGGgyG457c9GSmTBhPn0imOD/vmN9vSbkqw7xm31GaO3vZVtMS0j/3yvml1LV2s7KqIezYFbvqyU1PZu74oM+em5HMnRdM5fWddbyxK0rW4JKPwXlfOebxx4sReoPBcEIw6fQrSZp3Q3gJ4EEwNjeNsvx01uxtZN2+o0hJiNBfMLOEzBQ//94YmjsipWRFZT1Lp6qmKXb+vzPLmVCQzvee3U5/pD64k86Bs+445vHHixF6g8FwYjD3Orj210P2dqdWFLB671He2dNAsl+wcEIwNz89xc8lc8by9MbDqkuWxe66dg43d3H21PBMnNQkP1++dCbbDrfw5PrwlbejiRF6g8FwUrKkIp/6tm6eevcQp4zPJT0lNGXzo0sraO3q48/vBLtYrbBsmXMiVNp87ynjmF+Wy5cf38BF97zGZx9Zz29fr6Kzp3/4vogHjNAbDIaTEu3TH27u4lSbbaOZV5bHedOLefCNoFCvqKynvDCDCQUZru/p8wke+P8Wc8eyqVQUZrBmbyP/++w2fvh8jEnaYcYIvcFgOCmZVpJFTprKMD/dRehB5fA3tPfwyKr99PYP8E5VY0i2jRvjctP54iUzePDDp/LW3Rdy3aLx/G31AY6294Tt2903MpG+EXqDwXBS4vMJqwomLC53F/olFQWcMbmA/3t9N6v2NNLW3RfRtonEbedOprO3nz+/sy9k+7bDLSz+zn+4/9Uo5ZmHCCP0BoPhpOUT507my5fOIDfdPd8e4M4LpnGkpZv/eXIzPgFnTo5P6GeOzWHZjGJ+/9ZeunpVBN/bP8CXH99AW3cfP3lhR6Cg2nBhhN5gMJy0nDWliE+fPzXGPoUsnJjHnvp2TimLvAgrGrefN4WG9h4eX1sNwP+9tpvNB1v4yQ3zmViQweceXe9q7QwVRugNBoMhCkII7rBKHZwTw5+PxGmTClgwIY/fvlHFtsMt3PvyLq6YN47rF5fxy1sWUd/WzZcf34iqHDP0GKE3GAyGGFwws4QfXT+Pjy6tGNTxQghuP28y+xo6+MCDK8lOS+bbV6m2HXPH53L35bP4z7Yj/P6tvUM3aBtG6A0GgyEGQgjev2QChVmpg36Pi2ePZVJRJo3tPXz76jkh7/XRpRVcOLOEX75SGWyJOIR4KVNsMBgMhmPE7xP85IZ5rN/fxBWnjAt5TQjBj2+YT1tXH5nRatoPEiP0BoPBMEIsLi+ImMpZkJlCQWbKsHyusW4MBoMhwTFCbzAYDAmOEXqDwWBIcIzQGwwGQ4JjhN5gMBgSHCP0BoPBkOAYoTcYDIYExwi9wWAwJDhiuIroHAtCiDpgX8wd3SkC6odwOImCOS/umPPijjkv7hzP56VcShnezJbjVOiPBSHEGinlktEex/GGOS/umPPijjkv7pyo58VYNwaDwZDgGKE3GAyGBCcRhf43oz2A4xRzXtwx58Udc17cOSHPS8J59AaDwWAIJREjeoPBYDDYMEJvMBgMCU7CCL0Q4jIhxA4hRKUQ4qujPZ7RQggxQQixXAixTQixRQjxOWt7gRDiJSHELusxf7THOhoIIfxCiPVCiKet5yf9eRFC5AkhHhdCbLd+b8405wWEEF+w/oY2CyEeEUKknajnJSGEXgjhB34FXA7MBm4WQswe3VGNGn3Al6SUs4AzgM9Y5+KrwMtSymnAy9bzk5HPAdtsz815gXuB56WUM4H5qPNzUp8XIcR44LPAEinlXMAP3MQJel4SQuiB04BKKWWVlLIHeBS4epTHNCpIKQ9LKddZP7ei/mjHo87HH6zd/gBcMyoDHEWEEGXAFcCDts0n9XkRQuQA5wK/A5BS9kgpmzjJz4tFEpAuhEgCMoBDnKDnJVGEfjxwwPa82tp2UiOEqAAWAiuBMVLKw6AuBkDJKA5ttPg58F/AgG3byX5eJgN1wMOWpfWgECKTk/y8SCkPAj8B9gOHgWYp5YucoOclUYReuGw7qfNGhRBZwD+Az0spW0Z7PKONEOK9QK2Ucu1oj+U4IwlYBPxaSrkQaOcEsSOGE8t7vxqYBJQCmUKID47uqAZPogh9NTDB9rwMdZt1UiKESEaJ/F+klE9Ym48IIcZZr48DakdrfKPEUuAqIcRelLV3gRDiz5jzUg1USylXWs8fRwn/yX5eLgL2SCnrpJS9wBPAWZyg5yVRhH41ME0IMUkIkYKaNHlqlMc0KgghBMpv3SalvMf20lPAh62fPwz8a6THNppIKe+WUpZJKStQvx+vSCk/iDkvNcABIcQMa9OFwFZO8vOCsmzOEEJkWH9TF6Lmu07I85IwK2OFEO9BebB+4CEp5f+O7ohGByHE2cAbwCaCXvR/o3z6x4CJqF/iG6SUjaMyyFFGCHE+cJeU8r1CiEJO8vMihFiAmqBOAaqAj6KCwJP9vHwLuBGVybYe+DiQxQl4XhJG6A0Gg8HgTqJYNwaDwWCIgBF6g8FgSHCM0BsMBkOCY4TeYDAYEhwj9AaDwZDgGKE3GAyGBMcIvcFgMCQ4/z/f6nrONqXvLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.plot(history.history['val_loss'])# history.history\n",
    "plt.savefig(\"E:\\\\NN\\\\\"+modelName+\"_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "808e9d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 5ms/step\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# model =  tf.keras.models.load_model('E:\\\\caOnly_v1')\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "# model.load_weights(\"E:\\\\caOnly_v1_weights.h5\")\n",
    "\n",
    "# labels = (train_generator.class_indices)\n",
    "pred = model.predict_generator(loadTest(testData),verbose=1)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "print(np.unique(pred))\n",
    "\n",
    "y = []\n",
    "for ind,(dataP,label) in enumerate(loadTest(testData)):\n",
    "    y = y+list(np.argmax(label,axis=1))\n",
    "# print(pred[1:100],y[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ca3f6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4682124158563949\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "classes=['Healthy','sick']\n",
    "con_mat = tf.math.confusion_matrix(labels=y, predictions=pred).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = classes, \n",
    "                     columns = classes)\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.title(modelName +\"- on test dataset. Accuracy: {acc:f}\".format(acc=np.sum(y==pred)/len(y)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "# plt.savefig(\"E:\\\\NN\\\\\"+modelName+\"_confusionOnTest_Test.png\")\n",
    "print(np.sum(y==pred)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f130f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 6ms/step\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# model =  tf.keras.models.load_model('E:\\\\caOnly_v1')\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "# model.load_weights(\"E:\\\\caOnly_v1_weights.h5\")\n",
    "\n",
    "# labels = (train_generator.class_indices)\n",
    "pred = model.predict_generator(loadTest(validate),verbose=1)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "print(np.unique(pred))\n",
    "\n",
    "y = []\n",
    "for ind,(dataP,label) in enumerate(loadTest(validate)):\n",
    "    y = y+list(np.argmax(label,axis=1))\n",
    "# print(pred[1:100],y[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "132e7638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAJWCAYAAAByJXw0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2M0lEQVR4nO3defylc/3/8cfrMzN2hgkjY+xbCEm2NE2k0CIhokWqob4oIvq1kEoplb5J0yT7Ftkj9KWxRQiJQSHLzDC2WYwtM96/P67rM645zvl8ziznnOv6nMd9buc257qu97mu93U+Z3mf5/t9XVeklJAkSSqTnk5XQJIkqZYNFEmSVDo2UCRJUunYQJEkSaVjA0WSJJWODRRJklQ6NlBUehHxnoh4sNP1aKeISBGxdn5/bER8u5my87GdfSLimvmt5zxua77rKan72EBZABFxdESc1WDZoxHxckTMLNxWjojV8w/q3nmPRsSRC1iP8RHxSmGdbf8y7+u5mI91zfVFllK6MaW03sJYdxWllA5IKX1vQddTeO0NLqz77JTSBxZ03QtTvXqWbTsRcVpEzIqIlVtRt7LJn6u/RMRLEfFARLy/j7J/qvnc+29E/DNftmJEnBsRkyNiekTcHBFb1jx+74h4LCJejIhLImJYYdmiEXFKRMyIiKci4tCax24aEX/P6/n3iNi0Zvkh+eOm5+tZdKE8QWqJrmugtPpDr8ZHUkpLFW6TC8uWTSktBXwS+E5E7LiA2zqwsJ2F/mUeEYMW9jqlKoqIJYHdgOnAPm3edjs/v4rOBe4C3gJ8E/hDRKxQr2BKaafi5x7wV+CCfPFSwO3AO4FhwOnAFRGxFEBEbAj8Bvg0MBx4CTipsPqjgXWA1YD3AV/v/eyMiEWAS4GzgOXydV+azyciPggcCWwPrA6sCXx3QZ4UtVhKacDfgEeBI4B7gFeBwWQv1IeBF4AJwK6F8o8B78zvfwpIwAb59BeAS/L7RwNn9bHN99eZv3q+vsGFebcDh/VR/7HA8TXzLgUOze+PB77Q4LGjgYnA14CngSeBzzXxnJ0G/Bq4EngReD+wMnAh8AzwH+DgvOyOwH+B14CZwD/y+UOB3+XbnAR8HxiUL1sbuJ7sQ/5Z4Pf5/Bvy5+fFfF179u5DzXN7WP73nA78HlissPzr+TYn53+vBKzd5GulB/hW/hp4GjgDGFrzt/ss8Hhe7282WM9WwFO9+5vP2xW4J7+/BXALMC2v64nAIoWyc+qc/y2+X1h2eGH/9qsp+yGyL5IZwBPA0YXHPZ6XnZnftgb2BW4qlNmG7PU4Pf9/m8Ky8cD3gJvJ3jfXAMv38VwuzHquBVwHPJc/72eTNfJ7H3ME2WvsBeBBYPvC37P3vf4ccD4wrNF2mnyNfCav81eAe2uWDQNOzfd5KvlnRb5sF+DufJ8fBnas91lB4XOFN15zn8/re0M+/wKy19d0svfMhoXHLw78lOw1PB24KZ93BXBQTX3vAT7Wz/6uS/a5uXRh3o3AAU08V6sDs4E1+igzgzc+b48FziksW4vss2XpfHoS8IHC8u8B5+X3P5Avj5rXUu/zfA5wbGHZ9sBTzfzNvXXm1vEKtGUnsw+Au4GRwOL5vD3IvnB7yL4EXwTemi87A/hafn9c/mHypcKyQ/L7cz5IGmyzzwYKEMC7yX4lbN9H/UeRfSBGPr0c8DKwcj49nqzR8CzZl8fowmNHA7OAY4AhwM759pbr5zk7Lf9we3f+HC0B/B34DrAI2a+PR4APNnougEvIfg0tCawI3Absny87l+yXWA+wGLBt4XFzNSio30C5Lf/7DQPuJ/+wJGssPQVsmNf5zNr19bPf+wEP5fu3FHARcGbN3+63ZB/4m5B9cL+twboeBnYoTF8AHJnffydZI2Zwvt77ga/Wew4oNFDy/ZsCbJQ/r+fUlB0NvD1/XjfOy36s9rVX2M6+5A2U/LmcSvbrdTBZujcVeEvhdfYw2RfW4vn0jxrs+8Ku59rADsCiwApkX8on5MvWI3t/rFx4/Fr5/a8CtwKr5I/9DXBuo+00+Rq5Fvgx2S/8WcBmhWVXkDWYlyN7v703n78F2ftph3yfRwDr1/usoH4D5Yz8eez9/NoPWDrfpxOAuwuP/1X+txkBDCJrdC4KfAL4W6HcJmSNtkXIUoqTGuzvrsD9NfNOBH7ZxHP1HWB8H8s3BV7hjR8BlwJH1JSZSfZ+WS5/LoYXlu0O/DO/fwjwp5rH/pE3Psv/AexZWLZ8vr63zMvf31v7bh2vQFt2MvsA2K+fMncDu+T3Pw9clt+/n+xXeG8r/bHeDyT6b6DMJPuFPI03UpfeD5xpZB/+95MnEX3ULch+CYzKp78IXFdYvmXhw+qzZL8iez+gR5M1Zoof9k8DW/WzzdOAM2q28XhNmW8Ap9Z7Lsg+vF8l/0DN530S+Et+/wyyxt8qdbbdTAPlU4XpHwNj8/unAD8sLFu7dn397Pe1wJcL0+uRJUO9DYlUrDNZQ2mvBuv6PnBKfn9pskbwag3KfhW4uN5zwNwNlFMoNArIGgsN94/sy+vnNa+9Rg2UTwO31Tz+FmDf/P544FuFZV8Grmqw3YVazzrlPwbcVfgbP02W8g2pKXc/hcY/8NY6f8+mGyjAqsDrwKb59NXALwrrfp06jX+yhtHPG6zzUfpvoKzZR52WzcsMJWv8vAxsUqfcosDzwDr59PE0aJTUPO7TwK01834AnNbEYx/qff3UWbYM8E/gG4V511KTzJClIqPJfmAm5k5LdwAeze9/m/xzurD8bPJ0jkJqlU8Pyde3erN/f2/tvXXTGJQnihMR8ZmIuDsipkXENLJfesvni68H3hMRK5H9Avk98O6IWJ3sQ+DuJrf5sZTSsvntYzXLlk8pLZdSeltK6X/7WknK3k3nkX3BA+xN9sbrXf63lNILKaVXU0qnk6UoOxdW8VxKaVZh+iWydKA/xedsNWDl3ucrf87+H1lDpJ7VyD4AniyU/w1ZkgJZN0wAt0XEfRGxXxP1KXqqcL+4PyvX1HvO/YhYtTh4r8F6VyZrhPZ6jOzLrLifjbZd6xzg4/lAvI8Dd6aUHsvrsm5E/DEfsDeDLNpevsF6autX3L9iXYmILfPBjM9ExHTggCbX27vux2rmPUb2S7xXs/u+UOuZD648LyIm5c/XWb3lU0oPkTXwjgaezsv1Dl5dDbi48Bq8n6zLodHrtj+fJksT7s6nzwb2joghZF+gz6eUptZ53EiyL8j5VXwdD4qIH0XEw/lz8Wi+aPn8tli9baWUXiXr4vpURPSQfZ6c2cS2Z5I1JoqWIfsh1FBEbAusBPyhzrLFgcvJGj4/bHJbMwvT9erRXz1rl/fe73M/1Dnd1EBJvXciYjWymP5AsnhvWeBesi/M3g+8l4CDyfp8XyD7YB5D9mvz9fZWHci6RHbP674l2ViQRhL5viygVLj/BPCfQoNr2ZTS0imlneuU7S3/KllDrLf8MimlDQFSSk+llL6YUloZ2B84KRbOIahPksX5vUbO2ZmUHk9zD96rZzLZl1qvVcli/CnzWpGU0gSyL+adyBqV5xQW/xp4gOzX7DJkjb1m/mZPUtinvH5F5wCXASNTSkPJxi/1rrf2b1Srdt971z+piXq1up4/zOdvnD9fnyqUJ6V0Tkpp27z+CTguX/QEsFPN63axlNKkBtvpz2eANfOG5VPAz8gaBTvl2xoWEcvWedwTZOMp6nmRrDuy10p1yhTrujfZeJb3k/1gWj2fH2TdvK/0sa3TyQb2bg+8lFK6pUG5ovvI9nnpwrxN8vl9+SxwUUpprh8DeYP9ErLX1f51trVJoeyaZMnPv/KG35PF5TX1uA/YOCKK76ONa5bXPnZKSum5fvZDHdJNDZSiJcne8M8ARMTnyBKUouvJGjDX59Pja6Z79UTEYoVbSw5bSyndldf3ZODqlNK0vO7LRsQH820Pjoh9yMasXL2Qq3AbMCMijoiIxfNfcRtFxLvy5VOA1fNfZqSUniQbRPnTiFgmInoiYq2IeG9e7z0iorchMZXs7zG7sK4157Oe5wOfi4i3RcQSZH3g8+Jc4JCIWCM/suBYsgG8s/p5XCPnkDV0R/HGkQyQdfnMAGZGxPrAl5pc3/nAvhGxQb5/R9UsX5rsV/wrEbEF2ZdZr2fIuiAaPbdXAuvmh3kOjog9gQ3I+vHn1cKu59LkXaYRMYJsAC4AEbFeRGyXv/deIevi6H0tjQV+kDfsiYgVImKXPrbTUET0DtbdgmzsxKZknxvnAJ/NX/N/ImtsLxcRQyJiVP7w35G9LrfP3wsj8r87ZInsXnn5zcnGVfRlabLG/3NkDZtjexfkP55OAX4W2WkNBkXE1r2fS3mD5HWyQbTNpCeklP6V1/Go/HNmV7Iv/oY/kvKEZA+y7sni/CFkicrLwGfq/Ng7G/hIZOc+WpJs7NxF+Y9EyLqGv5U/v+uTdXf3bmM82d/94MgORz4wn39d4bGfz1+Ty5ENhp+rfiqZTvcxteNGnQGrZH2oz5P94vgZWcPjC4Xl+5N9aa6WT384n96yUObofF7xNrHRNvP5qzMfA/Pyx347f+wehXkrkB1t8QLZuJZbmXtg5mgK4zf6qltNmdMoHDmSz1uZ7Av8KbJGxa296yE7/PCmfP6d+byhZEnBRLIBgneRj9cgGzcyiexL52FgTGE7B5D9UppGNrBvrn2orT9vHv/yjbyOk8m++BPZL/VmnuMeskbNE2RfYGeRjymo97ejjyOo8uW9YxauqJk/iixBmUl2RMQxzH00zZzxGrV/C7KjUnr3r/bomN3JUpsXyBoWJ9Y8N8fk+zWNbJDuvjXb3ZZsMPT0/P9tG+1r7WPr7PvCrOeGeX1mkn1Zfo033msbkzWgXyB7T/+RNwbM9gCHkh3Z8wLZa+3YPrbzHmBmg/0ZC1xYZ/4WZA2GYbxx6OwUsvfCRYVyu5IdNfMC2diM3gHmawJ/y/ftCuB/efMYlOJrbimywaQv5M/hZ2qe28XJxvRM4o2jfIpjwb5FzbiWfN/G9vG3XD3/+7+cP5fF99+bnjOy7qPHKBxRk89/b77tl3jj6KmZwHsKZfYmG3P3Yr6fwwrLFiVrgM3In+NDa9b/jvx18jJwJ/COmuWH5o+bQXa01aLNfC5468yt96gQaUCKiLeRdd8tmuY/BZEGjIj4DNkPgm07XRepL93axaMBLCJ2jYhF8hj3OOByGycS5N1tXyY7gk4qNRsoJZH3uc6sd2vhNu9rsM22nh2zBfYni+0fJuuTbnZ8hzRgRXYm1WfIujjO6ae41HF28UiSpNIxQZEkSaXTqQtP9WvxdxxotCO1wNTbT+x0FaQBabHBC+X8U01p53fky3ed2Lb9KjJBkSRJpVPaBEWSJDUQAz9fGPh7KEmSKscGiiRJKh27eCRJqproyLjVtjJBkSRJpWOCIklS1ThIVpIkqf1MUCRJqhrHoEiSJLWfCYokSVXjGBRJkqT2M0GRJKlqHIMiSZLUfiYokiRVjWNQJEmS2s8ERZKkqnEMiiRJUvuZoEiSVDWOQZEkSWo/ExRJkqrGMSiSJEntZ4IiSVLVOAZFkiSp/WygSJKk0rGLR5KkqnGQrCRJUvuZoEiSVDUOkpUkSWo/ExRJkqrGBEWSJKn9TFAkSaqaHo/ikSRJajsTFEmSqsYxKJIkSe1ngiJJUtV4JllJkqT2M0GRJKlqHIMiSZLUfiYokiRVjWNQJEmS2s8ERZKkqnEMiiRJUvuZoEiSVDWOQZEkSWo/GyiSJKl07OKRJKlqHCQrSZLUfiYokiRVjYNkJUmS2s8ERZKkqnEMiiRJUvuZoEiSVDWOQZEkSWo/ExRJkqrGMSiSJEntZ4IiSVLVmKBIkiS1nw0USZKqJqJ9t36rEjtGxIMR8VBEHFln+eERcXd+uzciZkfEsP7WawNFkiTNl4gYBPwK2AnYAPhkRGxQLJNS+klKadOU0qbAN4DrU0rP97dux6BIklQ15RmDsgXwUErpEYCIOA/YBZjQoPwngXObWXFp9lCSJJVPRIyJiDsKtzGFxSOAJwrTE/N59dazBLAjcGEz2zVBkSSpatp4JtmU0jhgXKOa1HtIg7IfAW5upnsHTFAkSdL8mwiMLEyvAkxuUHYvmuzeARMUSZKqpzxjUG4H1omINYBJZI2QvWsLRcRQ4L3Ap5pdsQ0USZI0X1JKsyLiQOBqYBBwSkrpvog4IF8+Ni+6K3BNSunFZtdtA0WSJM23lNKVwJU188bWTJ8GnDYv67WBIklS1bRxkGynlKYTS5IkqZcJiiRJFRMmKJIkSe1ngiJJUsWYoEiSJHWACYokSVUz8AMUExRJklQ+JiiSJFWMY1AkSZI6wARFkqSKMUGRJEnqABMUSZIqxgRFkiSpA0xQJEmqGBMUSZKkDjBBkSSpagZ+gGKCIkmSyscERZKkinEMiiRJUgfYQJEkSaVjF48kSRVjF48kSVIHmKBIklQxJiiSJEkdYIIiSVLFmKBIkiR1gAmKJElVM/ADFBMUSZJUPiYokiRVjGNQJEmSOsAERZKkijFBkSRJ6gATFEmSKsYERZIkqQNMUCRJqpqBH6CYoEiSpPIxQZEkqWIcgyJJktQBJiiSJFWMCYokSVIH2ECRJEmlYxePJEkVYxePJElSB5igSJJUMSYokiRJHWCCIklS1Qz8AMUERZIklY8JiiRJFeMYFEmSpA4wQZEkqWJMUCRJkjrABEWSpIoxQZEkSeoAExRJkqpm4AcoJiiSJKl8TFAkSaoYx6BIkiR1gAmKJEkVY4IiSZLUASYokiRVjAmKJElSB9hAkSRJpWMXj/q0wzZv4/jDd2dQTw+nXfJXjj/1z3MtP+Qz27Pnzu8CYPCgHtZfYyVGbnckU2e8xNClFufXR+3NBmu9lZTggO+ezd/u+U8ndkMqnZtvvIHjfvQDXp/9Orvutgef/+KYuZZf8cfLOPV3vwVgiSWW5JvfPpr11l9/zvLZs2fzyU/sxorDh3PiSb9pa93Ved3QxWMDRQ319AQnHPkJPvSlE5k0ZRo3nX04f7z+nzzwyFNzyvz8jGv5+RnXArDzqI04aJ/3MXXGSwAc//XdueavE9j78N8xZPAgllhskY7sh1Q2s2fP5tgfHMNvfnsqw4cPZ+89d2f0+7ZjrbXXnlNmxIhVOOW0s1hm6FBuuvF6jjn625x93gVzlp995hmsueZazHxxZid2QWq5lnbxRMSHI8JupIp610ar8/ATz/LopOd4bdZsLrj6Tj48euOG5T+x4+acf9XfAVh6ycXYdrO1OO3iWwB4bdZsps98uS31lsru3n/ew8iRq7HKyJEMWWQRdtz5Q4z/y7Vzldn0HZuxzNChAGy88aZMmfLGD4MpTz3FjTeMZ9fddm9rvVUi0cZbh7S68bAX8O+I+HFEvK3F29JCtvKKQ5k4Zeqc6UlTpjJihaF1yy6+2BB22OZtXHLt3QCsMeItPDt1JuO++yluOfcITvrO3iYoUu7pKVNY6a0rzZlecfhwpkyZ0rD8xRf9gW3fM2rO9I9/dCyHfO1wenr8/aeBq6Wv7pTSp4B3AA8Dp0bELRExJiKWrlc+X3ZHRNwx69n7Wlk1NSHqNJ1Tg7IfGvV2brn7kTndO4MHD2LT9Ufy2wtuZOtPHsdLL7/KYfvt0MLaStWR6ryTGo0puO1vt3LxRX/gq4ceBsD14//CsGHD2GDDjVpaR5VbRLTt1iktb36nlGYAFwLnAW8FdgXujIiD6pQdl1LaPKW0+eDlN2x11dSPSU9PY5Xhy82ZHjF8OSY/M71u2T0++E4uyLt3IEtbJj09jdvvfQyAi//vbjZdf2RrKyxVxPDhK/HUk2902Tw9ZQorrrjim8r968EH+O5R3+KEX57Esstm78W777qT8eOvY6cdtuOIww7l9r/dyjeOOKxtdZfapdVjUD4SERcD1wFDgC1SSjsBmwC+o0rujvseY+1VV2C1ld/CkMGD2OODm3HF+HveVG6ZpRZj23euzeWFZVOee4GJT01lndWyD93RW6w31+BaqZttuNHbefzxR5k48Qle++9/uerKK3jv+7abq8yTkydz6FcO4gc//DGrr77GnPlfOeRr/Pm6G/jTn6/juON/xru23IofHnd8u3dBHdYNCUqrj+LZA/h5SumG4syU0ksRsV+Lt60FNHv26xxy3PlcftL/MKgnOP3SW7n/kaf4wu7bAnDyH24C4KPv24Rrb32Al17571yPP/S4Czj12H1ZZPAgHp30LGOOOqvt+yCV0eDBg/nGN7/Dl8Z8gddfn83Hdt2Ntddeh/N/fy4An9jzk/xm7K+YNn0ax37vuwAMGjyIc8+/qJPVltoqUmo0qqCzFn/HgeWsmFRxU28/sdNVkAakxQa375iXtQ/7U9u+Ix86fqeOxCit7uL5eET8OyKmR8SMiHghIma0cpuSJKn6Wt3F82PgIyml+1u8HUmSukY3nEm21UfxTLFxIkmS5lVLEpSI+Hh+946I+D1wCfBq7/KUkiO9JEmaT10QoLSsi+cjhfsvAR8oTCfABookSWqoJQ2UlNLnACLi3Smlm4vLIuLdrdimJEndwjEoC+6XTc6TJEmao1VjULYGtgFWiIhDC4uWAQa1YpuSJHWLLghQWjYGZRFgqXz9xQsDzgC8PrgkSepTq8agXA9cHxGnpZQea8U2JEnqVj09Az9CaVUXz+VkR+vUHciTUvpoK7YrSZIGhlZ18XhpTUmSNN9a2cUjSZJawEGyCygi1gF+CGwALNY7P6W0Ziu3K0mSqq3VFws8FTgK+DnwPuBz0L7LUUuSNBB5orYFt3hK6VogUkqPpZSOBrZr8TYlSVLFtTpBeSUieoB/R8SBwCRgxRZvU5KkAa0LApSWJyhfBZYADgbeCXwK+GyLtylJkiqupQlKSul2gIhIvRcQlCRJC8YxKAsoIraOiAnA/fn0JhFxUiu3KUmSqq/VY1BOAD4IXAaQUvpHRIxq8TYlSRrQTFAWgpTSEzWzZrd6m5IkqdpanaA8ERHbACkiFiEbLHt/i7cpSdKA1gUBSssTlAOA/wFGABOBTfNpSZI0AETEjhHxYEQ8FBFHNigzOiLujoj7IqKpy+G0+iieZ4F9WrkNSZK6TVnGoETEIOBXwA5kQcTtEXFZSmlCocyywEnAjimlxyOiqfOhtaSBEhG/BFKj5Smlg1uxXUmS1FZbAA+llB4BiIjzgF2ACYUyewMXpZQeB0gpPd3MiluVoNxRuP9dsuvxSJKkhaCdAUpEjAHGFGaNSymNy++PAIoHw0wEtqxZxbrAkIgYDywN/CKldEZ/221JAyWldHrv/Yj4anFakiRVR94YGddgcb2mUm0PymCys8lvDywO3BIRt6aU/tXXdlt9FA/00dUjSZLmXVnGoJAlJiML06sAk+uUeTal9CLwYkTcAGwC9NlAafl5UCRJ0oB1O7BORKyRn05kL/KTsxZcCrwnIgZHxBJkXUD9nnKkVYNkX+CN5GSJiJjRuwhIKaVlWrFdSZK6QVkClJTSrIg4ELgaGAScklK6LyIOyJePTSndHxFXAfcArwMnp5Tu7W/drRqDsnQr1itJksolpXQlcGXNvLE10z8BfjIv67WLR5IklU47BslKkqSFqESDZFvGBEWSJJWOCYokSRXTBQGKCYokSSofExRJkirGMSiSJEkdYIIiSVLFdEGAYoIiSZLKxwRFkqSKcQyKJElSB5igSJJUMV0QoJigSJKk8jFBkSSpYhyDIkmS1AEmKJIkVUwXBCgmKJIkqXxMUCRJqhjHoEiSJHWACYokSRVjgiJJktQBNlAkSVLp2MUjSVLFdEEPjwmKJEkqHxMUSZIqxkGykiRJHWCCIklSxXRBgGKCIkmSyscERZKkinEMiiRJUgeYoEiSVDFdEKCYoEiSpPIxQZEkqWJ6uiBCMUGRJEmlY4IiSVLFdEGAYoIiSZLKxwRFkqSK8TwokiRJHWCCIklSxfQM/ADFBEWSJJWPCYokSRXjGBRJkqQOsIEiSZJKxy4eSZIqpgt6eExQJElS+ZigSJJUMcHAj1BMUCRJUumYoEiSVDGeqE2SJKkDTFAkSaoYT9QmSZLUASYokiRVTBcEKCYokiSpfExQJEmqmJ4uiFBMUCRJUumYoEiSVDFdEKCYoEiSpPIxQZEkqWI8D4okSVIHmKBIklQxXRCgmKBIkqTyMUGRJKliPA+KJElSB9hAkSRJpWMXjyRJFTPwO3hMUCRJUgmZoEiSVDGeqE2SJKkDTFAkSaqYnoEfoJigSJKk8jFBkSSpYhyDIkmS1AEmKJIkVUwXBCgmKJIkqXxMUCRJqphuGIPSsIESEb8EUqPlKaWDW1IjSZLU9fpKUO5oWy0kSVLTuuE8KA0bKCml04vTEbFkSunF1ldJkiR1u34HyUbE1hExAbg/n94kIk5qec0kSVJdEdG2W6c0cxTPCcAHgecAUkr/AEa1sE6SJKnLNXUUT0rpiZpW1OzWVEeSJPWnC4agNNVAeSIitgFSRCwCHEze3SNJktQKzTRQDgB+AYwAJgFXA//TykpJkqTGerr5PCi9UkrPAvu0oS6SJElAc0fxrBkRl0fEMxHxdERcGhFrtqNykiSpOzVzFM85wPnAW4GVgQuAc1tZKUmS1FhE+26d0kwDJVJKZ6aUZuW3s+jjFPiSJEkLqq9r8QzL7/4lIo4EziNrmOwJXNGGukmSpDq6+mKBwN/JGiS9z8L+hWUJ+F6rKiVJkrpbX9fiWaOdFZEkSc3pggCluTPJRsRGwAbAYr3zUkpntKpSkiSpu/XbQImIo4DRZA2UK4GdgJsAGyiSJHVAN5yorZmjeHYHtgeeSil9DtgEWLSltZIkSV2tmS6el1NKr0fErIhYBnga8ERtkiR1SBcEKE0lKHdExLLAb8mO7LkTuK2VlZIkSdUQETtGxIMR8VB+WpLa5aMjYnpE3J3fvtPMepu5Fs+X87tjI+IqYJmU0j3zVn1JkrSwlOU8KBExCPgVsAMwEbg9Ii5LKU2oKXpjSunD87Luvk7Utllfy1JKd87LhiRJ0oCzBfBQSukRgIg4D9gFqG2gzLO+EpSf9rEsAdst6Mb78tBfftbK1Utda7mP/qLTVZAGpJev/ErbttXM+IyFJSLGAGMKs8allMbl90cATxSWTQS2rLOarSPiH8Bk4LCU0n39bbevE7W9r99aS5KkAS1vjIxrsLheX1Pt9fruBFZLKc2MiJ2BS4B1+ttuOxthkiRpIYiItt36MREYWZhehSwlmSOlNCOlNDO/fyUwJCKW72/FNlAkSdL8uh1YJyLWiIhFgL2Ay4oFImKlyFs6EbEFWdvjuf5W3NSp7iVJUnn0lOMgHlJKsyLiQOBqYBBwSkrpvog4IF8+luyEr1+KiFnAy8BeKaXabqA3aeZU9wHsA6yZUjomIlYFVkopeS4USZK6XN5tc2XNvLGF+ycCJ87reptJUE4CXic7aucY4AXgQuBd87oxSZK04MqSoLRSMw2ULVNKm0XEXQAppal5P5MkSVJLNNNAeS0/U1wCiIgVyBIVSZLUAWU5k2wrNXMUz/8CFwMrRsQPgJuAY1taK0mS1NWauRbP2RHxd2B7shOyfCyldH/LayZJkrpWM0fxrAq8BFxenJdSeryVFZMkSfU5SDZzBdn4kwAWA9YAHgQ2bGG9JElSF2umi+ftxen8Ksf7t6xGkiSpT10wRnbeT3WfUroTz4EiSZJaqJkxKIcWJnuAzYBnWlYjSZLUp54uiFCaGYOydOH+LLIxKRe2pjqSJEn9NFDyE7QtlVI6vE31kSRJ/Zjn8RkV1HAfI2JwSmk2WZeOJElS2/SVoNxG1ji5OyIuAy4AXuxdmFK6qMV1kyRJdXTBEJSmxqAMA54ju5px7/lQEmADRZIktURfDZQV8yN47uWNhkmv1NJaSZKkhrr9KJ5BwFLM3TDpZQNFkiS1TF8NlCdTSse0rSaSJKkpXRCg9HmkUhfsviRJKqO+EpTt21YLSZLUtG64mnHDBCWl9Hw7KyJJktSrmcOMJUlSiXTDUTzdcLZcSZJUMSYokiRVTBcEKCYokiSpfGygSJKk0rGLR5Kkiunqw4wlSZI6xQRFkqSKiS442bsJiiRJKh0TFEmSKsYxKJIkSR1ggiJJUsWYoEiSJHWACYokSRUTXXCuexMUSZJUOiYokiRVjGNQJEmSOsAERZKkiumCISgmKJIkqXxMUCRJqpieLohQTFAkSVLpmKBIklQxHsUjSZLUASYokiRVTBcMQTFBkSRJ5WMDRZIklY5dPJIkVUwPA7+PxwRFkiSVjgmKJEkV4yBZSZKkDjBBkSSpYjxRmyRJUgeYoEiSVDFeLFCSJKkDTFAkSaqYLghQTFAkSVL5mKBIklQxjkGRJEnqABMUSZIqpgsCFBMUSZJUPiYokiRVTDekC92wj5IkqWJMUCRJqpjogkEoJiiSJKl0TFAkSaqYgZ+fmKBIkqQSsoEiSZJKxy4eSZIqxlPdS5IkdYAJiiRJFTPw8xMTFEmSVEImKJIkVUwXDEExQZEkSeVjgiJJUsV4qntJkqQOMEGRJKliuiFd6IZ9lCRJFWOCIklSxTgGRZIkqQNMUCRJqpiBn5+YoEiSpBIyQZEkqWIcgyJJktQBJiiSJFVMN6QL3bCPkiSpYkxQJEmqGMegSJIkdYANFEmSVDp28UiSVDEDv4PHBEWSJJWQCYokSRXTBWNkTVAkSVL5mKBIklQxPV0wCsUERZIkzbeI2DEiHoyIhyLiyD7KvSsiZkfE7s2s1wRFkqSKKcsYlIgYBPwK2AGYCNweEZellCbUKXcccHWz6zZBkSRJ82sL4KGU0iMppf8C5wG71Cl3EHAh8HSzK7aBIklSxUQ7/0WMiYg7CrcxhaqMAJ4oTE/M571R14gRwK7A2HnZR7t4JElSQymlccC4BovrdTalmukTgCNSSrPn5RpCNlAkSaqYsoxBIUtMRhamVwEm15TZHDgvb5wsD+wcEbNSSpf0tWIbKJIkaX7dDqwTEWsAk4C9gL2LBVJKa/Tej4jTgD/21zgBGyiSJFVOWc6DklKaFREHkh2dMwg4JaV0X0QckC+fp3EnRTZQJEnSfEspXQlcWTOvbsMkpbRvs+u1gSJJUsWUaAxKy3iYsSRJKh0TFEmSKsYERZIkqQNMUCRJqpgoyVE8rWSCIkmSSscGiiRJKh27eCRJqpiegd/DY4IiSZLKxwRFkqSKcZCsJElSB5igSJJUMZ6oTZIkqQNMUCRJqhjHoEiSJHWACYokSRXjeVAkSZI6wARFkqSKcQyKJElSB5igSJJUMZ4HRZIkqQNMUNSn2265iRN/dhyvvz6bnT/6cfb+7BfmWv5/V/2R8848BYDFFl+CQ77+bdZadz0ALjzvLK649EJSSnxol93Y/ZOfbnv9pbLa4Z2rcfz+72VQT3Da1fdx/AV3zLX8kN02Y8/R6wMweFCw/shhjPzkOKbOfJWxX30/O22xBs9Me4nNv3x2J6qvDuuCAMUERY3Nnj2bX/zkB/zohJM49bxLue6aP/HoIw/PVWallVfh578+lZPPvohP77c/P/3RdwH4z8P/5opLL+SkU8/h5LP+wK03X8/Exx/rxG5IpdPTE5zw5dHs8p1LeMcBZ7LHe9dl/ZHD5irz8wvvZKuDzmGrg87hO6f9lRvvncTUma8CcOb/TWCXb1/SgZpL7WMDRQ09MOGfjFhlVVYeMZIhQ4aw3Q478dcb/jJXmY023pSllxkKwAYbbcwzT08B4LFHH2GDjTZmscUWZ9DgwWzyjs256fpr274PUhm9a93hPDx5Oo8+NYPXZr3OBTf8iw9vvWbD8p8YvR7nj39wzvTN907m+RdeaUdVVVI9EW27dWwfW7nyiFi0zrxh9cqqfJ59+mlWHL7SnOnlVxzOM89MaVj+yssuZsuttwVgjTXX4Z67/s706dN45ZWX+dtfb+TpKU+1vM5SFaz8lqWY+OwLc6YnPTuTEW9Zqm7ZxRcdzA7vXI1Lbn6oXdWTSqHVCcpFETGkdyIi3gr8uVHhiBgTEXdExB1nnXZyi6um/iTSm+ZFg9b0XXfcxp8uv4gvHngIAKutsSZ7fWY/Dj9oDEd85QDWWmc9Bg0a1NL6SlVR722U0pvfbwAf2nINbpkweU73jgTZGJR23Tql1YNkLwEuiIjdgJHAZcBhjQqnlMYB4wAmTftv/Xer2maFFYfPlXo8+/QUll9+xTeVe/jfD3L8sUfxoxN+zdChy86Zv/NHP87OH/04ACef9AtWWHF4y+ssVcGkZ2eyyvJLz5kesfxSTH7+xbpl9xi1Lhdc/692VU0qjZYmKCml35IlJpcAlwMHpJSuaeU2tfCs/7aNmPTEYzw5eSKvvfYa1/35T2w9avRcZaY89SRHHXkI3zj6h4xcdfW5lk19/rk5ZW4c/39s94Gd2lRzqdzu+NcU1l55WVYbvgxDBvewx6h1ueLWR95UbpklFmHbt6/C5bc8XGct0sDWkgQlIg4tTpKlJ3cDW0XEVimln7Viu1q4Bg0ezEGH/T+OOPgAZr8+m50+sitrrLk2l110PgAf/fgnOPN3Y5kxfRq/+PH3s8cMGsTY038PwNFHHsqM6dMYNHgwXzn8m3MG00rdbvbriUN+PZ7Lv/8xBvUEp18zgfsff54v7Px2AE6+8p8AfHSbtbj2zsd46dVZcz3+9K/vyHs2XoXll1mMh87Yj++d9TdOv+a+tu+HOqgLjjOORv2eC7TSiKP6Wp5S+m5/67CLR2qNtff+daerIA1IL1/5lbY1G259eFrbviO3WmvZjjSHWpKgNNMAkSRJ88eLBS6giPhzRCxbmF4uIq5u5TYlSVL1tfoonhVSStN6J1JKUyPizYeBSJKkpnmxwAU3OyJW7Z2IiNWgzsk1JEmSClqdoHwTuCkirs+nRwFjWrxNSZIGtC4IUFrbQEkpXRURmwFbkT2fh6SUnm3lNiVJUvW16jwo66eUHsgbJwCT8/9XjYhVU0p3tmK7kiR1hS6IUFqVoBxK1pXz08K84tiT7Vq0XUmSNAC06jwoveNMfg1clVKaERHfBjYDvteKbUqS1C08D8qC+1beONkW2AE4jazRIkmS1FDLDzPO//8QMDaldCmwSIu3KUnSgBbRvluntLqBMikifgN8ArgyIhZtwzYlSVLFtbqx8AngamDH/Iyyw4DDW7xNSZIGtGjjrVNafR6Ul4CLCtNPAk+2cpuSJKn6Wn0mWUmStLAN/IN4HA8iSZLKxwRFkqSK8TwokiRJHWADRZIklY5dPJIkVUwnT6DWLiYokiSpdExQJEmqmC4IUExQJElS+ZigSJJUNV0QoZigSJKk0jFBkSSpYjxRmyRJUgeYoEiSVDGeB0WSJKkDTFAkSaqYLghQTFAkSVL5mKBIklQ1XRChmKBIkqTSMUGRJKliPA+KJElSB5igSJJUMZ4HRZIkqQNMUCRJqpguCFBMUCRJUvnYQJEkSaVjF48kSVXTBX08JiiSJKl0TFAkSaoYT9QmSZLUASYokiRVjCdqkyRJ6gATFEmSKqYLAhQTFEmSVD4mKJIkVU0XRCgmKJIkqXRMUCRJqhjPgyJJktQBJiiSJFWM50GRJEnqABMUSZIqpgsCFBMUSZJUPiYokiRVTRdEKCYokiSpdExQJEmqGM+DIkmS1AE2UCRJUunYxSNJUsV4ojZJkqQOMEGRJKliuiBAMUGRJEnlYwNFkqSqiTbe+qtKxI4R8WBEPBQRR9ZZvktE3BMRd0fEHRGxbTO7aBePJEmaLxExCPgVsAMwEbg9Ii5LKU0oFLsWuCyllCJiY+B8YP3+1m0DRZKkiinRidq2AB5KKT0CEBHnAbsAcxooKaWZhfJLAqmZFdvFI0mSGoqIMXnXTO9tTGHxCOCJwvTEfF7tOnaNiAeAK4D9mtmuCYokSRXTzvOgpJTGAeMaVaXeQ+qs42Lg4ogYBXwPeH9/2zVBkSRJ82siMLIwvQowuVHhlNINwFoRsXx/K7aBIklSxZToIJ7bgXUiYo2IWATYC7hsrrpGrB2RZT4RsRmwCPBcfyu2i0eSJM2XlNKsiDgQuBoYBJySUrovIg7Il48FdgM+ExGvAS8De6aU+h0oawNFkqSKKdO1eFJKVwJX1swbW7h/HHDcvK7XLh5JklQ6JiiSJFVOiSKUFjFBkSRJpWOCIklSxZRpDEqrmKBIkqTSMUGRJKliuiBAMUGRJEnlYwNFkiSVjl08kiRVjINkJUmSOsAERZKkiokuGCZrgiJJkkrHBEWSpKoZ+AGKCYokSSofExRJkiqmCwIUExRJklQ+JiiSJFWM50GRJEnqABMUSZIqxvOgSJIkdYAJiiRJVTPwAxQTFEmSVD4mKJIkVUwXBCgmKJIkqXxMUCRJqhjPgyJJktQBJiiSJFWM50GRJEnqABsokiSpdOzikSSpYhwkK0mS1AE2UCRJUunYQJEkSaXjGBRJkirGMSiSJEkdYIIiSVLFeKI2SZKkDjBBkSSpYhyDIkmS1AEmKJIkVUwXBCgmKJIkqXxMUCRJqpouiFBMUCRJUumYoEiSVDGeB0WSJKkDTFAkSaoYz4MiSZLUASYokiRVTBcEKCYokiSpfGygSJKk0rGLR5KkqumCPh4TFEmSVDomKJIkVYwnapMkSeoAExRJkirGE7VJkiR1QKSUOl0HDQARMSalNK7T9ZAGGt9b6lYmKFpYxnS6AtIA5XtLXckGiiRJKh0bKJIkqXRsoGhhsY9cag3fW+pKDpKVJEmlY4IiSZJKxwaKJEkqHRsoXSwiZtZM7xsRJ87nukZHxB8L97cpLDstInZfsNpK3SEiTo6IDfpYfnREHNbOOkmd4Knu1QqjgZnAXztcD6lyUkpf6HQdpDIwQVFdEbFCRFwYEbfnt3fn87eIiL9GxF35/+vVPG514ADgkIi4OyLeky8alZd/pDdNiYgzI2KXwmPPjoiPtmcPpc6LiCUj4oqI+EdE3BsRe0bE+IjYPF++Y0TcmS+/ts7jvxgRf4qIxdtfe6m1TFC62+IRcXdhehhwWX7/F8DPU0o3RcSqwNXA24AHgFEppVkR8X7gWGC33hWklB6NiLHAzJTS8QAR8XngrcC2wPr5Nv4AnAwcAlwaEUOBbYDPtmpnpRLaEZicUvoQQP4++FJ+fwXgt2Tvt/9ExLDiAyPiQOADwMdSSq+2t9pS69lA6W4vp5Q27Z2IiH2BzfPJ9wMbxBuXzFwmIpYGhgKnR8Q6QAKGNLmtS1JKrwMTImI4QErp+oj4VUSsCHwcuDClNGsB90mqkn8Cx0fEccAfU0o3Ft5zWwE3pJT+A5BSer7wuE8DE8kaJ6+1s8JSu9hAUSM9wNYppZeLMyPil8BfUkq75t0545tcX/EXXvFC4WcC+wB7AfvNd22lCkop/Ssi3gnsDPwwIq4pLA6yHwH13AtsCqwC/KellZQ6xDEoauQa4MDeiYjYNL87FJiU39+3wWNfAJZucjunAV8FSCndN29VlKotIlYGXkopnQUcD2xWWHwL8N6IWCMvW+ziuQvYH7gsX4c04NhAUSMHA5tHxD0RMYFs4CvAj8l+6d0MDGrw2MuBXWsGydaVUpoC3A+cupDqLVXJ24Hb8rFg3wS+37sgpfQM2ZWML4qIfwC/Lz4wpXQTcBhwRUQs37YaS23iqe7VURGxBFk//GYppemdro8kqRxMUNQx+VFADwC/tHEiSSoyQZEkSaVjgiJJkkrHBookSSodGyiSJKl0bKBILRYRs/NDru+NiAvyI5fmd11zrgzdxFVv57qq9Dxs49F6h602ml9TZmZfy+uU98q8kuqygSK13ssppU1TShsB/+WNc8oAEBGNzifTp5TSF1JKE/ooMprs+kaSVDk2UKT2uhFYO083/hIR5wD/jIhBEfGT/MrR90TE/gCROTEiJkTEFcCKvSvq66q39a4q3ccVqt8SEdfkV6j+DXNfiqCuiLgkIv4eEfdFxJiaZT/N63JtfsE7ImKtiLgqf8yNEbH+Qnk2JQ1YXotHapOIGAzsBFyVz9oC2Ci/Uu0YYHpK6V0RsShwc35dlncA65GdcXQ4MAE4pWa9b7rqbUrp+TpXlT6H+leoPgq4KaV0TER8iOzspf3ZL9/G4sDtEXFhSuk5YEngzpTS1yLiO/m6DwTGAQeklP4dEVsCJwHbzcfTKKlL2ECRWm/x/FTmkCUovyPrermt90q1wAeAjXvHl5Bd82gdYBRwbkppNjA5Iq6rs/6+rnpb1OgK1aPIriZNSumKiJjaxD4dHBG75vdH5nV9DnidN07JfhbZadqXyvf3gsK2F21iG5K6mA0UqfVeTiltWpyRf1G/WJwFHJRSurqm3M40vqJt8bHNnHGx0RWqafLxveVHkzV2tk4pvRQR44HFGhRP+Xan1T4HktQXx6BI5XA18KWIGAIQEetGxJLADcBe+RiVtwLvq/PYRle9rb2qdKMrVN8A7JPP2wlYrp+6DgWm5o2T9ckSnF49QG8KtDdZ19EM4D8RsUe+jYiITfrZhqQuZwNFKoeTycaX3BkR9wK/IUs4Lwb+TXZBxV8D19c+sI+r3tZeVbrRFaq/C4yKiDvJupoe76euVwGDI+Ie4HvArYVlLwIbRsTfycaYHJPP3wf4fF6/+4BdmnhOJHUxr8UjSZJKxwRFkiSVjg0USZJUOjZQJElS6dhAkSRJpWMDRZIklY4NFEmSVDo2UCRJUun8fyvqeC6pjzQkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes=['Healthy','sick']\n",
    "con_mat = tf.math.confusion_matrix(labels=y, predictions=pred).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = classes, \n",
    "                     columns = classes)\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.title(modelName +\"- on validation dataset. Accuracy: {acc:f}\".format(acc=np.sum(y==pred)/len(y)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "# plt.savefig(\"E:\\\\NN\\\\\"+modelName+\"_confusionOnTest_val.png\")\n",
    "print(np.sum(y==pred)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf7f90f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899/899 [==============================] - 5s 5ms/step\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# model =  tf.keras.models.load_model('E:\\\\caOnly_v1')\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "# model.load_weights(\"E:\\\\caOnly_v1_weights.h5\")\n",
    "\n",
    "# labels = (train_generator.class_indices)\n",
    "pred = model.predict_generator(loadTest(trainData),verbose=1)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "print(np.unique(pred))\n",
    "\n",
    "y = []\n",
    "for ind,(dataP,label) in enumerate(loadTest(trainData)):\n",
    "    y = y+list(np.argmax(label,axis=1))\n",
    "# print(pred[1:100],y[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a7d0afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702819688350235\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes=['Healthy','sick']\n",
    "con_mat = tf.math.confusion_matrix(labels=y, predictions=pred).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = classes, \n",
    "                     columns = classes)\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.title(modelName +\"- on train dataset. Accuracy: {acc:f}\".format(acc=np.sum(y==pred)/len(y)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "# plt.savefig(\"E:\\\\NN\\\\\"+modelName+\"_confusionOnTest_Train.png\")\n",
    "print(np.sum(y==pred)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00d68bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSplits(i):\n",
    "    df = pd.read_csv('availableData2.csv')  \n",
    "    # try 30s with 20s overlab\n",
    "    dtL = 0.0032768\n",
    "    segN = int(np.ceil(15/dtL))\n",
    "    overlap = int(np.ceil(3/dtL))\n",
    "    dataSamples = prepData(segN,overlap,df)\n",
    "\n",
    "    df = prepData(segN,overlap,df)\n",
    "    testData = df[df.Mouse.isin(mTest)]\n",
    "    trainData = df[df.Mouse.isin(mTrain)]\n",
    "    return trainData,testData\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7738c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistory(history,modelName,dfName,i):\n",
    "    fig, ax = plt.subplots(2,1, figsize=(8, 8))\n",
    "    ax[0].plot(history.history['accuracy'],label='train')\n",
    "    ax[0].plot(history.history['val_accuracy'],label='validation')\n",
    "    ax[0].set_title('Accuracy')\n",
    "    ax[1].plot(history.history['loss'],label='train')\n",
    "    ax[1].plot(history.history['val_loss'],label='validation')\n",
    "    ax[1].set_title('Loss')\n",
    "    fig.savefig(\"E:\\\\NN\\\\\"+modelName+\"_history_\"+dfName+\"_\"+i[0]+\"_\"+i[1]+\".svg\")\n",
    "    fig.clf()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5240ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotConfusionMatrix(y,pred,modelName, dfName):\n",
    "    con_mat = tf.math.confusion_matrix(labels=y, predictions=pred).numpy()\n",
    "    con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                         index = classes, \n",
    "                         columns = classes)\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8, 8))\n",
    "    sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues,ax=ax)\n",
    "    #fig.tight_layout()\n",
    "    ax.set_title((modelName +\"- on \"+dfName+\" dataset. Accuracy: {acc:f}\").format(acc=np.sum(y==pred)/len(y)) )\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    fig.savefig(\"E:\\\\NN\\\\\"+modelName+\"_confusionOn_\"+dfName+\".svg\")\n",
    "    fig.clf()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62c05491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotROC(fpr,tpr,sname):\n",
    "    fig, ax = plt.subplots()\n",
    "    mean_fpr = np.arange(0,100)/100\n",
    "    mean_tpr = []\n",
    "    aucs = []\n",
    "    for i in range(len(fpr)):\n",
    "        ax.plot(fpr[i],tpr[i],alpha=0.3) #label=\"ROC fold {}\".format(i),\n",
    "        interp_tpr = np.interp(mean_fpr, fpr[i], tpr[i])\n",
    "        interp_tpr[0] = 0.0\n",
    "        mean_tpr.append(interp_tpr)\n",
    "        aucs.append(auc(fpr[i], tpr[i]))\n",
    "    ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "    \n",
    "    mean_auc = auc(mean_fpr, np.mean(mean_tpr,axis=0))\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(mean_fpr,np.mean(mean_tpr,axis=0),color='b',label = r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc))\n",
    "    ax.set_xlabel(\"TPR\")\n",
    "    ax.set_ylabel(\"FPR\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    fig.savefig(\"E:\\\\NN\\\\\"+sname+\".svg\")\n",
    "    fig.clf()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1f05038d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [00:00, ?it/s]\n",
      "  0%|                                                                                           | 0/90 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.6325 - accuracy: 0.6278 - val_loss: 0.6271 - val_accuracy: 0.6228\n",
      "Epoch 2/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6255 - accuracy: 0.6356 - val_loss: 0.6153 - val_accuracy: 0.6814\n",
      "Epoch 3/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6288 - accuracy: 0.6286 - val_loss: 0.6678 - val_accuracy: 0.5887\n",
      "Epoch 4/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6292 - accuracy: 0.6334 - val_loss: 0.6170 - val_accuracy: 0.6535\n",
      "Epoch 5/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6215 - accuracy: 0.6395 - val_loss: 0.6414 - val_accuracy: 0.6016\n",
      "Epoch 6/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6211 - accuracy: 0.6462 - val_loss: 0.6772 - val_accuracy: 0.5670\n",
      "Epoch 7/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6188 - accuracy: 0.6483 - val_loss: 0.6229 - val_accuracy: 0.6429\n",
      "Epoch 8/1200\n",
      "112/112 [==============================] - 5s 46ms/step - loss: 0.6198 - accuracy: 0.6449 - val_loss: 0.6423 - val_accuracy: 0.6362\n",
      "Epoch 9/1200\n",
      "112/112 [==============================] - 5s 44ms/step - loss: 0.6126 - accuracy: 0.6515 - val_loss: 0.7104 - val_accuracy: 0.5491\n",
      "Epoch 10/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6128 - accuracy: 0.6452 - val_loss: 0.6719 - val_accuracy: 0.5954\n",
      "Epoch 11/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6181 - accuracy: 0.6468 - val_loss: 0.6232 - val_accuracy: 0.6869\n",
      "Epoch 12/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6106 - accuracy: 0.6603 - val_loss: 0.6457 - val_accuracy: 0.6183\n",
      "Epoch 13/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6194 - accuracy: 0.6491 - val_loss: 0.6148 - val_accuracy: 0.6624\n",
      "Epoch 14/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6085 - accuracy: 0.6504 - val_loss: 0.6686 - val_accuracy: 0.5982\n",
      "Epoch 15/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6087 - accuracy: 0.6539 - val_loss: 0.6204 - val_accuracy: 0.6814\n",
      "Epoch 16/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6158 - accuracy: 0.6466 - val_loss: 0.6388 - val_accuracy: 0.6629\n",
      "Epoch 17/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6077 - accuracy: 0.6603 - val_loss: 0.6599 - val_accuracy: 0.6250\n",
      "Epoch 18/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6078 - accuracy: 0.6551 - val_loss: 0.6505 - val_accuracy: 0.6378\n",
      "Epoch 19/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6087 - accuracy: 0.6515 - val_loss: 0.6317 - val_accuracy: 0.6317\n",
      "Epoch 20/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6071 - accuracy: 0.6516 - val_loss: 0.6677 - val_accuracy: 0.6261\n",
      "Epoch 21/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5960 - accuracy: 0.6618 - val_loss: 0.6669 - val_accuracy: 0.6211\n",
      "Epoch 22/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5935 - accuracy: 0.6536 - val_loss: 0.6605 - val_accuracy: 0.6283\n",
      "Epoch 23/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5915 - accuracy: 0.6713 - val_loss: 0.6637 - val_accuracy: 0.6211\n",
      "Epoch 24/1200\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.6001 - accuracy: 0.6536 - val_loss: 0.6429 - val_accuracy: 0.6429\n",
      "Epoch 25/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5927 - accuracy: 0.6585 - val_loss: 0.6490 - val_accuracy: 0.6657\n",
      "Epoch 26/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6007 - accuracy: 0.6596 - val_loss: 0.6634 - val_accuracy: 0.6300\n",
      "Epoch 27/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6077 - accuracy: 0.6466 - val_loss: 0.6644 - val_accuracy: 0.6345\n",
      "Epoch 28/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6102 - accuracy: 0.6420 - val_loss: 0.6368 - val_accuracy: 0.6155\n",
      "Epoch 29/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6039 - accuracy: 0.6575 - val_loss: 0.7071 - val_accuracy: 0.5753\n",
      "Epoch 30/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6052 - accuracy: 0.6604 - val_loss: 0.6040 - val_accuracy: 0.6858\n",
      "Epoch 31/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5936 - accuracy: 0.6645 - val_loss: 0.6129 - val_accuracy: 0.6590\n",
      "Epoch 32/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6019 - accuracy: 0.6565 - val_loss: 0.6475 - val_accuracy: 0.6300\n",
      "Epoch 33/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5980 - accuracy: 0.6558 - val_loss: 0.5949 - val_accuracy: 0.6814\n",
      "Epoch 34/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5889 - accuracy: 0.6631 - val_loss: 0.6077 - val_accuracy: 0.6590\n",
      "Epoch 35/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5977 - accuracy: 0.6634 - val_loss: 0.6707 - val_accuracy: 0.5592\n",
      "Epoch 36/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5910 - accuracy: 0.6635 - val_loss: 0.6015 - val_accuracy: 0.6507\n",
      "Epoch 37/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5807 - accuracy: 0.6701 - val_loss: 0.6312 - val_accuracy: 0.6412\n",
      "Epoch 38/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5744 - accuracy: 0.6769 - val_loss: 0.6212 - val_accuracy: 0.6473\n",
      "Epoch 39/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5809 - accuracy: 0.6694 - val_loss: 0.6417 - val_accuracy: 0.6557\n",
      "Epoch 40/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5632 - accuracy: 0.6759 - val_loss: 0.6427 - val_accuracy: 0.6730\n",
      "Epoch 41/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5717 - accuracy: 0.6741 - val_loss: 0.6337 - val_accuracy: 0.6412\n",
      "Epoch 42/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5707 - accuracy: 0.6814 - val_loss: 0.6546 - val_accuracy: 0.6479\n",
      "Epoch 43/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5735 - accuracy: 0.6742 - val_loss: 0.6321 - val_accuracy: 0.6451\n",
      "Epoch 44/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5622 - accuracy: 0.6797 - val_loss: 0.6542 - val_accuracy: 0.6562\n",
      "Epoch 45/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5642 - accuracy: 0.6836 - val_loss: 0.6814 - val_accuracy: 0.5999\n",
      "Epoch 46/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5644 - accuracy: 0.6821 - val_loss: 0.6991 - val_accuracy: 0.6289\n",
      "Epoch 47/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5594 - accuracy: 0.6791 - val_loss: 0.6926 - val_accuracy: 0.6412\n",
      "Epoch 48/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5636 - accuracy: 0.6752 - val_loss: 0.6691 - val_accuracy: 0.6590\n",
      "Epoch 49/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5574 - accuracy: 0.6780 - val_loss: 0.6726 - val_accuracy: 0.6557\n",
      "Epoch 50/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5614 - accuracy: 0.6910 - val_loss: 0.7189 - val_accuracy: 0.6211\n",
      "Epoch 51/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5487 - accuracy: 0.6932 - val_loss: 0.6841 - val_accuracy: 0.6334\n",
      "Epoch 52/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5503 - accuracy: 0.6883 - val_loss: 0.6655 - val_accuracy: 0.6590\n",
      "Epoch 53/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5540 - accuracy: 0.6896 - val_loss: 0.6567 - val_accuracy: 0.6657\n",
      "Epoch 54/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5594 - accuracy: 0.6871 - val_loss: 0.6759 - val_accuracy: 0.6551\n",
      "Epoch 55/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5526 - accuracy: 0.6888 - val_loss: 0.6253 - val_accuracy: 0.6808\n",
      "Epoch 56/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5377 - accuracy: 0.6982 - val_loss: 0.6714 - val_accuracy: 0.6629\n",
      "Epoch 57/1200\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.5445 - accuracy: 0.6973 - val_loss: 0.6434 - val_accuracy: 0.6373\n",
      "Epoch 58/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5424 - accuracy: 0.6996 - val_loss: 0.6951 - val_accuracy: 0.6590\n",
      "Epoch 59/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5475 - accuracy: 0.6964 - val_loss: 0.6263 - val_accuracy: 0.6685\n",
      "Epoch 60/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5310 - accuracy: 0.7102 - val_loss: 0.6298 - val_accuracy: 0.6512\n",
      "Epoch 61/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5355 - accuracy: 0.6974 - val_loss: 0.6809 - val_accuracy: 0.6445s\n",
      "Epoch 62/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5494 - accuracy: 0.6999 - val_loss: 0.6656 - val_accuracy: 0.6401\n",
      "Epoch 63/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5336 - accuracy: 0.7038 - val_loss: 0.7236 - val_accuracy: 0.6473\n",
      "Epoch 64/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5339 - accuracy: 0.6989 - val_loss: 0.6782 - val_accuracy: 0.6602\n",
      "Epoch 65/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5397 - accuracy: 0.7001 - val_loss: 0.7389 - val_accuracy: 0.6356\n",
      "Epoch 66/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5285 - accuracy: 0.7041 - val_loss: 0.6828 - val_accuracy: 0.6518\n",
      "Epoch 67/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5314 - accuracy: 0.7027 - val_loss: 0.7019 - val_accuracy: 0.6328\n",
      "Epoch 68/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5274 - accuracy: 0.7081 - val_loss: 0.7146 - val_accuracy: 0.5932\n",
      "Epoch 69/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5304 - accuracy: 0.7024 - val_loss: 0.6099 - val_accuracy: 0.6490\n",
      "Epoch 70/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5379 - accuracy: 0.7008 - val_loss: 0.5711 - val_accuracy: 0.6814\n",
      "Epoch 71/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5449 - accuracy: 0.7023 - val_loss: 0.6399 - val_accuracy: 0.653564 - accura - ETA: 2s - loss: 0.5319 - ac - ETA: 1s - ETA: 0s - loss: 0.5\n",
      "Epoch 72/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5432 - accuracy: 0.7047 - val_loss: 0.6186 - val_accuracy: 0.6228\n",
      "Epoch 73/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5355 - accuracy: 0.7095 - val_loss: 0.6046 - val_accuracy: 0.6596\n",
      "Epoch 74/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5357 - accuracy: 0.7076 - val_loss: 0.6384 - val_accuracy: 0.6205\n",
      "Epoch 75/1200\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.5241 - accuracy: 0.7062 - val_loss: 0.6436 - val_accuracy: 0.6417\n",
      "Epoch 76/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5237 - accuracy: 0.7068 - val_loss: 0.6179 - val_accuracy: 0.6719\n",
      "Epoch 77/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5097 - accuracy: 0.7172 - val_loss: 0.6743 - val_accuracy: 0.6300\n",
      "Epoch 78/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5105 - accuracy: 0.7211 - val_loss: 0.6422 - val_accuracy: 0.6473\n",
      "Epoch 79/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5111 - accuracy: 0.7220 - val_loss: 0.6729 - val_accuracy: 0.6490\n",
      "Epoch 80/1200\n",
      "112/112 [==============================] - 5s 44ms/step - loss: 0.5078 - accuracy: 0.7157 - val_loss: 0.6530 - val_accuracy: 0.6579\n",
      "Epoch 81/1200\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.5081 - accuracy: 0.7310 - val_loss: 0.7517 - val_accuracy: 0.6339\n",
      "Epoch 82/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5078 - accuracy: 0.7182 - val_loss: 0.6537 - val_accuracy: 0.6741\n",
      "Epoch 83/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5020 - accuracy: 0.7234 - val_loss: 0.6914 - val_accuracy: 0.6217\n",
      "Epoch 84/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5051 - accuracy: 0.7231 - val_loss: 0.7273 - val_accuracy: 0.6825\n",
      "Epoch 85/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5066 - accuracy: 0.7274 - val_loss: 0.7376 - val_accuracy: 0.6350\n",
      "Epoch 86/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4995 - accuracy: 0.7284 - val_loss: 0.7036 - val_accuracy: 0.6384\n",
      "Epoch 87/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4943 - accuracy: 0.7302 - val_loss: 0.7803 - val_accuracy: 0.6429\n",
      "Epoch 88/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4931 - accuracy: 0.7268 - val_loss: 0.6967 - val_accuracy: 0.6395\n",
      "Epoch 89/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4970 - accuracy: 0.7294 - val_loss: 0.7468 - val_accuracy: 0.6613\n",
      "Epoch 90/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4778 - accuracy: 0.7418 - val_loss: 0.8332 - val_accuracy: 0.6334\n",
      "Epoch 91/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4856 - accuracy: 0.7370 - val_loss: 0.8175 - val_accuracy: 0.6200\n",
      "Epoch 92/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4759 - accuracy: 0.7451 - val_loss: 0.8244 - val_accuracy: 0.6345\n",
      "Epoch 93/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4675 - accuracy: 0.7479 - val_loss: 0.6671 - val_accuracy: 0.7081\n",
      "Epoch 94/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4919 - accuracy: 0.7324 - val_loss: 0.7790 - val_accuracy: 0.6468\n",
      "Epoch 95/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4837 - accuracy: 0.7372 - val_loss: 0.7801 - val_accuracy: 0.6512\n",
      "Epoch 96/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4795 - accuracy: 0.7457 - val_loss: 0.6861 - val_accuracy: 0.6641\n",
      "Epoch 97/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4761 - accuracy: 0.7508 - val_loss: 0.7866 - val_accuracy: 0.6267\n",
      "Epoch 98/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5004 - accuracy: 0.7373 - val_loss: 0.6120 - val_accuracy: 0.6585\n",
      "Epoch 99/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4955 - accuracy: 0.7453 - val_loss: 0.6842 - val_accuracy: 0.6390\n",
      "Epoch 100/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4952 - accuracy: 0.7365 - val_loss: 0.6308 - val_accuracy: 0.6602\n",
      "Epoch 101/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4898 - accuracy: 0.7376 - val_loss: 0.5981 - val_accuracy: 0.6741\n",
      "Epoch 102/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4816 - accuracy: 0.7472 - val_loss: 0.6358 - val_accuracy: 0.6590\n",
      "Epoch 103/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4761 - accuracy: 0.7393 - val_loss: 0.6271 - val_accuracy: 0.6512\n",
      "Epoch 104/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4785 - accuracy: 0.7420 - val_loss: 0.6114 - val_accuracy: 0.6652\n",
      "Epoch 105/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4942 - accuracy: 0.7369 - val_loss: 0.5772 - val_accuracy: 0.6970\n",
      "Epoch 106/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4766 - accuracy: 0.7525 - val_loss: 0.6295 - val_accuracy: 0.6507\n",
      "Epoch 107/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4849 - accuracy: 0.7355 - val_loss: 0.6611 - val_accuracy: 0.6685\n",
      "Epoch 108/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4743 - accuracy: 0.7520 - val_loss: 0.6041 - val_accuracy: 0.69704742 - accuracy\n",
      "Epoch 109/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4756 - accuracy: 0.7476 - val_loss: 0.6137 - val_accuracy: 0.6931\n",
      "Epoch 110/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4608 - accuracy: 0.7588 - val_loss: 0.6691 - val_accuracy: 0.6797\n",
      "Epoch 111/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4928 - accuracy: 0.7367 - val_loss: 0.6933 - val_accuracy: 0.6055\n",
      "Epoch 112/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4768 - accuracy: 0.7559 - val_loss: 0.6258 - val_accuracy: 0.6663\n",
      "Epoch 113/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4663 - accuracy: 0.7529 - val_loss: 0.6802 - val_accuracy: 0.6568\n",
      "Epoch 114/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4544 - accuracy: 0.7686 - val_loss: 0.6837 - val_accuracy: 0.6881\n",
      "Epoch 115/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4597 - accuracy: 0.7580 - val_loss: 0.6223 - val_accuracy: 0.6769\n",
      "Epoch 116/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4691 - accuracy: 0.7577 - val_loss: 0.6029 - val_accuracy: 0.6936\n",
      "Epoch 117/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4571 - accuracy: 0.7695 - val_loss: 0.6437 - val_accuracy: 0.6629\n",
      "Epoch 118/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4447 - accuracy: 0.7667 - val_loss: 0.6865 - val_accuracy: 0.6473\n",
      "Epoch 119/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4491 - accuracy: 0.7663 - val_loss: 0.7915 - val_accuracy: 0.6378\n",
      "Epoch 120/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4562 - accuracy: 0.7640 - val_loss: 0.7320 - val_accuracy: 0.6507\n",
      "Epoch 121/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4536 - accuracy: 0.7649 - val_loss: 0.6618 - val_accuracy: 0.6602\n",
      "Epoch 122/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4441 - accuracy: 0.7702 - val_loss: 0.6810 - val_accuracy: 0.6763\n",
      "Epoch 123/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4456 - accuracy: 0.7586 - val_loss: 0.7091 - val_accuracy: 0.6674\n",
      "Epoch 124/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4250 - accuracy: 0.7785 - val_loss: 0.6814 - val_accuracy: 0.6853\n",
      "Epoch 125/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4220 - accuracy: 0.7801 - val_loss: 0.7258 - val_accuracy: 0.6825\n",
      "Epoch 126/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4389 - accuracy: 0.7730 - val_loss: 0.6829 - val_accuracy: 0.6942\n",
      "Epoch 127/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4223 - accuracy: 0.7776 - val_loss: 0.7155 - val_accuracy: 0.6975\n",
      "Epoch 128/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4297 - accuracy: 0.7739 - val_loss: 0.7620 - val_accuracy: 0.6786\n",
      "Epoch 129/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4120 - accuracy: 0.7854 - val_loss: 0.7140 - val_accuracy: 0.6691\n",
      "Epoch 130/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4149 - accuracy: 0.7903 - val_loss: 0.6734 - val_accuracy: 0.7054\n",
      "Epoch 131/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4027 - accuracy: 0.7938 - val_loss: 0.6809 - val_accuracy: 0.7154\n",
      "Epoch 132/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4219 - accuracy: 0.7822 - val_loss: 0.8390 - val_accuracy: 0.6881\n",
      "Epoch 133/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4078 - accuracy: 0.7866 - val_loss: 0.7554 - val_accuracy: 0.6797\n",
      "Epoch 134/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4010 - accuracy: 0.7924 - val_loss: 0.7079 - val_accuracy: 0.7076\n",
      "Epoch 135/1200\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.4195 - accuracy: 0.7826 - val_loss: 0.7507 - val_accuracy: 0.7003\n",
      "Epoch 136/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4007 - accuracy: 0.7999 - val_loss: 0.8498 - val_accuracy: 0.5792\n",
      "Epoch 137/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4062 - accuracy: 0.7843 - val_loss: 0.7995 - val_accuracy: 0.6948\n",
      "Epoch 138/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3846 - accuracy: 0.8057 - val_loss: 0.7355 - val_accuracy: 0.7081\n",
      "Epoch 139/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4033 - accuracy: 0.7919 - val_loss: 0.7319 - val_accuracy: 0.7165\n",
      "Epoch 140/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4018 - accuracy: 0.7898 - val_loss: 0.7560 - val_accuracy: 0.6775\n",
      "Epoch 141/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3826 - accuracy: 0.8015 - val_loss: 0.7001 - val_accuracy: 0.7277\n",
      "Epoch 142/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3846 - accuracy: 0.8012 - val_loss: 0.7276 - val_accuracy: 0.7059- ETA: 0s - loss: 0.3834 - \n",
      "Epoch 143/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3929 - accuracy: 0.8058 - val_loss: 0.7700 - val_accuracy: 0.6747\n",
      "Epoch 144/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3892 - accuracy: 0.7963 - val_loss: 0.6986 - val_accuracy: 0.7215\n",
      "Epoch 145/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3872 - accuracy: 0.8023 - val_loss: 0.7052 - val_accuracy: 0.7137\n",
      "Epoch 146/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3872 - accuracy: 0.8034 - val_loss: 0.7545 - val_accuracy: 0.7126\n",
      "Epoch 147/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3940 - accuracy: 0.7960 - val_loss: 0.8221 - val_accuracy: 0.7132\n",
      "Epoch 148/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3726 - accuracy: 0.8069 - val_loss: 0.9654 - val_accuracy: 0.6970\n",
      "Epoch 149/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3786 - accuracy: 0.8002 - val_loss: 0.8149 - val_accuracy: 0.6847\n",
      "Epoch 150/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3861 - accuracy: 0.8054 - val_loss: 0.7998 - val_accuracy: 0.6406\n",
      "Epoch 151/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3665 - accuracy: 0.8090 - val_loss: 0.8999 - val_accuracy: 0.7154\n",
      "Epoch 152/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3893 - accuracy: 0.8097 - val_loss: 0.7582 - val_accuracy: 0.7015\n",
      "Epoch 153/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3667 - accuracy: 0.8128 - val_loss: 0.8259 - val_accuracy: 0.7015\n",
      "Epoch 154/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3594 - accuracy: 0.8108 - val_loss: 0.7485 - val_accuracy: 0.7042\n",
      "Epoch 155/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.3615 - accuracy: 0.8139 - val_loss: 0.9029 - val_accuracy: 0.6456\n",
      "Epoch 156/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3664 - accuracy: 0.8118 - val_loss: 0.7541 - val_accuracy: 0.6920\n",
      "Epoch 157/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3738 - accuracy: 0.8135 - val_loss: 0.6978 - val_accuracy: 0.7020\n",
      "Epoch 158/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3529 - accuracy: 0.8198 - val_loss: 0.8668 - val_accuracy: 0.7070\n",
      "Epoch 159/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3694 - accuracy: 0.8182 - val_loss: 0.7980 - val_accuracy: 0.7020\n",
      "Epoch 160/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3583 - accuracy: 0.8200 - val_loss: 0.8607 - val_accuracy: 0.7171\n",
      "Epoch 161/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3439 - accuracy: 0.8249 - val_loss: 0.8249 - val_accuracy: 0.6936\n",
      "Epoch 162/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3500 - accuracy: 0.8263 - val_loss: 0.7257 - val_accuracy: 0.7176\n",
      "Epoch 163/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3596 - accuracy: 0.8136 - val_loss: 0.8289 - val_accuracy: 0.6853\n",
      "Epoch 164/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3451 - accuracy: 0.8227 - val_loss: 0.8770 - val_accuracy: 0.7115\n",
      "Epoch 165/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3539 - accuracy: 0.8267 - val_loss: 0.8099 - val_accuracy: 0.7455\n",
      "Epoch 166/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3319 - accuracy: 0.8364 - val_loss: 1.0283 - val_accuracy: 0.7238\n",
      "Epoch 167/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3254 - accuracy: 0.8345 - val_loss: 0.9395 - val_accuracy: 0.7104\n",
      "Epoch 168/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3766 - accuracy: 0.8175 - val_loss: 0.7029 - val_accuracy: 0.7160\n",
      "Epoch 169/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3293 - accuracy: 0.8344 - val_loss: 0.7912 - val_accuracy: 0.7444\n",
      "Epoch 170/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.3376 - accuracy: 0.8306 - val_loss: 0.8073 - val_accuracy: 0.7310\n",
      "Epoch 171/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3174 - accuracy: 0.8418 - val_loss: 0.7982 - val_accuracy: 0.7344\n",
      "Epoch 172/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3268 - accuracy: 0.8382 - val_loss: 0.8334 - val_accuracy: 0.7054\n",
      "Epoch 173/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3265 - accuracy: 0.8309 - val_loss: 0.7557 - val_accuracy: 0.7528\n",
      "Epoch 174/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2986 - accuracy: 0.8527 - val_loss: 0.9651 - val_accuracy: 0.7210\n",
      "Epoch 175/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3229 - accuracy: 0.8447 - val_loss: 0.9558 - val_accuracy: 0.7444\n",
      "Epoch 176/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3103 - accuracy: 0.8461 - val_loss: 0.7773 - val_accuracy: 0.7121\n",
      "Epoch 177/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3188 - accuracy: 0.8393 - val_loss: 0.7887 - val_accuracy: 0.7545\n",
      "Epoch 178/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3093 - accuracy: 0.8444 - val_loss: 0.7166 - val_accuracy: 0.7433\n",
      "Epoch 179/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3102 - accuracy: 0.8468 - val_loss: 0.8480 - val_accuracy: 0.7227\n",
      "Epoch 180/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3090 - accuracy: 0.8431 - val_loss: 0.8475 - val_accuracy: 0.7321\n",
      "Epoch 181/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3149 - accuracy: 0.8456 - val_loss: 0.9827 - val_accuracy: 0.7059\n",
      "Epoch 182/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2927 - accuracy: 0.8548 - val_loss: 1.0394 - val_accuracy: 0.7176\n",
      "Epoch 183/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3018 - accuracy: 0.8511 - val_loss: 0.9824 - val_accuracy: 0.7098\n",
      "Epoch 184/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2952 - accuracy: 0.8545 - val_loss: 0.8085 - val_accuracy: 0.7695\n",
      "Epoch 185/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2869 - accuracy: 0.8598 - val_loss: 0.9569 - val_accuracy: 0.7193\n",
      "Epoch 186/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2953 - accuracy: 0.8553 - val_loss: 1.0008 - val_accuracy: 0.7321\n",
      "Epoch 187/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3007 - accuracy: 0.8530 - val_loss: 1.0302 - val_accuracy: 0.7243\n",
      "Epoch 188/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2945 - accuracy: 0.8584 - val_loss: 0.8043 - val_accuracy: 0.7467\n",
      "Epoch 189/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2886 - accuracy: 0.8566 - val_loss: 0.8704 - val_accuracy: 0.7416\n",
      "Epoch 190/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3037 - accuracy: 0.8545 - val_loss: 0.9160 - val_accuracy: 0.7020\n",
      "Epoch 191/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2706 - accuracy: 0.8691 - val_loss: 0.9110 - val_accuracy: 0.7400\n",
      "Epoch 192/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3437 - accuracy: 0.8365 - val_loss: 0.8298 - val_accuracy: 0.7271\n",
      "Epoch 193/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2853 - accuracy: 0.8617 - val_loss: 0.7568 - val_accuracy: 0.7550\n",
      "Epoch 194/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2897 - accuracy: 0.8623 - val_loss: 0.9869 - val_accuracy: 0.7143\n",
      "Epoch 195/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2737 - accuracy: 0.8684 - val_loss: 0.9599 - val_accuracy: 0.7204\n",
      "Epoch 196/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2705 - accuracy: 0.8690 - val_loss: 0.9114 - val_accuracy: 0.7260\n",
      "Epoch 197/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2720 - accuracy: 0.8676 - val_loss: 0.9641 - val_accuracy: 0.7584\n",
      "Epoch 198/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2786 - accuracy: 0.8622 - val_loss: 1.0019 - val_accuracy: 0.7405\n",
      "Epoch 199/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2709 - accuracy: 0.8670 - val_loss: 1.0865 - val_accuracy: 0.7377\n",
      "Epoch 200/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2779 - accuracy: 0.8693 - val_loss: 0.8243 - val_accuracy: 0.7539\n",
      "Epoch 201/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2719 - accuracy: 0.8719 - val_loss: 0.9338 - val_accuracy: 0.7422\n",
      "Epoch 202/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2681 - accuracy: 0.8725 - val_loss: 0.8599 - val_accuracy: 0.7645\n",
      "Epoch 203/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2723 - accuracy: 0.8708 - val_loss: 0.9675 - val_accuracy: 0.7277y: \n",
      "Epoch 204/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2754 - accuracy: 0.8747 - val_loss: 0.9894 - val_accuracy: 0.7589\n",
      "Epoch 205/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2809 - accuracy: 0.8729 - val_loss: 1.0791 - val_accuracy: 0.7165\n",
      "Epoch 206/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2568 - accuracy: 0.8730 - val_loss: 1.0310 - val_accuracy: 0.7349\n",
      "Epoch 207/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2527 - accuracy: 0.8781 - val_loss: 1.0342 - val_accuracy: 0.7411\n",
      "Epoch 208/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2653 - accuracy: 0.8726 - val_loss: 0.9904 - val_accuracy: 0.7427\n",
      "Epoch 209/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2679 - accuracy: 0.8736 - val_loss: 0.9874 - val_accuracy: 0.7472\n",
      "Epoch 210/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2495 - accuracy: 0.8788 - val_loss: 1.0389 - val_accuracy: 0.7617\n",
      "Epoch 211/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2504 - accuracy: 0.8760 - val_loss: 1.0380 - val_accuracy: 0.7511\n",
      "Epoch 212/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2653 - accuracy: 0.8718 - val_loss: 1.1695 - val_accuracy: 0.7266\n",
      "Epoch 213/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2504 - accuracy: 0.8793 - val_loss: 0.8635 - val_accuracy: 0.7712\n",
      "Epoch 214/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2466 - accuracy: 0.8788 - val_loss: 0.8414 - val_accuracy: 0.7645\n",
      "Epoch 215/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2513 - accuracy: 0.8800 - val_loss: 0.9694 - val_accuracy: 0.7584\n",
      "Epoch 216/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2471 - accuracy: 0.8814 - val_loss: 1.2358 - val_accuracy: 0.7433\n",
      "Epoch 217/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2394 - accuracy: 0.8867 - val_loss: 0.8879 - val_accuracy: 0.7640\n",
      "Epoch 218/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2425 - accuracy: 0.8856 - val_loss: 1.0621 - val_accuracy: 0.7690\n",
      "Epoch 219/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2487 - accuracy: 0.8884 - val_loss: 0.9903 - val_accuracy: 0.7628\n",
      "Epoch 220/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2288 - accuracy: 0.8908 - val_loss: 1.0613 - val_accuracy: 0.7600\n",
      "Epoch 221/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2244 - accuracy: 0.8947 - val_loss: 1.1222 - val_accuracy: 0.7517\n",
      "Epoch 222/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2733 - accuracy: 0.8732 - val_loss: 0.9242 - val_accuracy: 0.7606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2253 - accuracy: 0.8979 - val_loss: 1.1441 - val_accuracy: 0.7695\n",
      "Epoch 224/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2332 - accuracy: 0.8920 - val_loss: 1.0073 - val_accuracy: 0.7651\n",
      "Epoch 225/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2169 - accuracy: 0.8976 - val_loss: 1.2038 - val_accuracy: 0.7433\n",
      "Epoch 226/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2227 - accuracy: 0.8933 - val_loss: 1.0850 - val_accuracy: 0.7372\n",
      "Epoch 227/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2246 - accuracy: 0.8892 - val_loss: 1.0819 - val_accuracy: 0.7706\n",
      "Epoch 228/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2385 - accuracy: 0.8933 - val_loss: 0.9367 - val_accuracy: 0.7863\n",
      "Epoch 229/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2123 - accuracy: 0.9021 - val_loss: 0.9942 - val_accuracy: 0.7807\n",
      "Epoch 230/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2339 - accuracy: 0.8937 - val_loss: 1.0535 - val_accuracy: 0.7673\n",
      "Epoch 231/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2211 - accuracy: 0.8949 - val_loss: 1.0512 - val_accuracy: 0.7768\n",
      "Epoch 232/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2076 - accuracy: 0.9046 - val_loss: 1.3827 - val_accuracy: 0.7556\n",
      "Epoch 233/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2145 - accuracy: 0.8963 - val_loss: 1.2676 - val_accuracy: 0.7740\n",
      "Epoch 234/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2141 - accuracy: 0.8998 - val_loss: 0.9708 - val_accuracy: 0.7835\n",
      "Epoch 235/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2171 - accuracy: 0.9022 - val_loss: 0.9773 - val_accuracy: 0.7913\n",
      "Epoch 236/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1982 - accuracy: 0.9060 - val_loss: 1.1697 - val_accuracy: 0.8019\n",
      "Epoch 237/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2243 - accuracy: 0.9019 - val_loss: 0.9611 - val_accuracy: 0.7852\n",
      "Epoch 238/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2095 - accuracy: 0.9056 - val_loss: 0.9086 - val_accuracy: 0.7829\n",
      "Epoch 239/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2257 - accuracy: 0.8991 - val_loss: 1.1358 - val_accuracy: 0.7533\n",
      "Epoch 240/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2164 - accuracy: 0.9023 - val_loss: 0.9832 - val_accuracy: 0.7896\n",
      "Epoch 241/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2135 - accuracy: 0.9016 - val_loss: 1.2214 - val_accuracy: 0.7801\n",
      "Epoch 242/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2059 - accuracy: 0.9030 - val_loss: 1.0881 - val_accuracy: 0.7718\n",
      "Epoch 243/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2129 - accuracy: 0.9023 - val_loss: 1.2034 - val_accuracy: 0.7785\n",
      "Epoch 244/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2091 - accuracy: 0.9062 - val_loss: 0.9697 - val_accuracy: 0.7924\n",
      "Epoch 245/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2038 - accuracy: 0.9106 - val_loss: 1.0587 - val_accuracy: 0.8097\n",
      "Epoch 246/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2040 - accuracy: 0.9062 - val_loss: 1.2027 - val_accuracy: 0.7762\n",
      "Epoch 247/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1950 - accuracy: 0.9109 - val_loss: 1.1318 - val_accuracy: 0.7952\n",
      "Epoch 248/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1944 - accuracy: 0.9081 - val_loss: 1.2109 - val_accuracy: 0.7907\n",
      "Epoch 249/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2066 - accuracy: 0.9054 - val_loss: 1.0015 - val_accuracy: 0.7695\n",
      "Epoch 250/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1867 - accuracy: 0.9176 - val_loss: 1.0149 - val_accuracy: 0.7985\n",
      "Epoch 251/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1905 - accuracy: 0.9136 - val_loss: 1.1825 - val_accuracy: 0.7974\n",
      "Epoch 252/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1751 - accuracy: 0.9196 - val_loss: 1.0353 - val_accuracy: 0.7924\n",
      "Epoch 253/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1950 - accuracy: 0.9122 - val_loss: 1.1496 - val_accuracy: 0.7634\n",
      "Epoch 254/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1929 - accuracy: 0.9103 - val_loss: 1.1269 - val_accuracy: 0.7612\n",
      "Epoch 255/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1802 - accuracy: 0.9170 - val_loss: 1.1226 - val_accuracy: 0.7790\n",
      "Epoch 256/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1950 - accuracy: 0.9121 - val_loss: 1.0223 - val_accuracy: 0.7773\n",
      "Epoch 257/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1982 - accuracy: 0.9074 - val_loss: 1.1735 - val_accuracy: 0.7684 3s - - ETA: 2s - loss: 0.1\n",
      "Epoch 258/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1752 - accuracy: 0.9192 - val_loss: 1.0169 - val_accuracy: 0.8030\n",
      "Epoch 259/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2350 - accuracy: 0.9054 - val_loss: 1.1373 - val_accuracy: 0.7790\n",
      "Epoch 260/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1857 - accuracy: 0.9180 - val_loss: 1.2195 - val_accuracy: 0.7768\n",
      "Epoch 261/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1760 - accuracy: 0.9195 - val_loss: 1.0155 - val_accuracy: 0.7578\n",
      "Epoch 262/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2257 - accuracy: 0.9104 - val_loss: 0.9775 - val_accuracy: 0.7567\n",
      "Epoch 263/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1790 - accuracy: 0.9205 - val_loss: 1.0751 - val_accuracy: 0.8030\n",
      "Epoch 264/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1742 - accuracy: 0.9237 - val_loss: 1.0756 - val_accuracy: 0.7729\n",
      "Epoch 265/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1717 - accuracy: 0.9231 - val_loss: 1.2076 - val_accuracy: 0.7779\n",
      "Epoch 266/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1628 - accuracy: 0.9270 - val_loss: 1.3258 - val_accuracy: 0.7762\n",
      "Epoch 267/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1924 - accuracy: 0.9149 - val_loss: 1.0957 - val_accuracy: 0.7980\n",
      "Epoch 268/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1666 - accuracy: 0.9256 - val_loss: 1.0938 - val_accuracy: 0.7919\n",
      "Epoch 269/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1871 - accuracy: 0.9159 - val_loss: 1.2765 - val_accuracy: 0.7734\n",
      "Epoch 270/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1755 - accuracy: 0.9185 - val_loss: 1.0803 - val_accuracy: 0.7963\n",
      "Epoch 271/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1893 - accuracy: 0.9187 - val_loss: 1.3721 - val_accuracy: 0.7718\n",
      "Epoch 272/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1591 - accuracy: 0.9275 - val_loss: 1.0522 - val_accuracy: 0.7919\n",
      "Epoch 273/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2455 - accuracy: 0.9001 - val_loss: 1.0252 - val_accuracy: 0.7695\n",
      "Epoch 274/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1683 - accuracy: 0.9307 - val_loss: 1.1911 - val_accuracy: 0.7902\n",
      "Epoch 275/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1730 - accuracy: 0.9223 - val_loss: 0.9526 - val_accuracy: 0.7958\n",
      "Epoch 276/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1744 - accuracy: 0.9227 - val_loss: 1.2094 - val_accuracy: 0.7712\n",
      "Epoch 277/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1987 - accuracy: 0.9249 - val_loss: 1.3026 - val_accuracy: 0.7840\n",
      "Epoch 278/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1618 - accuracy: 0.9304 - val_loss: 1.1702 - val_accuracy: 0.7857\n",
      "Epoch 279/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1672 - accuracy: 0.9265 - val_loss: 1.5201 - val_accuracy: 0.7790\n",
      "Epoch 280/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1754 - accuracy: 0.9255 - val_loss: 1.0902 - val_accuracy: 0.8002\n",
      "Epoch 281/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1523 - accuracy: 0.9297 - val_loss: 1.4154 - val_accuracy: 0.8025\n",
      "Epoch 282/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1579 - accuracy: 0.9325 - val_loss: 1.3041 - val_accuracy: 0.7840\n",
      "Epoch 283/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1636 - accuracy: 0.9294 - val_loss: 1.1582 - val_accuracy: 0.8131\n",
      "Epoch 284/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1532 - accuracy: 0.9311 - val_loss: 1.1851 - val_accuracy: 0.7919\n",
      "Epoch 285/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1502 - accuracy: 0.9336 - val_loss: 1.1510 - val_accuracy: 0.8013\n",
      "Epoch 286/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1584 - accuracy: 0.9316 - val_loss: 1.5737 - val_accuracy: 0.7740\n",
      "Epoch 287/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1708 - accuracy: 0.9234 - val_loss: 1.5358 - val_accuracy: 0.7879\n",
      "Epoch 288/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1860 - accuracy: 0.9258 - val_loss: 0.9615 - val_accuracy: 0.8041\n",
      "Epoch 289/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1472 - accuracy: 0.9367 - val_loss: 1.1864 - val_accuracy: 0.7807\n",
      "Epoch 290/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1962 - accuracy: 0.9177 - val_loss: 1.3140 - val_accuracy: 0.7919\n",
      "Epoch 291/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1512 - accuracy: 0.9335 - val_loss: 1.2231 - val_accuracy: 0.7919\n",
      "Epoch 292/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1431 - accuracy: 0.9368 - val_loss: 1.7220 - val_accuracy: 0.7561\n",
      "Epoch 293/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.1757 - accuracy: 0.9210 - val_loss: 1.2029 - val_accuracy: 0.8008\n",
      "Epoch 294/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1521 - accuracy: 0.9340 - val_loss: 1.4237 - val_accuracy: 0.7729\n",
      "Epoch 295/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1450 - accuracy: 0.9355 - val_loss: 0.9845 - val_accuracy: 0.7958\n",
      "Epoch 296/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1573 - accuracy: 0.9318 - val_loss: 1.2957 - val_accuracy: 0.7801c\n",
      "Epoch 297/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1592 - accuracy: 0.9300 - val_loss: 1.2981 - val_accuracy: 0.7946\n",
      "Epoch 298/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1451 - accuracy: 0.9316 - val_loss: 1.3776 - val_accuracy: 0.7958\n",
      "Epoch 299/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1417 - accuracy: 0.9372 - val_loss: 1.1606 - val_accuracy: 0.7924\n",
      "Epoch 300/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1403 - accuracy: 0.9389 - val_loss: 1.4028 - val_accuracy: 0.7846\n",
      "Epoch 301/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2069 - accuracy: 0.9261 - val_loss: 1.3382 - val_accuracy: 0.7963\n",
      "Epoch 302/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1472 - accuracy: 0.9355 - val_loss: 1.2008 - val_accuracy: 0.8025\n",
      "Epoch 303/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1429 - accuracy: 0.9361 - val_loss: 1.2536 - val_accuracy: 0.7879\n",
      "Epoch 304/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1376 - accuracy: 0.9390 - val_loss: 1.3872 - val_accuracy: 0.7762\n",
      "Epoch 305/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1559 - accuracy: 0.9335 - val_loss: 1.8552 - val_accuracy: 0.7612\n",
      "Epoch 306/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1382 - accuracy: 0.9397 - val_loss: 1.4657 - val_accuracy: 0.7879\n",
      "Epoch 307/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1393 - accuracy: 0.9411 - val_loss: 1.4092 - val_accuracy: 0.7651\n",
      "Epoch 308/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1515 - accuracy: 0.9368 - val_loss: 1.6175 - val_accuracy: 0.7667\n",
      "Epoch 309/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1369 - accuracy: 0.9435 - val_loss: 0.9796 - val_accuracy: 0.8002\n",
      "Epoch 310/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1584 - accuracy: 0.9301 - val_loss: 1.5713 - val_accuracy: 0.7606\n",
      "Epoch 311/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1430 - accuracy: 0.9375 - val_loss: 1.6601 - val_accuracy: 0.7478\n",
      "Epoch 312/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1453 - accuracy: 0.9406 - val_loss: 1.7090 - val_accuracy: 0.7623\n",
      "Epoch 313/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1405 - accuracy: 0.9357 - val_loss: 1.5687 - val_accuracy: 0.7550\n",
      "Epoch 314/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1392 - accuracy: 0.9397 - val_loss: 2.0110 - val_accuracy: 0.7595\n",
      "Epoch 315/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1374 - accuracy: 0.9431 - val_loss: 1.1617 - val_accuracy: 0.7818\n",
      "Epoch 316/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1616 - accuracy: 0.9312 - val_loss: 1.3929 - val_accuracy: 0.7662\n",
      "Epoch 317/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1437 - accuracy: 0.9361 - val_loss: 1.2857 - val_accuracy: 0.7913\n",
      "Epoch 318/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1424 - accuracy: 0.9342 - val_loss: 1.2857 - val_accuracy: 0.7980\n",
      "Epoch 319/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1342 - accuracy: 0.9429 - val_loss: 1.5902 - val_accuracy: 0.8092\n",
      "Epoch 320/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1225 - accuracy: 0.9480 - val_loss: 1.2827 - val_accuracy: 0.8075\n",
      "Epoch 321/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1221 - accuracy: 0.9468 - val_loss: 1.2954 - val_accuracy: 0.7985\n",
      "Epoch 322/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3594 - accuracy: 0.8564 - val_loss: 0.6610 - val_accuracy: 0.7701\n",
      "Epoch 323/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1665 - accuracy: 0.9280 - val_loss: 1.2702 - val_accuracy: 0.8092\n",
      "Epoch 324/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1545 - accuracy: 0.9346 - val_loss: 1.3963 - val_accuracy: 0.7734\n",
      "Epoch 325/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1383 - accuracy: 0.9388 - val_loss: 1.2918 - val_accuracy: 0.7935\n",
      "Epoch 326/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1355 - accuracy: 0.9455 - val_loss: 1.3037 - val_accuracy: 0.8080\n",
      "Epoch 327/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1373 - accuracy: 0.9417 - val_loss: 1.3807 - val_accuracy: 0.7773\n",
      "Epoch 328/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1246 - accuracy: 0.9477 - val_loss: 1.6505 - val_accuracy: 0.7740\n",
      "Epoch 329/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1298 - accuracy: 0.9448 - val_loss: 1.6645 - val_accuracy: 0.7969\n",
      "Epoch 330/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1290 - accuracy: 0.9421 - val_loss: 1.4816 - val_accuracy: 0.7930\n",
      "Epoch 331/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1410 - accuracy: 0.9381 - val_loss: 1.7747 - val_accuracy: 0.7595\n",
      "Epoch 332/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1453 - accuracy: 0.9340 - val_loss: 1.4161 - val_accuracy: 0.7863\n",
      "Epoch 333/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1176 - accuracy: 0.9471 - val_loss: 1.4959 - val_accuracy: 0.8041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1272 - accuracy: 0.9461 - val_loss: 1.1178 - val_accuracy: 0.8136\n",
      "Epoch 335/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1429 - accuracy: 0.9429 - val_loss: 1.3697 - val_accuracy: 0.7985\n",
      "Epoch 336/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1236 - accuracy: 0.9481 - val_loss: 1.4602 - val_accuracy: 0.7427\n",
      "Epoch 337/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1533 - accuracy: 0.9330 - val_loss: 1.5490 - val_accuracy: 0.7662\n",
      "Epoch 338/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1190 - accuracy: 0.9475 - val_loss: 1.3535 - val_accuracy: 0.7902\n",
      "Epoch 339/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1181 - accuracy: 0.9477 - val_loss: 1.5756 - val_accuracy: 0.7706\n",
      "Epoch 340/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1306 - accuracy: 0.9422 - val_loss: 1.6430 - val_accuracy: 0.7985\n",
      "Epoch 341/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1264 - accuracy: 0.9443 - val_loss: 1.4949 - val_accuracy: 0.7930\n",
      "Epoch 342/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1291 - accuracy: 0.9478 - val_loss: 1.4593 - val_accuracy: 0.7941\n",
      "Epoch 343/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1221 - accuracy: 0.9471 - val_loss: 1.4699 - val_accuracy: 0.7952\n",
      "Epoch 344/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1255 - accuracy: 0.9439 - val_loss: 1.5685 - val_accuracy: 0.7958\n",
      "Epoch 345/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1285 - accuracy: 0.9445 - val_loss: 1.3087 - val_accuracy: 0.8119\n",
      "Epoch 346/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1438 - accuracy: 0.9375 - val_loss: 1.3848 - val_accuracy: 0.8064\n",
      "Epoch 347/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1228 - accuracy: 0.9460 - val_loss: 2.0566 - val_accuracy: 0.7835\n",
      "Epoch 348/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1575 - accuracy: 0.9346 - val_loss: 1.5944 - val_accuracy: 0.7712\n",
      "Epoch 349/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1170 - accuracy: 0.9509 - val_loss: 1.3248 - val_accuracy: 0.7991\n",
      "Epoch 350/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1442 - accuracy: 0.9429 - val_loss: 1.0808 - val_accuracy: 0.7991\n",
      "Epoch 351/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1190 - accuracy: 0.9516 - val_loss: 1.4150 - val_accuracy: 0.7991\n",
      "Epoch 352/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1149 - accuracy: 0.9485 - val_loss: 1.6685 - val_accuracy: 0.7695\n",
      "Epoch 353/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1155 - accuracy: 0.9509 - val_loss: 2.0708 - val_accuracy: 0.7812\n",
      "Epoch 354/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1266 - accuracy: 0.9459 - val_loss: 1.9028 - val_accuracy: 0.7673\n",
      "Epoch 355/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1211 - accuracy: 0.9457 - val_loss: 1.6375 - val_accuracy: 0.7919\n",
      "Epoch 356/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1234 - accuracy: 0.9496 - val_loss: 1.4466 - val_accuracy: 0.8103\n",
      "Epoch 357/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1276 - accuracy: 0.9494 - val_loss: 1.4278 - val_accuracy: 0.7896\n",
      "Epoch 358/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1173 - accuracy: 0.9510 - val_loss: 1.5142 - val_accuracy: 0.7896\n",
      "Epoch 359/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1186 - accuracy: 0.9501 - val_loss: 1.6166 - val_accuracy: 0.7796\n",
      "Epoch 360/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1202 - accuracy: 0.9506 - val_loss: 1.5835 - val_accuracy: 0.7857\n",
      "Epoch 361/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1287 - accuracy: 0.9442 - val_loss: 1.4762 - val_accuracy: 0.8108\n",
      "Epoch 362/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1169 - accuracy: 0.9498 - val_loss: 1.8438 - val_accuracy: 0.8002\n",
      "Epoch 363/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1279 - accuracy: 0.9501 - val_loss: 1.4071 - val_accuracy: 0.7874\n",
      "Epoch 364/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1167 - accuracy: 0.9474 - val_loss: 1.4797 - val_accuracy: 0.7902\n",
      "Epoch 365/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1121 - accuracy: 0.9541 - val_loss: 1.3757 - val_accuracy: 0.7416\n",
      "Epoch 366/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1293 - accuracy: 0.9459 - val_loss: 1.6471 - val_accuracy: 0.7868\n",
      "Epoch 367/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1095 - accuracy: 0.9542 - val_loss: 1.5968 - val_accuracy: 0.7840\n",
      "Epoch 368/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1166 - accuracy: 0.9561 - val_loss: 1.5746 - val_accuracy: 0.7907\n",
      "Epoch 369/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1178 - accuracy: 0.9512 - val_loss: 1.3875 - val_accuracy: 0.7846\n",
      "Epoch 370/1200\n",
      "112/112 [==============================] - 5s 40ms/step - loss: 0.1211 - accuracy: 0.9470 - val_loss: 1.6297 - val_accuracy: 0.8036\n",
      "Epoch 371/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1120 - accuracy: 0.9552 - val_loss: 1.3877 - val_accuracy: 0.8103\n",
      "Epoch 372/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1020 - accuracy: 0.9573 - val_loss: 1.5026 - val_accuracy: 0.7729\n",
      "Epoch 373/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1136 - accuracy: 0.9555 - val_loss: 1.3747 - val_accuracy: 0.8114\n",
      "Epoch 374/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1123 - accuracy: 0.9503 - val_loss: 1.9658 - val_accuracy: 0.7623\n",
      "Epoch 375/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1432 - accuracy: 0.9413 - val_loss: 1.3708 - val_accuracy: 0.7734\n",
      "Epoch 376/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1103 - accuracy: 0.9502 - val_loss: 1.4805 - val_accuracy: 0.7902- loss: 0.1078 - ac\n",
      "Epoch 377/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1095 - accuracy: 0.9568 - val_loss: 1.8771 - val_accuracy: 0.7723\n",
      "Epoch 378/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1122 - accuracy: 0.9537 - val_loss: 1.8426 - val_accuracy: 0.7740\n",
      "Epoch 379/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1050 - accuracy: 0.9574 - val_loss: 1.6361 - val_accuracy: 0.8058\n",
      "Epoch 380/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1095 - accuracy: 0.9535 - val_loss: 1.6814 - val_accuracy: 0.7885\n",
      "Epoch 381/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1248 - accuracy: 0.9508 - val_loss: 1.4196 - val_accuracy: 0.7946\n",
      "Epoch 382/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1115 - accuracy: 0.9538 - val_loss: 1.8561 - val_accuracy: 0.7863\n",
      "Epoch 383/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1111 - accuracy: 0.9519 - val_loss: 1.4657 - val_accuracy: 0.7913\n",
      "Epoch 384/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1044 - accuracy: 0.9545 - val_loss: 1.8297 - val_accuracy: 0.7863\n",
      "Epoch 385/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0985 - accuracy: 0.9559 - val_loss: 1.3157 - val_accuracy: 0.7812\n",
      "Epoch 386/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0905 - accuracy: 0.9607 - val_loss: 1.3146 - val_accuracy: 0.8147\n",
      "Epoch 387/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0996 - accuracy: 0.9611 - val_loss: 2.0818 - val_accuracy: 0.8052\n",
      "Epoch 388/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1086 - accuracy: 0.9556 - val_loss: 1.3876 - val_accuracy: 0.8153\n",
      "Epoch 389/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0992 - accuracy: 0.9595 - val_loss: 1.7489 - val_accuracy: 0.7991\n",
      "Epoch 390/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1126 - accuracy: 0.9519 - val_loss: 1.2345 - val_accuracy: 0.8008\n",
      "Epoch 391/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1226 - accuracy: 0.9496 - val_loss: 1.6792 - val_accuracy: 0.8013\n",
      "Epoch 392/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1110 - accuracy: 0.9521 - val_loss: 1.8517 - val_accuracy: 0.7818\n",
      "Epoch 393/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0976 - accuracy: 0.9573 - val_loss: 1.8751 - val_accuracy: 0.7980\n",
      "Epoch 394/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1059 - accuracy: 0.9562 - val_loss: 1.5096 - val_accuracy: 0.8304\n",
      "Epoch 395/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0974 - accuracy: 0.9607 - val_loss: 1.8097 - val_accuracy: 0.7734\n",
      "Epoch 396/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0920 - accuracy: 0.9622 - val_loss: 1.6538 - val_accuracy: 0.8276\n",
      "Epoch 397/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1055 - accuracy: 0.9566 - val_loss: 2.6881 - val_accuracy: 0.7673\n",
      "Epoch 398/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0947 - accuracy: 0.9615 - val_loss: 1.8869 - val_accuracy: 0.7840\n",
      "Epoch 399/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1222 - accuracy: 0.9489 - val_loss: 1.4556 - val_accuracy: 0.8153\n",
      "Epoch 400/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1023 - accuracy: 0.9621 - val_loss: 1.3479 - val_accuracy: 0.7958\n",
      "Epoch 401/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1166 - accuracy: 0.9528 - val_loss: 1.5929 - val_accuracy: 0.8013\n",
      "Epoch 402/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0898 - accuracy: 0.9650 - val_loss: 1.6074 - val_accuracy: 0.7941\n",
      "Epoch 403/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0888 - accuracy: 0.9637 - val_loss: 1.9022 - val_accuracy: 0.7718\n",
      "Epoch 404/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0941 - accuracy: 0.9615 - val_loss: 1.6665 - val_accuracy: 0.8108\n",
      "Epoch 405/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0952 - accuracy: 0.9611 - val_loss: 1.4864 - val_accuracy: 0.8198\n",
      "Epoch 406/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0909 - accuracy: 0.9608 - val_loss: 1.6144 - val_accuracy: 0.8225\n",
      "Epoch 407/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1126 - accuracy: 0.9523 - val_loss: 2.0625 - val_accuracy: 0.7868\n",
      "Epoch 408/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1071 - accuracy: 0.9574 - val_loss: 1.8016 - val_accuracy: 0.7907\n",
      "Epoch 409/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0980 - accuracy: 0.9580 - val_loss: 1.4430 - val_accuracy: 0.8002\n",
      "Epoch 410/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1058 - accuracy: 0.9537 - val_loss: 1.8170 - val_accuracy: 0.7662\n",
      "Epoch 411/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1024 - accuracy: 0.9588 - val_loss: 1.8776 - val_accuracy: 0.7924\n",
      "Epoch 412/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1028 - accuracy: 0.9577 - val_loss: 1.5672 - val_accuracy: 0.8153\n",
      "Epoch 413/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1047 - accuracy: 0.9598 - val_loss: 1.6253 - val_accuracy: 0.8186\n",
      "Epoch 414/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0883 - accuracy: 0.9653 - val_loss: 1.8686 - val_accuracy: 0.7974\n",
      "Epoch 415/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0879 - accuracy: 0.9629 - val_loss: 1.7503 - val_accuracy: 0.7930\n",
      "Epoch 416/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.1126 - accuracy: 0.9563 - val_loss: 1.4993 - val_accuracy: 0.7902\n",
      "Epoch 417/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0943 - accuracy: 0.9597 - val_loss: 1.8528 - val_accuracy: 0.7991\n",
      "Epoch 418/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1191 - accuracy: 0.9561 - val_loss: 1.6973 - val_accuracy: 0.8041\n",
      "Epoch 419/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0791 - accuracy: 0.9657 - val_loss: 1.4172 - val_accuracy: 0.7913loss: 0.0790 - accuracy: 0.\n",
      "Epoch 420/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1021 - accuracy: 0.9591 - val_loss: 1.4880 - val_accuracy: 0.8186\n",
      "Epoch 421/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1309 - accuracy: 0.9561 - val_loss: 1.3629 - val_accuracy: 0.7896\n",
      "Epoch 422/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0983 - accuracy: 0.9607 - val_loss: 1.9203 - val_accuracy: 0.7835\n",
      "Epoch 423/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0972 - accuracy: 0.9598 - val_loss: 1.3123 - val_accuracy: 0.8108\n",
      "Epoch 424/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1014 - accuracy: 0.9568 - val_loss: 1.7001 - val_accuracy: 0.8080\n",
      "Epoch 425/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0937 - accuracy: 0.9612 - val_loss: 1.7968 - val_accuracy: 0.7946\n",
      "Epoch 426/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0861 - accuracy: 0.9639 - val_loss: 1.6796 - val_accuracy: 0.8142\n",
      "Epoch 427/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0848 - accuracy: 0.9646 - val_loss: 1.7603 - val_accuracy: 0.7991\n",
      "Epoch 428/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0901 - accuracy: 0.9618 - val_loss: 1.6214 - val_accuracy: 0.7997\n",
      "Epoch 429/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0902 - accuracy: 0.9625 - val_loss: 1.8682 - val_accuracy: 0.7974\n",
      "Epoch 430/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0838 - accuracy: 0.9671 - val_loss: 1.5767 - val_accuracy: 0.8058\n",
      "Epoch 431/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.0936 - accuracy: 0.9632 - val_loss: 1.8346 - val_accuracy: 0.8058\n",
      "Epoch 432/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0986 - accuracy: 0.9604 - val_loss: 2.1709 - val_accuracy: 0.75950.0\n",
      "Epoch 433/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0930 - accuracy: 0.9636 - val_loss: 1.9325 - val_accuracy: 0.7779\n",
      "Epoch 434/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0958 - accuracy: 0.9629 - val_loss: 2.0394 - val_accuracy: 0.7679\n",
      "Epoch 435/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0991 - accuracy: 0.9619 - val_loss: 1.5998 - val_accuracy: 0.7946\n",
      "Epoch 436/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1095 - accuracy: 0.9534 - val_loss: 1.4390 - val_accuracy: 0.7935\n",
      "Epoch 437/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1023 - accuracy: 0.9594 - val_loss: 1.7294 - val_accuracy: 0.7935\n",
      "Epoch 438/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0905 - accuracy: 0.9637 - val_loss: 1.8457 - val_accuracy: 0.7662\n",
      "Epoch 439/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0997 - accuracy: 0.9580 - val_loss: 1.5871 - val_accuracy: 0.8092\n",
      "Epoch 440/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1052 - accuracy: 0.9595 - val_loss: 2.0132 - val_accuracy: 0.7467\n",
      "Epoch 441/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0883 - accuracy: 0.9637 - val_loss: 2.0395 - val_accuracy: 0.7824\n",
      "Epoch 442/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0897 - accuracy: 0.9625 - val_loss: 2.2610 - val_accuracy: 0.7863\n",
      "Epoch 443/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0899 - accuracy: 0.9648 - val_loss: 2.2382 - val_accuracy: 0.7902\n",
      "Epoch 444/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0879 - accuracy: 0.9658 - val_loss: 1.8901 - val_accuracy: 0.7935\n",
      "Epoch 445/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1028 - accuracy: 0.9619 - val_loss: 1.7904 - val_accuracy: 0.7768\n",
      "Epoch 446/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0971 - accuracy: 0.9597 - val_loss: 2.2992 - val_accuracy: 0.7835\n",
      "Epoch 447/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0810 - accuracy: 0.9674 - val_loss: 1.7785 - val_accuracy: 0.7980\n",
      "Epoch 448/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0754 - accuracy: 0.9690 - val_loss: 2.0353 - val_accuracy: 0.7985\n",
      "Epoch 449/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0854 - accuracy: 0.9662 - val_loss: 1.6861 - val_accuracy: 0.7980\n",
      "Epoch 450/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0914 - accuracy: 0.9646 - val_loss: 2.1423 - val_accuracy: 0.7712\n",
      "Epoch 451/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0908 - accuracy: 0.9636 - val_loss: 1.7673 - val_accuracy: 0.7762\n",
      "Epoch 452/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0733 - accuracy: 0.9693 - val_loss: 1.7244 - val_accuracy: 0.7868\n",
      "Epoch 453/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0822 - accuracy: 0.9697 - val_loss: 2.2572 - val_accuracy: 0.7812\n",
      "Epoch 454/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1172 - accuracy: 0.9600 - val_loss: 1.4780 - val_accuracy: 0.8092\n",
      "Epoch 455/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0775 - accuracy: 0.9682 - val_loss: 2.0119 - val_accuracy: 0.7818\n",
      "Epoch 456/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0788 - accuracy: 0.9686 - val_loss: 1.8838 - val_accuracy: 0.8103\n",
      "Epoch 457/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0765 - accuracy: 0.9689 - val_loss: 1.8865 - val_accuracy: 0.7952\n",
      "Epoch 458/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0790 - accuracy: 0.9671 - val_loss: 2.0976 - val_accuracy: 0.8025\n",
      "Epoch 459/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0832 - accuracy: 0.9643 - val_loss: 1.9037 - val_accuracy: 0.7857\n",
      "Epoch 460/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0791 - accuracy: 0.9665 - val_loss: 1.9684 - val_accuracy: 0.8175\n",
      "Epoch 461/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0777 - accuracy: 0.9704 - val_loss: 2.7120 - val_accuracy: 0.7913\n",
      "Epoch 462/1200\n",
      "112/112 [==============================] - 5s 40ms/step - loss: 0.0946 - accuracy: 0.9637 - val_loss: 1.6962 - val_accuracy: 0.8114\n",
      "Epoch 463/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0784 - accuracy: 0.9713 - val_loss: 2.1408 - val_accuracy: 0.7852\n",
      "Epoch 464/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0895 - accuracy: 0.9629 - val_loss: 1.8225 - val_accuracy: 0.7863\n",
      "Epoch 465/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0794 - accuracy: 0.9674 - val_loss: 1.7602 - val_accuracy: 0.7980\n",
      "Epoch 466/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0912 - accuracy: 0.9636 - val_loss: 1.8294 - val_accuracy: 0.8013\n",
      "Epoch 467/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0774 - accuracy: 0.9683 - val_loss: 2.1401 - val_accuracy: 0.7891\n",
      "Epoch 468/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1210 - accuracy: 0.9570 - val_loss: 2.4327 - val_accuracy: 0.7958\n",
      "Epoch 469/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0800 - accuracy: 0.9678 - val_loss: 1.8947 - val_accuracy: 0.8047\n",
      "Epoch 470/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0747 - accuracy: 0.9732 - val_loss: 1.7967 - val_accuracy: 0.8064\n",
      "Epoch 471/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1057 - accuracy: 0.9619 - val_loss: 1.7376 - val_accuracy: 0.7958\n",
      "Epoch 472/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0838 - accuracy: 0.9654 - val_loss: 1.8985 - val_accuracy: 0.7969\n",
      "Epoch 473/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0852 - accuracy: 0.9653 - val_loss: 2.0202 - val_accuracy: 0.8069\n",
      "Epoch 474/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0848 - accuracy: 0.9633 - val_loss: 1.5613 - val_accuracy: 0.8214\n",
      "Epoch 475/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0946 - accuracy: 0.9641 - val_loss: 1.7442 - val_accuracy: 0.8002\n",
      "Epoch 476/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0817 - accuracy: 0.9689 - val_loss: 1.9454 - val_accuracy: 0.7997\n",
      "Epoch 477/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0909 - accuracy: 0.9651 - val_loss: 1.8020 - val_accuracy: 0.7835\n",
      "Epoch 478/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0777 - accuracy: 0.9693 - val_loss: 2.1621 - val_accuracy: 0.7891\n",
      "Epoch 479/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0781 - accuracy: 0.9676 - val_loss: 2.0548 - val_accuracy: 0.7930\n",
      "Epoch 480/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0982 - accuracy: 0.9633 - val_loss: 1.7670 - val_accuracy: 0.8064\n",
      "Epoch 481/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0860 - accuracy: 0.9683 - val_loss: 1.8446 - val_accuracy: 0.8025\n",
      "Epoch 482/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0808 - accuracy: 0.9675 - val_loss: 2.0450 - val_accuracy: 0.7941\n",
      "Epoch 483/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0717 - accuracy: 0.9725 - val_loss: 2.1430 - val_accuracy: 0.8114\n",
      "Epoch 484/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0748 - accuracy: 0.9693 - val_loss: 1.9700 - val_accuracy: 0.8036\n",
      "Epoch 485/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0757 - accuracy: 0.9672 - val_loss: 2.8198 - val_accuracy: 0.7740\n",
      "Epoch 486/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0791 - accuracy: 0.9658 - val_loss: 1.6845 - val_accuracy: 0.8304\n",
      "Epoch 487/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0774 - accuracy: 0.9692 - val_loss: 1.7380 - val_accuracy: 0.8164\n",
      "Epoch 488/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0827 - accuracy: 0.9685 - val_loss: 1.7703 - val_accuracy: 0.7991\n",
      "Epoch 489/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0840 - accuracy: 0.9690 - val_loss: 1.4956 - val_accuracy: 0.8259\n",
      "Epoch 490/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0772 - accuracy: 0.9703 - val_loss: 1.6349 - val_accuracy: 0.8237\n",
      "Epoch 491/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0926 - accuracy: 0.9646 - val_loss: 2.2139 - val_accuracy: 0.8170\n",
      "Epoch 492/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0689 - accuracy: 0.9727 - val_loss: 2.0811 - val_accuracy: 0.7779\n",
      "Epoch 493/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0712 - accuracy: 0.9722 - val_loss: 1.9193 - val_accuracy: 0.8019\n",
      "Epoch 494/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0685 - accuracy: 0.9722 - val_loss: 2.0525 - val_accuracy: 0.7946\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00494: early stopping\n",
      "      1/Unknown - 0s 125ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 5ms/step\n",
      "     23/Unknown - 0s 5ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799/799 [==============================] - 4s 5ms/step\n",
      "200/200 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|                                         | 1/2 [38:14<38:14, 2294.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.6354 - accuracy: 0.6199 - val_loss: 0.6455 - val_accuracy: 0.5902\n",
      "Epoch 2/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6166 - accuracy: 0.6294 - val_loss: 0.6473 - val_accuracy: 0.6072\n",
      "Epoch 3/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.6170 - accuracy: 0.6299 - val_loss: 0.6564 - val_accuracy: 0.5618\n",
      "Epoch 4/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.6108 - accuracy: 0.6313 - val_loss: 0.6381 - val_accuracy: 0.6278\n",
      "Epoch 5/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6088 - accuracy: 0.6313 - val_loss: 0.6568 - val_accuracy: 0.5675\n",
      "Epoch 6/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.6115 - accuracy: 0.6292 - val_loss: 0.6633 - val_accuracy: 0.5469\n",
      "Epoch 7/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.6080 - accuracy: 0.6382 - val_loss: 0.6391 - val_accuracy: 0.5987\n",
      "Epoch 8/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.6109 - accuracy: 0.6327 - val_loss: 0.6852 - val_accuracy: 0.6016\n",
      "Epoch 9/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5993 - accuracy: 0.6403 - val_loss: 0.6348 - val_accuracy: 0.6463\n",
      "Epoch 10/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5989 - accuracy: 0.6412 - val_loss: 0.6440 - val_accuracy: 0.6470\n",
      "Epoch 11/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6070 - accuracy: 0.6357 - val_loss: 0.6713 - val_accuracy: 0.6051\n",
      "Epoch 12/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6016 - accuracy: 0.6285 - val_loss: 0.6731 - val_accuracy: 0.5817\n",
      "Epoch 13/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.6001 - accuracy: 0.6290 - val_loss: 0.6511 - val_accuracy: 0.6278\n",
      "Epoch 14/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6037 - accuracy: 0.6376 - val_loss: 0.6442 - val_accuracy: 0.6030\n",
      "Epoch 15/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5946 - accuracy: 0.6355 - val_loss: 0.6693 - val_accuracy: 0.5852\n",
      "Epoch 16/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5919 - accuracy: 0.6408 - val_loss: 0.6965 - val_accuracy: 0.5945\n",
      "Epoch 17/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6023 - accuracy: 0.6287 - val_loss: 0.6863 - val_accuracy: 0.5923\n",
      "Epoch 18/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5865 - accuracy: 0.6469 - val_loss: 0.6927 - val_accuracy: 0.5810\n",
      "Epoch 19/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5917 - accuracy: 0.6373 - val_loss: 0.7214 - val_accuracy: 0.5845\n",
      "Epoch 20/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5838 - accuracy: 0.6534 - val_loss: 0.6907 - val_accuracy: 0.6278\n",
      "Epoch 21/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5878 - accuracy: 0.6466 - val_loss: 0.6592 - val_accuracy: 0.6023\n",
      "Epoch 22/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5810 - accuracy: 0.6538 - val_loss: 0.7032 - val_accuracy: 0.5959\n",
      "Epoch 23/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5808 - accuracy: 0.6545 - val_loss: 0.7063 - val_accuracy: 0.5632\n",
      "Epoch 24/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5700 - accuracy: 0.6520 - val_loss: 0.7473 - val_accuracy: 0.6065\n",
      "Epoch 25/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5870 - accuracy: 0.6426 - val_loss: 0.7236 - val_accuracy: 0.5462\n",
      "Epoch 26/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5854 - accuracy: 0.6499 - val_loss: 0.6653 - val_accuracy: 0.6179\n",
      "Epoch 27/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5867 - accuracy: 0.6529 - val_loss: 0.7425 - val_accuracy: 0.5469\n",
      "Epoch 28/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5839 - accuracy: 0.6501 - val_loss: 0.7012 - val_accuracy: 0.5938\n",
      "Epoch 29/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5741 - accuracy: 0.6589 - val_loss: 0.7572 - val_accuracy: 0.5696\n",
      "Epoch 30/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5789 - accuracy: 0.6559 - val_loss: 0.7401 - val_accuracy: 0.5703\n",
      "Epoch 31/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5799 - accuracy: 0.6592 - val_loss: 0.7361 - val_accuracy: 0.5824\n",
      "Epoch 32/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5890 - accuracy: 0.6487 - val_loss: 0.7433 - val_accuracy: 0.5334\n",
      "Epoch 33/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5937 - accuracy: 0.6519 - val_loss: 0.7037 - val_accuracy: 0.5945\n",
      "Epoch 34/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5895 - accuracy: 0.6483 - val_loss: 0.7509 - val_accuracy: 0.5732\n",
      "Epoch 35/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5710 - accuracy: 0.6708 - val_loss: 0.7803 - val_accuracy: 0.5597\n",
      "Epoch 36/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.5871 - accuracy: 0.6531 - val_loss: 0.6706 - val_accuracy: 0.5930\n",
      "Epoch 37/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5774 - accuracy: 0.6601 - val_loss: 0.7051 - val_accuracy: 0.5952\n",
      "Epoch 38/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5619 - accuracy: 0.6728 - val_loss: 0.7328 - val_accuracy: 0.6065\n",
      "Epoch 39/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5789 - accuracy: 0.6594 - val_loss: 0.6780 - val_accuracy: 0.6065\n",
      "Epoch 40/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5612 - accuracy: 0.6724 - val_loss: 0.6749 - val_accuracy: 0.6463- loss: 0.552\n",
      "Epoch 41/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5620 - accuracy: 0.6764 - val_loss: 0.8129 - val_accuracy: 0.5774\n",
      "Epoch 42/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5637 - accuracy: 0.6691 - val_loss: 0.7562 - val_accuracy: 0.6186\n",
      "Epoch 43/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5662 - accuracy: 0.6754 - val_loss: 0.7460 - val_accuracy: 0.6009\n",
      "Epoch 44/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5526 - accuracy: 0.6831 - val_loss: 0.7329 - val_accuracy: 0.5987\n",
      "Epoch 45/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5575 - accuracy: 0.6871 - val_loss: 0.6431 - val_accuracy: 0.6584\n",
      "Epoch 46/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5615 - accuracy: 0.6743 - val_loss: 0.8730 - val_accuracy: 0.5227\n",
      "Epoch 47/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5604 - accuracy: 0.6726 - val_loss: 0.7759 - val_accuracy: 0.5767\n",
      "Epoch 48/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5576 - accuracy: 0.6824 - val_loss: 0.6928 - val_accuracy: 0.6570\n",
      "Epoch 49/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5619 - accuracy: 0.6794 - val_loss: 0.7247 - val_accuracy: 0.6172\n",
      "Epoch 50/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5470 - accuracy: 0.6966 - val_loss: 0.7155 - val_accuracy: 0.6335\n",
      "Epoch 51/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5509 - accuracy: 0.6852 - val_loss: 0.7082 - val_accuracy: 0.6243\n",
      "Epoch 52/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5473 - accuracy: 0.6819 - val_loss: 0.6695 - val_accuracy: 0.6470\n",
      "Epoch 53/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5574 - accuracy: 0.6796 - val_loss: 0.8016 - val_accuracy: 0.6101\n",
      "Epoch 54/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5555 - accuracy: 0.6873 - val_loss: 0.8586 - val_accuracy: 0.52770.5589 - accura\n",
      "Epoch 55/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5420 - accuracy: 0.6866 - val_loss: 0.7943 - val_accuracy: 0.5838\n",
      "Epoch 56/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5465 - accuracy: 0.6900 - val_loss: 0.7457 - val_accuracy: 0.5852\n",
      "Epoch 57/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5577 - accuracy: 0.6849 - val_loss: 0.7394 - val_accuracy: 0.6115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5373 - accuracy: 0.6910 - val_loss: 0.6651 - val_accuracy: 0.6499\n",
      "Epoch 59/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5337 - accuracy: 0.6873 - val_loss: 0.8017 - val_accuracy: 0.6300\n",
      "Epoch 60/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5262 - accuracy: 0.7072 - val_loss: 0.6939 - val_accuracy: 0.6570\n",
      "Epoch 61/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5409 - accuracy: 0.6929 - val_loss: 0.8037 - val_accuracy: 0.5852\n",
      "Epoch 62/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5181 - accuracy: 0.7089 - val_loss: 0.7240 - val_accuracy: 0.6456\n",
      "Epoch 63/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5226 - accuracy: 0.7047 - val_loss: 0.8018 - val_accuracy: 0.6293\n",
      "Epoch 64/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5393 - accuracy: 0.6887 - val_loss: 0.7117 - val_accuracy: 0.6634\n",
      "Epoch 65/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5161 - accuracy: 0.7119 - val_loss: 0.7165 - val_accuracy: 0.6080\n",
      "Epoch 66/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5195 - accuracy: 0.7135 - val_loss: 0.7890 - val_accuracy: 0.6122\n",
      "Epoch 67/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5214 - accuracy: 0.7105 - val_loss: 0.7293 - val_accuracy: 0.6357\n",
      "Epoch 68/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5245 - accuracy: 0.7066 - val_loss: 0.7786 - val_accuracy: 0.6349\n",
      "Epoch 69/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5259 - accuracy: 0.7101 - val_loss: 0.8469 - val_accuracy: 0.6108\n",
      "Epoch 70/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5390 - accuracy: 0.6859 - val_loss: 0.8430 - val_accuracy: 0.6300\n",
      "Epoch 71/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5172 - accuracy: 0.7116 - val_loss: 0.8585 - val_accuracy: 0.5994\n",
      "Epoch 72/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5068 - accuracy: 0.7130 - val_loss: 0.8392 - val_accuracy: 0.5945\n",
      "Epoch 73/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5263 - accuracy: 0.7063 - val_loss: 0.7189 - val_accuracy: 0.6428\n",
      "Epoch 74/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5166 - accuracy: 0.7131 - val_loss: 0.8800 - val_accuracy: 0.6349\n",
      "Epoch 75/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5141 - accuracy: 0.7149 - val_loss: 0.7336 - val_accuracy: 0.6349\n",
      "Epoch 76/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5037 - accuracy: 0.7180 - val_loss: 0.7671 - val_accuracy: 0.6641\n",
      "Epoch 77/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5108 - accuracy: 0.7186 - val_loss: 0.7879 - val_accuracy: 0.5952\n",
      "Epoch 78/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4917 - accuracy: 0.7272 - val_loss: 0.7618 - val_accuracy: 0.6186\n",
      "Epoch 79/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5073 - accuracy: 0.7144 - val_loss: 0.7065 - val_accuracy: 0.6392\n",
      "Epoch 80/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5056 - accuracy: 0.7288 - val_loss: 0.7467 - val_accuracy: 0.6435\n",
      "Epoch 81/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5099 - accuracy: 0.7159 - val_loss: 0.6630 - val_accuracy: 0.6534\n",
      "Epoch 82/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4990 - accuracy: 0.7182 - val_loss: 0.7309 - val_accuracy: 0.6108\n",
      "Epoch 83/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4867 - accuracy: 0.7330 - val_loss: 0.7603 - val_accuracy: 0.6342\n",
      "Epoch 84/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5005 - accuracy: 0.7140 - val_loss: 0.8490 - val_accuracy: 0.6143\n",
      "Epoch 85/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4851 - accuracy: 0.7338 - val_loss: 0.8702 - val_accuracy: 0.6094\n",
      "Epoch 86/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4863 - accuracy: 0.7395 - val_loss: 0.7874 - val_accuracy: 0.6335\n",
      "Epoch 87/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4917 - accuracy: 0.7298 - val_loss: 0.8984 - val_accuracy: 0.6151\n",
      "Epoch 88/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4974 - accuracy: 0.7191 - val_loss: 0.9221 - val_accuracy: 0.6158\n",
      "Epoch 89/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4812 - accuracy: 0.7391 - val_loss: 0.7084 - val_accuracy: 0.6321ccuracy: 0.\n",
      "Epoch 90/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4699 - accuracy: 0.7475 - val_loss: 0.8078 - val_accuracy: 0.6236\n",
      "Epoch 91/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4830 - accuracy: 0.7395 - val_loss: 0.7395 - val_accuracy: 0.6506\n",
      "Epoch 92/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4869 - accuracy: 0.7252 - val_loss: 0.7877 - val_accuracy: 0.6676\n",
      "Epoch 93/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4683 - accuracy: 0.7428 - val_loss: 0.7437 - val_accuracy: 0.6172\n",
      "Epoch 94/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4806 - accuracy: 0.7368 - val_loss: 0.8701 - val_accuracy: 0.6286\n",
      "Epoch 95/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4617 - accuracy: 0.7502 - val_loss: 0.9199 - val_accuracy: 0.6257\n",
      "Epoch 96/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4799 - accuracy: 0.7410 - val_loss: 0.7718 - val_accuracy: 0.6790\n",
      "Epoch 97/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4730 - accuracy: 0.7400 - val_loss: 0.7755 - val_accuracy: 0.6293\n",
      "Epoch 98/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4602 - accuracy: 0.7489 - val_loss: 0.8876 - val_accuracy: 0.6080\n",
      "Epoch 99/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4776 - accuracy: 0.7346 - val_loss: 0.7601 - val_accuracy: 0.6463\n",
      "Epoch 100/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4530 - accuracy: 0.7532 - val_loss: 0.7892 - val_accuracy: 0.5909\n",
      "Epoch 101/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4631 - accuracy: 0.7421 - val_loss: 0.8162 - val_accuracy: 0.6357\n",
      "Epoch 102/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4632 - accuracy: 0.7442 - val_loss: 0.8219 - val_accuracy: 0.6697\n",
      "Epoch 103/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4372 - accuracy: 0.7604 - val_loss: 0.7468 - val_accuracy: 0.6364\n",
      "Epoch 104/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4512 - accuracy: 0.7561 - val_loss: 0.8797 - val_accuracy: 0.6229\n",
      "Epoch 105/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4505 - accuracy: 0.7609 - val_loss: 0.9922 - val_accuracy: 0.6293\n",
      "Epoch 106/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4544 - accuracy: 0.7604 - val_loss: 0.9011 - val_accuracy: 0.6257\n",
      "Epoch 107/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4591 - accuracy: 0.7565 - val_loss: 0.9012 - val_accuracy: 0.6527\n",
      "Epoch 108/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4311 - accuracy: 0.7681 - val_loss: 0.8929 - val_accuracy: 0.6385\n",
      "Epoch 109/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4250 - accuracy: 0.7767 - val_loss: 0.9713 - val_accuracy: 0.6300\n",
      "Epoch 110/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4666 - accuracy: 0.7465 - val_loss: 0.8068 - val_accuracy: 0.6499\n",
      "Epoch 111/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4404 - accuracy: 0.7626 - val_loss: 0.9830 - val_accuracy: 0.6172\n",
      "Epoch 112/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4178 - accuracy: 0.7753 - val_loss: 0.9832 - val_accuracy: 0.6087\n",
      "Epoch 113/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4286 - accuracy: 0.7744 - val_loss: 1.0141 - val_accuracy: 0.6257\n",
      "Epoch 114/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4297 - accuracy: 0.7704 - val_loss: 1.1123 - val_accuracy: 0.6165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4210 - accuracy: 0.7719 - val_loss: 0.9548 - val_accuracy: 0.6385\n",
      "Epoch 116/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4403 - accuracy: 0.7691 - val_loss: 0.9728 - val_accuracy: 0.6392\n",
      "Epoch 117/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4126 - accuracy: 0.7811 - val_loss: 0.8455 - val_accuracy: 0.6534\n",
      "Epoch 118/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4149 - accuracy: 0.7784 - val_loss: 0.9294 - val_accuracy: 0.6229\n",
      "Epoch 119/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4184 - accuracy: 0.7814 - val_loss: 1.0027 - val_accuracy: 0.6200\n",
      "Epoch 120/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4189 - accuracy: 0.7765 - val_loss: 1.1232 - val_accuracy: 0.6548\n",
      "Epoch 121/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4141 - accuracy: 0.7877 - val_loss: 0.8376 - val_accuracy: 0.6584\n",
      "Epoch 122/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4173 - accuracy: 0.7848 - val_loss: 1.0508 - val_accuracy: 0.6271\n",
      "Epoch 123/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4002 - accuracy: 0.7939 - val_loss: 1.1242 - val_accuracy: 0.6179\n",
      "Epoch 124/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4133 - accuracy: 0.7821 - val_loss: 0.8900 - val_accuracy: 0.6605\n",
      "Epoch 125/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4043 - accuracy: 0.7927 - val_loss: 0.9362 - val_accuracy: 0.6435\n",
      "Epoch 126/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4106 - accuracy: 0.7812 - val_loss: 0.9417 - val_accuracy: 0.5959\n",
      "Epoch 127/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4080 - accuracy: 0.7909 - val_loss: 0.9349 - val_accuracy: 0.6655\n",
      "Epoch 128/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4046 - accuracy: 0.7846 - val_loss: 1.0682 - val_accuracy: 0.6001\n",
      "Epoch 129/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3881 - accuracy: 0.7893 - val_loss: 1.3429 - val_accuracy: 0.6257\n",
      "Epoch 130/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4028 - accuracy: 0.8021 - val_loss: 1.1429 - val_accuracy: 0.6733\n",
      "Epoch 131/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3977 - accuracy: 0.7971 - val_loss: 0.9315 - val_accuracy: 0.6477\n",
      "Epoch 132/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3868 - accuracy: 0.7967 - val_loss: 0.9940 - val_accuracy: 0.6662\n",
      "Epoch 133/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3802 - accuracy: 0.8009 - val_loss: 1.0573 - val_accuracy: 0.6662\n",
      "Epoch 134/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.3914 - accuracy: 0.7886 - val_loss: 1.0476 - val_accuracy: 0.6712\n",
      "Epoch 135/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3836 - accuracy: 0.8046 - val_loss: 0.9574 - val_accuracy: 0.6662\n",
      "Epoch 136/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3958 - accuracy: 0.7965 - val_loss: 0.9755 - val_accuracy: 0.6655\n",
      "Epoch 137/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3877 - accuracy: 0.7941 - val_loss: 0.9265 - val_accuracy: 0.6683\n",
      "Epoch 138/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3758 - accuracy: 0.8069 - val_loss: 0.8743 - val_accuracy: 0.6385\n",
      "Epoch 139/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3705 - accuracy: 0.8053 - val_loss: 1.0349 - val_accuracy: 0.6534\n",
      "Epoch 140/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3736 - accuracy: 0.8057 - val_loss: 1.1401 - val_accuracy: 0.6527\n",
      "Epoch 141/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3987 - accuracy: 0.7907 - val_loss: 1.1639 - val_accuracy: 0.6250\n",
      "Epoch 142/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3743 - accuracy: 0.8074 - val_loss: 1.1619 - val_accuracy: 0.6754\n",
      "Epoch 143/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3541 - accuracy: 0.8218 - val_loss: 1.2223 - val_accuracy: 0.6882\n",
      "Epoch 144/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3667 - accuracy: 0.8113 - val_loss: 1.0429 - val_accuracy: 0.6641\n",
      "Epoch 145/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3834 - accuracy: 0.8039 - val_loss: 1.1167 - val_accuracy: 0.6669 1s - loss: 0.3586  - ETA: 0s - loss: 0.383\n",
      "Epoch 146/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4361 - accuracy: 0.7716 - val_loss: 1.1585 - val_accuracy: 0.6378\n",
      "Epoch 147/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3784 - accuracy: 0.7958 - val_loss: 1.1194 - val_accuracy: 0.6250\n",
      "Epoch 148/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.3545 - accuracy: 0.8132 - val_loss: 1.1065 - val_accuracy: 0.6200\n",
      "Epoch 149/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3425 - accuracy: 0.8230 - val_loss: 1.0560 - val_accuracy: 0.6229\n",
      "Epoch 150/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3511 - accuracy: 0.8146 - val_loss: 1.0609 - val_accuracy: 0.6761\n",
      "Epoch 151/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.3673 - accuracy: 0.8167 - val_loss: 1.2161 - val_accuracy: 0.6300\n",
      "Epoch 152/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3575 - accuracy: 0.8157 - val_loss: 1.1344 - val_accuracy: 0.6832\n",
      "Epoch 153/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3526 - accuracy: 0.8227 - val_loss: 1.1003 - val_accuracy: 0.6960\n",
      "Epoch 154/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3683 - accuracy: 0.8114 - val_loss: 1.1475 - val_accuracy: 0.6918\n",
      "Epoch 155/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3416 - accuracy: 0.8269 - val_loss: 1.3542 - val_accuracy: 0.6662\n",
      "Epoch 156/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3536 - accuracy: 0.8174 - val_loss: 1.0558 - val_accuracy: 0.6449\n",
      "Epoch 157/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3481 - accuracy: 0.8216 - val_loss: 1.2788 - val_accuracy: 0.6754\n",
      "Epoch 158/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3421 - accuracy: 0.8311 - val_loss: 1.0560 - val_accuracy: 0.6349 accuracy: 0.\n",
      "Epoch 159/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3416 - accuracy: 0.8322 - val_loss: 1.2762 - val_accuracy: 0.6442\n",
      "Epoch 160/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3476 - accuracy: 0.8229 - val_loss: 1.1203 - val_accuracy: 0.6861\n",
      "Epoch 161/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3527 - accuracy: 0.8160 - val_loss: 1.3203 - val_accuracy: 0.6889\n",
      "Epoch 162/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3301 - accuracy: 0.8297 - val_loss: 1.2949 - val_accuracy: 0.6520\n",
      "Epoch 163/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3422 - accuracy: 0.8250 - val_loss: 1.3454 - val_accuracy: 0.6562\n",
      "Epoch 164/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3387 - accuracy: 0.8299 - val_loss: 1.3323 - val_accuracy: 0.6726\n",
      "Epoch 165/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3284 - accuracy: 0.8325 - val_loss: 1.6121 - val_accuracy: 0.6562\n",
      "Epoch 166/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3334 - accuracy: 0.8350 - val_loss: 1.0351 - val_accuracy: 0.6442\n",
      "Epoch 167/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3167 - accuracy: 0.8380 - val_loss: 1.3926 - val_accuracy: 0.7060\n",
      "Epoch 168/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3219 - accuracy: 0.8344 - val_loss: 1.3473 - val_accuracy: 0.6697\n",
      "Epoch 169/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3299 - accuracy: 0.8380 - val_loss: 1.0830 - val_accuracy: 0.6932\n",
      "Epoch 170/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3282 - accuracy: 0.8337 - val_loss: 1.2032 - val_accuracy: 0.6726\n",
      "Epoch 171/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2885 - accuracy: 0.8596 - val_loss: 1.5842 - val_accuracy: 0.6527\n",
      "Epoch 172/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3260 - accuracy: 0.8388 - val_loss: 1.3548 - val_accuracy: 0.6932\n",
      "Epoch 173/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3091 - accuracy: 0.8464 - val_loss: 1.4309 - val_accuracy: 0.6484\n",
      "Epoch 174/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3084 - accuracy: 0.8459 - val_loss: 1.2778 - val_accuracy: 0.6491\n",
      "Epoch 175/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3145 - accuracy: 0.8376 - val_loss: 1.5467 - val_accuracy: 0.6861\n",
      "Epoch 176/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3289 - accuracy: 0.8357 - val_loss: 1.4522 - val_accuracy: 0.6783\n",
      "Epoch 177/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3246 - accuracy: 0.8353 - val_loss: 1.3907 - val_accuracy: 0.6939\n",
      "Epoch 178/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2807 - accuracy: 0.8638 - val_loss: 1.4913 - val_accuracy: 0.6740\n",
      "Epoch 179/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3244 - accuracy: 0.8334 - val_loss: 1.3408 - val_accuracy: 0.6776\n",
      "Epoch 180/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2900 - accuracy: 0.8574 - val_loss: 1.5012 - val_accuracy: 0.6690\n",
      "Epoch 181/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3145 - accuracy: 0.8474 - val_loss: 1.1808 - val_accuracy: 0.7003\n",
      "Epoch 182/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2890 - accuracy: 0.8581 - val_loss: 1.6297 - val_accuracy: 0.6626\n",
      "Epoch 183/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3497 - accuracy: 0.8306 - val_loss: 1.1860 - val_accuracy: 0.7045\n",
      "Epoch 184/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3098 - accuracy: 0.8460 - val_loss: 1.3210 - val_accuracy: 0.7166\n",
      "Epoch 185/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2872 - accuracy: 0.8604 - val_loss: 1.5748 - val_accuracy: 0.6925\n",
      "Epoch 186/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2886 - accuracy: 0.8553 - val_loss: 1.4109 - val_accuracy: 0.6839\n",
      "Epoch 187/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2669 - accuracy: 0.8704 - val_loss: 1.2452 - val_accuracy: 0.6953\n",
      "Epoch 188/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2774 - accuracy: 0.8676 - val_loss: 1.5651 - val_accuracy: 0.6520\n",
      "Epoch 189/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2971 - accuracy: 0.8603 - val_loss: 1.5708 - val_accuracy: 0.6896\n",
      "Epoch 190/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2789 - accuracy: 0.8666 - val_loss: 1.7111 - val_accuracy: 0.6385\n",
      "Epoch 191/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2887 - accuracy: 0.8581 - val_loss: 1.3463 - val_accuracy: 0.67400.268 - ETA: \n",
      "Epoch 192/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2827 - accuracy: 0.8622 - val_loss: 1.6192 - val_accuracy: 0.7145\n",
      "Epoch 193/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2880 - accuracy: 0.8539 - val_loss: 1.5531 - val_accuracy: 0.6740ETA: 0s - loss: 0.2872 - \n",
      "Epoch 194/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2893 - accuracy: 0.8550 - val_loss: 1.5750 - val_accuracy: 0.6960\n",
      "Epoch 195/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2696 - accuracy: 0.8706 - val_loss: 1.6024 - val_accuracy: 0.6953\n",
      "Epoch 196/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2653 - accuracy: 0.8636 - val_loss: 1.6273 - val_accuracy: 0.6797\n",
      "Epoch 197/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2596 - accuracy: 0.8739 - val_loss: 1.4721 - val_accuracy: 0.6882\n",
      "Epoch 198/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2784 - accuracy: 0.8683 - val_loss: 1.5042 - val_accuracy: 0.6726\n",
      "Epoch 199/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2970 - accuracy: 0.8573 - val_loss: 1.5423 - val_accuracy: 0.7074\n",
      "Epoch 200/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2613 - accuracy: 0.8669 - val_loss: 1.4602 - val_accuracy: 0.6960\n",
      "Epoch 201/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2667 - accuracy: 0.8725 - val_loss: 1.4527 - val_accuracy: 0.6726\n",
      "Epoch 202/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2602 - accuracy: 0.8810 - val_loss: 1.8436 - val_accuracy: 0.6967\n",
      "Epoch 203/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2614 - accuracy: 0.8750 - val_loss: 1.9540 - val_accuracy: 0.7074\n",
      "Epoch 204/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2641 - accuracy: 0.8768 - val_loss: 1.4194 - val_accuracy: 0.6733loss: 0.2866 \n",
      "Epoch 205/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2979 - accuracy: 0.8585 - val_loss: 1.3649 - val_accuracy: 0.6790\n",
      "Epoch 206/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2465 - accuracy: 0.8808 - val_loss: 1.9929 - val_accuracy: 0.7003\n",
      "Epoch 207/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2498 - accuracy: 0.8824 - val_loss: 1.6911 - val_accuracy: 0.6996\n",
      "Epoch 208/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2641 - accuracy: 0.8636 - val_loss: 1.8715 - val_accuracy: 0.6818\n",
      "Epoch 209/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2744 - accuracy: 0.8636 - val_loss: 1.6016 - val_accuracy: 0.7131\n",
      "Epoch 210/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2551 - accuracy: 0.8769 - val_loss: 1.6812 - val_accuracy: 0.6967\n",
      "Epoch 211/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2337 - accuracy: 0.8854 - val_loss: 1.8002 - val_accuracy: 0.6612\n",
      "Epoch 212/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2464 - accuracy: 0.8822 - val_loss: 1.7698 - val_accuracy: 0.6697\n",
      "Epoch 213/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2445 - accuracy: 0.8850 - val_loss: 1.7716 - val_accuracy: 0.6619\n",
      "Epoch 214/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2442 - accuracy: 0.8848 - val_loss: 1.7057 - val_accuracy: 0.6847\n",
      "Epoch 215/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2336 - accuracy: 0.8926 - val_loss: 1.8600 - val_accuracy: 0.7152\n",
      "Epoch 216/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2440 - accuracy: 0.8801 - val_loss: 1.5881 - val_accuracy: 0.7067\n",
      "Epoch 217/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2576 - accuracy: 0.8864 - val_loss: 1.4094 - val_accuracy: 0.6854\n",
      "Epoch 218/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2187 - accuracy: 0.8976 - val_loss: 1.8739 - val_accuracy: 0.6818\n",
      "Epoch 219/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2210 - accuracy: 0.8962 - val_loss: 2.1008 - val_accuracy: 0.7074\n",
      "Epoch 220/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2699 - accuracy: 0.8697 - val_loss: 1.7669 - val_accuracy: 0.6939\n",
      "Epoch 221/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2680 - accuracy: 0.8722 - val_loss: 1.6259 - val_accuracy: 0.6953\n",
      "Epoch 222/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2325 - accuracy: 0.8822 - val_loss: 1.6906 - val_accuracy: 0.7038acy: \n",
      "Epoch 223/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2328 - accuracy: 0.8880 - val_loss: 1.9239 - val_accuracy: 0.6996\n",
      "Epoch 224/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2168 - accuracy: 0.8991 - val_loss: 2.0520 - val_accuracy: 0.7166\n",
      "Epoch 225/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.2146 - accuracy: 0.9017 - val_loss: 2.2361 - val_accuracy: 0.6776\n",
      "Epoch 226/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2205 - accuracy: 0.8978 - val_loss: 2.1218 - val_accuracy: 0.6854\n",
      "Epoch 227/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2128 - accuracy: 0.9012 - val_loss: 2.2216 - val_accuracy: 0.6896\n",
      "Epoch 228/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2286 - accuracy: 0.8899 - val_loss: 1.9658 - val_accuracy: 0.6839\n",
      "Epoch 229/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2178 - accuracy: 0.9003 - val_loss: 1.6937 - val_accuracy: 0.6918\n",
      "Epoch 230/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2209 - accuracy: 0.8957 - val_loss: 1.9105 - val_accuracy: 0.6996\n",
      "Epoch 231/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2236 - accuracy: 0.8897 - val_loss: 1.8211 - val_accuracy: 0.7138\n",
      "Epoch 232/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.2570 - accuracy: 0.8783 - val_loss: 2.1818 - val_accuracy: 0.6889\n",
      "Epoch 233/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2155 - accuracy: 0.8971 - val_loss: 1.6119 - val_accuracy: 0.7259\n",
      "Epoch 234/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2260 - accuracy: 0.8931 - val_loss: 2.4499 - val_accuracy: 0.669790 - accuracy\n",
      "Epoch 235/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2068 - accuracy: 0.9045 - val_loss: 1.5883 - val_accuracy: 0.6932\n",
      "Epoch 236/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2403 - accuracy: 0.8952 - val_loss: 1.3713 - val_accuracy: 0.7010\n",
      "Epoch 237/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2324 - accuracy: 0.8903 - val_loss: 1.4815 - val_accuracy: 0.6967\n",
      "Epoch 238/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1917 - accuracy: 0.9092 - val_loss: 2.0210 - val_accuracy: 0.7102\n",
      "Epoch 239/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2173 - accuracy: 0.8943 - val_loss: 1.9027 - val_accuracy: 0.6989\n",
      "Epoch 240/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2132 - accuracy: 0.9027 - val_loss: 2.1068 - val_accuracy: 0.6996\n",
      "Epoch 241/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2089 - accuracy: 0.9027 - val_loss: 1.9026 - val_accuracy: 0.6868\n",
      "Epoch 242/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2389 - accuracy: 0.8966 - val_loss: 1.9139 - val_accuracy: 0.6896\n",
      "Epoch 243/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2016 - accuracy: 0.9033 - val_loss: 2.0856 - val_accuracy: 0.7138\n",
      "Epoch 244/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1954 - accuracy: 0.9096 - val_loss: 2.1652 - val_accuracy: 0.6903\n",
      "Epoch 245/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1878 - accuracy: 0.9133 - val_loss: 2.0264 - val_accuracy: 0.6605\n",
      "Epoch 246/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1876 - accuracy: 0.9150 - val_loss: 2.6033 - val_accuracy: 0.6868\n",
      "Epoch 247/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1879 - accuracy: 0.9203 - val_loss: 2.2011 - val_accuracy: 0.6825\n",
      "Epoch 248/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1810 - accuracy: 0.9164 - val_loss: 2.3026 - val_accuracy: 0.6932\n",
      "Epoch 249/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1897 - accuracy: 0.9122 - val_loss: 2.1088 - val_accuracy: 0.6982\n",
      "Epoch 250/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1817 - accuracy: 0.9157 - val_loss: 2.0104 - val_accuracy: 0.7067\n",
      "Epoch 251/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1883 - accuracy: 0.9087 - val_loss: 2.4341 - val_accuracy: 0.6790\n",
      "Epoch 252/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1914 - accuracy: 0.9103 - val_loss: 2.4220 - val_accuracy: 0.6932\n",
      "Epoch 253/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2083 - accuracy: 0.9038 - val_loss: 1.7941 - val_accuracy: 0.7237\n",
      "Epoch 254/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1807 - accuracy: 0.9159 - val_loss: 2.3816 - val_accuracy: 0.6889\n",
      "Epoch 255/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1844 - accuracy: 0.9140 - val_loss: 2.7146 - val_accuracy: 0.6974\n",
      "Epoch 256/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1704 - accuracy: 0.9206 - val_loss: 2.1052 - val_accuracy: 0.6655\n",
      "Epoch 257/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1999 - accuracy: 0.9091 - val_loss: 2.4165 - val_accuracy: 0.6797\n",
      "Epoch 258/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1697 - accuracy: 0.9254 - val_loss: 2.5082 - val_accuracy: 0.6882\n",
      "Epoch 259/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1687 - accuracy: 0.9231 - val_loss: 2.2410 - val_accuracy: 0.6967\n",
      "Epoch 260/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2046 - accuracy: 0.9040 - val_loss: 2.1563 - val_accuracy: 0.6719\n",
      "Epoch 261/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1772 - accuracy: 0.9208 - val_loss: 2.3976 - val_accuracy: 0.7173\n",
      "Epoch 262/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1656 - accuracy: 0.9243 - val_loss: 1.9154 - val_accuracy: 0.7195\n",
      "Epoch 263/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1800 - accuracy: 0.9170 - val_loss: 2.0353 - val_accuracy: 0.7017\n",
      "Epoch 264/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2006 - accuracy: 0.9145 - val_loss: 2.1368 - val_accuracy: 0.7045\n",
      "Epoch 265/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1746 - accuracy: 0.9194 - val_loss: 2.1975 - val_accuracy: 0.7095\n",
      "Epoch 266/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1704 - accuracy: 0.9215 - val_loss: 1.9240 - val_accuracy: 0.7138\n",
      "Epoch 267/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1741 - accuracy: 0.9199 - val_loss: 1.9432 - val_accuracy: 0.7202\n",
      "Epoch 268/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1678 - accuracy: 0.9226 - val_loss: 2.4039 - val_accuracy: 0.6982\n",
      "Epoch 269/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1546 - accuracy: 0.9294 - val_loss: 2.5678 - val_accuracy: 0.6925\n",
      "Epoch 270/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1579 - accuracy: 0.9314 - val_loss: 2.5900 - val_accuracy: 0.6854\n",
      "Epoch 271/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1716 - accuracy: 0.9266 - val_loss: 2.6413 - val_accuracy: 0.6932\n",
      "Epoch 272/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1905 - accuracy: 0.9159 - val_loss: 2.3047 - val_accuracy: 0.7053\n",
      "Epoch 273/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2210 - accuracy: 0.9040 - val_loss: 1.5071 - val_accuracy: 0.7088\n",
      "Epoch 274/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1701 - accuracy: 0.9194 - val_loss: 2.0116 - val_accuracy: 0.6726\n",
      "Epoch 275/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1615 - accuracy: 0.9291 - val_loss: 1.9223 - val_accuracy: 0.7159\n",
      "Epoch 276/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1571 - accuracy: 0.9264 - val_loss: 2.6971 - val_accuracy: 0.6967\n",
      "Epoch 277/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1403 - accuracy: 0.9387 - val_loss: 2.7624 - val_accuracy: 0.7145\n",
      "Epoch 278/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1747 - accuracy: 0.9242 - val_loss: 2.4212 - val_accuracy: 0.6889\n",
      "Epoch 279/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1535 - accuracy: 0.9310 - val_loss: 2.5397 - val_accuracy: 0.7067\n",
      "Epoch 280/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1544 - accuracy: 0.9287 - val_loss: 2.9031 - val_accuracy: 0.7088\n",
      "Epoch 281/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1689 - accuracy: 0.9226 - val_loss: 2.3536 - val_accuracy: 0.7251\n",
      "Epoch 282/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1510 - accuracy: 0.9308 - val_loss: 2.4495 - val_accuracy: 0.7166\n",
      "Epoch 283/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1645 - accuracy: 0.9263 - val_loss: 2.1663 - val_accuracy: 0.7251\n",
      "Epoch 284/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1514 - accuracy: 0.9324 - val_loss: 2.6162 - val_accuracy: 0.6974\n",
      "Epoch 285/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1585 - accuracy: 0.9298 - val_loss: 2.3844 - val_accuracy: 0.7124\n",
      "Epoch 286/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1826 - accuracy: 0.9312 - val_loss: 2.0751 - val_accuracy: 0.7365\n",
      "Epoch 287/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1593 - accuracy: 0.9278 - val_loss: 2.2042 - val_accuracy: 0.6974\n",
      "Epoch 288/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1410 - accuracy: 0.9370 - val_loss: 2.2868 - val_accuracy: 0.7010\n",
      "Epoch 289/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2002 - accuracy: 0.9110 - val_loss: 2.7890 - val_accuracy: 0.6911\n",
      "Epoch 290/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1561 - accuracy: 0.9284 - val_loss: 2.5436 - val_accuracy: 0.7180\n",
      "Epoch 291/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1491 - accuracy: 0.9373 - val_loss: 2.3393 - val_accuracy: 0.7067\n",
      "Epoch 292/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1433 - accuracy: 0.9386 - val_loss: 2.4896 - val_accuracy: 0.6918\n",
      "Epoch 293/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1539 - accuracy: 0.9257 - val_loss: 2.4719 - val_accuracy: 0.7259\n",
      "Epoch 294/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1403 - accuracy: 0.9403 - val_loss: 2.9611 - val_accuracy: 0.6967\n",
      "Epoch 295/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1377 - accuracy: 0.9377 - val_loss: 2.4688 - val_accuracy: 0.7393\n",
      "Epoch 296/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1705 - accuracy: 0.9280 - val_loss: 2.4980 - val_accuracy: 0.7216\n",
      "Epoch 297/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1295 - accuracy: 0.9408 - val_loss: 2.4121 - val_accuracy: 0.7344\n",
      "Epoch 298/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1381 - accuracy: 0.9438 - val_loss: 2.3606 - val_accuracy: 0.7159\n",
      "Epoch 299/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1283 - accuracy: 0.9398 - val_loss: 2.5894 - val_accuracy: 0.7216\n",
      "Epoch 300/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1396 - accuracy: 0.9403 - val_loss: 2.5584 - val_accuracy: 0.6982\n",
      "Epoch 301/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1494 - accuracy: 0.9312 - val_loss: 2.8294 - val_accuracy: 0.7031\n",
      "Epoch 302/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1334 - accuracy: 0.9394 - val_loss: 2.7298 - val_accuracy: 0.7266\n",
      "Epoch 303/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1340 - accuracy: 0.9370 - val_loss: 2.8340 - val_accuracy: 0.7266\n",
      "Epoch 304/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1478 - accuracy: 0.9373 - val_loss: 2.9370 - val_accuracy: 0.7024\n",
      "Epoch 305/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1247 - accuracy: 0.9429 - val_loss: 2.3441 - val_accuracy: 0.7287\n",
      "Epoch 306/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1772 - accuracy: 0.9205 - val_loss: 2.8883 - val_accuracy: 0.6953\n",
      "Epoch 307/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1229 - accuracy: 0.9466 - val_loss: 2.6332 - val_accuracy: 0.7074\n",
      "Epoch 308/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1190 - accuracy: 0.9475 - val_loss: 2.8359 - val_accuracy: 0.6875\n",
      "Epoch 309/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1266 - accuracy: 0.9447 - val_loss: 3.3281 - val_accuracy: 0.7017\n",
      "Epoch 310/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1347 - accuracy: 0.9422 - val_loss: 2.9910 - val_accuracy: 0.7251\n",
      "Epoch 311/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1506 - accuracy: 0.9368 - val_loss: 2.8588 - val_accuracy: 0.7159\n",
      "Epoch 312/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1355 - accuracy: 0.9408 - val_loss: 2.7994 - val_accuracy: 0.7124\n",
      "Epoch 313/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1982 - accuracy: 0.9099 - val_loss: 2.4249 - val_accuracy: 0.7365\n",
      "Epoch 314/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1512 - accuracy: 0.9287 - val_loss: 2.4208 - val_accuracy: 0.7131\n",
      "Epoch 315/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1195 - accuracy: 0.9529 - val_loss: 2.9797 - val_accuracy: 0.7095\n",
      "Epoch 316/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1303 - accuracy: 0.9428 - val_loss: 3.0069 - val_accuracy: 0.7088\n",
      "Epoch 317/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1378 - accuracy: 0.9447 - val_loss: 2.6865 - val_accuracy: 0.7294\n",
      "Epoch 318/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1168 - accuracy: 0.9459 - val_loss: 3.0709 - val_accuracy: 0.7067\n",
      "Epoch 319/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1956 - accuracy: 0.9166 - val_loss: 2.2616 - val_accuracy: 0.7031\n",
      "Epoch 320/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1242 - accuracy: 0.9442 - val_loss: 2.4771 - val_accuracy: 0.7109\n",
      "Epoch 321/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1427 - accuracy: 0.9396 - val_loss: 2.2354 - val_accuracy: 0.7152\n",
      "Epoch 322/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1192 - accuracy: 0.9505 - val_loss: 2.7386 - val_accuracy: 0.7145\n",
      "Epoch 323/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1395 - accuracy: 0.9405 - val_loss: 3.3394 - val_accuracy: 0.7081\n",
      "Epoch 324/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1298 - accuracy: 0.9466 - val_loss: 2.1639 - val_accuracy: 0.6804\n",
      "Epoch 325/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1684 - accuracy: 0.9359 - val_loss: 2.2990 - val_accuracy: 0.7266\n",
      "Epoch 326/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1133 - accuracy: 0.9510 - val_loss: 2.9159 - val_accuracy: 0.7010\n",
      "Epoch 327/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1165 - accuracy: 0.9528 - val_loss: 3.6632 - val_accuracy: 0.7081\n",
      "Epoch 328/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1250 - accuracy: 0.9465 - val_loss: 3.2283 - val_accuracy: 0.7017\n",
      "Epoch 329/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1129 - accuracy: 0.9501 - val_loss: 2.9312 - val_accuracy: 0.6967\n",
      "Epoch 330/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1012 - accuracy: 0.9591 - val_loss: 3.2426 - val_accuracy: 0.7209\n",
      "Epoch 331/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1197 - accuracy: 0.9484 - val_loss: 3.1468 - val_accuracy: 0.6939\n",
      "Epoch 332/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1105 - accuracy: 0.9524 - val_loss: 3.4193 - val_accuracy: 0.7230\n",
      "Epoch 333/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1108 - accuracy: 0.9556 - val_loss: 2.9475 - val_accuracy: 0.7159\n",
      "Epoch 334/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1054 - accuracy: 0.9542 - val_loss: 3.1076 - val_accuracy: 0.7152\n",
      "Epoch 335/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1216 - accuracy: 0.9517 - val_loss: 2.3646 - val_accuracy: 0.7351\n",
      "Epoch 336/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1180 - accuracy: 0.9505 - val_loss: 3.1804 - val_accuracy: 0.7188\n",
      "Epoch 337/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1579 - accuracy: 0.9357 - val_loss: 2.8284 - val_accuracy: 0.6903\n",
      "Epoch 338/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1258 - accuracy: 0.9494 - val_loss: 3.3174 - val_accuracy: 0.7195\n",
      "Epoch 339/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1185 - accuracy: 0.9519 - val_loss: 2.5987 - val_accuracy: 0.7308: 0.1191 - accuracy: \n",
      "Epoch 340/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1431 - accuracy: 0.9363 - val_loss: 2.7989 - val_accuracy: 0.7081\n",
      "Epoch 341/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1050 - accuracy: 0.9545 - val_loss: 2.8350 - val_accuracy: 0.6953\n",
      "Epoch 342/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1085 - accuracy: 0.9545 - val_loss: 2.9657 - val_accuracy: 0.7131\n",
      "Epoch 343/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1144 - accuracy: 0.9498 - val_loss: 2.8412 - val_accuracy: 0.7237\n",
      "Epoch 344/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0915 - accuracy: 0.9617 - val_loss: 3.3821 - val_accuracy: 0.6967\n",
      "Epoch 345/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1052 - accuracy: 0.9544 - val_loss: 3.5535 - val_accuracy: 0.7095\n",
      "Epoch 346/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1028 - accuracy: 0.9563 - val_loss: 2.9446 - val_accuracy: 0.7031\n",
      "Epoch 347/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1172 - accuracy: 0.9501 - val_loss: 3.3756 - val_accuracy: 0.7109\n",
      "Epoch 348/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0883 - accuracy: 0.9587 - val_loss: 3.5880 - val_accuracy: 0.6996\n",
      "Epoch 349/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1225 - accuracy: 0.9531 - val_loss: 2.7596 - val_accuracy: 0.7216\n",
      "Epoch 350/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1133 - accuracy: 0.9515 - val_loss: 2.8454 - val_accuracy: 0.6903\n",
      "Epoch 351/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1427 - accuracy: 0.9386 - val_loss: 2.9136 - val_accuracy: 0.6974\n",
      "Epoch 352/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1242 - accuracy: 0.9470 - val_loss: 3.1056 - val_accuracy: 0.6974\n",
      "Epoch 353/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0899 - accuracy: 0.9610 - val_loss: 3.0364 - val_accuracy: 0.7379\n",
      "Epoch 354/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0894 - accuracy: 0.9644 - val_loss: 3.0352 - val_accuracy: 0.7294\n",
      "Epoch 355/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1684 - accuracy: 0.9257 - val_loss: 2.8861 - val_accuracy: 0.6967\n",
      "Epoch 356/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1168 - accuracy: 0.9522 - val_loss: 3.1580 - val_accuracy: 0.7216\n",
      "Epoch 357/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1204 - accuracy: 0.9505 - val_loss: 3.0797 - val_accuracy: 0.7045\n",
      "Epoch 358/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1103 - accuracy: 0.9570 - val_loss: 2.8320 - val_accuracy: 0.7195loss: 0\n",
      "Epoch 359/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1011 - accuracy: 0.9566 - val_loss: 2.9467 - val_accuracy: 0.7259\n",
      "Epoch 360/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0931 - accuracy: 0.9610 - val_loss: 3.3978 - val_accuracy: 0.7159\n",
      "Epoch 361/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0980 - accuracy: 0.9601 - val_loss: 3.2559 - val_accuracy: 0.7024\n",
      "Epoch 362/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0967 - accuracy: 0.9608 - val_loss: 2.9768 - val_accuracy: 0.7237\n",
      "Epoch 363/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1225 - accuracy: 0.9524 - val_loss: 3.0834 - val_accuracy: 0.7145\n",
      "Epoch 364/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0962 - accuracy: 0.9601 - val_loss: 3.2111 - val_accuracy: 0.7344\n",
      "Epoch 365/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1046 - accuracy: 0.9580 - val_loss: 3.3061 - val_accuracy: 0.7202\n",
      "Epoch 366/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0889 - accuracy: 0.9626 - val_loss: 3.1675 - val_accuracy: 0.7251\n",
      "Epoch 367/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0897 - accuracy: 0.9617 - val_loss: 3.2105 - val_accuracy: 0.7308\n",
      "Epoch 368/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0932 - accuracy: 0.9630 - val_loss: 3.6407 - val_accuracy: 0.7138\n",
      "Epoch 369/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0999 - accuracy: 0.9579 - val_loss: 3.5649 - val_accuracy: 0.7024\n",
      "Epoch 370/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0893 - accuracy: 0.9644 - val_loss: 3.7245 - val_accuracy: 0.7202\n",
      "Epoch 371/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0993 - accuracy: 0.9614 - val_loss: 3.2176 - val_accuracy: 0.7280\n",
      "Epoch 372/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1251 - accuracy: 0.9489 - val_loss: 2.4024 - val_accuracy: 0.7322\n",
      "Epoch 373/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0998 - accuracy: 0.9559 - val_loss: 3.1107 - val_accuracy: 0.7216\n",
      "Epoch 374/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0950 - accuracy: 0.9614 - val_loss: 3.3392 - val_accuracy: 0.7379\n",
      "Epoch 375/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1059 - accuracy: 0.9587 - val_loss: 3.3394 - val_accuracy: 0.7102\n",
      "Epoch 376/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0961 - accuracy: 0.9630 - val_loss: 3.2777 - val_accuracy: 0.7251\n",
      "Epoch 377/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0940 - accuracy: 0.9642 - val_loss: 3.0882 - val_accuracy: 0.7358\n",
      "Epoch 378/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0917 - accuracy: 0.9647 - val_loss: 3.2827 - val_accuracy: 0.7351\n",
      "Epoch 379/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0915 - accuracy: 0.9649 - val_loss: 3.2503 - val_accuracy: 0.7230\n",
      "Epoch 380/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0869 - accuracy: 0.9652 - val_loss: 2.8668 - val_accuracy: 0.7287\n",
      "Epoch 381/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0811 - accuracy: 0.9659 - val_loss: 3.9940 - val_accuracy: 0.7067\n",
      "Epoch 382/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0862 - accuracy: 0.9656 - val_loss: 2.9620 - val_accuracy: 0.7308\n",
      "Epoch 383/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1264 - accuracy: 0.9545 - val_loss: 3.0009 - val_accuracy: 0.7244\n",
      "Epoch 384/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0889 - accuracy: 0.9608 - val_loss: 3.4785 - val_accuracy: 0.7031\n",
      "Epoch 385/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.1261 - accuracy: 0.9472 - val_loss: 3.7664 - val_accuracy: 0.7003\n",
      "Epoch 386/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0913 - accuracy: 0.9642 - val_loss: 3.2887 - val_accuracy: 0.7429\n",
      "Epoch 387/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0860 - accuracy: 0.9668 - val_loss: 3.0704 - val_accuracy: 0.7180\n",
      "Epoch 388/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0863 - accuracy: 0.9658 - val_loss: 3.4543 - val_accuracy: 0.7266\n",
      "Epoch 389/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0789 - accuracy: 0.9680 - val_loss: 3.7794 - val_accuracy: 0.7237uracy: \n",
      "Epoch 390/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1007 - accuracy: 0.9601 - val_loss: 3.4033 - val_accuracy: 0.7209\n",
      "Epoch 391/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0758 - accuracy: 0.9700 - val_loss: 3.4257 - val_accuracy: 0.7294\n",
      "Epoch 392/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0804 - accuracy: 0.9666 - val_loss: 3.2053 - val_accuracy: 0.7251\n",
      "Epoch 393/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0993 - accuracy: 0.9626 - val_loss: 3.8168 - val_accuracy: 0.7045\n",
      "Epoch 394/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0834 - accuracy: 0.9654 - val_loss: 3.4822 - val_accuracy: 0.7109\n",
      "Epoch 395/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0896 - accuracy: 0.9642 - val_loss: 3.6526 - val_accuracy: 0.7010\n",
      "Epoch 396/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0837 - accuracy: 0.9668 - val_loss: 4.0094 - val_accuracy: 0.6882\n",
      "Epoch 397/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0752 - accuracy: 0.9695 - val_loss: 3.7685 - val_accuracy: 0.7237\n",
      "Epoch 398/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.1262 - accuracy: 0.9547 - val_loss: 3.0824 - val_accuracy: 0.7102\n",
      "Epoch 399/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0837 - accuracy: 0.9652 - val_loss: 3.6945 - val_accuracy: 0.7124\n",
      "Epoch 400/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0862 - accuracy: 0.9675 - val_loss: 3.7819 - val_accuracy: 0.7095\n",
      "Epoch 401/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0791 - accuracy: 0.9714 - val_loss: 4.6554 - val_accuracy: 0.7088\n",
      "Epoch 402/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0814 - accuracy: 0.9682 - val_loss: 3.7344 - val_accuracy: 0.7180\n",
      "Epoch 403/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1025 - accuracy: 0.9628 - val_loss: 4.4714 - val_accuracy: 0.7116\n",
      "Epoch 404/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1372 - accuracy: 0.9515 - val_loss: 2.6188 - val_accuracy: 0.7358\n",
      "Epoch 405/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0873 - accuracy: 0.9656 - val_loss: 3.8000 - val_accuracy: 0.7188\n",
      "Epoch 406/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0687 - accuracy: 0.9740 - val_loss: 4.1811 - val_accuracy: 0.7145\n",
      "Epoch 407/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0820 - accuracy: 0.9673 - val_loss: 3.5347 - val_accuracy: 0.7131\n",
      "Epoch 408/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0762 - accuracy: 0.9679 - val_loss: 3.7495 - val_accuracy: 0.7088\n",
      "Epoch 409/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0747 - accuracy: 0.9730 - val_loss: 3.8844 - val_accuracy: 0.7152\n",
      "Epoch 410/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0878 - accuracy: 0.9670 - val_loss: 3.7607 - val_accuracy: 0.71310918 - ac - ETA: 0s - loss: 0\n",
      "Epoch 411/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0850 - accuracy: 0.9651 - val_loss: 3.7211 - val_accuracy: 0.7322\n",
      "Epoch 412/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0723 - accuracy: 0.9703 - val_loss: 4.1986 - val_accuracy: 0.7116\n",
      "Epoch 413/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0996 - accuracy: 0.9619 - val_loss: 3.6511 - val_accuracy: 0.7202\n",
      "Epoch 414/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1035 - accuracy: 0.9593 - val_loss: 3.3929 - val_accuracy: 0.7138\n",
      "Epoch 415/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0671 - accuracy: 0.9752 - val_loss: 4.1520 - val_accuracy: 0.7188\n",
      "Epoch 416/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0728 - accuracy: 0.9733 - val_loss: 3.3662 - val_accuracy: 0.7315\n",
      "Epoch 417/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0680 - accuracy: 0.9721 - val_loss: 3.9969 - val_accuracy: 0.7273\n",
      "Epoch 418/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0846 - accuracy: 0.9698 - val_loss: 3.2919 - val_accuracy: 0.7159\n",
      "Epoch 419/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0762 - accuracy: 0.9698 - val_loss: 4.1190 - val_accuracy: 0.7102\n",
      "Epoch 420/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0732 - accuracy: 0.9723 - val_loss: 4.2987 - val_accuracy: 0.7166\n",
      "Epoch 421/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1115 - accuracy: 0.9616 - val_loss: 3.1080 - val_accuracy: 0.7372\n",
      "Epoch 422/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0766 - accuracy: 0.9686 - val_loss: 2.9052 - val_accuracy: 0.7500\n",
      "Epoch 423/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0733 - accuracy: 0.9712 - val_loss: 3.5399 - val_accuracy: 0.7237\n",
      "Epoch 424/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1055 - accuracy: 0.9598 - val_loss: 3.7773 - val_accuracy: 0.6918\n",
      "Epoch 425/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0904 - accuracy: 0.9642 - val_loss: 3.5701 - val_accuracy: 0.7159\n",
      "Epoch 426/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0644 - accuracy: 0.9733 - val_loss: 3.6020 - val_accuracy: 0.7464\n",
      "Epoch 427/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1103 - accuracy: 0.9600 - val_loss: 3.5699 - val_accuracy: 0.7188\n",
      "Epoch 428/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0847 - accuracy: 0.9677 - val_loss: 4.0015 - val_accuracy: 0.7209\n",
      "Epoch 429/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0754 - accuracy: 0.9716 - val_loss: 4.2502 - val_accuracy: 0.7102\n",
      "Epoch 430/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0751 - accuracy: 0.9703 - val_loss: 3.7497 - val_accuracy: 0.7166\n",
      "Epoch 431/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0642 - accuracy: 0.9747 - val_loss: 4.2355 - val_accuracy: 0.7081\n",
      "Epoch 432/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0816 - accuracy: 0.9709 - val_loss: 4.1287 - val_accuracy: 0.7209\n",
      "Epoch 433/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0821 - accuracy: 0.9700 - val_loss: 3.7008 - val_accuracy: 0.7429\n",
      "Epoch 434/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0711 - accuracy: 0.9707 - val_loss: 3.7241 - val_accuracy: 0.7145\n",
      "Epoch 435/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0635 - accuracy: 0.9767 - val_loss: 4.0825 - val_accuracy: 0.7230\n",
      "Epoch 436/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0663 - accuracy: 0.9761 - val_loss: 3.7845 - val_accuracy: 0.7251\n",
      "Epoch 437/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0927 - accuracy: 0.9672 - val_loss: 3.0437 - val_accuracy: 0.7230\n",
      "Epoch 438/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0683 - accuracy: 0.9756 - val_loss: 3.3558 - val_accuracy: 0.7372\n",
      "Epoch 439/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0785 - accuracy: 0.9705 - val_loss: 3.3629 - val_accuracy: 0.7294\n",
      "Epoch 440/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0675 - accuracy: 0.9744 - val_loss: 3.9023 - val_accuracy: 0.7251\n",
      "Epoch 441/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0757 - accuracy: 0.9724 - val_loss: 3.7715 - val_accuracy: 0.7188\n",
      "Epoch 442/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0658 - accuracy: 0.9765 - val_loss: 3.0873 - val_accuracy: 0.7237\n",
      "Epoch 443/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1072 - accuracy: 0.9631 - val_loss: 2.1015 - val_accuracy: 0.7202\n",
      "Epoch 444/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0971 - accuracy: 0.9661 - val_loss: 3.1295 - val_accuracy: 0.7294\n",
      "Epoch 445/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0719 - accuracy: 0.9728 - val_loss: 3.8506 - val_accuracy: 0.7251\n",
      "Epoch 446/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0633 - accuracy: 0.9775 - val_loss: 3.3901 - val_accuracy: 0.7351\n",
      "Epoch 447/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0697 - accuracy: 0.9779 - val_loss: 4.0161 - val_accuracy: 0.7173\n",
      "Epoch 448/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0643 - accuracy: 0.9758 - val_loss: 4.1845 - val_accuracy: 0.7180\n",
      "Epoch 449/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0762 - accuracy: 0.9723 - val_loss: 2.8945 - val_accuracy: 0.7180 accuracy: 0.97\n",
      "Epoch 450/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0869 - accuracy: 0.9672 - val_loss: 3.7390 - val_accuracy: 0.7152\n",
      "Epoch 451/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0696 - accuracy: 0.9735 - val_loss: 3.9690 - val_accuracy: 0.6918\n",
      "Epoch 452/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1207 - accuracy: 0.9556 - val_loss: 2.9196 - val_accuracy: 0.7330\n",
      "Epoch 453/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0604 - accuracy: 0.9737 - val_loss: 2.9165 - val_accuracy: 0.7259\n",
      "Epoch 454/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0663 - accuracy: 0.9705 - val_loss: 3.1512 - val_accuracy: 0.7408\n",
      "Epoch 455/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0743 - accuracy: 0.9714 - val_loss: 3.5590 - val_accuracy: 0.7379\n",
      "Epoch 456/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0638 - accuracy: 0.9763 - val_loss: 4.0947 - val_accuracy: 0.7116\n",
      "Epoch 457/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0801 - accuracy: 0.9726 - val_loss: 3.9493 - val_accuracy: 0.7166\n",
      "Epoch 458/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1014 - accuracy: 0.9637 - val_loss: 4.0066 - val_accuracy: 0.7131\n",
      "Epoch 459/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0781 - accuracy: 0.9714 - val_loss: 4.5636 - val_accuracy: 0.7159\n",
      "Epoch 460/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0594 - accuracy: 0.9759 - val_loss: 4.2924 - val_accuracy: 0.7166\n",
      "Epoch 461/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0608 - accuracy: 0.9781 - val_loss: 3.8885 - val_accuracy: 0.6939\n",
      "Epoch 462/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0751 - accuracy: 0.9707 - val_loss: 3.7983 - val_accuracy: 0.7188\n",
      "Epoch 463/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0540 - accuracy: 0.9796 - val_loss: 4.1894 - val_accuracy: 0.7145\n",
      "Epoch 464/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0635 - accuracy: 0.9726 - val_loss: 3.6272 - val_accuracy: 0.7557\n",
      "Epoch 465/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0698 - accuracy: 0.9758 - val_loss: 3.4205 - val_accuracy: 0.7259\n",
      "Epoch 466/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0640 - accuracy: 0.9782 - val_loss: 4.6184 - val_accuracy: 0.7301\n",
      "Epoch 467/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0585 - accuracy: 0.9767 - val_loss: 4.5023 - val_accuracy: 0.7074\n",
      "Epoch 468/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0621 - accuracy: 0.9779 - val_loss: 4.3317 - val_accuracy: 0.7259\n",
      "Epoch 469/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0604 - accuracy: 0.9775 - val_loss: 4.7359 - val_accuracy: 0.6974\n",
      "Epoch 470/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0566 - accuracy: 0.9784 - val_loss: 4.3534 - val_accuracy: 0.7251\n",
      "Epoch 471/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0746 - accuracy: 0.9744 - val_loss: 4.2360 - val_accuracy: 0.7209\n",
      "Epoch 472/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0609 - accuracy: 0.9763 - val_loss: 4.7061 - val_accuracy: 0.7045\n",
      "Epoch 473/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0554 - accuracy: 0.9798 - val_loss: 4.7977 - val_accuracy: 0.7074\n",
      "Epoch 474/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0608 - accuracy: 0.9772 - val_loss: 4.5539 - val_accuracy: 0.7408\n",
      "Epoch 475/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.1010 - accuracy: 0.9682 - val_loss: 4.0799 - val_accuracy: 0.7159\n",
      "Epoch 476/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0569 - accuracy: 0.9791 - val_loss: 3.9339 - val_accuracy: 0.7195\n",
      "Epoch 477/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0554 - accuracy: 0.9791 - val_loss: 4.7798 - val_accuracy: 0.7053\n",
      "Epoch 478/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0667 - accuracy: 0.9795 - val_loss: 3.7830 - val_accuracy: 0.6989\n",
      "Epoch 479/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0807 - accuracy: 0.9700 - val_loss: 3.5350 - val_accuracy: 0.7266\n",
      "Epoch 480/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0567 - accuracy: 0.9805 - val_loss: 4.3551 - val_accuracy: 0.7216\n",
      "Epoch 481/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0598 - accuracy: 0.9768 - val_loss: 3.6286 - val_accuracy: 0.7251\n",
      "Epoch 482/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0545 - accuracy: 0.9800 - val_loss: 3.4269 - val_accuracy: 0.7209\n",
      "Epoch 483/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0528 - accuracy: 0.9817 - val_loss: 4.0645 - val_accuracy: 0.7415\n",
      "Epoch 484/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0739 - accuracy: 0.9745 - val_loss: 4.0638 - val_accuracy: 0.7273\n",
      "Epoch 485/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0622 - accuracy: 0.9781 - val_loss: 3.8344 - val_accuracy: 0.7116\n",
      "Epoch 486/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0613 - accuracy: 0.9793 - val_loss: 3.5361 - val_accuracy: 0.7393\n",
      "Epoch 487/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0590 - accuracy: 0.9788 - val_loss: 4.7169 - val_accuracy: 0.7131\n",
      "Epoch 488/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0710 - accuracy: 0.9775 - val_loss: 4.2746 - val_accuracy: 0.7358\n",
      "Epoch 489/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0564 - accuracy: 0.9796 - val_loss: 4.3217 - val_accuracy: 0.7322\n",
      "Epoch 490/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0564 - accuracy: 0.9798 - val_loss: 4.9381 - val_accuracy: 0.7159\n",
      "Epoch 491/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0586 - accuracy: 0.9782 - val_loss: 3.7393 - val_accuracy: 0.7266\n",
      "Epoch 492/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0612 - accuracy: 0.9791 - val_loss: 4.1777 - val_accuracy: 0.7337\n",
      "Epoch 493/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0637 - accuracy: 0.9772 - val_loss: 4.1872 - val_accuracy: 0.7095\n",
      "Epoch 494/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0707 - accuracy: 0.9765 - val_loss: 4.0953 - val_accuracy: 0.7124\n",
      "Epoch 495/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0703 - accuracy: 0.9714 - val_loss: 4.4804 - val_accuracy: 0.7259\n",
      "Epoch 496/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0603 - accuracy: 0.9775 - val_loss: 4.0797 - val_accuracy: 0.7166\n",
      "Epoch 497/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0541 - accuracy: 0.9795 - val_loss: 4.3728 - val_accuracy: 0.7209\n",
      "Epoch 498/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0685 - accuracy: 0.9756 - val_loss: 4.3566 - val_accuracy: 0.7095\n",
      "Epoch 499/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0525 - accuracy: 0.9795 - val_loss: 4.6707 - val_accuracy: 0.7337\n",
      "Epoch 500/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0704 - accuracy: 0.9779 - val_loss: 4.1520 - val_accuracy: 0.7294\n",
      "Epoch 501/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0708 - accuracy: 0.9742 - val_loss: 3.9868 - val_accuracy: 0.7436\n",
      "Epoch 502/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0674 - accuracy: 0.9774 - val_loss: 3.8707 - val_accuracy: 0.7322\n",
      "Epoch 503/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0511 - accuracy: 0.9816 - val_loss: 4.0880 - val_accuracy: 0.7386\n",
      "Epoch 504/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0500 - accuracy: 0.9830 - val_loss: 4.1774 - val_accuracy: 0.7216\n",
      "Epoch 505/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0536 - accuracy: 0.9814 - val_loss: 3.9148 - val_accuracy: 0.7173\n",
      "Epoch 506/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0813 - accuracy: 0.9693 - val_loss: 4.1392 - val_accuracy: 0.7287\n",
      "Epoch 507/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0452 - accuracy: 0.9853 - val_loss: 5.2137 - val_accuracy: 0.7251\n",
      "Epoch 508/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0495 - accuracy: 0.9816 - val_loss: 5.1632 - val_accuracy: 0.7138\n",
      "Epoch 509/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0674 - accuracy: 0.9775 - val_loss: 3.5820 - val_accuracy: 0.6932\n",
      "Epoch 510/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1699 - accuracy: 0.9366 - val_loss: 3.3895 - val_accuracy: 0.7188\n",
      "Epoch 511/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0745 - accuracy: 0.9751 - val_loss: 3.7451 - val_accuracy: 0.7195\n",
      "Epoch 512/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0540 - accuracy: 0.9819 - val_loss: 4.1974 - val_accuracy: 0.7422\n",
      "Epoch 513/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0686 - accuracy: 0.9782 - val_loss: 3.6792 - val_accuracy: 0.7202\n",
      "Epoch 514/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0542 - accuracy: 0.9807 - val_loss: 4.9407 - val_accuracy: 0.7116\n",
      "Epoch 515/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0573 - accuracy: 0.9774 - val_loss: 3.8210 - val_accuracy: 0.7294\n",
      "Epoch 516/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0893 - accuracy: 0.9640 - val_loss: 4.3121 - val_accuracy: 0.7294\n",
      "Epoch 517/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0846 - accuracy: 0.9670 - val_loss: 4.7883 - val_accuracy: 0.7223\n",
      "Epoch 518/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0526 - accuracy: 0.9817 - val_loss: 4.3006 - val_accuracy: 0.7124\n",
      "Epoch 519/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0551 - accuracy: 0.9795 - val_loss: 4.1325 - val_accuracy: 0.7124\n",
      "Epoch 520/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0479 - accuracy: 0.9817 - val_loss: 4.4827 - val_accuracy: 0.7301\n",
      "Epoch 521/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0426 - accuracy: 0.9821 - val_loss: 4.2795 - val_accuracy: 0.7408\n",
      "Epoch 522/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0563 - accuracy: 0.9798 - val_loss: 4.5147 - val_accuracy: 0.7223\n",
      "Epoch 523/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0572 - accuracy: 0.9814 - val_loss: 3.7501 - val_accuracy: 0.7237\n",
      "Epoch 524/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 3.7189 - val_accuracy: 0.7365loss: 0.0553 - accuracy\n",
      "Epoch 525/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0641 - accuracy: 0.9789 - val_loss: 4.7148 - val_accuracy: 0.7209\n",
      "Epoch 526/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0498 - accuracy: 0.9817 - val_loss: 4.1745 - val_accuracy: 0.7138\n",
      "Epoch 527/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0419 - accuracy: 0.9853 - val_loss: 5.5035 - val_accuracy: 0.7259\n",
      "Epoch 528/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0465 - accuracy: 0.9842 - val_loss: 5.0217 - val_accuracy: 0.7244\n",
      "Epoch 529/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0561 - accuracy: 0.9831 - val_loss: 4.2946 - val_accuracy: 0.7273\n",
      "Epoch 530/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0467 - accuracy: 0.9823 - val_loss: 4.0644 - val_accuracy: 0.7202\n",
      "Epoch 531/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0458 - accuracy: 0.9830 - val_loss: 5.0020 - val_accuracy: 0.7060\n",
      "Epoch 532/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0563 - accuracy: 0.9823 - val_loss: 3.6081 - val_accuracy: 0.7280\n",
      "Epoch 533/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0807 - accuracy: 0.9742 - val_loss: 4.0772 - val_accuracy: 0.7195\n",
      "Epoch 534/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0582 - accuracy: 0.9807 - val_loss: 3.7743 - val_accuracy: 0.7216\n",
      "Epoch 535/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1020 - accuracy: 0.9654 - val_loss: 3.6896 - val_accuracy: 0.7301\n",
      "Epoch 536/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0461 - accuracy: 0.9837 - val_loss: 4.2640 - val_accuracy: 0.7259\n",
      "Epoch 537/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0544 - accuracy: 0.9807 - val_loss: 4.2149 - val_accuracy: 0.7401\n",
      "Epoch 538/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0657 - accuracy: 0.9751 - val_loss: 4.1858 - val_accuracy: 0.7372\n",
      "Epoch 539/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0425 - accuracy: 0.9851 - val_loss: 4.3242 - val_accuracy: 0.7230\n",
      "Epoch 540/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0484 - accuracy: 0.9833 - val_loss: 5.1243 - val_accuracy: 0.7173\n",
      "Epoch 541/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0428 - accuracy: 0.9840 - val_loss: 4.7707 - val_accuracy: 0.7152\n",
      "Epoch 542/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0727 - accuracy: 0.9765 - val_loss: 4.7289 - val_accuracy: 0.7244\n",
      "Epoch 543/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0531 - accuracy: 0.9840 - val_loss: 4.4004 - val_accuracy: 0.7322\n",
      "Epoch 544/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0598 - accuracy: 0.9814 - val_loss: 4.0449 - val_accuracy: 0.7301\n",
      "Epoch 545/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0516 - accuracy: 0.9830 - val_loss: 4.6066 - val_accuracy: 0.7131\n",
      "Epoch 546/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0445 - accuracy: 0.9840 - val_loss: 4.6611 - val_accuracy: 0.7251\n",
      "Epoch 547/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0567 - accuracy: 0.9805 - val_loss: 4.3953 - val_accuracy: 0.7131\n",
      "Epoch 548/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0430 - accuracy: 0.9858 - val_loss: 4.4928 - val_accuracy: 0.7067\n",
      "Epoch 549/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0362 - accuracy: 0.9881 - val_loss: 4.6125 - val_accuracy: 0.7095\n",
      "Epoch 550/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 5.4456 - val_accuracy: 0.7294\n",
      "Epoch 551/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0396 - accuracy: 0.9872 - val_loss: 5.1745 - val_accuracy: 0.7102\n",
      "Epoch 552/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.0418 - accuracy: 0.9858 - val_loss: 4.9501 - val_accuracy: 0.7216\n",
      "Epoch 553/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0546 - accuracy: 0.9830 - val_loss: 4.3291 - val_accuracy: 0.6982\n",
      "Epoch 554/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0442 - accuracy: 0.9828 - val_loss: 5.2102 - val_accuracy: 0.7060\n",
      "Epoch 555/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0504 - accuracy: 0.9835 - val_loss: 5.2544 - val_accuracy: 0.7081\n",
      "Epoch 556/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0521 - accuracy: 0.9823 - val_loss: 5.0640 - val_accuracy: 0.7116\n",
      "Epoch 557/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0426 - accuracy: 0.9853 - val_loss: 3.9362 - val_accuracy: 0.7315\n",
      "Epoch 558/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0440 - accuracy: 0.9846 - val_loss: 5.2438 - val_accuracy: 0.7159\n",
      "Epoch 559/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0451 - accuracy: 0.9847 - val_loss: 5.3819 - val_accuracy: 0.7351\n",
      "Epoch 560/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 5.2226 - val_accuracy: 0.7322\n",
      "Epoch 561/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0984 - accuracy: 0.9688 - val_loss: 4.2452 - val_accuracy: 0.7322\n",
      "Epoch 562/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 4s 42ms/step - loss: 0.0482 - accuracy: 0.9819 - val_loss: 4.3829 - val_accuracy: 0.7102\n",
      "Epoch 563/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0423 - accuracy: 0.9828 - val_loss: 5.5244 - val_accuracy: 0.7131 0s - loss: 0.0405 - \n",
      "Epoch 564/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.0464 - accuracy: 0.9835 - val_loss: 3.9337 - val_accuracy: 0.7315\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00564: early stopping\n",
      "149/149 [==============================] - 1s 5ms/step\n",
      "     23/Unknown - 0s 5ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639/639 [==============================] - 3s 5ms/step\n",
      "160/160 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [1:12:46<00:00, 2183.43s/it]\u001b[A\n",
      "  1%|                                                                          | 1/90 [1:12:46<107:57:34, 4366.91s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.6341 - accuracy: 0.6221 - val_loss: 0.6460 - val_accuracy: 0.6133\n",
      "Epoch 2/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6340 - accuracy: 0.6286 - val_loss: 0.6178 - val_accuracy: 0.6518\n",
      "Epoch 3/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6334 - accuracy: 0.6223 - val_loss: 0.6429 - val_accuracy: 0.6010\n",
      "Epoch 4/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6261 - accuracy: 0.6366 - val_loss: 0.6369 - val_accuracy: 0.6417\n",
      "Epoch 5/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6295 - accuracy: 0.6345 - val_loss: 0.6393 - val_accuracy: 0.6016\n",
      "Epoch 6/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6209 - accuracy: 0.6508 - val_loss: 0.6390 - val_accuracy: 0.5831\n",
      "Epoch 7/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6307 - accuracy: 0.6318 - val_loss: 0.6246 - val_accuracy: 0.6233\n",
      "Epoch 8/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6273 - accuracy: 0.6336 - val_loss: 0.6326 - val_accuracy: 0.6295\n",
      "Epoch 9/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6162 - accuracy: 0.6431 - val_loss: 0.6900 - val_accuracy: 0.5592\n",
      "Epoch 10/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6157 - accuracy: 0.6498 - val_loss: 0.6323 - val_accuracy: 0.6261\n",
      "Epoch 11/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6217 - accuracy: 0.6394 - val_loss: 0.6447 - val_accuracy: 0.6088\n",
      "Epoch 12/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6170 - accuracy: 0.6482 - val_loss: 0.6393 - val_accuracy: 0.6295\n",
      "Epoch 13/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6125 - accuracy: 0.6561 - val_loss: 0.6314 - val_accuracy: 0.6484\n",
      "Epoch 14/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6125 - accuracy: 0.6528 - val_loss: 0.6297 - val_accuracy: 0.6724\n",
      "Epoch 15/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6175 - accuracy: 0.6441 - val_loss: 0.6458 - val_accuracy: 0.6384\n",
      "Epoch 16/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6108 - accuracy: 0.6528 - val_loss: 0.6445 - val_accuracy: 0.6127\n",
      "Epoch 17/1200\n",
      "112/112 [==============================] - 5s 40ms/step - loss: 0.5975 - accuracy: 0.6639 - val_loss: 0.6403 - val_accuracy: 0.6440\n",
      "Epoch 18/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6130 - accuracy: 0.6355 - val_loss: 0.6492 - val_accuracy: 0.6339\n",
      "Epoch 19/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6019 - accuracy: 0.6603 - val_loss: 0.6242 - val_accuracy: 0.6814\n",
      "Epoch 20/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6009 - accuracy: 0.6557 - val_loss: 0.6391 - val_accuracy: 0.6468\n",
      "Epoch 21/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6076 - accuracy: 0.6508 - val_loss: 0.6255 - val_accuracy: 0.6401\n",
      "Epoch 22/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6037 - accuracy: 0.6461 - val_loss: 0.6327 - val_accuracy: 0.6412\n",
      "Epoch 23/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5976 - accuracy: 0.6620 - val_loss: 0.6601 - val_accuracy: 0.6607\n",
      "Epoch 24/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5950 - accuracy: 0.6600 - val_loss: 0.6827 - val_accuracy: 0.6350\n",
      "Epoch 25/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5961 - accuracy: 0.6544 - val_loss: 0.6227 - val_accuracy: 0.6585\n",
      "Epoch 26/1200\n",
      "112/112 [==============================] - 5s 40ms/step - loss: 0.5932 - accuracy: 0.6595 - val_loss: 0.6474 - val_accuracy: 0.6451\n",
      "Epoch 27/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5871 - accuracy: 0.6597 - val_loss: 0.6675 - val_accuracy: 0.6300\n",
      "Epoch 28/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5959 - accuracy: 0.6648 - val_loss: 0.6661 - val_accuracy: 0.6434\n",
      "Epoch 29/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5926 - accuracy: 0.6597 - val_loss: 0.6698 - val_accuracy: 0.6339\n",
      "Epoch 30/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5809 - accuracy: 0.6797 - val_loss: 0.6255 - val_accuracy: 0.6797\n",
      "Epoch 31/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5958 - accuracy: 0.6589 - val_loss: 0.7114 - val_accuracy: 0.5792\n",
      "Epoch 32/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.5917 - accuracy: 0.6635 - val_loss: 0.6480 - val_accuracy: 0.6512\n",
      "Epoch 33/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.5855 - accuracy: 0.6670 - val_loss: 0.6588 - val_accuracy: 0.6205\n",
      "Epoch 34/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.5921 - accuracy: 0.6677 - val_loss: 0.6528 - val_accuracy: 0.6211\n",
      "Epoch 35/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.5786 - accuracy: 0.6793 - val_loss: 0.6480 - val_accuracy: 0.6451y\n",
      "Epoch 36/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5782 - accuracy: 0.6712 - val_loss: 0.6461 - val_accuracy: 0.6590\n",
      "Epoch 37/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5730 - accuracy: 0.6688 - val_loss: 0.6908 - val_accuracy: 0.6055\n",
      "Epoch 38/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5914 - accuracy: 0.6593 - val_loss: 0.6199 - val_accuracy: 0.6769\n",
      "Epoch 39/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5938 - accuracy: 0.6607 - val_loss: 0.5956 - val_accuracy: 0.6914\n",
      "Epoch 40/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5846 - accuracy: 0.6735 - val_loss: 0.5833 - val_accuracy: 0.6853\n",
      "Epoch 41/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5788 - accuracy: 0.6772 - val_loss: 0.6540 - val_accuracy: 0.6328\n",
      "Epoch 42/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5841 - accuracy: 0.6710 - val_loss: 0.6119 - val_accuracy: 0.6462\n",
      "Epoch 43/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5786 - accuracy: 0.6794 - val_loss: 0.6351 - val_accuracy: 0.6445\n",
      "Epoch 44/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5733 - accuracy: 0.6772 - val_loss: 0.5996 - val_accuracy: 0.6540\n",
      "Epoch 45/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5757 - accuracy: 0.6787 - val_loss: 0.6253 - val_accuracy: 0.6300\n",
      "Epoch 46/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5603 - accuracy: 0.6885 - val_loss: 0.5959 - val_accuracy: 0.6752\n",
      "Epoch 47/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5798 - accuracy: 0.6786 - val_loss: 0.6164 - val_accuracy: 0.6596\n",
      "Epoch 48/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5722 - accuracy: 0.6715 - val_loss: 0.6161 - val_accuracy: 0.6518\n",
      "Epoch 49/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5654 - accuracy: 0.6925 - val_loss: 0.6705 - val_accuracy: 0.6412\n",
      "Epoch 50/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5780 - accuracy: 0.6801 - val_loss: 0.6387 - val_accuracy: 0.6350\n",
      "Epoch 51/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5763 - accuracy: 0.6713 - val_loss: 0.6342 - val_accuracy: 0.6150\n",
      "Epoch 52/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5549 - accuracy: 0.6945 - val_loss: 0.6121 - val_accuracy: 0.6546\n",
      "Epoch 53/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.5537 - accuracy: 0.6971 - val_loss: 0.6010 - val_accuracy: 0.6685\n",
      "Epoch 54/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5456 - accuracy: 0.6946 - val_loss: 0.6272 - val_accuracy: 0.6518\n",
      "Epoch 55/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5486 - accuracy: 0.6992 - val_loss: 0.5929 - val_accuracy: 0.6808\n",
      "Epoch 56/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5585 - accuracy: 0.6871 - val_loss: 0.6517 - val_accuracy: 0.6557\n",
      "Epoch 57/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5546 - accuracy: 0.6984 - val_loss: 0.6570 - val_accuracy: 0.6133\n",
      "Epoch 58/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5519 - accuracy: 0.6922 - val_loss: 0.6120 - val_accuracy: 0.6635\n",
      "Epoch 59/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5488 - accuracy: 0.6967 - val_loss: 0.6520 - val_accuracy: 0.6585\n",
      "Epoch 60/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5480 - accuracy: 0.6928 - val_loss: 0.6542 - val_accuracy: 0.6250\n",
      "Epoch 61/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5456 - accuracy: 0.7027 - val_loss: 0.6099 - val_accuracy: 0.6596\n",
      "Epoch 62/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5462 - accuracy: 0.6985 - val_loss: 0.6486 - val_accuracy: 0.6401\n",
      "Epoch 63/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.5433 - accuracy: 0.6957 - val_loss: 0.6572 - val_accuracy: 0.6579\n",
      "Epoch 64/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.5324 - accuracy: 0.7125 - val_loss: 0.6785 - val_accuracy: 0.6484\n",
      "Epoch 65/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5417 - accuracy: 0.7044 - val_loss: 0.6321 - val_accuracy: 0.6607\n",
      "Epoch 66/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5258 - accuracy: 0.7098 - val_loss: 0.6497 - val_accuracy: 0.6378\n",
      "Epoch 67/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5269 - accuracy: 0.7141 - val_loss: 0.6885 - val_accuracy: 0.6289\n",
      "Epoch 68/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5279 - accuracy: 0.7027 - val_loss: 0.6610 - val_accuracy: 0.5960\n",
      "Epoch 69/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5319 - accuracy: 0.7141 - val_loss: 0.6566 - val_accuracy: 0.6362\n",
      "Epoch 70/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5332 - accuracy: 0.7112 - val_loss: 0.6190 - val_accuracy: 0.6529\n",
      "Epoch 71/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5314 - accuracy: 0.7072 - val_loss: 0.6384 - val_accuracy: 0.6802\n",
      "Epoch 72/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5336 - accuracy: 0.7069 - val_loss: 0.6714 - val_accuracy: 0.5954\n",
      "Epoch 73/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5287 - accuracy: 0.7107 - val_loss: 0.6704 - val_accuracy: 0.6395\n",
      "Epoch 74/1200\n",
      "112/112 [==============================] - 5s 40ms/step - loss: 0.5258 - accuracy: 0.7167 - val_loss: 0.6573 - val_accuracy: 0.6272\n",
      "Epoch 75/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5196 - accuracy: 0.7193 - val_loss: 0.6393 - val_accuracy: 0.6177\n",
      "Epoch 76/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5143 - accuracy: 0.7221 - val_loss: 0.6725 - val_accuracy: 0.6222\n",
      "Epoch 77/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5123 - accuracy: 0.7224 - val_loss: 0.6595 - val_accuracy: 0.6473\n",
      "Epoch 78/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5029 - accuracy: 0.7256 - val_loss: 0.6407 - val_accuracy: 0.6423\n",
      "Epoch 79/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5028 - accuracy: 0.7250 - val_loss: 0.6603 - val_accuracy: 0.6384\n",
      "Epoch 80/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5054 - accuracy: 0.7280 - val_loss: 0.6865 - val_accuracy: 0.6451\n",
      "Epoch 81/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5244 - accuracy: 0.7162 - val_loss: 0.7193 - val_accuracy: 0.6406\n",
      "Epoch 82/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5099 - accuracy: 0.7196 - val_loss: 0.6829 - val_accuracy: 0.6390\n",
      "Epoch 83/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5078 - accuracy: 0.7228 - val_loss: 0.6626 - val_accuracy: 0.6663\n",
      "Epoch 84/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5104 - accuracy: 0.7241 - val_loss: 0.6291 - val_accuracy: 0.6747\n",
      "Epoch 85/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4966 - accuracy: 0.7326 - val_loss: 0.6294 - val_accuracy: 0.6172\n",
      "Epoch 86/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4962 - accuracy: 0.7305 - val_loss: 0.6750 - val_accuracy: 0.6345\n",
      "Epoch 87/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4990 - accuracy: 0.7281 - val_loss: 0.6323 - val_accuracy: 0.6696\n",
      "Epoch 88/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4995 - accuracy: 0.7360 - val_loss: 0.6877 - val_accuracy: 0.6300\n",
      "Epoch 89/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4893 - accuracy: 0.7381 - val_loss: 0.6818 - val_accuracy: 0.6350\n",
      "Epoch 90/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5005 - accuracy: 0.7294 - val_loss: 0.6340 - val_accuracy: 0.6529\n",
      "Epoch 91/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4925 - accuracy: 0.7395 - val_loss: 0.6774 - val_accuracy: 0.6339\n",
      "Epoch 92/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4962 - accuracy: 0.7349 - val_loss: 0.7413 - val_accuracy: 0.6373\n",
      "Epoch 93/1200\n",
      "112/112 [==============================] - 5s 40ms/step - loss: 0.4762 - accuracy: 0.7468 - val_loss: 0.7850 - val_accuracy: 0.6624\n",
      "Epoch 94/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.4874 - accuracy: 0.7386 - val_loss: 0.7238 - val_accuracy: 0.6222\n",
      "Epoch 95/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4896 - accuracy: 0.7462 - val_loss: 0.7042 - val_accuracy: 0.6607\n",
      "Epoch 96/1200\n",
      "112/112 [==============================] - 5s 40ms/step - loss: 0.4820 - accuracy: 0.7454 - val_loss: 0.7045 - val_accuracy: 0.6523\n",
      "Epoch 97/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4809 - accuracy: 0.7478 - val_loss: 0.6507 - val_accuracy: 0.6585\n",
      "Epoch 98/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4837 - accuracy: 0.7507 - val_loss: 0.6441 - val_accuracy: 0.6825\n",
      "Epoch 99/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4695 - accuracy: 0.7433 - val_loss: 0.6614 - val_accuracy: 0.6708\n",
      "Epoch 100/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4636 - accuracy: 0.7573 - val_loss: 0.6825 - val_accuracy: 0.6652\n",
      "Epoch 101/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4877 - accuracy: 0.7387 - val_loss: 0.6574 - val_accuracy: 0.6546\n",
      "Epoch 102/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4636 - accuracy: 0.7570 - val_loss: 0.6578 - val_accuracy: 0.6557\n",
      "Epoch 103/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4649 - accuracy: 0.7549 - val_loss: 0.6645 - val_accuracy: 0.6685\n",
      "Epoch 104/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4673 - accuracy: 0.7592 - val_loss: 0.8739 - val_accuracy: 0.6122\n",
      "Epoch 105/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4541 - accuracy: 0.7674 - val_loss: 0.6540 - val_accuracy: 0.6568: 0.4539 - accuracy\n",
      "Epoch 106/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4406 - accuracy: 0.7739 - val_loss: 0.6492 - val_accuracy: 0.6791\n",
      "Epoch 107/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4695 - accuracy: 0.7606 - val_loss: 0.6555 - val_accuracy: 0.7003\n",
      "Epoch 108/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4486 - accuracy: 0.7688 - val_loss: 0.6213 - val_accuracy: 0.6696\n",
      "Epoch 109/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4551 - accuracy: 0.7649 - val_loss: 0.7180 - val_accuracy: 0.6244\n",
      "Epoch 110/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4590 - accuracy: 0.7634 - val_loss: 0.8319 - val_accuracy: 0.5647\n",
      "Epoch 111/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4608 - accuracy: 0.7614 - val_loss: 0.6429 - val_accuracy: 0.6970\n",
      "Epoch 112/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4441 - accuracy: 0.7727 - val_loss: 0.7006 - val_accuracy: 0.6663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4520 - accuracy: 0.7613 - val_loss: 0.6116 - val_accuracy: 0.6724\n",
      "Epoch 114/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4730 - accuracy: 0.7465 - val_loss: 0.6155 - val_accuracy: 0.6769\n",
      "Epoch 115/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4616 - accuracy: 0.7591 - val_loss: 0.6509 - val_accuracy: 0.6959\n",
      "Epoch 116/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4491 - accuracy: 0.7580 - val_loss: 0.7185 - val_accuracy: 0.6802\n",
      "Epoch 117/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4342 - accuracy: 0.7725 - val_loss: 0.7231 - val_accuracy: 0.6747\n",
      "Epoch 118/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4353 - accuracy: 0.7762 - val_loss: 0.6843 - val_accuracy: 0.6350\n",
      "Epoch 119/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4280 - accuracy: 0.7789 - val_loss: 0.7142 - val_accuracy: 0.6702\n",
      "Epoch 120/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4383 - accuracy: 0.7775 - val_loss: 0.6735 - val_accuracy: 0.6618\n",
      "Epoch 121/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4475 - accuracy: 0.7624 - val_loss: 0.6975 - val_accuracy: 0.6719\n",
      "Epoch 122/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4555 - accuracy: 0.7612 - val_loss: 0.7156 - val_accuracy: 0.6724\n",
      "Epoch 123/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4212 - accuracy: 0.7852 - val_loss: 0.7217 - val_accuracy: 0.6423\n",
      "Epoch 124/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.4067 - accuracy: 0.7930 - val_loss: 0.8052 - val_accuracy: 0.6652\n",
      "Epoch 125/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4277 - accuracy: 0.7819 - val_loss: 0.7432 - val_accuracy: 0.6523\n",
      "Epoch 126/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4163 - accuracy: 0.7923 - val_loss: 0.7217 - val_accuracy: 0.6830\n",
      "Epoch 127/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4183 - accuracy: 0.7895 - val_loss: 0.7032 - val_accuracy: 0.6708\n",
      "Epoch 128/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4209 - accuracy: 0.7833 - val_loss: 0.6949 - val_accuracy: 0.6808\n",
      "Epoch 129/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4077 - accuracy: 0.7953 - val_loss: 0.7302 - val_accuracy: 0.6708\n",
      "Epoch 130/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4079 - accuracy: 0.7945 - val_loss: 0.7060 - val_accuracy: 0.6892\n",
      "Epoch 131/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4152 - accuracy: 0.7889 - val_loss: 0.7937 - val_accuracy: 0.6423\n",
      "Epoch 132/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4003 - accuracy: 0.7992 - val_loss: 0.7729 - val_accuracy: 0.6802\n",
      "Epoch 133/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3968 - accuracy: 0.7952 - val_loss: 0.8950 - val_accuracy: 0.6161\n",
      "Epoch 134/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4035 - accuracy: 0.7938 - val_loss: 0.8410 - val_accuracy: 0.6685\n",
      "Epoch 135/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4051 - accuracy: 0.7988 - val_loss: 0.8782 - val_accuracy: 0.6205\n",
      "Epoch 136/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4141 - accuracy: 0.7949 - val_loss: 0.6801 - val_accuracy: 0.6641\n",
      "Epoch 137/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3880 - accuracy: 0.8041 - val_loss: 0.7873 - val_accuracy: 0.6657\n",
      "Epoch 138/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3997 - accuracy: 0.8001 - val_loss: 0.8171 - val_accuracy: 0.6847\n",
      "Epoch 139/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.3809 - accuracy: 0.8135 - val_loss: 0.8073 - val_accuracy: 0.7305\n",
      "Epoch 140/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.3798 - accuracy: 0.8138 - val_loss: 0.8986 - val_accuracy: 0.6981\n",
      "Epoch 141/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3902 - accuracy: 0.8034 - val_loss: 0.7829 - val_accuracy: 0.6864\n",
      "Epoch 142/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3799 - accuracy: 0.8107 - val_loss: 0.8186 - val_accuracy: 0.7015\n",
      "Epoch 143/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3773 - accuracy: 0.8128 - val_loss: 0.7307 - val_accuracy: 0.7215\n",
      "Epoch 144/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3941 - accuracy: 0.8085 - val_loss: 0.8265 - val_accuracy: 0.5765\n",
      "Epoch 145/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3924 - accuracy: 0.8059 - val_loss: 0.8286 - val_accuracy: 0.6747\n",
      "Epoch 146/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3631 - accuracy: 0.8231 - val_loss: 0.7273 - val_accuracy: 0.7154\n",
      "Epoch 147/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3733 - accuracy: 0.8182 - val_loss: 0.7427 - val_accuracy: 0.6959\n",
      "Epoch 148/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3737 - accuracy: 0.8142 - val_loss: 0.7970 - val_accuracy: 0.7093\n",
      "Epoch 149/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3582 - accuracy: 0.8245 - val_loss: 0.8797 - val_accuracy: 0.6786\n",
      "Epoch 150/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3695 - accuracy: 0.8086 - val_loss: 0.9233 - val_accuracy: 0.6853\n",
      "Epoch 151/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3586 - accuracy: 0.8299 - val_loss: 0.7367 - val_accuracy: 0.7003\n",
      "Epoch 152/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3676 - accuracy: 0.8209 - val_loss: 0.6606 - val_accuracy: 0.7048\n",
      "Epoch 153/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3836 - accuracy: 0.8083 - val_loss: 0.7210 - val_accuracy: 0.7294\n",
      "Epoch 154/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3733 - accuracy: 0.8104 - val_loss: 0.7136 - val_accuracy: 0.6903\n",
      "Epoch 155/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.3649 - accuracy: 0.8150 - val_loss: 0.8157 - val_accuracy: 0.6825\n",
      "Epoch 156/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3612 - accuracy: 0.8058 - val_loss: 0.8432 - val_accuracy: 0.7160\n",
      "Epoch 157/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3446 - accuracy: 0.8278 - val_loss: 0.9686 - val_accuracy: 0.6897\n",
      "Epoch 158/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3376 - accuracy: 0.8347 - val_loss: 0.9368 - val_accuracy: 0.7065\n",
      "Epoch 159/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3360 - accuracy: 0.8407 - val_loss: 0.8890 - val_accuracy: 0.6936\n",
      "Epoch 160/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3390 - accuracy: 0.8309 - val_loss: 0.7561 - val_accuracy: 0.7366\n",
      "Epoch 161/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3400 - accuracy: 0.8311 - val_loss: 0.8460 - val_accuracy: 0.6853\n",
      "Epoch 162/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3584 - accuracy: 0.8260 - val_loss: 0.7011 - val_accuracy: 0.7522\n",
      "Epoch 163/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.3337 - accuracy: 0.8404 - val_loss: 0.8237 - val_accuracy: 0.7450\n",
      "Epoch 164/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3355 - accuracy: 0.8378 - val_loss: 0.8677 - val_accuracy: 0.7148\n",
      "Epoch 165/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3310 - accuracy: 0.8397 - val_loss: 0.9124 - val_accuracy: 0.6908\n",
      "Epoch 166/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3208 - accuracy: 0.8507 - val_loss: 0.9423 - val_accuracy: 0.7121ss: 0.3196 - accuracy: \n",
      "Epoch 167/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3185 - accuracy: 0.8493 - val_loss: 0.8797 - val_accuracy: 0.7232\n",
      "Epoch 168/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3156 - accuracy: 0.8471 - val_loss: 0.7681 - val_accuracy: 0.7439\n",
      "Epoch 169/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3555 - accuracy: 0.8259 - val_loss: 0.8766 - val_accuracy: 0.7238\n",
      "Epoch 170/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3265 - accuracy: 0.8419 - val_loss: 0.7962 - val_accuracy: 0.6959\n",
      "Epoch 171/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3174 - accuracy: 0.8477 - val_loss: 0.9322 - val_accuracy: 0.7031\n",
      "Epoch 172/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3018 - accuracy: 0.8583 - val_loss: 0.7866 - val_accuracy: 0.7266\n",
      "Epoch 173/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3038 - accuracy: 0.8559 - val_loss: 1.0039 - val_accuracy: 0.7294\n",
      "Epoch 174/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3300 - accuracy: 0.8485 - val_loss: 0.8010 - val_accuracy: 0.7360\n",
      "Epoch 175/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3107 - accuracy: 0.8506 - val_loss: 0.7516 - val_accuracy: 0.7355\n",
      "Epoch 176/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3027 - accuracy: 0.8577 - val_loss: 0.8478 - val_accuracy: 0.7433\n",
      "Epoch 177/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3080 - accuracy: 0.8555 - val_loss: 0.8532 - val_accuracy: 0.7143\n",
      "Epoch 178/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3118 - accuracy: 0.8525 - val_loss: 0.9402 - val_accuracy: 0.6987\n",
      "Epoch 179/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3031 - accuracy: 0.8602 - val_loss: 0.7522 - val_accuracy: 0.7026\n",
      "Epoch 180/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2961 - accuracy: 0.8562 - val_loss: 0.8507 - val_accuracy: 0.7109\n",
      "Epoch 181/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3015 - accuracy: 0.8555 - val_loss: 0.9499 - val_accuracy: 0.7182ss: 0.3015 - accuracy: 0.85\n",
      "Epoch 182/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2897 - accuracy: 0.8640 - val_loss: 1.0019 - val_accuracy: 0.7355\n",
      "Epoch 183/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2890 - accuracy: 0.8634 - val_loss: 0.8252 - val_accuracy: 0.7528\n",
      "Epoch 184/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2892 - accuracy: 0.8633 - val_loss: 1.1316 - val_accuracy: 0.7360\n",
      "Epoch 185/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2894 - accuracy: 0.8637 - val_loss: 0.9760 - val_accuracy: 0.7199\n",
      "Epoch 186/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2980 - accuracy: 0.8567 - val_loss: 0.8493 - val_accuracy: 0.7271\n",
      "Epoch 187/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2812 - accuracy: 0.8691 - val_loss: 0.8487 - val_accuracy: 0.7489\n",
      "Epoch 188/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2791 - accuracy: 0.8687 - val_loss: 0.9442 - val_accuracy: 0.7360\n",
      "Epoch 189/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2915 - accuracy: 0.8647 - val_loss: 1.0903 - val_accuracy: 0.7333\n",
      "Epoch 190/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2858 - accuracy: 0.8615 - val_loss: 1.0144 - val_accuracy: 0.7617\n",
      "Epoch 191/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2796 - accuracy: 0.8693 - val_loss: 1.1106 - val_accuracy: 0.7260\n",
      "Epoch 192/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2779 - accuracy: 0.8696 - val_loss: 0.9212 - val_accuracy: 0.7266\n",
      "Epoch 193/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2904 - accuracy: 0.8601 - val_loss: 1.0124 - val_accuracy: 0.7461\n",
      "Epoch 194/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2821 - accuracy: 0.8638 - val_loss: 1.0893 - val_accuracy: 0.7344\n",
      "Epoch 195/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2591 - accuracy: 0.8836 - val_loss: 0.9920 - val_accuracy: 0.7305\n",
      "Epoch 196/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2664 - accuracy: 0.8740 - val_loss: 1.0415 - val_accuracy: 0.7377\n",
      "Epoch 197/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2943 - accuracy: 0.8643 - val_loss: 1.1797 - val_accuracy: 0.7366\n",
      "Epoch 198/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2576 - accuracy: 0.8802 - val_loss: 1.1170 - val_accuracy: 0.7260\n",
      "Epoch 199/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2988 - accuracy: 0.8489 - val_loss: 0.9539 - val_accuracy: 0.7483\n",
      "Epoch 200/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2634 - accuracy: 0.8793 - val_loss: 1.2505 - val_accuracy: 0.7266\n",
      "Epoch 201/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.2621 - accuracy: 0.8816 - val_loss: 1.0088 - val_accuracy: 0.7489\n",
      "Epoch 202/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2562 - accuracy: 0.8782 - val_loss: 1.1123 - val_accuracy: 0.7160\n",
      "Epoch 203/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2532 - accuracy: 0.8825 - val_loss: 0.9988 - val_accuracy: 0.7360\n",
      "Epoch 204/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2747 - accuracy: 0.8697 - val_loss: 1.3912 - val_accuracy: 0.7282\n",
      "Epoch 205/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2494 - accuracy: 0.8849 - val_loss: 0.9181 - val_accuracy: 0.7360\n",
      "Epoch 206/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2504 - accuracy: 0.8839 - val_loss: 1.2049 - val_accuracy: 0.7383\n",
      "Epoch 207/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2572 - accuracy: 0.8830 - val_loss: 1.1709 - val_accuracy: 0.7294\n",
      "Epoch 208/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2640 - accuracy: 0.8781 - val_loss: 1.2266 - val_accuracy: 0.7405\n",
      "Epoch 209/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2456 - accuracy: 0.8876 - val_loss: 1.2985 - val_accuracy: 0.7589\n",
      "Epoch 210/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2348 - accuracy: 0.8890 - val_loss: 0.9881 - val_accuracy: 0.7522\n",
      "Epoch 211/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2542 - accuracy: 0.8820 - val_loss: 0.8376 - val_accuracy: 0.7433\n",
      "Epoch 212/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2351 - accuracy: 0.8936 - val_loss: 1.0736 - val_accuracy: 0.7455\n",
      "Epoch 213/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2464 - accuracy: 0.8892 - val_loss: 1.0826 - val_accuracy: 0.7500\n",
      "Epoch 214/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2411 - accuracy: 0.8926 - val_loss: 0.9600 - val_accuracy: 0.7829\n",
      "Epoch 215/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2400 - accuracy: 0.8926 - val_loss: 0.9849 - val_accuracy: 0.7796\n",
      "Epoch 216/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.2491 - accuracy: 0.8848 - val_loss: 1.1334 - val_accuracy: 0.7522\n",
      "Epoch 217/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2405 - accuracy: 0.8937 - val_loss: 0.8678 - val_accuracy: 0.7701\n",
      "Epoch 218/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2278 - accuracy: 0.8968 - val_loss: 1.1989 - val_accuracy: 0.7494\n",
      "Epoch 219/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2365 - accuracy: 0.8912 - val_loss: 0.8651 - val_accuracy: 0.7450\n",
      "Epoch 220/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2339 - accuracy: 0.8922 - val_loss: 1.0560 - val_accuracy: 0.7628\n",
      "Epoch 221/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2357 - accuracy: 0.8916 - val_loss: 1.1308 - val_accuracy: 0.7316\n",
      "Epoch 222/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2332 - accuracy: 0.8938 - val_loss: 0.9686 - val_accuracy: 0.7829\n",
      "Epoch 223/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2264 - accuracy: 0.8954 - val_loss: 0.9966 - val_accuracy: 0.7478\n",
      "Epoch 224/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2450 - accuracy: 0.8913 - val_loss: 0.9890 - val_accuracy: 0.7366\n",
      "Epoch 225/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2274 - accuracy: 0.9012 - val_loss: 1.0424 - val_accuracy: 0.7489: 0.2267 - accuracy: \n",
      "Epoch 226/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2321 - accuracy: 0.8979 - val_loss: 0.9820 - val_accuracy: 0.7299\n",
      "Epoch 227/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2305 - accuracy: 0.8969 - val_loss: 1.0729 - val_accuracy: 0.7656\n",
      "Epoch 228/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2256 - accuracy: 0.9003 - val_loss: 1.0747 - val_accuracy: 0.7679\n",
      "Epoch 229/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2452 - accuracy: 0.8901 - val_loss: 1.1042 - val_accuracy: 0.7383\n",
      "Epoch 230/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2812 - accuracy: 0.8772 - val_loss: 0.8602 - val_accuracy: 0.7812\n",
      "Epoch 231/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.2213 - accuracy: 0.9022 - val_loss: 0.9880 - val_accuracy: 0.7729\n",
      "Epoch 232/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2200 - accuracy: 0.9008 - val_loss: 0.8589 - val_accuracy: 0.7690\n",
      "Epoch 233/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2164 - accuracy: 0.9033 - val_loss: 0.9432 - val_accuracy: 0.7690\n",
      "Epoch 234/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2148 - accuracy: 0.8996 - val_loss: 1.2202 - val_accuracy: 0.7349\n",
      "Epoch 235/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2102 - accuracy: 0.9076 - val_loss: 1.1896 - val_accuracy: 0.7561\n",
      "Epoch 236/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2096 - accuracy: 0.9086 - val_loss: 1.3934 - val_accuracy: 0.7522\n",
      "Epoch 237/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2185 - accuracy: 0.9035 - val_loss: 1.0832 - val_accuracy: 0.7517\n",
      "Epoch 238/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2036 - accuracy: 0.9061 - val_loss: 1.1571 - val_accuracy: 0.7517\n",
      "Epoch 239/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1988 - accuracy: 0.9093 - val_loss: 1.4076 - val_accuracy: 0.7757\n",
      "Epoch 240/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2073 - accuracy: 0.9065 - val_loss: 0.8617 - val_accuracy: 0.7930\n",
      "Epoch 241/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2035 - accuracy: 0.9082 - val_loss: 1.1096 - val_accuracy: 0.7584\n",
      "Epoch 242/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1976 - accuracy: 0.9090 - val_loss: 1.1556 - val_accuracy: 0.7545\n",
      "Epoch 243/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1994 - accuracy: 0.9136 - val_loss: 0.8615 - val_accuracy: 0.7422\n",
      "Epoch 244/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2110 - accuracy: 0.9092 - val_loss: 0.8706 - val_accuracy: 0.7561\n",
      "Epoch 245/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2030 - accuracy: 0.9118 - val_loss: 1.3682 - val_accuracy: 0.7701\n",
      "Epoch 246/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2092 - accuracy: 0.9057 - val_loss: 0.8733 - val_accuracy: 0.7846\n",
      "Epoch 247/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1950 - accuracy: 0.9129 - val_loss: 0.9557 - val_accuracy: 0.7868\n",
      "Epoch 248/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1874 - accuracy: 0.9174 - val_loss: 1.2050 - val_accuracy: 0.7634\n",
      "Epoch 249/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2372 - accuracy: 0.9004 - val_loss: 0.8705 - val_accuracy: 0.7628\n",
      "Epoch 250/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2019 - accuracy: 0.9109 - val_loss: 0.8192 - val_accuracy: 0.7455\n",
      "Epoch 251/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1886 - accuracy: 0.9187 - val_loss: 1.1040 - val_accuracy: 0.7712\n",
      "Epoch 252/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2112 - accuracy: 0.9085 - val_loss: 0.9618 - val_accuracy: 0.7695\n",
      "Epoch 253/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1932 - accuracy: 0.9109 - val_loss: 1.2851 - val_accuracy: 0.7695 0s - loss: 0.1946 - ac\n",
      "Epoch 254/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2038 - accuracy: 0.9039 - val_loss: 1.0442 - val_accuracy: 0.7383\n",
      "Epoch 255/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1811 - accuracy: 0.9209 - val_loss: 1.0100 - val_accuracy: 0.7863\n",
      "Epoch 256/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1888 - accuracy: 0.9174 - val_loss: 1.0314 - val_accuracy: 0.7751\n",
      "Epoch 257/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2278 - accuracy: 0.9090 - val_loss: 1.1779 - val_accuracy: 0.7712\n",
      "Epoch 258/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1961 - accuracy: 0.9125 - val_loss: 1.1499 - val_accuracy: 0.7673\n",
      "Epoch 259/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1808 - accuracy: 0.9202 - val_loss: 1.1347 - val_accuracy: 0.7762\n",
      "Epoch 260/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1948 - accuracy: 0.9152 - val_loss: 1.1086 - val_accuracy: 0.7829\n",
      "Epoch 261/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.1898 - accuracy: 0.9152 - val_loss: 1.1882 - val_accuracy: 0.7896\n",
      "Epoch 262/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1929 - accuracy: 0.9167 - val_loss: 0.8895 - val_accuracy: 0.7913\n",
      "Epoch 263/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1794 - accuracy: 0.9251 - val_loss: 1.2835 - val_accuracy: 0.7885\n",
      "Epoch 264/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1672 - accuracy: 0.9261 - val_loss: 1.1853 - val_accuracy: 0.7768\n",
      "Epoch 265/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1758 - accuracy: 0.9247 - val_loss: 1.0702 - val_accuracy: 0.7640\n",
      "Epoch 266/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1736 - accuracy: 0.9235 - val_loss: 0.9561 - val_accuracy: 0.7857\n",
      "Epoch 267/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1681 - accuracy: 0.9305 - val_loss: 1.1197 - val_accuracy: 0.7863\n",
      "Epoch 268/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1816 - accuracy: 0.9202 - val_loss: 1.1731 - val_accuracy: 0.7729\n",
      "Epoch 269/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1795 - accuracy: 0.9240 - val_loss: 1.1380 - val_accuracy: 0.7550\n",
      "Epoch 270/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1896 - accuracy: 0.9189 - val_loss: 1.2163 - val_accuracy: 0.7779\n",
      "Epoch 271/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1666 - accuracy: 0.9300 - val_loss: 1.1134 - val_accuracy: 0.7958\n",
      "Epoch 272/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1640 - accuracy: 0.9277 - val_loss: 1.0434 - val_accuracy: 0.7919\n",
      "Epoch 273/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1818 - accuracy: 0.9233 - val_loss: 1.0239 - val_accuracy: 0.7885\n",
      "Epoch 274/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1675 - accuracy: 0.9289 - val_loss: 1.0136 - val_accuracy: 0.7640\n",
      "Epoch 275/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1766 - accuracy: 0.9231 - val_loss: 1.1950 - val_accuracy: 0.7796\n",
      "Epoch 276/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1840 - accuracy: 0.9201 - val_loss: 1.0401 - val_accuracy: 0.7807\n",
      "Epoch 277/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.1553 - accuracy: 0.9360 - val_loss: 1.1643 - val_accuracy: 0.7974\n",
      "Epoch 278/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1806 - accuracy: 0.9213 - val_loss: 1.1542 - val_accuracy: 0.7757\n",
      "Epoch 279/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1666 - accuracy: 0.9282 - val_loss: 1.4090 - val_accuracy: 0.7879\n",
      "Epoch 280/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1619 - accuracy: 0.9314 - val_loss: 1.5112 - val_accuracy: 0.7812\n",
      "Epoch 281/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1944 - accuracy: 0.9208 - val_loss: 1.1448 - val_accuracy: 0.7729\n",
      "Epoch 282/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1680 - accuracy: 0.9247 - val_loss: 1.2970 - val_accuracy: 0.7768\n",
      "Epoch 283/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2459 - accuracy: 0.8890 - val_loss: 1.2001 - val_accuracy: 0.7400\n",
      "Epoch 284/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2324 - accuracy: 0.8864 - val_loss: 0.8185 - val_accuracy: 0.7550\n",
      "Epoch 285/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1917 - accuracy: 0.9074 - val_loss: 1.3093 - val_accuracy: 0.7634\n",
      "Epoch 286/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1994 - accuracy: 0.9016 - val_loss: 1.1605 - val_accuracy: 0.7801\n",
      "Epoch 287/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2791 - accuracy: 0.8838 - val_loss: 1.0424 - val_accuracy: 0.8086\n",
      "Epoch 288/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1733 - accuracy: 0.9153 - val_loss: 1.0655 - val_accuracy: 0.8002\n",
      "Epoch 289/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1590 - accuracy: 0.9270 - val_loss: 1.2699 - val_accuracy: 0.7779\n",
      "Epoch 290/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1727 - accuracy: 0.9251 - val_loss: 1.1111 - val_accuracy: 0.7746\n",
      "Epoch 291/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1675 - accuracy: 0.9235 - val_loss: 1.1722 - val_accuracy: 0.7517\n",
      "Epoch 292/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.1653 - accuracy: 0.9314 - val_loss: 1.3640 - val_accuracy: 0.7751\n",
      "Epoch 293/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1685 - accuracy: 0.9279 - val_loss: 1.0105 - val_accuracy: 0.7919\n",
      "Epoch 294/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1650 - accuracy: 0.9316 - val_loss: 1.2139 - val_accuracy: 0.7768\n",
      "Epoch 295/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1538 - accuracy: 0.9365 - val_loss: 1.0165 - val_accuracy: 0.7958\n",
      "Epoch 296/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1637 - accuracy: 0.9315 - val_loss: 1.2915 - val_accuracy: 0.7902\n",
      "Epoch 297/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1425 - accuracy: 0.9389 - val_loss: 1.3529 - val_accuracy: 0.7902\n",
      "Epoch 298/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1406 - accuracy: 0.9386 - val_loss: 1.5334 - val_accuracy: 0.7919\n",
      "Epoch 299/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1424 - accuracy: 0.9395 - val_loss: 1.4750 - val_accuracy: 0.7963\n",
      "Epoch 300/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1423 - accuracy: 0.9372 - val_loss: 1.1352 - val_accuracy: 0.8097\n",
      "Epoch 301/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1391 - accuracy: 0.9385 - val_loss: 1.4609 - val_accuracy: 0.8030\n",
      "Epoch 302/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1594 - accuracy: 0.9339 - val_loss: 1.2187 - val_accuracy: 0.7963\n",
      "Epoch 303/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1571 - accuracy: 0.9342 - val_loss: 1.3003 - val_accuracy: 0.7991\n",
      "Epoch 304/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1391 - accuracy: 0.9443 - val_loss: 1.5823 - val_accuracy: 0.7935\n",
      "Epoch 305/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1493 - accuracy: 0.9369 - val_loss: 1.3448 - val_accuracy: 0.8064\n",
      "Epoch 306/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1289 - accuracy: 0.9464 - val_loss: 1.2003 - val_accuracy: 0.8030\n",
      "Epoch 307/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1300 - accuracy: 0.9470 - val_loss: 1.2599 - val_accuracy: 0.7946\n",
      "Epoch 308/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1363 - accuracy: 0.9449 - val_loss: 1.1600 - val_accuracy: 0.7969\n",
      "Epoch 309/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1414 - accuracy: 0.9402 - val_loss: 1.2675 - val_accuracy: 0.7790\n",
      "Epoch 310/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1432 - accuracy: 0.9396 - val_loss: 1.1530 - val_accuracy: 0.8075\n",
      "Epoch 311/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1393 - accuracy: 0.9403 - val_loss: 1.3478 - val_accuracy: 0.8097\n",
      "Epoch 312/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1328 - accuracy: 0.9429 - val_loss: 1.2903 - val_accuracy: 0.8092\n",
      "Epoch 313/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1261 - accuracy: 0.9446 - val_loss: 1.3414 - val_accuracy: 0.7963\n",
      "Epoch 314/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1478 - accuracy: 0.9397 - val_loss: 1.2294 - val_accuracy: 0.8164\n",
      "Epoch 315/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1232 - accuracy: 0.9470 - val_loss: 1.3021 - val_accuracy: 0.8036\n",
      "Epoch 316/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1458 - accuracy: 0.9400 - val_loss: 1.4406 - val_accuracy: 0.8131\n",
      "Epoch 317/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1402 - accuracy: 0.9434 - val_loss: 1.3625 - val_accuracy: 0.7868\n",
      "Epoch 318/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1296 - accuracy: 0.9457 - val_loss: 1.1562 - val_accuracy: 0.8075\n",
      "Epoch 319/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1669 - accuracy: 0.9318 - val_loss: 1.1312 - val_accuracy: 0.8019\n",
      "Epoch 320/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1243 - accuracy: 0.9480 - val_loss: 1.2798 - val_accuracy: 0.7879\n",
      "Epoch 321/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1323 - accuracy: 0.9492 - val_loss: 1.5967 - val_accuracy: 0.8125\n",
      "Epoch 322/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1327 - accuracy: 0.9461 - val_loss: 1.5827 - val_accuracy: 0.7768\n",
      "Epoch 323/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.1238 - accuracy: 0.9485 - val_loss: 1.5381 - val_accuracy: 0.7857\n",
      "Epoch 324/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1406 - accuracy: 0.9422 - val_loss: 1.1329 - val_accuracy: 0.7790\n",
      "Epoch 325/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1253 - accuracy: 0.9475 - val_loss: 1.0583 - val_accuracy: 0.7997\n",
      "Epoch 326/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1273 - accuracy: 0.9480 - val_loss: 1.4083 - val_accuracy: 0.7952\n",
      "Epoch 327/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1648 - accuracy: 0.9357 - val_loss: 1.4041 - val_accuracy: 0.7896\n",
      "Epoch 328/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1181 - accuracy: 0.9502 - val_loss: 1.2264 - val_accuracy: 0.8147\n",
      "Epoch 329/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1760 - accuracy: 0.9217 - val_loss: 1.2482 - val_accuracy: 0.7679\n",
      "Epoch 330/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2312 - accuracy: 0.8836 - val_loss: 1.2930 - val_accuracy: 0.7818\n",
      "Epoch 331/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1813 - accuracy: 0.9134 - val_loss: 1.4791 - val_accuracy: 0.7701\n",
      "Epoch 332/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1530 - accuracy: 0.9279 - val_loss: 1.6091 - val_accuracy: 0.7985\n",
      "Epoch 333/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1550 - accuracy: 0.9325 - val_loss: 1.2938 - val_accuracy: 0.8013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1321 - accuracy: 0.9474 - val_loss: 1.0412 - val_accuracy: 0.7952\n",
      "Epoch 335/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1135 - accuracy: 0.9519 - val_loss: 1.2810 - val_accuracy: 0.7991\n",
      "Epoch 336/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1199 - accuracy: 0.9499 - val_loss: 1.0216 - val_accuracy: 0.8170\n",
      "Epoch 337/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1197 - accuracy: 0.9494 - val_loss: 0.8423 - val_accuracy: 0.8186\n",
      "Epoch 338/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.2362 - accuracy: 0.9138 - val_loss: 0.7612 - val_accuracy: 0.7946\n",
      "Epoch 339/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1296 - accuracy: 0.9505 - val_loss: 1.2455 - val_accuracy: 0.7974\n",
      "Epoch 340/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1107 - accuracy: 0.9519 - val_loss: 1.1626 - val_accuracy: 0.8242\n",
      "Epoch 341/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1177 - accuracy: 0.9527 - val_loss: 1.1431 - val_accuracy: 0.8030\n",
      "Epoch 342/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1091 - accuracy: 0.9544 - val_loss: 1.5906 - val_accuracy: 0.7930\n",
      "Epoch 343/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1121 - accuracy: 0.9574 - val_loss: 1.1865 - val_accuracy: 0.8119\n",
      "Epoch 344/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1141 - accuracy: 0.9542 - val_loss: 1.5217 - val_accuracy: 0.8064\n",
      "Epoch 345/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1010 - accuracy: 0.9577 - val_loss: 1.2804 - val_accuracy: 0.7969\n",
      "Epoch 346/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1722 - accuracy: 0.9395 - val_loss: 1.2075 - val_accuracy: 0.7997\n",
      "Epoch 347/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1057 - accuracy: 0.9555 - val_loss: 1.4156 - val_accuracy: 0.8192\n",
      "Epoch 348/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1213 - accuracy: 0.9528 - val_loss: 1.3099 - val_accuracy: 0.8142\n",
      "Epoch 349/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1088 - accuracy: 0.9563 - val_loss: 1.2931 - val_accuracy: 0.7941\n",
      "Epoch 350/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1258 - accuracy: 0.9487 - val_loss: 1.2362 - val_accuracy: 0.7958\n",
      "Epoch 351/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1082 - accuracy: 0.9577 - val_loss: 1.1643 - val_accuracy: 0.8002\n",
      "Epoch 352/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1041 - accuracy: 0.9556 - val_loss: 1.0316 - val_accuracy: 0.8142\n",
      "Epoch 353/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.1067 - accuracy: 0.9566 - val_loss: 1.0998 - val_accuracy: 0.8153\n",
      "Epoch 354/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1625 - accuracy: 0.9286 - val_loss: 1.2216 - val_accuracy: 0.7930\n",
      "Epoch 355/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1410 - accuracy: 0.9344 - val_loss: 1.5524 - val_accuracy: 0.7840\n",
      "Epoch 356/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1006 - accuracy: 0.9587 - val_loss: 1.2996 - val_accuracy: 0.8192\n",
      "Epoch 357/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1058 - accuracy: 0.9583 - val_loss: 1.5121 - val_accuracy: 0.8103\n",
      "Epoch 358/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0956 - accuracy: 0.9637 - val_loss: 1.4769 - val_accuracy: 0.8119\n",
      "Epoch 359/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1050 - accuracy: 0.9579 - val_loss: 1.4577 - val_accuracy: 0.8114\n",
      "Epoch 360/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1024 - accuracy: 0.9616 - val_loss: 1.5545 - val_accuracy: 0.8080\n",
      "Epoch 361/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1008 - accuracy: 0.9576 - val_loss: 1.6181 - val_accuracy: 0.7980\n",
      "Epoch 362/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1161 - accuracy: 0.9555 - val_loss: 1.3387 - val_accuracy: 0.8041\n",
      "Epoch 363/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1026 - accuracy: 0.9584 - val_loss: 1.3341 - val_accuracy: 0.8354\n",
      "Epoch 364/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1013 - accuracy: 0.9593 - val_loss: 1.5728 - val_accuracy: 0.8064\n",
      "Epoch 365/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1065 - accuracy: 0.9565 - val_loss: 1.4463 - val_accuracy: 0.8086\n",
      "Epoch 366/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1157 - accuracy: 0.9521 - val_loss: 1.5717 - val_accuracy: 0.8013\n",
      "Epoch 367/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1281 - accuracy: 0.9517 - val_loss: 1.5083 - val_accuracy: 0.7852\n",
      "Epoch 368/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1128 - accuracy: 0.9549 - val_loss: 1.2797 - val_accuracy: 0.7891\n",
      "Epoch 369/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0898 - accuracy: 0.9616 - val_loss: 1.7437 - val_accuracy: 0.8013\n",
      "Epoch 370/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0928 - accuracy: 0.9634 - val_loss: 1.3816 - val_accuracy: 0.8086\n",
      "Epoch 371/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0951 - accuracy: 0.9607 - val_loss: 1.6505 - val_accuracy: 0.8064\n",
      "Epoch 372/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1227 - accuracy: 0.9526 - val_loss: 1.2375 - val_accuracy: 0.8158\n",
      "Epoch 373/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0904 - accuracy: 0.9632 - val_loss: 1.2774 - val_accuracy: 0.8186\n",
      "Epoch 374/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0947 - accuracy: 0.9612 - val_loss: 1.2771 - val_accuracy: 0.8153\n",
      "Epoch 375/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1206 - accuracy: 0.9517 - val_loss: 1.4764 - val_accuracy: 0.8131\n",
      "Epoch 376/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0908 - accuracy: 0.9671 - val_loss: 0.9360 - val_accuracy: 0.8415\n",
      "Epoch 377/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1003 - accuracy: 0.9630 - val_loss: 1.5504 - val_accuracy: 0.8158\n",
      "Epoch 378/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0840 - accuracy: 0.9667 - val_loss: 1.3620 - val_accuracy: 0.8225\n",
      "Epoch 379/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1078 - accuracy: 0.9584 - val_loss: 1.2555 - val_accuracy: 0.7946\n",
      "Epoch 380/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1042 - accuracy: 0.9581 - val_loss: 1.4776 - val_accuracy: 0.8131\n",
      "Epoch 381/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0911 - accuracy: 0.9634 - val_loss: 1.5472 - val_accuracy: 0.8198\n",
      "Epoch 382/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0951 - accuracy: 0.9634 - val_loss: 1.3354 - val_accuracy: 0.8069\n",
      "Epoch 383/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1353 - accuracy: 0.9512 - val_loss: 1.1311 - val_accuracy: 0.8142\n",
      "Epoch 384/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.0982 - accuracy: 0.9641 - val_loss: 1.3254 - val_accuracy: 0.8326\n",
      "Epoch 385/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0898 - accuracy: 0.9648 - val_loss: 1.3016 - val_accuracy: 0.8181\n",
      "Epoch 386/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0902 - accuracy: 0.9647 - val_loss: 1.5366 - val_accuracy: 0.7991\n",
      "Epoch 387/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0948 - accuracy: 0.9623 - val_loss: 1.4319 - val_accuracy: 0.8097\n",
      "Epoch 388/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0923 - accuracy: 0.9626 - val_loss: 1.7931 - val_accuracy: 0.8086\n",
      "Epoch 389/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1001 - accuracy: 0.9605 - val_loss: 1.5799 - val_accuracy: 0.8047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1026 - accuracy: 0.9583 - val_loss: 1.4220 - val_accuracy: 0.8164\n",
      "Epoch 391/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0800 - accuracy: 0.9660 - val_loss: 1.3612 - val_accuracy: 0.8092\n",
      "Epoch 392/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0977 - accuracy: 0.9604 - val_loss: 1.5398 - val_accuracy: 0.8147\n",
      "Epoch 393/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0964 - accuracy: 0.9614 - val_loss: 1.3340 - val_accuracy: 0.8253\n",
      "Epoch 394/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0946 - accuracy: 0.9612 - val_loss: 1.0771 - val_accuracy: 0.8203\n",
      "Epoch 395/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1012 - accuracy: 0.9633 - val_loss: 1.3571 - val_accuracy: 0.8064\n",
      "Epoch 396/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.0941 - accuracy: 0.9634 - val_loss: 1.5699 - val_accuracy: 0.8142\n",
      "Epoch 397/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1046 - accuracy: 0.9583 - val_loss: 1.6744 - val_accuracy: 0.8225\n",
      "Epoch 398/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0838 - accuracy: 0.9681 - val_loss: 1.2546 - val_accuracy: 0.8125\n",
      "Epoch 399/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.0718 - accuracy: 0.9704 - val_loss: 1.5193 - val_accuracy: 0.8337\n",
      "Epoch 400/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0930 - accuracy: 0.9660 - val_loss: 1.4809 - val_accuracy: 0.8136\n",
      "Epoch 401/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0823 - accuracy: 0.9683 - val_loss: 1.4092 - val_accuracy: 0.8108\n",
      "Epoch 402/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0951 - accuracy: 0.9650 - val_loss: 1.3125 - val_accuracy: 0.8108\n",
      "Epoch 403/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0813 - accuracy: 0.9685 - val_loss: 1.3454 - val_accuracy: 0.8337\n",
      "Epoch 404/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0722 - accuracy: 0.9745 - val_loss: 1.6057 - val_accuracy: 0.7969\n",
      "Epoch 405/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0764 - accuracy: 0.9692 - val_loss: 1.9112 - val_accuracy: 0.8013\n",
      "Epoch 406/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.0777 - accuracy: 0.9703 - val_loss: 1.4223 - val_accuracy: 0.8142\n",
      "Epoch 407/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1103 - accuracy: 0.9598 - val_loss: 1.3965 - val_accuracy: 0.8052\n",
      "Epoch 408/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0781 - accuracy: 0.9692 - val_loss: 1.2337 - val_accuracy: 0.8426\n",
      "Epoch 409/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0909 - accuracy: 0.9653 - val_loss: 1.5794 - val_accuracy: 0.8170\n",
      "Epoch 410/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1529 - accuracy: 0.9346 - val_loss: 1.8909 - val_accuracy: 0.7852\n",
      "Epoch 411/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0806 - accuracy: 0.9725 - val_loss: 1.4999 - val_accuracy: 0.8186\n",
      "Epoch 412/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0686 - accuracy: 0.9743 - val_loss: 1.5460 - val_accuracy: 0.8069\n",
      "Epoch 413/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0754 - accuracy: 0.9688 - val_loss: 1.7348 - val_accuracy: 0.8248\n",
      "Epoch 414/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.1191 - accuracy: 0.9598 - val_loss: 1.2352 - val_accuracy: 0.8142\n",
      "Epoch 415/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0927 - accuracy: 0.9644 - val_loss: 1.8258 - val_accuracy: 0.8064\n",
      "Epoch 416/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0804 - accuracy: 0.9694 - val_loss: 1.5900 - val_accuracy: 0.8170\n",
      "Epoch 417/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0821 - accuracy: 0.9685 - val_loss: 1.6174 - val_accuracy: 0.8119\n",
      "Epoch 418/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0856 - accuracy: 0.9671 - val_loss: 1.5595 - val_accuracy: 0.8058\n",
      "Epoch 419/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0740 - accuracy: 0.9704 - val_loss: 1.2507 - val_accuracy: 0.8170\n",
      "Epoch 420/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0813 - accuracy: 0.9685 - val_loss: 1.4702 - val_accuracy: 0.8231\n",
      "Epoch 421/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0719 - accuracy: 0.9706 - val_loss: 1.5510 - val_accuracy: 0.8125\n",
      "Epoch 422/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0873 - accuracy: 0.9675 - val_loss: 1.6449 - val_accuracy: 0.8052\n",
      "Epoch 423/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0773 - accuracy: 0.9678 - val_loss: 1.4718 - val_accuracy: 0.8298\n",
      "Epoch 424/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0821 - accuracy: 0.9675 - val_loss: 1.6178 - val_accuracy: 0.7924\n",
      "Epoch 425/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0721 - accuracy: 0.9722 - val_loss: 1.3674 - val_accuracy: 0.8326\n",
      "Epoch 426/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0742 - accuracy: 0.9731 - val_loss: 1.5509 - val_accuracy: 0.8259\n",
      "Epoch 427/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0663 - accuracy: 0.9736 - val_loss: 1.4501 - val_accuracy: 0.8125\n",
      "Epoch 428/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1104 - accuracy: 0.9643 - val_loss: 1.5940 - val_accuracy: 0.8186\n",
      "Epoch 429/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0803 - accuracy: 0.9713 - val_loss: 1.5205 - val_accuracy: 0.8331\n",
      "Epoch 430/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.0717 - accuracy: 0.9717 - val_loss: 1.3991 - val_accuracy: 0.8348\n",
      "Epoch 431/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0811 - accuracy: 0.9689 - val_loss: 1.6720 - val_accuracy: 0.8181\n",
      "Epoch 432/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0726 - accuracy: 0.9717 - val_loss: 1.3795 - val_accuracy: 0.8287\n",
      "Epoch 433/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0787 - accuracy: 0.9704 - val_loss: 1.4536 - val_accuracy: 0.8320\n",
      "Epoch 434/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0582 - accuracy: 0.9788 - val_loss: 2.0127 - val_accuracy: 0.8092\n",
      "Epoch 435/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0946 - accuracy: 0.9651 - val_loss: 1.3941 - val_accuracy: 0.8119\n",
      "Epoch 436/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0682 - accuracy: 0.9729 - val_loss: 1.9133 - val_accuracy: 0.8041\n",
      "Epoch 437/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0684 - accuracy: 0.9756 - val_loss: 1.7249 - val_accuracy: 0.8142\n",
      "Epoch 438/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0739 - accuracy: 0.9742 - val_loss: 1.5125 - val_accuracy: 0.8041\n",
      "Epoch 439/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0751 - accuracy: 0.9750 - val_loss: 1.4559 - val_accuracy: 0.8186\n",
      "Epoch 440/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0785 - accuracy: 0.9681 - val_loss: 1.7770 - val_accuracy: 0.8052\n",
      "Epoch 441/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0715 - accuracy: 0.9722 - val_loss: 1.7531 - val_accuracy: 0.7952\n",
      "Epoch 442/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0737 - accuracy: 0.9739 - val_loss: 1.2438 - val_accuracy: 0.8259\n",
      "Epoch 443/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0840 - accuracy: 0.9693 - val_loss: 1.5249 - val_accuracy: 0.8136\n",
      "Epoch 444/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0772 - accuracy: 0.9700 - val_loss: 1.3147 - val_accuracy: 0.8393\n",
      "Epoch 445/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0870 - accuracy: 0.9662 - val_loss: 1.7685 - val_accuracy: 0.8030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0542 - accuracy: 0.9803 - val_loss: 1.6553 - val_accuracy: 0.8147\n",
      "Epoch 447/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0874 - accuracy: 0.9694 - val_loss: 1.6110 - val_accuracy: 0.7919\n",
      "Epoch 448/1200\n",
      "112/112 [==============================] - 5s 40ms/step - loss: 0.0710 - accuracy: 0.9739 - val_loss: 1.6099 - val_accuracy: 0.8008\n",
      "Epoch 449/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0624 - accuracy: 0.9749 - val_loss: 1.6753 - val_accuracy: 0.8142\n",
      "Epoch 450/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0637 - accuracy: 0.9764 - val_loss: 1.8584 - val_accuracy: 0.7840\n",
      "Epoch 451/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0629 - accuracy: 0.9775 - val_loss: 1.7685 - val_accuracy: 0.8142\n",
      "Epoch 452/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0591 - accuracy: 0.9764 - val_loss: 2.1159 - val_accuracy: 0.8203\n",
      "Epoch 453/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0808 - accuracy: 0.9722 - val_loss: 1.6388 - val_accuracy: 0.8209\n",
      "Epoch 454/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0694 - accuracy: 0.9764 - val_loss: 1.7303 - val_accuracy: 0.7701\n",
      "Epoch 455/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0769 - accuracy: 0.9728 - val_loss: 1.6205 - val_accuracy: 0.8153\n",
      "Epoch 456/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0611 - accuracy: 0.9787 - val_loss: 1.6714 - val_accuracy: 0.8281\n",
      "Epoch 457/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0546 - accuracy: 0.9791 - val_loss: 1.4322 - val_accuracy: 0.8242\n",
      "Epoch 458/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0793 - accuracy: 0.9722 - val_loss: 1.8006 - val_accuracy: 0.7963\n",
      "Epoch 459/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0667 - accuracy: 0.9771 - val_loss: 2.2004 - val_accuracy: 0.7796\n",
      "Epoch 460/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0545 - accuracy: 0.9805 - val_loss: 1.7050 - val_accuracy: 0.8136\n",
      "Epoch 461/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0934 - accuracy: 0.9674 - val_loss: 1.3120 - val_accuracy: 0.8186\n",
      "Epoch 462/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0564 - accuracy: 0.9795 - val_loss: 1.5282 - val_accuracy: 0.8058\n",
      "Epoch 463/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0682 - accuracy: 0.9784 - val_loss: 1.4665 - val_accuracy: 0.7974\n",
      "Epoch 464/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0904 - accuracy: 0.9674 - val_loss: 1.4100 - val_accuracy: 0.8220\n",
      "Epoch 465/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0569 - accuracy: 0.9787 - val_loss: 1.7378 - val_accuracy: 0.8002\n",
      "Epoch 466/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0575 - accuracy: 0.9794 - val_loss: 1.3676 - val_accuracy: 0.8225\n",
      "Epoch 467/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0626 - accuracy: 0.9781 - val_loss: 1.8552 - val_accuracy: 0.8064\n",
      "Epoch 468/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1216 - accuracy: 0.9554 - val_loss: 1.6520 - val_accuracy: 0.7640\n",
      "Epoch 469/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1927 - accuracy: 0.9142 - val_loss: 1.6891 - val_accuracy: 0.7913\n",
      "Epoch 470/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1656 - accuracy: 0.9294 - val_loss: 1.4172 - val_accuracy: 0.7963\n",
      "Epoch 471/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1192 - accuracy: 0.9457 - val_loss: 1.6234 - val_accuracy: 0.7907\n",
      "Epoch 472/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0827 - accuracy: 0.9675 - val_loss: 1.7057 - val_accuracy: 0.8080\n",
      "Epoch 473/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0679 - accuracy: 0.9743 - val_loss: 1.6448 - val_accuracy: 0.8075\n",
      "Epoch 474/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0637 - accuracy: 0.9777 - val_loss: 2.3379 - val_accuracy: 0.8002\n",
      "Epoch 475/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0591 - accuracy: 0.9775 - val_loss: 1.7723 - val_accuracy: 0.8052\n",
      "Epoch 476/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.0680 - accuracy: 0.9734 - val_loss: 1.6159 - val_accuracy: 0.8002\n",
      "Epoch 477/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0538 - accuracy: 0.9794 - val_loss: 1.9357 - val_accuracy: 0.8142\n",
      "Epoch 478/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0493 - accuracy: 0.9816 - val_loss: 1.8360 - val_accuracy: 0.8136\n",
      "Epoch 479/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0698 - accuracy: 0.9749 - val_loss: 1.8962 - val_accuracy: 0.8158\n",
      "Epoch 480/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0647 - accuracy: 0.9767 - val_loss: 1.9419 - val_accuracy: 0.8080\n",
      "Epoch 481/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0667 - accuracy: 0.9763 - val_loss: 1.3513 - val_accuracy: 0.8136\n",
      "Epoch 482/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0882 - accuracy: 0.9699 - val_loss: 1.8698 - val_accuracy: 0.8181\n",
      "Epoch 483/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0680 - accuracy: 0.9792 - val_loss: 1.5040 - val_accuracy: 0.8019\n",
      "Epoch 484/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0497 - accuracy: 0.9837 - val_loss: 1.4998 - val_accuracy: 0.8198\n",
      "Epoch 485/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0456 - accuracy: 0.9835 - val_loss: 2.2311 - val_accuracy: 0.7980\n",
      "Epoch 486/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0612 - accuracy: 0.9768 - val_loss: 2.0659 - val_accuracy: 0.8025\n",
      "Epoch 487/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0560 - accuracy: 0.9777 - val_loss: 1.6897 - val_accuracy: 0.8119\n",
      "Epoch 488/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0592 - accuracy: 0.9771 - val_loss: 1.5964 - val_accuracy: 0.8086\n",
      "Epoch 489/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0642 - accuracy: 0.9777 - val_loss: 2.0219 - val_accuracy: 0.7919\n",
      "Epoch 490/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0627 - accuracy: 0.9767 - val_loss: 1.7292 - val_accuracy: 0.8175\n",
      "Epoch 491/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.0462 - accuracy: 0.9844 - val_loss: 1.9941 - val_accuracy: 0.8092\n",
      "Epoch 492/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0969 - accuracy: 0.9718 - val_loss: 2.0282 - val_accuracy: 0.7818\n",
      "Epoch 493/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0687 - accuracy: 0.9742 - val_loss: 1.5551 - val_accuracy: 0.8237\n",
      "Epoch 494/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0477 - accuracy: 0.9809 - val_loss: 1.5916 - val_accuracy: 0.8209\n",
      "Epoch 495/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0572 - accuracy: 0.9785 - val_loss: 2.0375 - val_accuracy: 0.8103\n",
      "Epoch 496/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0458 - accuracy: 0.9845 - val_loss: 1.8863 - val_accuracy: 0.8147\n",
      "Epoch 497/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0583 - accuracy: 0.9780 - val_loss: 1.3611 - val_accuracy: 0.8203\n",
      "Epoch 498/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0832 - accuracy: 0.9690 - val_loss: 1.3997 - val_accuracy: 0.8248\n",
      "Epoch 499/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0505 - accuracy: 0.9809 - val_loss: 1.7188 - val_accuracy: 0.8170\n",
      "Epoch 500/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0664 - accuracy: 0.9764 - val_loss: 1.5208 - val_accuracy: 0.8153\n",
      "Epoch 501/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0703 - accuracy: 0.9750 - val_loss: 1.7029 - val_accuracy: 0.8080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0791 - accuracy: 0.9759 - val_loss: 1.7791 - val_accuracy: 0.8147\n",
      "Epoch 503/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0646 - accuracy: 0.9741 - val_loss: 1.8134 - val_accuracy: 0.8025\n",
      "Epoch 504/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0673 - accuracy: 0.9777 - val_loss: 1.9460 - val_accuracy: 0.8069\n",
      "Epoch 505/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0516 - accuracy: 0.9794 - val_loss: 1.2947 - val_accuracy: 0.8265\n",
      "Epoch 506/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0548 - accuracy: 0.9787 - val_loss: 2.4042 - val_accuracy: 0.8147\n",
      "Epoch 507/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0429 - accuracy: 0.9852 - val_loss: 1.9794 - val_accuracy: 0.8242\n",
      "Epoch 508/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0484 - accuracy: 0.9819 - val_loss: 1.7215 - val_accuracy: 0.8103\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00508: early stopping\n",
      "149/149 [==============================] - 1s 5ms/step\n",
      "     22/Unknown - 0s 5ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799/799 [==============================] - 4s 5ms/step\n",
      "200/200 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|                                         | 1/2 [38:54<38:54, 2334.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.6311 - accuracy: 0.6185 - val_loss: 0.6172 - val_accuracy: 0.6442\n",
      "Epoch 2/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6183 - accuracy: 0.6371 - val_loss: 0.6248 - val_accuracy: 0.6435\n",
      "Epoch 3/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6175 - accuracy: 0.6199 - val_loss: 0.6492 - val_accuracy: 0.5732\n",
      "Epoch 4/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6132 - accuracy: 0.6334 - val_loss: 0.6492 - val_accuracy: 0.6136\n",
      "Epoch 5/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6164 - accuracy: 0.6246 - val_loss: 0.6558 - val_accuracy: 0.5831\n",
      "Epoch 6/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6079 - accuracy: 0.6399 - val_loss: 0.6228 - val_accuracy: 0.6207\n",
      "Epoch 7/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6045 - accuracy: 0.6369 - val_loss: 0.6594 - val_accuracy: 0.5959\n",
      "Epoch 8/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5997 - accuracy: 0.6417 - val_loss: 0.6302 - val_accuracy: 0.6378\n",
      "Epoch 9/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6014 - accuracy: 0.6406 - val_loss: 0.6770 - val_accuracy: 0.5732\n",
      "Epoch 10/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5968 - accuracy: 0.6462 - val_loss: 0.6827 - val_accuracy: 0.5938\n",
      "Epoch 11/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5881 - accuracy: 0.6469 - val_loss: 0.6604 - val_accuracy: 0.6136\n",
      "Epoch 12/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5910 - accuracy: 0.6455 - val_loss: 0.6628 - val_accuracy: 0.6243\n",
      "Epoch 13/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5865 - accuracy: 0.6433 - val_loss: 0.6749 - val_accuracy: 0.6229\n",
      "Epoch 14/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5955 - accuracy: 0.6403 - val_loss: 0.6713 - val_accuracy: 0.5852\n",
      "Epoch 15/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5892 - accuracy: 0.6427 - val_loss: 0.6806 - val_accuracy: 0.5781\n",
      "Epoch 16/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5965 - accuracy: 0.6433 - val_loss: 0.6976 - val_accuracy: 0.5923\n",
      "Epoch 17/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5862 - accuracy: 0.6505 - val_loss: 0.6808 - val_accuracy: 0.5696\n",
      "Epoch 18/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5967 - accuracy: 0.6450 - val_loss: 0.7010 - val_accuracy: 0.5859\n",
      "Epoch 19/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5766 - accuracy: 0.6531 - val_loss: 0.7305 - val_accuracy: 0.5632\n",
      "Epoch 20/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5985 - accuracy: 0.6382 - val_loss: 0.7262 - val_accuracy: 0.5398\n",
      "Epoch 21/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5787 - accuracy: 0.6663 - val_loss: 0.7102 - val_accuracy: 0.5476\n",
      "Epoch 22/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5826 - accuracy: 0.6494 - val_loss: 0.7471 - val_accuracy: 0.5682\n",
      "Epoch 23/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5742 - accuracy: 0.6552 - val_loss: 0.7509 - val_accuracy: 0.5511\n",
      "Epoch 24/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5764 - accuracy: 0.6684 - val_loss: 0.6540 - val_accuracy: 0.6193\n",
      "Epoch 25/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5783 - accuracy: 0.6468 - val_loss: 0.6887 - val_accuracy: 0.5881\n",
      "Epoch 26/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5872 - accuracy: 0.6454 - val_loss: 0.6768 - val_accuracy: 0.6264\n",
      "Epoch 27/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5688 - accuracy: 0.6619 - val_loss: 0.7867 - val_accuracy: 0.5838\n",
      "Epoch 28/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5825 - accuracy: 0.6503 - val_loss: 0.7266 - val_accuracy: 0.5362\n",
      "Epoch 29/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5729 - accuracy: 0.6757 - val_loss: 0.7204 - val_accuracy: 0.5760\n",
      "Epoch 30/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5759 - accuracy: 0.6668 - val_loss: 0.7416 - val_accuracy: 0.5455\n",
      "Epoch 31/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5813 - accuracy: 0.6598 - val_loss: 0.7274 - val_accuracy: 0.5817\n",
      "Epoch 32/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5659 - accuracy: 0.6649 - val_loss: 0.7539 - val_accuracy: 0.5817\n",
      "Epoch 33/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5683 - accuracy: 0.6654 - val_loss: 0.6928 - val_accuracy: 0.6051\n",
      "Epoch 34/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5586 - accuracy: 0.6706 - val_loss: 0.6472 - val_accuracy: 0.6385\n",
      "Epoch 35/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5735 - accuracy: 0.6626 - val_loss: 0.7643 - val_accuracy: 0.6030\n",
      "Epoch 36/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5657 - accuracy: 0.6721 - val_loss: 0.7190 - val_accuracy: 0.5902\n",
      "Epoch 37/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5567 - accuracy: 0.6835 - val_loss: 0.8732 - val_accuracy: 0.5589A: \n",
      "Epoch 38/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5767 - accuracy: 0.6680 - val_loss: 0.7113 - val_accuracy: 0.6271\n",
      "Epoch 39/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5597 - accuracy: 0.6759 - val_loss: 0.7068 - val_accuracy: 0.6335\n",
      "Epoch 40/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5558 - accuracy: 0.6792 - val_loss: 0.8146 - val_accuracy: 0.5582\n",
      "Epoch 41/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5546 - accuracy: 0.6715 - val_loss: 0.7017 - val_accuracy: 0.6428\n",
      "Epoch 42/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5554 - accuracy: 0.6870 - val_loss: 0.8159 - val_accuracy: 0.5589\n",
      "Epoch 43/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5551 - accuracy: 0.6901 - val_loss: 0.7746 - val_accuracy: 0.6143\n",
      "Epoch 44/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5484 - accuracy: 0.6905 - val_loss: 0.8157 - val_accuracy: 0.5760\n",
      "Epoch 45/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5535 - accuracy: 0.6829 - val_loss: 0.6939 - val_accuracy: 0.6499\n",
      "Epoch 46/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5544 - accuracy: 0.6833 - val_loss: 0.6919 - val_accuracy: 0.6307\n",
      "Epoch 47/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5600 - accuracy: 0.6745 - val_loss: 0.8352 - val_accuracy: 0.6044\n",
      "Epoch 48/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5528 - accuracy: 0.6922 - val_loss: 0.7087 - val_accuracy: 0.6023\n",
      "Epoch 49/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5546 - accuracy: 0.6849 - val_loss: 0.7089 - val_accuracy: 0.6278\n",
      "Epoch 50/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5499 - accuracy: 0.6933 - val_loss: 0.6669 - val_accuracy: 0.6967\n",
      "Epoch 51/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5534 - accuracy: 0.6877 - val_loss: 0.7195 - val_accuracy: 0.6520\n",
      "Epoch 52/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5414 - accuracy: 0.6973 - val_loss: 0.7027 - val_accuracy: 0.6271\n",
      "Epoch 53/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5446 - accuracy: 0.6959 - val_loss: 0.7027 - val_accuracy: 0.6470\n",
      "Epoch 54/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5509 - accuracy: 0.6931 - val_loss: 0.7338 - val_accuracy: 0.6534\n",
      "Epoch 55/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5316 - accuracy: 0.6993 - val_loss: 0.8615 - val_accuracy: 0.5810\n",
      "Epoch 56/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5372 - accuracy: 0.6940 - val_loss: 0.8004 - val_accuracy: 0.5952\n",
      "Epoch 57/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5219 - accuracy: 0.7110 - val_loss: 0.6784 - val_accuracy: 0.6719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5250 - accuracy: 0.7070 - val_loss: 0.8634 - val_accuracy: 0.5987\n",
      "Epoch 59/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5224 - accuracy: 0.7029 - val_loss: 0.8104 - val_accuracy: 0.6200\n",
      "Epoch 60/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5472 - accuracy: 0.6933 - val_loss: 0.7598 - val_accuracy: 0.5895\n",
      "Epoch 61/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5161 - accuracy: 0.7138 - val_loss: 0.6668 - val_accuracy: 0.6570\n",
      "Epoch 62/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5304 - accuracy: 0.6921 - val_loss: 0.6711 - val_accuracy: 0.6911\n",
      "Epoch 63/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5397 - accuracy: 0.6914 - val_loss: 0.7993 - val_accuracy: 0.6200\n",
      "Epoch 64/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5216 - accuracy: 0.7068 - val_loss: 0.8519 - val_accuracy: 0.6264\n",
      "Epoch 65/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5159 - accuracy: 0.7158 - val_loss: 0.6762 - val_accuracy: 0.6562\n",
      "Epoch 66/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5282 - accuracy: 0.6972 - val_loss: 0.7089 - val_accuracy: 0.6243\n",
      "Epoch 67/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5131 - accuracy: 0.7084 - val_loss: 0.8592 - val_accuracy: 0.6087\n",
      "Epoch 68/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5292 - accuracy: 0.7010 - val_loss: 0.7869 - val_accuracy: 0.6165\n",
      "Epoch 69/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5137 - accuracy: 0.7130 - val_loss: 0.8168 - val_accuracy: 0.6058\n",
      "Epoch 70/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5123 - accuracy: 0.7214 - val_loss: 0.7283 - val_accuracy: 0.6676\n",
      "Epoch 71/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.5020 - accuracy: 0.7214 - val_loss: 0.6954 - val_accuracy: 0.6577\n",
      "Epoch 72/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5162 - accuracy: 0.7112 - val_loss: 0.7941 - val_accuracy: 0.6413- los\n",
      "Epoch 73/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4893 - accuracy: 0.7286 - val_loss: 0.7903 - val_accuracy: 0.6278\n",
      "Epoch 74/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5063 - accuracy: 0.7233 - val_loss: 0.8039 - val_accuracy: 0.6364\n",
      "Epoch 75/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4992 - accuracy: 0.7259 - val_loss: 0.8432 - val_accuracy: 0.6122\n",
      "Epoch 76/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5088 - accuracy: 0.7135 - val_loss: 0.6337 - val_accuracy: 0.6797\n",
      "Epoch 77/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5040 - accuracy: 0.7288 - val_loss: 0.8541 - val_accuracy: 0.6584\n",
      "Epoch 78/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4870 - accuracy: 0.7361 - val_loss: 0.8061 - val_accuracy: 0.6371\n",
      "Epoch 79/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4949 - accuracy: 0.7300 - val_loss: 0.8404 - val_accuracy: 0.6115\n",
      "Epoch 80/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5016 - accuracy: 0.7289 - val_loss: 0.9180 - val_accuracy: 0.6165\n",
      "Epoch 81/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5108 - accuracy: 0.7108 - val_loss: 0.7721 - val_accuracy: 0.6349\n",
      "Epoch 82/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4867 - accuracy: 0.7272 - val_loss: 0.7439 - val_accuracy: 0.6641\n",
      "Epoch 83/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4945 - accuracy: 0.7295 - val_loss: 0.7141 - val_accuracy: 0.6328\n",
      "Epoch 84/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.4871 - accuracy: 0.7263 - val_loss: 0.8725 - val_accuracy: 0.5973\n",
      "Epoch 85/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4775 - accuracy: 0.7456 - val_loss: 0.8961 - val_accuracy: 0.5795\n",
      "Epoch 86/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4829 - accuracy: 0.7379 - val_loss: 0.9752 - val_accuracy: 0.5533\n",
      "Epoch 87/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.4919 - accuracy: 0.7338 - val_loss: 0.9142 - val_accuracy: 0.5895\n",
      "Epoch 88/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.4687 - accuracy: 0.7456 - val_loss: 0.9114 - val_accuracy: 0.6264\n",
      "Epoch 89/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4631 - accuracy: 0.7463 - val_loss: 0.9567 - val_accuracy: 0.5810\n",
      "Epoch 90/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.4972 - accuracy: 0.7240 - val_loss: 0.8575 - val_accuracy: 0.6200\n",
      "Epoch 91/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.4733 - accuracy: 0.7351 - val_loss: 0.9001 - val_accuracy: 0.6136\n",
      "Epoch 92/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4866 - accuracy: 0.7245 - val_loss: 0.8030 - val_accuracy: 0.6108\n",
      "Epoch 93/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4705 - accuracy: 0.7386 - val_loss: 0.7197 - val_accuracy: 0.6562\n",
      "Epoch 94/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4654 - accuracy: 0.7386 - val_loss: 0.8441 - val_accuracy: 0.6349\n",
      "Epoch 95/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4769 - accuracy: 0.7444 - val_loss: 0.9137 - val_accuracy: 0.6364\n",
      "Epoch 96/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4597 - accuracy: 0.7612 - val_loss: 0.8582 - val_accuracy: 0.6286\n",
      "Epoch 97/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4611 - accuracy: 0.7511 - val_loss: 0.8374 - val_accuracy: 0.6399\n",
      "Epoch 98/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4751 - accuracy: 0.7423 - val_loss: 0.7932 - val_accuracy: 0.6506\n",
      "Epoch 99/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4488 - accuracy: 0.7489 - val_loss: 0.9292 - val_accuracy: 0.5966\n",
      "Epoch 100/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4840 - accuracy: 0.7323 - val_loss: 0.9321 - val_accuracy: 0.6165\n",
      "Epoch 101/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4588 - accuracy: 0.7467 - val_loss: 0.7689 - val_accuracy: 0.6435\n",
      "Epoch 102/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4345 - accuracy: 0.7658 - val_loss: 0.9800 - val_accuracy: 0.6499\n",
      "Epoch 103/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4402 - accuracy: 0.7670 - val_loss: 0.9847 - val_accuracy: 0.5476\n",
      "Epoch 104/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4763 - accuracy: 0.7488 - val_loss: 0.8350 - val_accuracy: 0.6222\n",
      "Epoch 105/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4273 - accuracy: 0.7760 - val_loss: 0.9420 - val_accuracy: 0.6612\n",
      "Epoch 106/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4537 - accuracy: 0.7563 - val_loss: 0.8021 - val_accuracy: 0.6847\n",
      "Epoch 107/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4393 - accuracy: 0.7676 - val_loss: 0.9017 - val_accuracy: 0.6236\n",
      "Epoch 108/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4278 - accuracy: 0.7711 - val_loss: 0.9137 - val_accuracy: 0.6491\n",
      "Epoch 109/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4152 - accuracy: 0.7830 - val_loss: 1.0304 - val_accuracy: 0.6108\n",
      "Epoch 110/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.4312 - accuracy: 0.7726 - val_loss: 0.9391 - val_accuracy: 0.6101\n",
      "Epoch 111/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4196 - accuracy: 0.7725 - val_loss: 0.9946 - val_accuracy: 0.6364\n",
      "Epoch 112/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4281 - accuracy: 0.7781 - val_loss: 0.8455 - val_accuracy: 0.6527\n",
      "Epoch 113/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.4092 - accuracy: 0.7870 - val_loss: 1.0187 - val_accuracy: 0.6335\n",
      "Epoch 114/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4367 - accuracy: 0.7658 - val_loss: 1.0217 - val_accuracy: 0.6534\n",
      "Epoch 115/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4119 - accuracy: 0.7790 - val_loss: 0.9815 - val_accuracy: 0.6200\n",
      "Epoch 116/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4268 - accuracy: 0.7788 - val_loss: 0.9650 - val_accuracy: 0.6513\n",
      "Epoch 117/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4087 - accuracy: 0.7821 - val_loss: 0.9518 - val_accuracy: 0.6555\n",
      "Epoch 118/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4350 - accuracy: 0.7763 - val_loss: 0.9885 - val_accuracy: 0.6214\n",
      "Epoch 119/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4225 - accuracy: 0.7744 - val_loss: 0.9335 - val_accuracy: 0.6655\n",
      "Epoch 120/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4066 - accuracy: 0.7798 - val_loss: 0.9523 - val_accuracy: 0.6328\n",
      "Epoch 121/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4056 - accuracy: 0.7807 - val_loss: 1.0309 - val_accuracy: 0.6477\n",
      "Epoch 122/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4129 - accuracy: 0.7821 - val_loss: 0.9023 - val_accuracy: 0.6712\n",
      "Epoch 123/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3997 - accuracy: 0.7941 - val_loss: 1.0842 - val_accuracy: 0.6143\n",
      "Epoch 124/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4122 - accuracy: 0.7832 - val_loss: 1.0630 - val_accuracy: 0.6463\n",
      "Epoch 125/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4142 - accuracy: 0.7858 - val_loss: 1.0481 - val_accuracy: 0.6477\n",
      "Epoch 126/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3957 - accuracy: 0.7955 - val_loss: 1.0712 - val_accuracy: 0.6286\n",
      "Epoch 127/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3824 - accuracy: 0.7983 - val_loss: 1.1134 - val_accuracy: 0.6570\n",
      "Epoch 128/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.3967 - accuracy: 0.7907 - val_loss: 0.9554 - val_accuracy: 0.6733\n",
      "Epoch 129/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.3809 - accuracy: 0.8023 - val_loss: 1.0450 - val_accuracy: 0.6491\n",
      "Epoch 130/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4068 - accuracy: 0.7816 - val_loss: 0.9424 - val_accuracy: 0.6506\n",
      "Epoch 131/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3895 - accuracy: 0.7995 - val_loss: 1.1164 - val_accuracy: 0.6641\n",
      "Epoch 132/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4071 - accuracy: 0.7855 - val_loss: 0.9689 - val_accuracy: 0.6854\n",
      "Epoch 133/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3750 - accuracy: 0.8106 - val_loss: 1.3321 - val_accuracy: 0.6257\n",
      "Epoch 134/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3744 - accuracy: 0.8027 - val_loss: 0.9411 - val_accuracy: 0.6499\n",
      "Epoch 135/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.3666 - accuracy: 0.8113 - val_loss: 1.0812 - val_accuracy: 0.6484\n",
      "Epoch 136/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3944 - accuracy: 0.7886 - val_loss: 1.1303 - val_accuracy: 0.6321\n",
      "Epoch 137/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3787 - accuracy: 0.8116 - val_loss: 0.8444 - val_accuracy: 0.6236\n",
      "Epoch 138/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.3690 - accuracy: 0.8148 - val_loss: 1.1479 - val_accuracy: 0.6548\n",
      "Epoch 139/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3506 - accuracy: 0.8241 - val_loss: 1.1428 - val_accuracy: 0.6712\n",
      "Epoch 140/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3607 - accuracy: 0.8136 - val_loss: 1.1077 - val_accuracy: 0.6271\n",
      "Epoch 141/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.3467 - accuracy: 0.8218 - val_loss: 1.1137 - val_accuracy: 0.6534\n",
      "Epoch 142/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4263 - accuracy: 0.7823 - val_loss: 0.8846 - val_accuracy: 0.6875\n",
      "Epoch 143/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3819 - accuracy: 0.8009 - val_loss: 1.0410 - val_accuracy: 0.6761\n",
      "Epoch 144/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.3805 - accuracy: 0.7944 - val_loss: 0.9405 - val_accuracy: 0.6733\n",
      "Epoch 145/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.3637 - accuracy: 0.8062 - val_loss: 1.2774 - val_accuracy: 0.6257 1s - loss: 0.3788 - accura - ETA: 1s - loss: - ETA: 0s - loss: 0.3678 - \n",
      "Epoch 146/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3519 - accuracy: 0.8255 - val_loss: 1.1343 - val_accuracy: 0.6648\n",
      "Epoch 147/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3644 - accuracy: 0.8183 - val_loss: 1.2842 - val_accuracy: 0.6577\n",
      "Epoch 148/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.3556 - accuracy: 0.8185 - val_loss: 1.0995 - val_accuracy: 0.6449\n",
      "Epoch 149/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3350 - accuracy: 0.8297 - val_loss: 1.4671 - val_accuracy: 0.6548\n",
      "Epoch 150/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3610 - accuracy: 0.8085 - val_loss: 1.2920 - val_accuracy: 0.6548\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00150: early stopping\n",
      "149/149 [==============================] - 1s 5ms/step\n",
      "     23/Unknown - 0s 5ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639/639 [==============================] - 3s 5ms/step\n",
      "160/160 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [48:07<00:00, 1443.66s/it]\u001b[A\n",
      "  2%|                                                                          | 2/90 [2:00:54<85:28:20, 3496.59s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "112/112 [==============================] - 6s 44ms/step - loss: 0.6329 - accuracy: 0.6289 - val_loss: 0.6924 - val_accuracy: 0.5285\n",
      "Epoch 2/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6327 - accuracy: 0.6302 - val_loss: 0.6864 - val_accuracy: 0.5753\n",
      "Epoch 3/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6288 - accuracy: 0.6288 - val_loss: 0.6504 - val_accuracy: 0.5938\n",
      "Epoch 4/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6285 - accuracy: 0.6324 - val_loss: 0.6340 - val_accuracy: 0.5977\n",
      "Epoch 5/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6223 - accuracy: 0.6436 - val_loss: 0.6203 - val_accuracy: 0.6462\n",
      "Epoch 6/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6272 - accuracy: 0.6342 - val_loss: 0.6528 - val_accuracy: 0.6177\n",
      "Epoch 7/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6271 - accuracy: 0.6387 - val_loss: 0.6317 - val_accuracy: 0.6445\n",
      "Epoch 8/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6185 - accuracy: 0.6427 - val_loss: 0.6349 - val_accuracy: 0.6267\n",
      "Epoch 9/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6158 - accuracy: 0.6383 - val_loss: 0.6537 - val_accuracy: 0.5820\n",
      "Epoch 10/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6147 - accuracy: 0.6445 - val_loss: 0.6779 - val_accuracy: 0.5843\n",
      "Epoch 11/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.6157 - accuracy: 0.6486 - val_loss: 0.6501 - val_accuracy: 0.6177\n",
      "Epoch 12/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6075 - accuracy: 0.6415 - val_loss: 0.6525 - val_accuracy: 0.6066\n",
      "Epoch 13/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6146 - accuracy: 0.6359 - val_loss: 0.6194 - val_accuracy: 0.6657\n",
      "Epoch 14/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6117 - accuracy: 0.6430 - val_loss: 0.6370 - val_accuracy: 0.6272\n",
      "Epoch 15/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6081 - accuracy: 0.6408 - val_loss: 0.6396 - val_accuracy: 0.6311\n",
      "Epoch 16/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6105 - accuracy: 0.6542 - val_loss: 0.6346 - val_accuracy: 0.6373ccura\n",
      "Epoch 17/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6082 - accuracy: 0.6515 - val_loss: 0.6156 - val_accuracy: 0.6752\n",
      "Epoch 18/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5986 - accuracy: 0.6558 - val_loss: 0.6478 - val_accuracy: 0.6323\n",
      "Epoch 19/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.6008 - accuracy: 0.6433 - val_loss: 0.6287 - val_accuracy: 0.6535\n",
      "Epoch 20/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6105 - accuracy: 0.6406 - val_loss: 0.6445 - val_accuracy: 0.6618\n",
      "Epoch 21/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5957 - accuracy: 0.6503 - val_loss: 0.6656 - val_accuracy: 0.6384\n",
      "Epoch 22/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.6044 - accuracy: 0.6509 - val_loss: 0.6672 - val_accuracy: 0.6194\n",
      "Epoch 23/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5931 - accuracy: 0.6606 - val_loss: 0.7012 - val_accuracy: 0.5938\n",
      "Epoch 24/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5955 - accuracy: 0.6629 - val_loss: 0.6779 - val_accuracy: 0.6127\n",
      "Epoch 25/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5924 - accuracy: 0.6564 - val_loss: 0.6621 - val_accuracy: 0.6412\n",
      "Epoch 26/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.5905 - accuracy: 0.6543 - val_loss: 0.6389 - val_accuracy: 0.6317\n",
      "Epoch 27/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5972 - accuracy: 0.6596 - val_loss: 0.6471 - val_accuracy: 0.6367\n",
      "Epoch 28/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5850 - accuracy: 0.6649 - val_loss: 0.7443 - val_accuracy: 0.5586\n",
      "Epoch 29/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5903 - accuracy: 0.6603 - val_loss: 0.6639 - val_accuracy: 0.6456\n",
      "Epoch 30/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5846 - accuracy: 0.6689 - val_loss: 0.6456 - val_accuracy: 0.6445\n",
      "Epoch 31/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5898 - accuracy: 0.6676 - val_loss: 0.6671 - val_accuracy: 0.6083\n",
      "Epoch 32/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5700 - accuracy: 0.6749 - val_loss: 0.6572 - val_accuracy: 0.6641\n",
      "Epoch 33/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5843 - accuracy: 0.6620 - val_loss: 0.6839 - val_accuracy: 0.6222\n",
      "Epoch 34/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5681 - accuracy: 0.6839 - val_loss: 0.6513 - val_accuracy: 0.6551\n",
      "Epoch 35/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5860 - accuracy: 0.6684 - val_loss: 0.6600 - val_accuracy: 0.6501\n",
      "Epoch 36/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5667 - accuracy: 0.6828 - val_loss: 0.6459 - val_accuracy: 0.6635\n",
      "Epoch 37/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5715 - accuracy: 0.6684 - val_loss: 0.6414 - val_accuracy: 0.6233\n",
      "Epoch 38/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5859 - accuracy: 0.6741 - val_loss: 0.6410 - val_accuracy: 0.6568\n",
      "Epoch 39/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5785 - accuracy: 0.6696 - val_loss: 0.6693 - val_accuracy: 0.6473\n",
      "Epoch 40/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5732 - accuracy: 0.6759 - val_loss: 0.6340 - val_accuracy: 0.6730\n",
      "Epoch 41/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.5570 - accuracy: 0.6883 - val_loss: 0.6310 - val_accuracy: 0.6791\n",
      "Epoch 42/1200\n",
      "112/112 [==============================] - 5s 40ms/step - loss: 0.5759 - accuracy: 0.6742 - val_loss: 0.6968 - val_accuracy: 0.6384\n",
      "Epoch 43/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5747 - accuracy: 0.6821 - val_loss: 0.6602 - val_accuracy: 0.6205\n",
      "Epoch 44/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5650 - accuracy: 0.6874 - val_loss: 0.6783 - val_accuracy: 0.6278\n",
      "Epoch 45/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5737 - accuracy: 0.6749 - val_loss: 0.6470 - val_accuracy: 0.6484\n",
      "Epoch 46/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5604 - accuracy: 0.6886 - val_loss: 0.6759 - val_accuracy: 0.6473\n",
      "Epoch 47/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5640 - accuracy: 0.6927 - val_loss: 0.6642 - val_accuracy: 0.6479\n",
      "Epoch 48/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5487 - accuracy: 0.6982 - val_loss: 0.6772 - val_accuracy: 0.6412\n",
      "Epoch 49/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5594 - accuracy: 0.6936 - val_loss: 0.6764 - val_accuracy: 0.6228\n",
      "Epoch 50/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5566 - accuracy: 0.6874 - val_loss: 0.6548 - val_accuracy: 0.6339\n",
      "Epoch 51/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5586 - accuracy: 0.6885 - val_loss: 0.6950 - val_accuracy: 0.6066\n",
      "Epoch 52/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5482 - accuracy: 0.7044 - val_loss: 0.6953 - val_accuracy: 0.6105\n",
      "Epoch 53/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5587 - accuracy: 0.6915 - val_loss: 0.6739 - val_accuracy: 0.6267\n",
      "Epoch 54/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5555 - accuracy: 0.6952 - val_loss: 0.6649 - val_accuracy: 0.6529\n",
      "Epoch 55/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5468 - accuracy: 0.6946 - val_loss: 0.6713 - val_accuracy: 0.6540\n",
      "Epoch 56/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5448 - accuracy: 0.7058 - val_loss: 0.6156 - val_accuracy: 0.6775\n",
      "Epoch 57/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.5415 - accuracy: 0.7044 - val_loss: 0.6833 - val_accuracy: 0.6267 ac\n",
      "Epoch 58/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5517 - accuracy: 0.6858 - val_loss: 0.6559 - val_accuracy: 0.6440\n",
      "Epoch 59/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5405 - accuracy: 0.7091 - val_loss: 0.6054 - val_accuracy: 0.6775\n",
      "Epoch 60/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5469 - accuracy: 0.7001 - val_loss: 0.6706 - val_accuracy: 0.6155\n",
      "Epoch 61/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5320 - accuracy: 0.7112 - val_loss: 0.6488 - val_accuracy: 0.6490\n",
      "Epoch 62/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5407 - accuracy: 0.7101 - val_loss: 0.6211 - val_accuracy: 0.6780\n",
      "Epoch 63/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5261 - accuracy: 0.7144 - val_loss: 0.5998 - val_accuracy: 0.6685\n",
      "Epoch 64/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5283 - accuracy: 0.7190 - val_loss: 0.6633 - val_accuracy: 0.6451\n",
      "Epoch 65/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5309 - accuracy: 0.7179 - val_loss: 0.6370 - val_accuracy: 0.6434loss: 0.5303 \n",
      "Epoch 66/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5224 - accuracy: 0.7197 - val_loss: 0.6907 - val_accuracy: 0.6261\n",
      "Epoch 67/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5196 - accuracy: 0.7199 - val_loss: 0.6855 - val_accuracy: 0.6585\n",
      "Epoch 68/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5341 - accuracy: 0.7215 - val_loss: 0.6078 - val_accuracy: 0.6903\n",
      "Epoch 69/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5257 - accuracy: 0.7126 - val_loss: 0.6802 - val_accuracy: 0.6501\n",
      "Epoch 70/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5245 - accuracy: 0.7225 - val_loss: 0.7042 - val_accuracy: 0.6239\n",
      "Epoch 71/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5310 - accuracy: 0.7015 - val_loss: 0.6148 - val_accuracy: 0.6473- ETA: 0s - loss: 0.5321 - accuracy: \n",
      "Epoch 72/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5262 - accuracy: 0.7040 - val_loss: 0.6842 - val_accuracy: 0.6228\n",
      "Epoch 73/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5169 - accuracy: 0.7176 - val_loss: 0.6830 - val_accuracy: 0.6635\n",
      "Epoch 74/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5139 - accuracy: 0.7114 - val_loss: 0.6885 - val_accuracy: 0.6585\n",
      "Epoch 75/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5137 - accuracy: 0.7174 - val_loss: 0.5776 - val_accuracy: 0.6551\n",
      "Epoch 76/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5408 - accuracy: 0.7024 - val_loss: 0.5699 - val_accuracy: 0.7037\n",
      "Epoch 77/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5288 - accuracy: 0.7100 - val_loss: 0.5592 - val_accuracy: 0.6925\n",
      "Epoch 78/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5222 - accuracy: 0.7119 - val_loss: 0.6095 - val_accuracy: 0.6691\n",
      "Epoch 79/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5256 - accuracy: 0.7167 - val_loss: 0.5986 - val_accuracy: 0.6948\n",
      "Epoch 80/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5241 - accuracy: 0.7193 - val_loss: 0.6371 - val_accuracy: 0.6362\n",
      "Epoch 81/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5185 - accuracy: 0.7275 - val_loss: 0.5734 - val_accuracy: 0.6881\n",
      "Epoch 82/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5100 - accuracy: 0.7326 - val_loss: 0.5950 - val_accuracy: 0.6875\n",
      "Epoch 83/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5210 - accuracy: 0.7232 - val_loss: 0.6063 - val_accuracy: 0.6529\n",
      "Epoch 84/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5193 - accuracy: 0.7196 - val_loss: 0.6031 - val_accuracy: 0.6456\n",
      "Epoch 85/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5102 - accuracy: 0.7231 - val_loss: 0.5923 - val_accuracy: 0.6936\n",
      "Epoch 86/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4970 - accuracy: 0.7274 - val_loss: 0.6745 - val_accuracy: 0.6055\n",
      "Epoch 87/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.5024 - accuracy: 0.7314 - val_loss: 0.6730 - val_accuracy: 0.6300\n",
      "Epoch 88/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5139 - accuracy: 0.7143 - val_loss: 0.6286 - val_accuracy: 0.6456\n",
      "Epoch 89/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4911 - accuracy: 0.7344 - val_loss: 0.6039 - val_accuracy: 0.6719 - accuracy: 0.\n",
      "Epoch 90/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4978 - accuracy: 0.7260 - val_loss: 0.6461 - val_accuracy: 0.6641\n",
      "Epoch 91/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4778 - accuracy: 0.7412 - val_loss: 0.6907 - val_accuracy: 0.6261\n",
      "Epoch 92/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4839 - accuracy: 0.7334 - val_loss: 0.6272 - val_accuracy: 0.6830\n",
      "Epoch 93/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4986 - accuracy: 0.7252 - val_loss: 0.6823 - val_accuracy: 0.6551\n",
      "Epoch 94/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.5892 - accuracy: 0.6579 - val_loss: 0.6829 - val_accuracy: 0.6066\n",
      "Epoch 95/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.5035 - accuracy: 0.7249 - val_loss: 0.6225 - val_accuracy: 0.6635\n",
      "Epoch 96/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4708 - accuracy: 0.7426 - val_loss: 0.6872 - val_accuracy: 0.6551\n",
      "Epoch 97/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4823 - accuracy: 0.7366 - val_loss: 0.6987 - val_accuracy: 0.6440\n",
      "Epoch 98/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4720 - accuracy: 0.7458 - val_loss: 0.6412 - val_accuracy: 0.6741\n",
      "Epoch 99/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4812 - accuracy: 0.7380 - val_loss: 0.6517 - val_accuracy: 0.7104\n",
      "Epoch 100/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4709 - accuracy: 0.7436 - val_loss: 0.7615 - val_accuracy: 0.6624\n",
      "Epoch 101/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4739 - accuracy: 0.7436 - val_loss: 0.6476 - val_accuracy: 0.7026\n",
      "Epoch 102/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.4709 - accuracy: 0.7513 - val_loss: 0.8224 - val_accuracy: 0.5709\n",
      "Epoch 103/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4788 - accuracy: 0.7402 - val_loss: 0.7785 - val_accuracy: 0.6295\n",
      "Epoch 104/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4718 - accuracy: 0.7448 - val_loss: 0.6434 - val_accuracy: 0.6719\n",
      "Epoch 105/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4582 - accuracy: 0.7602 - val_loss: 0.7253 - val_accuracy: 0.6708\n",
      "Epoch 106/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4576 - accuracy: 0.7545 - val_loss: 0.6723 - val_accuracy: 0.6596\n",
      "Epoch 107/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4459 - accuracy: 0.7564 - val_loss: 0.6520 - val_accuracy: 0.6903\n",
      "Epoch 108/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4519 - accuracy: 0.7571 - val_loss: 0.6314 - val_accuracy: 0.7109\n",
      "Epoch 109/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4608 - accuracy: 0.7549 - val_loss: 0.6229 - val_accuracy: 0.6830\n",
      "Epoch 110/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4521 - accuracy: 0.7610 - val_loss: 0.7441 - val_accuracy: 0.6786\n",
      "Epoch 111/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4450 - accuracy: 0.7613 - val_loss: 0.7038 - val_accuracy: 0.6847\n",
      "Epoch 112/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4297 - accuracy: 0.7673 - val_loss: 0.7091 - val_accuracy: 0.6842\n",
      "Epoch 113/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4323 - accuracy: 0.7659 - val_loss: 0.6423 - val_accuracy: 0.7003\n",
      "Epoch 114/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4498 - accuracy: 0.7593 - val_loss: 0.7010 - val_accuracy: 0.6529\n",
      "Epoch 115/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4341 - accuracy: 0.7670 - val_loss: 0.6376 - val_accuracy: 0.7042\n",
      "Epoch 116/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4344 - accuracy: 0.7753 - val_loss: 0.6539 - val_accuracy: 0.6741\n",
      "Epoch 117/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4364 - accuracy: 0.7775 - val_loss: 0.7449 - val_accuracy: 0.6724\n",
      "Epoch 118/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.4287 - accuracy: 0.7683 - val_loss: 0.6974 - val_accuracy: 0.6959\n",
      "Epoch 119/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4304 - accuracy: 0.7697 - val_loss: 0.6924 - val_accuracy: 0.6842\n",
      "Epoch 120/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4336 - accuracy: 0.7709 - val_loss: 0.6657 - val_accuracy: 0.6797\n",
      "Epoch 121/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4202 - accuracy: 0.7801 - val_loss: 0.7389 - val_accuracy: 0.6579\n",
      "Epoch 122/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4208 - accuracy: 0.7782 - val_loss: 0.6533 - val_accuracy: 0.7037\n",
      "Epoch 123/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4405 - accuracy: 0.7669 - val_loss: 0.6097 - val_accuracy: 0.7137\n",
      "Epoch 124/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4101 - accuracy: 0.7849 - val_loss: 0.6689 - val_accuracy: 0.7009\n",
      "Epoch 125/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.4302 - accuracy: 0.7725 - val_loss: 0.6735 - val_accuracy: 0.7132\n",
      "Epoch 126/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4052 - accuracy: 0.7807 - val_loss: 0.6607 - val_accuracy: 0.7243\n",
      "Epoch 127/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4208 - accuracy: 0.7829 - val_loss: 0.6675 - val_accuracy: 0.7065\n",
      "Epoch 128/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4070 - accuracy: 0.7930 - val_loss: 0.6721 - val_accuracy: 0.7243\n",
      "Epoch 129/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3978 - accuracy: 0.7885 - val_loss: 0.6277 - val_accuracy: 0.7232\n",
      "Epoch 130/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3973 - accuracy: 0.7937 - val_loss: 0.7873 - val_accuracy: 0.6847\n",
      "Epoch 131/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4124 - accuracy: 0.7839 - val_loss: 0.7006 - val_accuracy: 0.7204\n",
      "Epoch 132/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4055 - accuracy: 0.7872 - val_loss: 0.6647 - val_accuracy: 0.7249\n",
      "Epoch 133/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4145 - accuracy: 0.7909 - val_loss: 0.6784 - val_accuracy: 0.7048\n",
      "Epoch 134/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3905 - accuracy: 0.7998 - val_loss: 0.6693 - val_accuracy: 0.7394\n",
      "Epoch 135/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3858 - accuracy: 0.7991 - val_loss: 0.7584 - val_accuracy: 0.6948\n",
      "Epoch 136/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.4056 - accuracy: 0.7907 - val_loss: 0.7081 - val_accuracy: 0.6892\n",
      "Epoch 137/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3795 - accuracy: 0.8062 - val_loss: 0.7032 - val_accuracy: 0.7054\n",
      "Epoch 138/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3874 - accuracy: 0.7976 - val_loss: 0.6476 - val_accuracy: 0.7115\n",
      "Epoch 139/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3846 - accuracy: 0.8083 - val_loss: 0.6568 - val_accuracy: 0.7260\n",
      "Epoch 140/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3846 - accuracy: 0.8001 - val_loss: 0.7817 - val_accuracy: 0.6836\n",
      "Epoch 141/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3701 - accuracy: 0.8178 - val_loss: 0.7479 - val_accuracy: 0.6975\n",
      "Epoch 142/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3829 - accuracy: 0.8041 - val_loss: 0.7289 - val_accuracy: 0.7400\n",
      "Epoch 143/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3690 - accuracy: 0.8193 - val_loss: 0.8211 - val_accuracy: 0.6964\n",
      "Epoch 144/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3722 - accuracy: 0.8104 - val_loss: 0.8257 - val_accuracy: 0.6975\n",
      "Epoch 145/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3781 - accuracy: 0.8054 - val_loss: 0.7851 - val_accuracy: 0.7210\n",
      "Epoch 146/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3694 - accuracy: 0.8110 - val_loss: 0.7754 - val_accuracy: 0.6858\n",
      "Epoch 147/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3557 - accuracy: 0.8232 - val_loss: 0.7467 - val_accuracy: 0.7065\n",
      "Epoch 148/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3809 - accuracy: 0.8112 - val_loss: 0.7120 - val_accuracy: 0.7338\n",
      "Epoch 149/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3686 - accuracy: 0.8117 - val_loss: 0.8592 - val_accuracy: 0.7171\n",
      "Epoch 150/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3588 - accuracy: 0.8172 - val_loss: 0.8197 - val_accuracy: 0.7003\n",
      "Epoch 151/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3540 - accuracy: 0.8199 - val_loss: 0.7339 - val_accuracy: 0.7478\n",
      "Epoch 152/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3439 - accuracy: 0.8378 - val_loss: 0.7504 - val_accuracy: 0.7215\n",
      "Epoch 153/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3743 - accuracy: 0.8138 - val_loss: 0.7901 - val_accuracy: 0.6217\n",
      "Epoch 154/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3575 - accuracy: 0.8231 - val_loss: 0.7420 - val_accuracy: 0.7344\n",
      "Epoch 155/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3275 - accuracy: 0.8359 - val_loss: 0.7773 - val_accuracy: 0.7277\n",
      "Epoch 156/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3449 - accuracy: 0.8292 - val_loss: 0.6988 - val_accuracy: 0.7388\n",
      "Epoch 157/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3404 - accuracy: 0.8295 - val_loss: 0.7915 - val_accuracy: 0.7277\n",
      "Epoch 158/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3576 - accuracy: 0.8200 - val_loss: 0.7730 - val_accuracy: 0.7628\n",
      "Epoch 159/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3257 - accuracy: 0.8362 - val_loss: 0.8470 - val_accuracy: 0.7294\n",
      "Epoch 160/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3264 - accuracy: 0.8380 - val_loss: 0.8727 - val_accuracy: 0.7310\n",
      "Epoch 161/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3332 - accuracy: 0.8312 - val_loss: 0.8624 - val_accuracy: 0.7232\n",
      "Epoch 162/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3608 - accuracy: 0.8249 - val_loss: 0.8330 - val_accuracy: 0.7288\n",
      "Epoch 163/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3352 - accuracy: 0.8312 - val_loss: 0.7439 - val_accuracy: 0.7450\n",
      "Epoch 164/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3246 - accuracy: 0.8337 - val_loss: 0.8182 - val_accuracy: 0.7271\n",
      "Epoch 165/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3219 - accuracy: 0.8393 - val_loss: 0.7314 - val_accuracy: 0.7483\n",
      "Epoch 166/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3404 - accuracy: 0.8312 - val_loss: 0.7616 - val_accuracy: 0.7494\n",
      "Epoch 167/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3221 - accuracy: 0.8379 - val_loss: 0.9236 - val_accuracy: 0.7388\n",
      "Epoch 168/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3078 - accuracy: 0.8503 - val_loss: 0.9359 - val_accuracy: 0.7494\n",
      "Epoch 169/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3198 - accuracy: 0.8421 - val_loss: 0.9278 - val_accuracy: 0.7238\n",
      "Epoch 170/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3120 - accuracy: 0.8465 - val_loss: 0.7101 - val_accuracy: 0.7740\n",
      "Epoch 171/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3196 - accuracy: 0.8472 - val_loss: 0.7809 - val_accuracy: 0.7305\n",
      "Epoch 172/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3176 - accuracy: 0.8431 - val_loss: 0.8265 - val_accuracy: 0.7087\n",
      "Epoch 173/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3001 - accuracy: 0.8556 - val_loss: 0.7267 - val_accuracy: 0.7701\n",
      "Epoch 174/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2939 - accuracy: 0.8564 - val_loss: 0.8682 - val_accuracy: 0.7199\n",
      "Epoch 175/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2980 - accuracy: 0.8537 - val_loss: 0.7157 - val_accuracy: 0.7712\n",
      "Epoch 176/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3101 - accuracy: 0.8503 - val_loss: 0.8594 - val_accuracy: 0.7355\n",
      "Epoch 177/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2905 - accuracy: 0.8574 - val_loss: 0.9158 - val_accuracy: 0.7277\n",
      "Epoch 178/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2998 - accuracy: 0.8537 - val_loss: 0.7931 - val_accuracy: 0.7695\n",
      "Epoch 179/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.3002 - accuracy: 0.8532 - val_loss: 0.8175 - val_accuracy: 0.7673\n",
      "Epoch 180/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3427 - accuracy: 0.8271 - val_loss: 0.7409 - val_accuracy: 0.7584\n",
      "Epoch 181/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3051 - accuracy: 0.8485 - val_loss: 0.7626 - val_accuracy: 0.7533\n",
      "Epoch 182/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3012 - accuracy: 0.8538 - val_loss: 0.6788 - val_accuracy: 0.7718\n",
      "Epoch 183/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3230 - accuracy: 0.8421 - val_loss: 0.8682 - val_accuracy: 0.7673\n",
      "Epoch 184/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3141 - accuracy: 0.8465 - val_loss: 0.7297 - val_accuracy: 0.7606\n",
      "Epoch 185/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3075 - accuracy: 0.8475 - val_loss: 0.8120 - val_accuracy: 0.7478\n",
      "Epoch 186/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2755 - accuracy: 0.8652 - val_loss: 0.7937 - val_accuracy: 0.7533\n",
      "Epoch 187/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3253 - accuracy: 0.8482 - val_loss: 0.8157 - val_accuracy: 0.7673\n",
      "Epoch 188/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2903 - accuracy: 0.8581 - val_loss: 0.7930 - val_accuracy: 0.7517\n",
      "Epoch 189/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2865 - accuracy: 0.8620 - val_loss: 0.8562 - val_accuracy: 0.7539\n",
      "Epoch 190/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2882 - accuracy: 0.8606 - val_loss: 0.7928 - val_accuracy: 0.7545\n",
      "Epoch 191/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2844 - accuracy: 0.8661 - val_loss: 0.7036 - val_accuracy: 0.7561\n",
      "Epoch 192/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2704 - accuracy: 0.8717 - val_loss: 0.6907 - val_accuracy: 0.7439\n",
      "Epoch 193/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2807 - accuracy: 0.8677 - val_loss: 0.9933 - val_accuracy: 0.7349\n",
      "Epoch 194/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2758 - accuracy: 0.8687 - val_loss: 0.8016 - val_accuracy: 0.7751\n",
      "Epoch 195/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2723 - accuracy: 0.8693 - val_loss: 0.7772 - val_accuracy: 0.7695\n",
      "Epoch 196/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2894 - accuracy: 0.8567 - val_loss: 0.7737 - val_accuracy: 0.7868\n",
      "Epoch 197/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2729 - accuracy: 0.8717 - val_loss: 0.8414 - val_accuracy: 0.7812\n",
      "Epoch 198/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2684 - accuracy: 0.8742 - val_loss: 1.1600 - val_accuracy: 0.7517\n",
      "Epoch 199/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2589 - accuracy: 0.8722 - val_loss: 1.1943 - val_accuracy: 0.7388\n",
      "Epoch 200/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2679 - accuracy: 0.8714 - val_loss: 1.0990 - val_accuracy: 0.7561\n",
      "Epoch 201/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2563 - accuracy: 0.8771 - val_loss: 0.8055 - val_accuracy: 0.7377\n",
      "Epoch 202/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2575 - accuracy: 0.8775 - val_loss: 1.0475 - val_accuracy: 0.7455\n",
      "Epoch 203/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2533 - accuracy: 0.8814 - val_loss: 1.1508 - val_accuracy: 0.7545\n",
      "Epoch 204/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2615 - accuracy: 0.8779 - val_loss: 0.8053 - val_accuracy: 0.7695\n",
      "Epoch 205/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2411 - accuracy: 0.8876 - val_loss: 0.8141 - val_accuracy: 0.7796\n",
      "Epoch 206/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2409 - accuracy: 0.8846 - val_loss: 0.9302 - val_accuracy: 0.8030\n",
      "Epoch 207/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.3043 - accuracy: 0.8609 - val_loss: 0.8953 - val_accuracy: 0.7679\n",
      "Epoch 208/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2385 - accuracy: 0.8811 - val_loss: 0.8126 - val_accuracy: 0.7573\n",
      "Epoch 209/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2578 - accuracy: 0.8781 - val_loss: 0.9734 - val_accuracy: 0.7946\n",
      "Epoch 210/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.2274 - accuracy: 0.8888 - val_loss: 0.9613 - val_accuracy: 0.7779\n",
      "Epoch 211/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2370 - accuracy: 0.8898 - val_loss: 1.0897 - val_accuracy: 0.7584\n",
      "Epoch 212/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.3424 - accuracy: 0.8358 - val_loss: 0.7548 - val_accuracy: 0.7539\n",
      "Epoch 213/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2326 - accuracy: 0.8892 - val_loss: 1.0356 - val_accuracy: 0.8002\n",
      "Epoch 214/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2357 - accuracy: 0.8852 - val_loss: 0.8995 - val_accuracy: 0.7891\n",
      "Epoch 215/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2815 - accuracy: 0.8806 - val_loss: 0.9317 - val_accuracy: 0.7734\n",
      "Epoch 216/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2307 - accuracy: 0.8969 - val_loss: 0.9712 - val_accuracy: 0.7411\n",
      "Epoch 217/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2338 - accuracy: 0.8910 - val_loss: 0.8959 - val_accuracy: 0.7952\n",
      "Epoch 218/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2359 - accuracy: 0.8881 - val_loss: 0.9887 - val_accuracy: 0.7667\n",
      "Epoch 219/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2644 - accuracy: 0.8818 - val_loss: 0.9652 - val_accuracy: 0.7511\n",
      "Epoch 220/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2234 - accuracy: 0.8933 - val_loss: 0.8476 - val_accuracy: 0.7846\n",
      "Epoch 221/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2042 - accuracy: 0.9015 - val_loss: 1.0557 - val_accuracy: 0.7812\n",
      "Epoch 222/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2406 - accuracy: 0.8852 - val_loss: 1.1446 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2350 - accuracy: 0.8920 - val_loss: 0.9043 - val_accuracy: 0.7969\n",
      "Epoch 224/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2184 - accuracy: 0.9035 - val_loss: 0.8146 - val_accuracy: 0.7690\n",
      "Epoch 225/1200\n",
      "112/112 [==============================] - 4s 40ms/step - loss: 0.2211 - accuracy: 0.8997 - val_loss: 0.8961 - val_accuracy: 0.7846\n",
      "Epoch 226/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2155 - accuracy: 0.8983 - val_loss: 0.9591 - val_accuracy: 0.7985\n",
      "Epoch 227/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2092 - accuracy: 0.9012 - val_loss: 1.3471 - val_accuracy: 0.7612\n",
      "Epoch 228/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2222 - accuracy: 0.8940 - val_loss: 0.8251 - val_accuracy: 0.8008\n",
      "Epoch 229/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2192 - accuracy: 0.8940 - val_loss: 0.8834 - val_accuracy: 0.7818\n",
      "Epoch 230/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2080 - accuracy: 0.9043 - val_loss: 1.1644 - val_accuracy: 0.7824\n",
      "Epoch 231/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2035 - accuracy: 0.9029 - val_loss: 1.3853 - val_accuracy: 0.7483\n",
      "Epoch 232/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2095 - accuracy: 0.9009 - val_loss: 1.2280 - val_accuracy: 0.7634\n",
      "Epoch 233/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2089 - accuracy: 0.9047 - val_loss: 1.1296 - val_accuracy: 0.7718\n",
      "Epoch 234/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1988 - accuracy: 0.9068 - val_loss: 1.1517 - val_accuracy: 0.7874\n",
      "Epoch 235/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2151 - accuracy: 0.9039 - val_loss: 1.1375 - val_accuracy: 0.7628\n",
      "Epoch 236/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2074 - accuracy: 0.9057 - val_loss: 0.6694 - val_accuracy: 0.7835\n",
      "Epoch 237/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1983 - accuracy: 0.9096 - val_loss: 1.0941 - val_accuracy: 0.7963\n",
      "Epoch 238/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2143 - accuracy: 0.9044 - val_loss: 1.1238 - val_accuracy: 0.7656\n",
      "Epoch 239/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1933 - accuracy: 0.9124 - val_loss: 1.2403 - val_accuracy: 0.7718\n",
      "Epoch 240/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2051 - accuracy: 0.9088 - val_loss: 1.1101 - val_accuracy: 0.7740\n",
      "Epoch 241/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2081 - accuracy: 0.9003 - val_loss: 0.9390 - val_accuracy: 0.7985\n",
      "Epoch 242/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2065 - accuracy: 0.9053 - val_loss: 0.9907 - val_accuracy: 0.7896\n",
      "Epoch 243/1200\n",
      "112/112 [==============================] - 5s 46ms/step - loss: 0.1967 - accuracy: 0.9163 - val_loss: 0.8928 - val_accuracy: 0.7863\n",
      "Epoch 244/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2097 - accuracy: 0.9046 - val_loss: 1.3343 - val_accuracy: 0.7740\n",
      "Epoch 245/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2054 - accuracy: 0.9039 - val_loss: 1.0574 - val_accuracy: 0.7506\n",
      "Epoch 246/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1863 - accuracy: 0.9180 - val_loss: 0.9394 - val_accuracy: 0.8209\n",
      "Epoch 247/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1856 - accuracy: 0.9141 - val_loss: 1.2984 - val_accuracy: 0.7695\n",
      "Epoch 248/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2093 - accuracy: 0.9096 - val_loss: 0.7404 - val_accuracy: 0.7338\n",
      "Epoch 249/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1885 - accuracy: 0.9131 - val_loss: 1.1669 - val_accuracy: 0.7879\n",
      "Epoch 250/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2044 - accuracy: 0.9085 - val_loss: 1.0107 - val_accuracy: 0.7812\n",
      "Epoch 251/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2232 - accuracy: 0.9039 - val_loss: 0.8812 - val_accuracy: 0.7617\n",
      "Epoch 252/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1770 - accuracy: 0.9201 - val_loss: 1.0820 - val_accuracy: 0.7891\n",
      "Epoch 253/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1945 - accuracy: 0.9125 - val_loss: 1.0934 - val_accuracy: 0.7885\n",
      "Epoch 254/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1720 - accuracy: 0.9162 - val_loss: 1.0016 - val_accuracy: 0.8002\n",
      "Epoch 255/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1716 - accuracy: 0.9203 - val_loss: 1.1787 - val_accuracy: 0.7835\n",
      "Epoch 256/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1726 - accuracy: 0.9192 - val_loss: 1.1005 - val_accuracy: 0.7673\n",
      "Epoch 257/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1893 - accuracy: 0.9118 - val_loss: 1.1364 - val_accuracy: 0.7919\n",
      "Epoch 258/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1934 - accuracy: 0.9132 - val_loss: 1.1344 - val_accuracy: 0.7768\n",
      "Epoch 259/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1752 - accuracy: 0.9199 - val_loss: 1.0299 - val_accuracy: 0.8092\n",
      "Epoch 260/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1753 - accuracy: 0.9196 - val_loss: 0.8777 - val_accuracy: 0.8181\n",
      "Epoch 261/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1698 - accuracy: 0.9231 - val_loss: 1.1790 - val_accuracy: 0.7958\n",
      "Epoch 262/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1630 - accuracy: 0.9323 - val_loss: 1.0567 - val_accuracy: 0.7974\n",
      "Epoch 263/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1757 - accuracy: 0.9217 - val_loss: 1.0820 - val_accuracy: 0.7439\n",
      "Epoch 264/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1958 - accuracy: 0.9167 - val_loss: 1.0453 - val_accuracy: 0.7087\n",
      "Epoch 265/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1888 - accuracy: 0.9181 - val_loss: 1.1999 - val_accuracy: 0.7840\n",
      "Epoch 266/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1716 - accuracy: 0.9276 - val_loss: 1.1250 - val_accuracy: 0.7779\n",
      "Epoch 267/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1767 - accuracy: 0.9245 - val_loss: 1.0275 - val_accuracy: 0.7718\n",
      "Epoch 268/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1668 - accuracy: 0.9244 - val_loss: 1.2512 - val_accuracy: 0.8080\n",
      "Epoch 269/1200\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.1703 - accuracy: 0.9275 - val_loss: 1.4631 - val_accuracy: 0.7812\n",
      "Epoch 270/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1686 - accuracy: 0.9269 - val_loss: 1.2214 - val_accuracy: 0.7924\n",
      "Epoch 271/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.2215 - accuracy: 0.9118 - val_loss: 0.9662 - val_accuracy: 0.7958\n",
      "Epoch 272/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1578 - accuracy: 0.9293 - val_loss: 0.9679 - val_accuracy: 0.8069\n",
      "Epoch 273/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1665 - accuracy: 0.9248 - val_loss: 0.9560 - val_accuracy: 0.8164\n",
      "Epoch 274/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1526 - accuracy: 0.9333 - val_loss: 1.1736 - val_accuracy: 0.7902\n",
      "Epoch 275/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1563 - accuracy: 0.9294 - val_loss: 1.0878 - val_accuracy: 0.7773\n",
      "Epoch 276/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1626 - accuracy: 0.9322 - val_loss: 1.2455 - val_accuracy: 0.7746\n",
      "Epoch 277/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1646 - accuracy: 0.9275 - val_loss: 1.1487 - val_accuracy: 0.7941\n",
      "Epoch 278/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1617 - accuracy: 0.9289 - val_loss: 1.1294 - val_accuracy: 0.8052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1723 - accuracy: 0.9294 - val_loss: 1.1291 - val_accuracy: 0.7919\n",
      "Epoch 280/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1480 - accuracy: 0.9344 - val_loss: 1.1768 - val_accuracy: 0.7779\n",
      "Epoch 281/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1586 - accuracy: 0.9316 - val_loss: 1.4815 - val_accuracy: 0.7801\n",
      "Epoch 282/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1486 - accuracy: 0.9335 - val_loss: 1.2395 - val_accuracy: 0.8019\n",
      "Epoch 283/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1503 - accuracy: 0.9339 - val_loss: 1.0715 - val_accuracy: 0.8030\n",
      "Epoch 284/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1415 - accuracy: 0.9403 - val_loss: 1.3564 - val_accuracy: 0.7952\n",
      "Epoch 285/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1420 - accuracy: 0.9351 - val_loss: 1.1420 - val_accuracy: 0.8281\n",
      "Epoch 286/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1498 - accuracy: 0.9328 - val_loss: 1.3270 - val_accuracy: 0.7885\n",
      "Epoch 287/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1960 - accuracy: 0.9223 - val_loss: 1.1161 - val_accuracy: 0.8069\n",
      "Epoch 288/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1362 - accuracy: 0.9390 - val_loss: 0.9336 - val_accuracy: 0.8181\n",
      "Epoch 289/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1523 - accuracy: 0.9315 - val_loss: 1.2405 - val_accuracy: 0.7857\n",
      "Epoch 290/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1626 - accuracy: 0.9286 - val_loss: 1.1941 - val_accuracy: 0.8075\n",
      "Epoch 291/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1336 - accuracy: 0.9446 - val_loss: 1.0292 - val_accuracy: 0.7891\n",
      "Epoch 292/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1442 - accuracy: 0.9369 - val_loss: 1.0925 - val_accuracy: 0.8203\n",
      "Epoch 293/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1399 - accuracy: 0.9389 - val_loss: 1.4184 - val_accuracy: 0.7974\n",
      "Epoch 294/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1443 - accuracy: 0.9408 - val_loss: 1.2249 - val_accuracy: 0.7812\n",
      "Epoch 295/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1408 - accuracy: 0.9406 - val_loss: 1.2257 - val_accuracy: 0.7846\n",
      "Epoch 296/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1327 - accuracy: 0.9408 - val_loss: 1.5812 - val_accuracy: 0.7840\n",
      "Epoch 297/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1458 - accuracy: 0.9379 - val_loss: 1.3101 - val_accuracy: 0.7974\n",
      "Epoch 298/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1490 - accuracy: 0.9392 - val_loss: 1.1592 - val_accuracy: 0.8225\n",
      "Epoch 299/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1373 - accuracy: 0.9389 - val_loss: 1.2874 - val_accuracy: 0.7835\n",
      "Epoch 300/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1508 - accuracy: 0.9309 - val_loss: 1.1795 - val_accuracy: 0.7974\n",
      "Epoch 301/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1432 - accuracy: 0.9360 - val_loss: 1.2989 - val_accuracy: 0.7746\n",
      "Epoch 302/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1390 - accuracy: 0.9378 - val_loss: 1.0962 - val_accuracy: 0.8108\n",
      "Epoch 303/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1512 - accuracy: 0.9337 - val_loss: 1.3418 - val_accuracy: 0.7985\n",
      "Epoch 304/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1393 - accuracy: 0.9386 - val_loss: 1.2928 - val_accuracy: 0.8153\n",
      "Epoch 305/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1568 - accuracy: 0.9346 - val_loss: 1.1346 - val_accuracy: 0.8058\n",
      "Epoch 306/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1567 - accuracy: 0.9335 - val_loss: 1.3166 - val_accuracy: 0.7952\n",
      "Epoch 307/1200\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.1221 - accuracy: 0.9482 - val_loss: 1.3073 - val_accuracy: 0.7952\n",
      "Epoch 308/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1607 - accuracy: 0.9400 - val_loss: 1.2093 - val_accuracy: 0.7924\n",
      "Epoch 309/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1567 - accuracy: 0.9329 - val_loss: 1.2405 - val_accuracy: 0.7980\n",
      "Epoch 310/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1330 - accuracy: 0.9429 - val_loss: 1.4363 - val_accuracy: 0.8019\n",
      "Epoch 311/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1392 - accuracy: 0.9403 - val_loss: 1.0812 - val_accuracy: 0.8047s - loss: 0.1394 - accuracy: \n",
      "Epoch 312/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1149 - accuracy: 0.9512 - val_loss: 1.3567 - val_accuracy: 0.8047\n",
      "Epoch 313/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1476 - accuracy: 0.9400 - val_loss: 1.1942 - val_accuracy: 0.8097\n",
      "Epoch 314/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1199 - accuracy: 0.9492 - val_loss: 1.4264 - val_accuracy: 0.8013\n",
      "Epoch 315/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1248 - accuracy: 0.9467 - val_loss: 1.3328 - val_accuracy: 0.8030\n",
      "Epoch 316/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1405 - accuracy: 0.9344 - val_loss: 1.4041 - val_accuracy: 0.7958\n",
      "Epoch 317/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1152 - accuracy: 0.9509 - val_loss: 1.3001 - val_accuracy: 0.8186\n",
      "Epoch 318/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1305 - accuracy: 0.9432 - val_loss: 1.2507 - val_accuracy: 0.8376\n",
      "Epoch 319/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1481 - accuracy: 0.9364 - val_loss: 1.1632 - val_accuracy: 0.8186\n",
      "Epoch 320/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1321 - accuracy: 0.9466 - val_loss: 1.2037 - val_accuracy: 0.8214\n",
      "Epoch 321/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1162 - accuracy: 0.9482 - val_loss: 1.5306 - val_accuracy: 0.8125\n",
      "Epoch 322/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1273 - accuracy: 0.9459 - val_loss: 1.1413 - val_accuracy: 0.8097\n",
      "Epoch 323/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1208 - accuracy: 0.9477 - val_loss: 1.4406 - val_accuracy: 0.7974\n",
      "Epoch 324/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1167 - accuracy: 0.9496 - val_loss: 1.4270 - val_accuracy: 0.8253\n",
      "Epoch 325/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1271 - accuracy: 0.9502 - val_loss: 1.4499 - val_accuracy: 0.8002\n",
      "Epoch 326/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1336 - accuracy: 0.9449 - val_loss: 1.4148 - val_accuracy: 0.7896\n",
      "Epoch 327/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1331 - accuracy: 0.9464 - val_loss: 1.0713 - val_accuracy: 0.8142\n",
      "Epoch 328/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1275 - accuracy: 0.9450 - val_loss: 1.3273 - val_accuracy: 0.7919\n",
      "Epoch 329/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.2635 - accuracy: 0.9217 - val_loss: 1.0268 - val_accuracy: 0.8092\n",
      "Epoch 330/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1252 - accuracy: 0.9455 - val_loss: 1.1288 - val_accuracy: 0.7969\n",
      "Epoch 331/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1134 - accuracy: 0.9528 - val_loss: 1.1157 - val_accuracy: 0.8465\n",
      "Epoch 332/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1202 - accuracy: 0.9467 - val_loss: 1.1928 - val_accuracy: 0.8348\n",
      "Epoch 333/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1351 - accuracy: 0.9467 - val_loss: 1.1239 - val_accuracy: 0.8136\n",
      "Epoch 334/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1154 - accuracy: 0.9526 - val_loss: 1.2845 - val_accuracy: 0.8276\n",
      "Epoch 335/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1123 - accuracy: 0.9509 - val_loss: 1.4992 - val_accuracy: 0.8058\n",
      "Epoch 336/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1320 - accuracy: 0.9418 - val_loss: 1.1486 - val_accuracy: 0.8103\n",
      "Epoch 337/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1098 - accuracy: 0.9537 - val_loss: 1.3707 - val_accuracy: 0.8292\n",
      "Epoch 338/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1149 - accuracy: 0.9528 - val_loss: 1.3289 - val_accuracy: 0.8041\n",
      "Epoch 339/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1281 - accuracy: 0.9459 - val_loss: 1.2263 - val_accuracy: 0.7829\n",
      "Epoch 340/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1049 - accuracy: 0.9547 - val_loss: 1.5568 - val_accuracy: 0.8220\n",
      "Epoch 341/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1133 - accuracy: 0.9492 - val_loss: 1.5993 - val_accuracy: 0.8064\n",
      "Epoch 342/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1156 - accuracy: 0.9519 - val_loss: 1.4904 - val_accuracy: 0.8142\n",
      "Epoch 343/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1234 - accuracy: 0.9523 - val_loss: 1.2575 - val_accuracy: 0.7913\n",
      "Epoch 344/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1173 - accuracy: 0.9488 - val_loss: 1.3308 - val_accuracy: 0.8097\n",
      "Epoch 345/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1135 - accuracy: 0.9530 - val_loss: 1.6431 - val_accuracy: 0.8103\n",
      "Epoch 346/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1074 - accuracy: 0.9540 - val_loss: 1.3047 - val_accuracy: 0.8225\n",
      "Epoch 347/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1185 - accuracy: 0.9499 - val_loss: 1.3794 - val_accuracy: 0.8097\n",
      "Epoch 348/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1140 - accuracy: 0.9577 - val_loss: 1.3651 - val_accuracy: 0.7824\n",
      "Epoch 349/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1054 - accuracy: 0.9591 - val_loss: 1.3879 - val_accuracy: 0.8103\n",
      "Epoch 350/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1102 - accuracy: 0.9533 - val_loss: 1.1394 - val_accuracy: 0.7941\n",
      "Epoch 351/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1206 - accuracy: 0.9530 - val_loss: 1.4218 - val_accuracy: 0.7896\n",
      "Epoch 352/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1156 - accuracy: 0.9538 - val_loss: 1.4680 - val_accuracy: 0.8075\n",
      "Epoch 353/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1127 - accuracy: 0.9530 - val_loss: 1.4210 - val_accuracy: 0.6897\n",
      "Epoch 354/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1220 - accuracy: 0.9473 - val_loss: 1.4909 - val_accuracy: 0.8131\n",
      "Epoch 355/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1214 - accuracy: 0.9443 - val_loss: 1.7466 - val_accuracy: 0.8036\n",
      "Epoch 356/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1015 - accuracy: 0.9581 - val_loss: 1.1530 - val_accuracy: 0.8147\n",
      "Epoch 357/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1352 - accuracy: 0.9547 - val_loss: 1.3432 - val_accuracy: 0.8158\n",
      "Epoch 358/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0992 - accuracy: 0.9594 - val_loss: 1.4167 - val_accuracy: 0.8092\n",
      "Epoch 359/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1192 - accuracy: 0.9513 - val_loss: 1.4098 - val_accuracy: 0.8192\n",
      "Epoch 360/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1012 - accuracy: 0.9590 - val_loss: 1.3994 - val_accuracy: 0.8175\n",
      "Epoch 361/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1042 - accuracy: 0.9556 - val_loss: 1.4797 - val_accuracy: 0.8203\n",
      "Epoch 362/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1001 - accuracy: 0.9604 - val_loss: 1.6106 - val_accuracy: 0.8080\n",
      "Epoch 363/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0969 - accuracy: 0.9605 - val_loss: 1.8876 - val_accuracy: 0.8008\n",
      "Epoch 364/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0966 - accuracy: 0.9601 - val_loss: 1.6569 - val_accuracy: 0.7930\n",
      "Epoch 365/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0920 - accuracy: 0.9621 - val_loss: 1.4917 - val_accuracy: 0.8287\n",
      "Epoch 366/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1008 - accuracy: 0.9597 - val_loss: 1.3116 - val_accuracy: 0.8231\n",
      "Epoch 367/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1077 - accuracy: 0.9544 - val_loss: 1.4393 - val_accuracy: 0.8058\n",
      "Epoch 368/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1039 - accuracy: 0.9612 - val_loss: 1.6025 - val_accuracy: 0.8008\n",
      "Epoch 369/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1087 - accuracy: 0.9540 - val_loss: 1.5514 - val_accuracy: 0.8198\n",
      "Epoch 370/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1065 - accuracy: 0.9591 - val_loss: 1.2760 - val_accuracy: 0.8069\n",
      "Epoch 371/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1060 - accuracy: 0.9565 - val_loss: 1.7133 - val_accuracy: 0.7985\n",
      "Epoch 372/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1104 - accuracy: 0.9556 - val_loss: 1.5149 - val_accuracy: 0.7835\n",
      "Epoch 373/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1105 - accuracy: 0.9576 - val_loss: 1.3662 - val_accuracy: 0.7924\n",
      "Epoch 374/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0937 - accuracy: 0.9646 - val_loss: 1.4109 - val_accuracy: 0.8142\n",
      "Epoch 375/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0950 - accuracy: 0.9622 - val_loss: 1.4158 - val_accuracy: 0.8108\n",
      "Epoch 376/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1020 - accuracy: 0.9561 - val_loss: 1.6127 - val_accuracy: 0.7963\n",
      "Epoch 377/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1057 - accuracy: 0.9577 - val_loss: 2.0554 - val_accuracy: 0.7891\n",
      "Epoch 378/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0799 - accuracy: 0.9703 - val_loss: 1.3233 - val_accuracy: 0.8220\n",
      "Epoch 379/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1035 - accuracy: 0.9614 - val_loss: 1.6958 - val_accuracy: 0.7561\n",
      "Epoch 380/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1371 - accuracy: 0.9421 - val_loss: 1.5582 - val_accuracy: 0.8170\n",
      "Epoch 381/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1020 - accuracy: 0.9590 - val_loss: 1.6155 - val_accuracy: 0.8097\n",
      "Epoch 382/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0917 - accuracy: 0.9665 - val_loss: 1.6757 - val_accuracy: 0.8047\n",
      "Epoch 383/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0972 - accuracy: 0.9602 - val_loss: 1.4963 - val_accuracy: 0.8114\n",
      "Epoch 384/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0942 - accuracy: 0.9629 - val_loss: 1.1424 - val_accuracy: 0.8170\n",
      "Epoch 385/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.1111 - accuracy: 0.9574 - val_loss: 1.3025 - val_accuracy: 0.7863ETA: 0s - loss: 0\n",
      "Epoch 386/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1287 - accuracy: 0.9573 - val_loss: 1.3777 - val_accuracy: 0.8248\n",
      "Epoch 387/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0830 - accuracy: 0.9676 - val_loss: 1.7149 - val_accuracy: 0.8170\n",
      "Epoch 388/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0913 - accuracy: 0.9639 - val_loss: 1.7663 - val_accuracy: 0.8158\n",
      "Epoch 389/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1036 - accuracy: 0.9587 - val_loss: 1.9024 - val_accuracy: 0.7718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0957 - accuracy: 0.9625 - val_loss: 1.7952 - val_accuracy: 0.8064\n",
      "Epoch 391/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1254 - accuracy: 0.9544 - val_loss: 1.8823 - val_accuracy: 0.7935\n",
      "Epoch 392/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0941 - accuracy: 0.9622 - val_loss: 1.3128 - val_accuracy: 0.7941\n",
      "Epoch 393/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0843 - accuracy: 0.9634 - val_loss: 1.5637 - val_accuracy: 0.8013\n",
      "Epoch 394/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1045 - accuracy: 0.9607 - val_loss: 1.4595 - val_accuracy: 0.7874\n",
      "Epoch 395/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0859 - accuracy: 0.9648 - val_loss: 1.5385 - val_accuracy: 0.8136\n",
      "Epoch 396/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0933 - accuracy: 0.9653 - val_loss: 1.4083 - val_accuracy: 0.8036\n",
      "Epoch 397/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0929 - accuracy: 0.9651 - val_loss: 1.4391 - val_accuracy: 0.7997\n",
      "Epoch 398/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1062 - accuracy: 0.9609 - val_loss: 2.0318 - val_accuracy: 0.7919\n",
      "Epoch 399/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0924 - accuracy: 0.9672 - val_loss: 1.7598 - val_accuracy: 0.8198\n",
      "Epoch 400/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0793 - accuracy: 0.9665 - val_loss: 1.8138 - val_accuracy: 0.8092\n",
      "Epoch 401/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0904 - accuracy: 0.9630 - val_loss: 1.4387 - val_accuracy: 0.8158\n",
      "Epoch 402/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0980 - accuracy: 0.9634 - val_loss: 2.1794 - val_accuracy: 0.7801\n",
      "Epoch 403/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0819 - accuracy: 0.9672 - val_loss: 1.2913 - val_accuracy: 0.8119\n",
      "Epoch 404/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0765 - accuracy: 0.9675 - val_loss: 1.8688 - val_accuracy: 0.8047\n",
      "Epoch 405/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1203 - accuracy: 0.9547 - val_loss: 1.5266 - val_accuracy: 0.8041\n",
      "Epoch 406/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0892 - accuracy: 0.9655 - val_loss: 1.7225 - val_accuracy: 0.8103\n",
      "Epoch 407/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0918 - accuracy: 0.9623 - val_loss: 1.4809 - val_accuracy: 0.8209\n",
      "Epoch 408/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0741 - accuracy: 0.9700 - val_loss: 2.1413 - val_accuracy: 0.7812\n",
      "Epoch 409/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0939 - accuracy: 0.9644 - val_loss: 1.5623 - val_accuracy: 0.8186\n",
      "Epoch 410/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0770 - accuracy: 0.9682 - val_loss: 1.6948 - val_accuracy: 0.7969\n",
      "Epoch 411/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0865 - accuracy: 0.9651 - val_loss: 1.6007 - val_accuracy: 0.8298\n",
      "Epoch 412/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0906 - accuracy: 0.9646 - val_loss: 1.4803 - val_accuracy: 0.8175\n",
      "Epoch 413/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0852 - accuracy: 0.9662 - val_loss: 1.7421 - val_accuracy: 0.8064\n",
      "Epoch 414/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0911 - accuracy: 0.9665 - val_loss: 1.5740 - val_accuracy: 0.8209\n",
      "Epoch 415/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0797 - accuracy: 0.9665 - val_loss: 1.5194 - val_accuracy: 0.8047\n",
      "Epoch 416/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0854 - accuracy: 0.9661 - val_loss: 1.9462 - val_accuracy: 0.7946\n",
      "Epoch 417/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0762 - accuracy: 0.9671 - val_loss: 1.7319 - val_accuracy: 0.8075\n",
      "Epoch 418/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0904 - accuracy: 0.9665 - val_loss: 1.7453 - val_accuracy: 0.8125\n",
      "Epoch 419/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0885 - accuracy: 0.9658 - val_loss: 1.4980 - val_accuracy: 0.8225\n",
      "Epoch 420/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0712 - accuracy: 0.9699 - val_loss: 1.7697 - val_accuracy: 0.8036\n",
      "Epoch 421/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1114 - accuracy: 0.9537 - val_loss: 1.6891 - val_accuracy: 0.7985\n",
      "Epoch 422/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1088 - accuracy: 0.9616 - val_loss: 1.3863 - val_accuracy: 0.8036\n",
      "Epoch 423/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 1.3056 - val_accuracy: 0.8203\n",
      "Epoch 424/1200\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 0.0933 - accuracy: 0.9633 - val_loss: 1.4670 - val_accuracy: 0.8119\n",
      "Epoch 425/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0753 - accuracy: 0.9686 - val_loss: 1.7889 - val_accuracy: 0.7958\n",
      "Epoch 426/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0686 - accuracy: 0.9724 - val_loss: 1.5266 - val_accuracy: 0.8209\n",
      "Epoch 427/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0826 - accuracy: 0.9681 - val_loss: 2.0309 - val_accuracy: 0.7896\n",
      "Epoch 428/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.1202 - accuracy: 0.9499 - val_loss: 1.5784 - val_accuracy: 0.8008\n",
      "Epoch 429/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0880 - accuracy: 0.9667 - val_loss: 1.3085 - val_accuracy: 0.8170\n",
      "Epoch 430/1200\n",
      "112/112 [==============================] - 5s 42ms/step - loss: 0.0801 - accuracy: 0.9690 - val_loss: 1.8367 - val_accuracy: 0.8058\n",
      "Epoch 431/1200\n",
      "112/112 [==============================] - 5s 41ms/step - loss: 0.0832 - accuracy: 0.9696 - val_loss: 1.5396 - val_accuracy: 0.8186\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00431: early stopping\n",
      "149/149 [==============================] - 1s 5ms/step\n",
      "     23/Unknown - 0s 5ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799/799 [==============================] - 4s 5ms/step\n",
      "200/200 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|                                         | 1/2 [33:24<33:24, 2004.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "89/89 [==============================] - 5s 44ms/step - loss: 0.6229 - accuracy: 0.6306 - val_loss: 0.6905 - val_accuracy: 0.5518\n",
      "Epoch 2/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.6211 - accuracy: 0.6220 - val_loss: 0.6352 - val_accuracy: 0.6278\n",
      "Epoch 3/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6258 - accuracy: 0.6166 - val_loss: 0.6403 - val_accuracy: 0.6122\n",
      "Epoch 4/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6118 - accuracy: 0.6419 - val_loss: 0.6457 - val_accuracy: 0.5881\n",
      "Epoch 5/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6132 - accuracy: 0.6408 - val_loss: 0.6579 - val_accuracy: 0.6222\n",
      "Epoch 6/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6107 - accuracy: 0.6373 - val_loss: 0.6439 - val_accuracy: 0.6250\n",
      "Epoch 7/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6139 - accuracy: 0.6352 - val_loss: 0.6563 - val_accuracy: 0.6413\n",
      "Epoch 8/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5987 - accuracy: 0.6455 - val_loss: 0.6292 - val_accuracy: 0.6477\n",
      "Epoch 9/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6002 - accuracy: 0.6406 - val_loss: 0.6782 - val_accuracy: 0.5582\n",
      "Epoch 10/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6078 - accuracy: 0.6273 - val_loss: 0.6564 - val_accuracy: 0.6321\n",
      "Epoch 11/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.5932 - accuracy: 0.6362 - val_loss: 0.6513 - val_accuracy: 0.6044\n",
      "Epoch 12/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6020 - accuracy: 0.6357 - val_loss: 0.6627 - val_accuracy: 0.5902\n",
      "Epoch 13/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5989 - accuracy: 0.6390 - val_loss: 0.6514 - val_accuracy: 0.6101\n",
      "Epoch 14/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5924 - accuracy: 0.6427 - val_loss: 0.6727 - val_accuracy: 0.6037\n",
      "Epoch 15/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5890 - accuracy: 0.6417 - val_loss: 0.6976 - val_accuracy: 0.5866\n",
      "Epoch 16/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5893 - accuracy: 0.6419 - val_loss: 0.6899 - val_accuracy: 0.6172\n",
      "Epoch 17/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.6149 - accuracy: 0.6301 - val_loss: 0.6875 - val_accuracy: 0.5859\n",
      "Epoch 18/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5850 - accuracy: 0.6429 - val_loss: 0.6855 - val_accuracy: 0.5866\n",
      "Epoch 19/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5823 - accuracy: 0.6526 - val_loss: 0.6941 - val_accuracy: 0.5788\n",
      "Epoch 20/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5903 - accuracy: 0.6471 - val_loss: 0.6719 - val_accuracy: 0.6143\n",
      "Epoch 21/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5840 - accuracy: 0.6471 - val_loss: 0.6788 - val_accuracy: 0.5959\n",
      "Epoch 22/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5934 - accuracy: 0.6436 - val_loss: 0.6685 - val_accuracy: 0.5810\n",
      "Epoch 23/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5828 - accuracy: 0.6434 - val_loss: 0.7130 - val_accuracy: 0.6001\n",
      "Epoch 24/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5830 - accuracy: 0.6462 - val_loss: 0.6840 - val_accuracy: 0.5980\n",
      "Epoch 25/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5775 - accuracy: 0.6492 - val_loss: 0.7329 - val_accuracy: 0.5852ss: 0.5774 - accuracy: \n",
      "Epoch 26/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5843 - accuracy: 0.6478 - val_loss: 0.7055 - val_accuracy: 0.6016\n",
      "Epoch 27/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5777 - accuracy: 0.6568 - val_loss: 0.7075 - val_accuracy: 0.5696\n",
      "Epoch 28/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5794 - accuracy: 0.6629 - val_loss: 0.7010 - val_accuracy: 0.5895\n",
      "Epoch 29/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5757 - accuracy: 0.6624 - val_loss: 0.6915 - val_accuracy: 0.5888\n",
      "Epoch 30/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5769 - accuracy: 0.6541 - val_loss: 0.6674 - val_accuracy: 0.6016\n",
      "Epoch 31/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5865 - accuracy: 0.6503 - val_loss: 0.7382 - val_accuracy: 0.5710\n",
      "Epoch 32/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5904 - accuracy: 0.6520 - val_loss: 0.7258 - val_accuracy: 0.5597\n",
      "Epoch 33/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5732 - accuracy: 0.6594 - val_loss: 0.7492 - val_accuracy: 0.6065\n",
      "Epoch 34/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5701 - accuracy: 0.6717 - val_loss: 0.7302 - val_accuracy: 0.5859\n",
      "Epoch 35/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5774 - accuracy: 0.6675 - val_loss: 0.7772 - val_accuracy: 0.5717\n",
      "Epoch 36/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5736 - accuracy: 0.6687 - val_loss: 0.7207 - val_accuracy: 0.5632\n",
      "Epoch 37/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5723 - accuracy: 0.6699 - val_loss: 0.7555 - val_accuracy: 0.5952\n",
      "Epoch 38/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5692 - accuracy: 0.6735 - val_loss: 0.6974 - val_accuracy: 0.5433\n",
      "Epoch 39/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5790 - accuracy: 0.6529 - val_loss: 0.7353 - val_accuracy: 0.5824\n",
      "Epoch 40/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5584 - accuracy: 0.6821 - val_loss: 0.6665 - val_accuracy: 0.6257\n",
      "Epoch 41/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5631 - accuracy: 0.6782 - val_loss: 0.6804 - val_accuracy: 0.6449\n",
      "Epoch 42/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5579 - accuracy: 0.6784 - val_loss: 0.7734 - val_accuracy: 0.6001\n",
      "Epoch 43/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5621 - accuracy: 0.6784 - val_loss: 0.7147 - val_accuracy: 0.6080\n",
      "Epoch 44/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5818 - accuracy: 0.6524 - val_loss: 0.7598 - val_accuracy: 0.5646\n",
      "Epoch 45/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5527 - accuracy: 0.6778 - val_loss: 0.6990 - val_accuracy: 0.6158\n",
      "Epoch 46/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5689 - accuracy: 0.6699 - val_loss: 0.6830 - val_accuracy: 0.5824\n",
      "Epoch 47/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5583 - accuracy: 0.6626 - val_loss: 0.7555 - val_accuracy: 0.5625\n",
      "Epoch 48/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5565 - accuracy: 0.6871 - val_loss: 0.8155 - val_accuracy: 0.5732\n",
      "Epoch 49/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5543 - accuracy: 0.6775 - val_loss: 0.7025 - val_accuracy: 0.6349\n",
      "Epoch 50/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5555 - accuracy: 0.6789 - val_loss: 0.6584 - val_accuracy: 0.6335\n",
      "Epoch 51/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5734 - accuracy: 0.6698 - val_loss: 0.7093 - val_accuracy: 0.5803\n",
      "Epoch 52/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5621 - accuracy: 0.6643 - val_loss: 0.7403 - val_accuracy: 0.6108\n",
      "Epoch 53/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5482 - accuracy: 0.6789 - val_loss: 0.7981 - val_accuracy: 0.6101\n",
      "Epoch 54/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5482 - accuracy: 0.6898 - val_loss: 0.7670 - val_accuracy: 0.5923\n",
      "Epoch 55/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5583 - accuracy: 0.6829 - val_loss: 0.8232 - val_accuracy: 0.6271\n",
      "Epoch 56/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5541 - accuracy: 0.6812 - val_loss: 0.6846 - val_accuracy: 0.6101\n",
      "Epoch 57/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5520 - accuracy: 0.6880 - val_loss: 0.7824 - val_accuracy: 0.5803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5329 - accuracy: 0.6963 - val_loss: 0.8689 - val_accuracy: 0.5689\n",
      "Epoch 59/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5408 - accuracy: 0.7012 - val_loss: 0.8133 - val_accuracy: 0.6108\n",
      "Epoch 60/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5362 - accuracy: 0.6984 - val_loss: 0.7854 - val_accuracy: 0.5952\n",
      "Epoch 61/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5588 - accuracy: 0.6761 - val_loss: 0.7449 - val_accuracy: 0.5312\n",
      "Epoch 62/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5283 - accuracy: 0.7008 - val_loss: 0.8885 - val_accuracy: 0.5703\n",
      "Epoch 63/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5556 - accuracy: 0.6801 - val_loss: 0.6774 - val_accuracy: 0.6385\n",
      "Epoch 64/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5250 - accuracy: 0.7070 - val_loss: 0.7173 - val_accuracy: 0.6428\n",
      "Epoch 65/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5385 - accuracy: 0.7042 - val_loss: 0.8467 - val_accuracy: 0.5930\n",
      "Epoch 66/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5332 - accuracy: 0.6986 - val_loss: 0.7313 - val_accuracy: 0.5909\n",
      "Epoch 67/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5249 - accuracy: 0.7028 - val_loss: 0.8047 - val_accuracy: 0.6250\n",
      "Epoch 68/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5285 - accuracy: 0.7012 - val_loss: 0.7426 - val_accuracy: 0.6456\n",
      "Epoch 69/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5229 - accuracy: 0.7075 - val_loss: 0.6936 - val_accuracy: 0.6136\n",
      "Epoch 70/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5211 - accuracy: 0.7029 - val_loss: 0.6520 - val_accuracy: 0.6634\n",
      "Epoch 71/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5296 - accuracy: 0.6980 - val_loss: 0.7914 - val_accuracy: 0.6065\n",
      "Epoch 72/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5346 - accuracy: 0.6935 - val_loss: 0.7932 - val_accuracy: 0.5987\n",
      "Epoch 73/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5129 - accuracy: 0.7147 - val_loss: 0.7658 - val_accuracy: 0.6442\n",
      "Epoch 74/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5167 - accuracy: 0.7140 - val_loss: 0.7652 - val_accuracy: 0.6143\n",
      "Epoch 75/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5109 - accuracy: 0.7079 - val_loss: 0.7316 - val_accuracy: 0.6349\n",
      "Epoch 76/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5316 - accuracy: 0.6896 - val_loss: 0.7543 - val_accuracy: 0.5071\n",
      "Epoch 77/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5172 - accuracy: 0.7195 - val_loss: 0.7932 - val_accuracy: 0.6271\n",
      "Epoch 78/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4997 - accuracy: 0.7263 - val_loss: 0.6732 - val_accuracy: 0.6513\n",
      "Epoch 79/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5185 - accuracy: 0.7117 - val_loss: 0.7974 - val_accuracy: 0.6286\n",
      "Epoch 80/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5159 - accuracy: 0.7140 - val_loss: 0.7766 - val_accuracy: 0.5902\n",
      "Epoch 81/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5160 - accuracy: 0.7117 - val_loss: 0.7054 - val_accuracy: 0.6385\n",
      "Epoch 82/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5130 - accuracy: 0.7079 - val_loss: 0.7573 - val_accuracy: 0.6435\n",
      "Epoch 83/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4970 - accuracy: 0.7177 - val_loss: 0.8992 - val_accuracy: 0.6023\n",
      "Epoch 84/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5196 - accuracy: 0.7123 - val_loss: 0.6996 - val_accuracy: 0.6328\n",
      "Epoch 85/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4888 - accuracy: 0.7245 - val_loss: 0.7774 - val_accuracy: 0.6222\n",
      "Epoch 86/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.5086 - accuracy: 0.7223 - val_loss: 0.8394 - val_accuracy: 0.5604\n",
      "Epoch 87/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4891 - accuracy: 0.7284 - val_loss: 0.8487 - val_accuracy: 0.6314\n",
      "Epoch 88/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4956 - accuracy: 0.7282 - val_loss: 0.7901 - val_accuracy: 0.6520\n",
      "Epoch 89/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4845 - accuracy: 0.7277 - val_loss: 0.8260 - val_accuracy: 0.6378\n",
      "Epoch 90/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4937 - accuracy: 0.7209 - val_loss: 0.8439 - val_accuracy: 0.6392\n",
      "Epoch 91/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4941 - accuracy: 0.7238 - val_loss: 0.8873 - val_accuracy: 0.6193\n",
      "Epoch 92/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.5074 - accuracy: 0.7186 - val_loss: 0.7670 - val_accuracy: 0.6108\n",
      "Epoch 93/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4865 - accuracy: 0.7282 - val_loss: 0.9025 - val_accuracy: 0.6342\n",
      "Epoch 94/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4709 - accuracy: 0.7405 - val_loss: 0.7591 - val_accuracy: 0.6207\n",
      "Epoch 95/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4877 - accuracy: 0.7388 - val_loss: 0.8966 - val_accuracy: 0.6193\n",
      "Epoch 96/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4813 - accuracy: 0.7338 - val_loss: 0.9328 - val_accuracy: 0.5859\n",
      "Epoch 97/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4681 - accuracy: 0.7467 - val_loss: 0.8449 - val_accuracy: 0.6321\n",
      "Epoch 98/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4625 - accuracy: 0.7460 - val_loss: 0.9368 - val_accuracy: 0.6243\n",
      "Epoch 99/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4850 - accuracy: 0.7316 - val_loss: 0.8173 - val_accuracy: 0.6435\n",
      "Epoch 100/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4652 - accuracy: 0.7553 - val_loss: 0.7393 - val_accuracy: 0.6577\n",
      "Epoch 101/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4782 - accuracy: 0.7389 - val_loss: 0.8984 - val_accuracy: 0.5398\n",
      "Epoch 102/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4795 - accuracy: 0.7263 - val_loss: 0.7430 - val_accuracy: 0.6229\n",
      "Epoch 103/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4659 - accuracy: 0.7489 - val_loss: 0.7351 - val_accuracy: 0.6705\n",
      "Epoch 104/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4648 - accuracy: 0.7432 - val_loss: 0.8050 - val_accuracy: 0.6307\n",
      "Epoch 105/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4475 - accuracy: 0.7654 - val_loss: 0.7943 - val_accuracy: 0.6648\n",
      "Epoch 106/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4823 - accuracy: 0.7328 - val_loss: 0.6888 - val_accuracy: 0.6697\n",
      "Epoch 107/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4798 - accuracy: 0.7298 - val_loss: 0.7028 - val_accuracy: 0.6257\n",
      "Epoch 108/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4735 - accuracy: 0.7388 - val_loss: 0.8043 - val_accuracy: 0.6690\n",
      "Epoch 109/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4393 - accuracy: 0.7625 - val_loss: 0.8047 - val_accuracy: 0.6641\n",
      "Epoch 110/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4635 - accuracy: 0.7421 - val_loss: 0.9193 - val_accuracy: 0.6229\n",
      "Epoch 111/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4552 - accuracy: 0.7512 - val_loss: 0.8577 - val_accuracy: 0.6406\n",
      "Epoch 112/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4517 - accuracy: 0.7496 - val_loss: 0.8485 - val_accuracy: 0.6321\n",
      "Epoch 113/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4661 - accuracy: 0.7551 - val_loss: 0.8730 - val_accuracy: 0.6435\n",
      "Epoch 114/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4310 - accuracy: 0.7676 - val_loss: 1.1219 - val_accuracy: 0.6143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4452 - accuracy: 0.7662 - val_loss: 0.7794 - val_accuracy: 0.6570\n",
      "Epoch 116/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4755 - accuracy: 0.7400 - val_loss: 0.8387 - val_accuracy: 0.6584\n",
      "Epoch 117/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4333 - accuracy: 0.7646 - val_loss: 0.9805 - val_accuracy: 0.6378\n",
      "Epoch 118/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4678 - accuracy: 0.7432 - val_loss: 0.9217 - val_accuracy: 0.5092\n",
      "Epoch 119/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4376 - accuracy: 0.7588 - val_loss: 0.8825 - val_accuracy: 0.6456\n",
      "Epoch 120/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4342 - accuracy: 0.7711 - val_loss: 1.0286 - val_accuracy: 0.6165\n",
      "Epoch 121/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4372 - accuracy: 0.7640 - val_loss: 0.7547 - val_accuracy: 0.6534\n",
      "Epoch 122/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4406 - accuracy: 0.7654 - val_loss: 0.8901 - val_accuracy: 0.6399\n",
      "Epoch 123/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4377 - accuracy: 0.7709 - val_loss: 0.9510 - val_accuracy: 0.6158\n",
      "Epoch 124/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4386 - accuracy: 0.7602 - val_loss: 0.9026 - val_accuracy: 0.6669\n",
      "Epoch 125/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4294 - accuracy: 0.7705 - val_loss: 0.9805 - val_accuracy: 0.6286\n",
      "Epoch 126/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4283 - accuracy: 0.7781 - val_loss: 0.9949 - val_accuracy: 0.6321\n",
      "Epoch 127/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4109 - accuracy: 0.7858 - val_loss: 0.8762 - val_accuracy: 0.6705\n",
      "Epoch 128/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4165 - accuracy: 0.7865 - val_loss: 1.0015 - val_accuracy: 0.6740\n",
      "Epoch 129/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4312 - accuracy: 0.7805 - val_loss: 0.8023 - val_accuracy: 0.6420\n",
      "Epoch 130/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4141 - accuracy: 0.7797 - val_loss: 0.9322 - val_accuracy: 0.6406\n",
      "Epoch 131/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4119 - accuracy: 0.7902 - val_loss: 0.9254 - val_accuracy: 0.6435\n",
      "Epoch 132/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4121 - accuracy: 0.7827 - val_loss: 1.0511 - val_accuracy: 0.5604\n",
      "Epoch 133/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3934 - accuracy: 0.7963 - val_loss: 1.0532 - val_accuracy: 0.6385\n",
      "Epoch 134/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3980 - accuracy: 0.7914 - val_loss: 1.0260 - val_accuracy: 0.6676\n",
      "Epoch 135/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4114 - accuracy: 0.7781 - val_loss: 0.9223 - val_accuracy: 0.6520\n",
      "Epoch 136/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3847 - accuracy: 0.7958 - val_loss: 1.2366 - val_accuracy: 0.6222\n",
      "Epoch 137/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.4126 - accuracy: 0.7856 - val_loss: 0.9190 - val_accuracy: 0.6527\n",
      "Epoch 138/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3897 - accuracy: 0.8021 - val_loss: 1.1431 - val_accuracy: 0.6385\n",
      "Epoch 139/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.3892 - accuracy: 0.7979 - val_loss: 1.0559 - val_accuracy: 0.6484\n",
      "Epoch 140/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3928 - accuracy: 0.7962 - val_loss: 0.9506 - val_accuracy: 0.6371\n",
      "Epoch 141/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4043 - accuracy: 0.7930 - val_loss: 1.1973 - val_accuracy: 0.6271\n",
      "Epoch 142/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3757 - accuracy: 0.8107 - val_loss: 1.0913 - val_accuracy: 0.6257\n",
      "Epoch 143/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3681 - accuracy: 0.8132 - val_loss: 1.3172 - val_accuracy: 0.6477\n",
      "Epoch 144/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3761 - accuracy: 0.8069 - val_loss: 0.8396 - val_accuracy: 0.6001\n",
      "Epoch 145/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3935 - accuracy: 0.7963 - val_loss: 1.2387 - val_accuracy: 0.6300\n",
      "Epoch 146/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3784 - accuracy: 0.8055 - val_loss: 1.0203 - val_accuracy: 0.6463\n",
      "Epoch 147/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.4110 - accuracy: 0.7900 - val_loss: 1.0213 - val_accuracy: 0.6342\n",
      "Epoch 148/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3778 - accuracy: 0.7985 - val_loss: 1.1104 - val_accuracy: 0.6577\n",
      "Epoch 149/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3590 - accuracy: 0.8200 - val_loss: 0.9432 - val_accuracy: 0.6683\n",
      "Epoch 150/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3754 - accuracy: 0.8041 - val_loss: 0.9151 - val_accuracy: 0.6825ccura\n",
      "Epoch 151/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3667 - accuracy: 0.8020 - val_loss: 1.1476 - val_accuracy: 0.6655\n",
      "Epoch 152/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3553 - accuracy: 0.8290 - val_loss: 1.2690 - val_accuracy: 0.6307\n",
      "Epoch 153/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3709 - accuracy: 0.8046 - val_loss: 1.1655 - val_accuracy: 0.6683\n",
      "Epoch 154/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3669 - accuracy: 0.8186 - val_loss: 1.0990 - val_accuracy: 0.6399\n",
      "Epoch 155/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3637 - accuracy: 0.8153 - val_loss: 0.9538 - val_accuracy: 0.6499\n",
      "Epoch 156/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3838 - accuracy: 0.8025 - val_loss: 1.2756 - val_accuracy: 0.6577\n",
      "Epoch 157/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3849 - accuracy: 0.8050 - val_loss: 0.9652 - val_accuracy: 0.6463\n",
      "Epoch 158/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.3942 - accuracy: 0.8011 - val_loss: 0.9464 - val_accuracy: 0.6307\n",
      "Epoch 159/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.3826 - accuracy: 0.7960 - val_loss: 0.9659 - val_accuracy: 0.6371\n",
      "Epoch 160/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3590 - accuracy: 0.8083 - val_loss: 1.0811 - val_accuracy: 0.6243\n",
      "Epoch 161/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3487 - accuracy: 0.8225 - val_loss: 1.1106 - val_accuracy: 0.6712\n",
      "Epoch 162/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3658 - accuracy: 0.8243 - val_loss: 0.8273 - val_accuracy: 0.5852\n",
      "Epoch 163/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3821 - accuracy: 0.7992 - val_loss: 1.0633 - val_accuracy: 0.6662\n",
      "Epoch 164/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3688 - accuracy: 0.8113 - val_loss: 1.0110 - val_accuracy: 0.6719\n",
      "Epoch 165/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3352 - accuracy: 0.8269 - val_loss: 1.2037 - val_accuracy: 0.6314\n",
      "Epoch 166/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3413 - accuracy: 0.8274 - val_loss: 0.9904 - val_accuracy: 0.6541\n",
      "Epoch 167/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3437 - accuracy: 0.8308 - val_loss: 1.2327 - val_accuracy: 0.6591\n",
      "Epoch 168/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3300 - accuracy: 0.8364 - val_loss: 1.5049 - val_accuracy: 0.6413\n",
      "Epoch 169/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3758 - accuracy: 0.8146 - val_loss: 1.0290 - val_accuracy: 0.6669\n",
      "Epoch 170/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3358 - accuracy: 0.8316 - val_loss: 1.0462 - val_accuracy: 0.6513\n",
      "Epoch 171/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3416 - accuracy: 0.8276 - val_loss: 1.2146 - val_accuracy: 0.6527\n",
      "Epoch 172/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3257 - accuracy: 0.8409 - val_loss: 1.1686 - val_accuracy: 0.6946\n",
      "Epoch 173/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3385 - accuracy: 0.8278 - val_loss: 1.2060 - val_accuracy: 0.6804\n",
      "Epoch 174/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3211 - accuracy: 0.8330 - val_loss: 1.2171 - val_accuracy: 0.6470\n",
      "Epoch 175/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3278 - accuracy: 0.8357 - val_loss: 1.2668 - val_accuracy: 0.6626\n",
      "Epoch 176/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3348 - accuracy: 0.8394 - val_loss: 1.2269 - val_accuracy: 0.6648\n",
      "Epoch 177/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3399 - accuracy: 0.8288 - val_loss: 1.2374 - val_accuracy: 0.6669\n",
      "Epoch 178/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3142 - accuracy: 0.8455 - val_loss: 1.2959 - val_accuracy: 0.6747\n",
      "Epoch 179/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3396 - accuracy: 0.8272 - val_loss: 1.0984 - val_accuracy: 0.6967\n",
      "Epoch 180/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3193 - accuracy: 0.8294 - val_loss: 1.1840 - val_accuracy: 0.6470\n",
      "Epoch 181/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2958 - accuracy: 0.8492 - val_loss: 1.1065 - val_accuracy: 0.7116\n",
      "Epoch 182/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3065 - accuracy: 0.8513 - val_loss: 1.4559 - val_accuracy: 0.6605\n",
      "Epoch 183/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3316 - accuracy: 0.8325 - val_loss: 1.3972 - val_accuracy: 0.6662\n",
      "Epoch 184/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2879 - accuracy: 0.8606 - val_loss: 1.3243 - val_accuracy: 0.6634\n",
      "Epoch 185/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2946 - accuracy: 0.8485 - val_loss: 1.4562 - val_accuracy: 0.6875\n",
      "Epoch 186/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3287 - accuracy: 0.8337 - val_loss: 1.2524 - val_accuracy: 0.6662\n",
      "Epoch 187/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2816 - accuracy: 0.8629 - val_loss: 1.4332 - val_accuracy: 0.6797\n",
      "Epoch 188/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2836 - accuracy: 0.8618 - val_loss: 1.5956 - val_accuracy: 0.6669\n",
      "Epoch 189/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2932 - accuracy: 0.8524 - val_loss: 1.3102 - val_accuracy: 0.6804\n",
      "Epoch 190/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3157 - accuracy: 0.8452 - val_loss: 1.5820 - val_accuracy: 0.6641\n",
      "Epoch 191/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3445 - accuracy: 0.8309 - val_loss: 1.3554 - val_accuracy: 0.6776\n",
      "Epoch 192/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2920 - accuracy: 0.8574 - val_loss: 1.5187 - val_accuracy: 0.6626\n",
      "Epoch 193/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2622 - accuracy: 0.8741 - val_loss: 1.5240 - val_accuracy: 0.6541\n",
      "Epoch 194/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2773 - accuracy: 0.8583 - val_loss: 1.1598 - val_accuracy: 0.6641\n",
      "Epoch 195/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2800 - accuracy: 0.8631 - val_loss: 1.5966 - val_accuracy: 0.6868\n",
      "Epoch 196/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.3093 - accuracy: 0.8548 - val_loss: 0.9967 - val_accuracy: 0.6854\n",
      "Epoch 197/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2710 - accuracy: 0.8669 - val_loss: 1.4265 - val_accuracy: 0.6790\n",
      "Epoch 198/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3032 - accuracy: 0.8557 - val_loss: 1.1234 - val_accuracy: 0.7024\n",
      "Epoch 199/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.2917 - accuracy: 0.8587 - val_loss: 1.1655 - val_accuracy: 0.6982ccuracy: \n",
      "Epoch 200/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2838 - accuracy: 0.8622 - val_loss: 1.5363 - val_accuracy: 0.6690\n",
      "Epoch 201/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2596 - accuracy: 0.8754 - val_loss: 1.4546 - val_accuracy: 0.7074\n",
      "Epoch 202/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2546 - accuracy: 0.8771 - val_loss: 1.7843 - val_accuracy: 0.6797\n",
      "Epoch 203/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2750 - accuracy: 0.8676 - val_loss: 1.4578 - val_accuracy: 0.6918\n",
      "Epoch 204/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2724 - accuracy: 0.8699 - val_loss: 1.2661 - val_accuracy: 0.7116\n",
      "Epoch 205/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2756 - accuracy: 0.8669 - val_loss: 1.4587 - val_accuracy: 0.6925\n",
      "Epoch 206/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2786 - accuracy: 0.8583 - val_loss: 1.9856 - val_accuracy: 0.6371\n",
      "Epoch 207/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2870 - accuracy: 0.8689 - val_loss: 1.3368 - val_accuracy: 0.6889\n",
      "Epoch 208/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2527 - accuracy: 0.8796 - val_loss: 1.4433 - val_accuracy: 0.6719\n",
      "Epoch 209/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2891 - accuracy: 0.8578 - val_loss: 1.7040 - val_accuracy: 0.6690\n",
      "Epoch 210/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2529 - accuracy: 0.8782 - val_loss: 1.1905 - val_accuracy: 0.6250\n",
      "Epoch 211/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2432 - accuracy: 0.8847 - val_loss: 1.5303 - val_accuracy: 0.6598\n",
      "Epoch 212/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2422 - accuracy: 0.8859 - val_loss: 1.4896 - val_accuracy: 0.7017\n",
      "Epoch 213/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2873 - accuracy: 0.8620 - val_loss: 1.4971 - val_accuracy: 0.7003\n",
      "Epoch 214/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2524 - accuracy: 0.8789 - val_loss: 1.5467 - val_accuracy: 0.7003\n",
      "Epoch 215/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2590 - accuracy: 0.8766 - val_loss: 1.8566 - val_accuracy: 0.6776\n",
      "Epoch 216/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2328 - accuracy: 0.8882 - val_loss: 1.6517 - val_accuracy: 0.6747\n",
      "Epoch 217/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2486 - accuracy: 0.8845 - val_loss: 1.3221 - val_accuracy: 0.7081\n",
      "Epoch 218/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2479 - accuracy: 0.8822 - val_loss: 1.3804 - val_accuracy: 0.7024\n",
      "Epoch 219/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2385 - accuracy: 0.8836 - val_loss: 1.9281 - val_accuracy: 0.6747\n",
      "Epoch 220/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2590 - accuracy: 0.8854 - val_loss: 1.6169 - val_accuracy: 0.6868\n",
      "Epoch 221/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2486 - accuracy: 0.8827 - val_loss: 1.4971 - val_accuracy: 0.6982\n",
      "Epoch 222/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2433 - accuracy: 0.8840 - val_loss: 1.5199 - val_accuracy: 0.7024\n",
      "Epoch 223/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2353 - accuracy: 0.8890 - val_loss: 1.6304 - val_accuracy: 0.7017\n",
      "Epoch 224/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2906 - accuracy: 0.8611 - val_loss: 1.3516 - val_accuracy: 0.6839\n",
      "Epoch 225/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2600 - accuracy: 0.8706 - val_loss: 1.5988 - val_accuracy: 0.7010\n",
      "Epoch 226/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2296 - accuracy: 0.8926 - val_loss: 1.8321 - val_accuracy: 0.6854\n",
      "Epoch 227/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2332 - accuracy: 0.8885 - val_loss: 1.3677 - val_accuracy: 0.6861\n",
      "Epoch 228/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2309 - accuracy: 0.8897 - val_loss: 1.8381 - val_accuracy: 0.6783\n",
      "Epoch 229/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2661 - accuracy: 0.8748 - val_loss: 1.6063 - val_accuracy: 0.6918\n",
      "Epoch 230/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2203 - accuracy: 0.8982 - val_loss: 1.9281 - val_accuracy: 0.6925\n",
      "Epoch 231/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2646 - accuracy: 0.8666 - val_loss: 1.3437 - val_accuracy: 0.7053\n",
      "Epoch 232/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2254 - accuracy: 0.8933 - val_loss: 1.7508 - val_accuracy: 0.6754\n",
      "Epoch 233/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2236 - accuracy: 0.8927 - val_loss: 1.6655 - val_accuracy: 0.7188\n",
      "Epoch 234/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1987 - accuracy: 0.9106 - val_loss: 1.6345 - val_accuracy: 0.7230\n",
      "Epoch 235/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2483 - accuracy: 0.8780 - val_loss: 1.5179 - val_accuracy: 0.7131\n",
      "Epoch 236/1200\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 0.2207 - accuracy: 0.8920 - val_loss: 1.4753 - val_accuracy: 0.7145\n",
      "Epoch 237/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2222 - accuracy: 0.8924 - val_loss: 1.5185 - val_accuracy: 0.7010\n",
      "Epoch 238/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2087 - accuracy: 0.9050 - val_loss: 1.6674 - val_accuracy: 0.6761\n",
      "Epoch 239/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2031 - accuracy: 0.9098 - val_loss: 1.7110 - val_accuracy: 0.7053\n",
      "Epoch 240/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1990 - accuracy: 0.9071 - val_loss: 2.2394 - val_accuracy: 0.6882\n",
      "Epoch 241/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2123 - accuracy: 0.9022 - val_loss: 2.1316 - val_accuracy: 0.6932\n",
      "Epoch 242/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2210 - accuracy: 0.8966 - val_loss: 2.1042 - val_accuracy: 0.6967\n",
      "Epoch 243/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2193 - accuracy: 0.8934 - val_loss: 1.6182 - val_accuracy: 0.7124\n",
      "Epoch 244/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2165 - accuracy: 0.9005 - val_loss: 1.9879 - val_accuracy: 0.6989\n",
      "Epoch 245/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1940 - accuracy: 0.9134 - val_loss: 1.8609 - val_accuracy: 0.6690\n",
      "Epoch 246/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1936 - accuracy: 0.9117 - val_loss: 2.0730 - val_accuracy: 0.7102\n",
      "Epoch 247/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2137 - accuracy: 0.9048 - val_loss: 1.7051 - val_accuracy: 0.6953\n",
      "Epoch 248/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1933 - accuracy: 0.9110 - val_loss: 1.8213 - val_accuracy: 0.6918\n",
      "Epoch 249/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1942 - accuracy: 0.9152 - val_loss: 1.8383 - val_accuracy: 0.6989\n",
      "Epoch 250/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1843 - accuracy: 0.9154 - val_loss: 1.8374 - val_accuracy: 0.7081\n",
      "Epoch 251/1200\n",
      "89/89 [==============================] - 5s 58ms/step - loss: 0.1941 - accuracy: 0.9142 - val_loss: 1.8196 - val_accuracy: 0.6804\n",
      "Epoch 252/1200\n",
      "89/89 [==============================] - 4s 48ms/step - loss: 0.1704 - accuracy: 0.9257 - val_loss: 2.0197 - val_accuracy: 0.6712\n",
      "Epoch 253/1200\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.1923 - accuracy: 0.9129 - val_loss: 1.6020 - val_accuracy: 0.6925\n",
      "Epoch 254/1200\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.2233 - accuracy: 0.9001 - val_loss: 1.6064 - val_accuracy: 0.6768\n",
      "Epoch 255/1200\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.1876 - accuracy: 0.9140 - val_loss: 1.8714 - val_accuracy: 0.7301\n",
      "Epoch 256/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.3405 - accuracy: 0.8504 - val_loss: 0.9905 - val_accuracy: 0.6044\n",
      "Epoch 257/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.3953 - accuracy: 0.8107 - val_loss: 1.2684 - val_accuracy: 0.6555\n",
      "Epoch 258/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.2281 - accuracy: 0.8996 - val_loss: 1.4681 - val_accuracy: 0.6918\n",
      "Epoch 259/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.2097 - accuracy: 0.9068 - val_loss: 1.8886 - val_accuracy: 0.6797\n",
      "Epoch 260/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2454 - accuracy: 0.8855 - val_loss: 1.4603 - val_accuracy: 0.6953\n",
      "Epoch 261/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2353 - accuracy: 0.8838 - val_loss: 1.4054 - val_accuracy: 0.7202\n",
      "Epoch 262/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.2025 - accuracy: 0.9080 - val_loss: 1.4937 - val_accuracy: 0.7102\n",
      "Epoch 263/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1891 - accuracy: 0.9171 - val_loss: 1.8248 - val_accuracy: 0.6889\n",
      "Epoch 264/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1692 - accuracy: 0.9261 - val_loss: 2.0156 - val_accuracy: 0.6953\n",
      "Epoch 265/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.2111 - accuracy: 0.8976 - val_loss: 1.5521 - val_accuracy: 0.6974\n",
      "Epoch 266/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1941 - accuracy: 0.9077 - val_loss: 1.7048 - val_accuracy: 0.7216\n",
      "Epoch 267/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1742 - accuracy: 0.9222 - val_loss: 1.7191 - val_accuracy: 0.708801 - \n",
      "Epoch 268/1200\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 0.1894 - accuracy: 0.9140 - val_loss: 1.8687 - val_accuracy: 0.6960\n",
      "Epoch 269/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1755 - accuracy: 0.9199 - val_loss: 1.9080 - val_accuracy: 0.7166\n",
      "Epoch 270/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1877 - accuracy: 0.9133 - val_loss: 1.8258 - val_accuracy: 0.7024\n",
      "Epoch 271/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1870 - accuracy: 0.9112 - val_loss: 2.1395 - val_accuracy: 0.7060\n",
      "Epoch 272/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1615 - accuracy: 0.9300 - val_loss: 1.6593 - val_accuracy: 0.7173\n",
      "Epoch 273/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1572 - accuracy: 0.9268 - val_loss: 2.1640 - val_accuracy: 0.7131\n",
      "Epoch 274/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.2251 - accuracy: 0.9052 - val_loss: 1.6139 - val_accuracy: 0.7003\n",
      "Epoch 275/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1677 - accuracy: 0.9224 - val_loss: 1.8394 - val_accuracy: 0.7166\n",
      "Epoch 276/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1682 - accuracy: 0.9212 - val_loss: 2.0827 - val_accuracy: 0.7010\n",
      "Epoch 277/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1772 - accuracy: 0.9192 - val_loss: 2.1539 - val_accuracy: 0.6790\n",
      "Epoch 278/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1730 - accuracy: 0.9228 - val_loss: 1.5957 - val_accuracy: 0.6832\n",
      "Epoch 279/1200\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.1712 - accuracy: 0.9236 - val_loss: 1.9493 - val_accuracy: 0.6953\n",
      "Epoch 280/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1520 - accuracy: 0.9314 - val_loss: 2.4464 - val_accuracy: 0.7088\n",
      "Epoch 281/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1674 - accuracy: 0.9259 - val_loss: 2.1552 - val_accuracy: 0.7074\n",
      "Epoch 282/1200\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.1458 - accuracy: 0.9349 - val_loss: 2.2245 - val_accuracy: 0.7365\n",
      "Epoch 283/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1458 - accuracy: 0.9326 - val_loss: 2.0885 - val_accuracy: 0.7152\n",
      "Epoch 284/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1798 - accuracy: 0.9199 - val_loss: 1.8596 - val_accuracy: 0.7024\n",
      "Epoch 285/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1535 - accuracy: 0.9310 - val_loss: 2.0458 - val_accuracy: 0.7038\n",
      "Epoch 286/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1991 - accuracy: 0.9078 - val_loss: 1.6156 - val_accuracy: 0.7180\n",
      "Epoch 287/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1670 - accuracy: 0.9238 - val_loss: 2.0494 - val_accuracy: 0.7038\n",
      "Epoch 288/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.2136 - accuracy: 0.9034 - val_loss: 1.4716 - val_accuracy: 0.7195\n",
      "Epoch 289/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1905 - accuracy: 0.9036 - val_loss: 2.5106 - val_accuracy: 0.6783\n",
      "Epoch 290/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1940 - accuracy: 0.9145 - val_loss: 1.9425 - val_accuracy: 0.7259\n",
      "Epoch 291/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1532 - accuracy: 0.9350 - val_loss: 1.7171 - val_accuracy: 0.7330\n",
      "Epoch 292/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1489 - accuracy: 0.9405 - val_loss: 1.8867 - val_accuracy: 0.7251\n",
      "Epoch 293/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1585 - accuracy: 0.9331 - val_loss: 2.1068 - val_accuracy: 0.6861\n",
      "Epoch 294/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1563 - accuracy: 0.9303 - val_loss: 2.0059 - val_accuracy: 0.7266\n",
      "Epoch 295/1200\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.1355 - accuracy: 0.9391 - val_loss: 1.9750 - val_accuracy: 0.7060\n",
      "Epoch 296/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1454 - accuracy: 0.9386 - val_loss: 2.5443 - val_accuracy: 0.7145\n",
      "Epoch 297/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1495 - accuracy: 0.9324 - val_loss: 2.1958 - val_accuracy: 0.7138\n",
      "Epoch 298/1200\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 0.1254 - accuracy: 0.9458 - val_loss: 2.7409 - val_accuracy: 0.6697\n",
      "Epoch 299/1200\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 0.1408 - accuracy: 0.9379 - val_loss: 2.7910 - val_accuracy: 0.6982\n",
      "Epoch 300/1200\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.9349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|                                         | 1/2 [51:51<51:51, 3111.74s/it]\n",
      "  2%|                                                                         | 2/90 [2:52:46<126:41:46, 5183.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20792/2711303082.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloadTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msampleSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstepValidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                     epochs=1200,callbacks=[early_stopping])#,\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1223\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1225\u001b[1;33m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[0;32m   1226\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "dt = 0.05\n",
    "dfrigor = pd.DataFrame(columns=['itr'])\n",
    "\n",
    "modelName = 'retesting_v5n_allSplits'\n",
    "batchSize = 64\n",
    "sampleSize = batchSize//2\n",
    "classes=['Healthy','Acute']\n",
    "\n",
    "# os.mkdir('E:\\\\NN\\\\confusionMatrices\\\\retestingLFPv5n')\n",
    "folder = 'confusionMatrices\\\\retestingLFPv5n\\\\' \n",
    "comb_List = []\n",
    "comb = combinations(miceList, 2)\n",
    "for i in tqdm(comb):\n",
    "    comb_List.append(i)\n",
    "\n",
    "fpr = []\n",
    "tpr = []\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,\n",
    "    patience=100,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "for i in tqdm(comb_List[1:]):\n",
    "    \n",
    "    trainData,testData = dataSplits(i) \n",
    "            \n",
    "    for l in tqdm(range(2)): # 5-fold cross validation\n",
    "        results = {'Test':{},'Train':{},'Val':{}}\n",
    "        \n",
    "        valData = trainData.iloc[(len(trainData)//5)*l:(len(trainData)//5)*(l+1)]\n",
    "        trainData = trainData.drop(valData.index)\n",
    "\n",
    "        stepTrain=len(trainData)//batchSize\n",
    "        stepValidate=len(valData)//batchSize\n",
    "\n",
    "        model =  tf.keras.models.load_model('E:\\\\rawLFP_v5n_tunning_binary')\n",
    "        model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "        # model.load_weights('E:\\\\'+modelName+'_bestWeights.h5')\n",
    "        \n",
    "        history = model.fit(loadTrain(trainData,sampleSize),\n",
    "                    steps_per_epoch=stepTrain,\n",
    "                    validation_data=loadTrain(validate,sampleSize),\n",
    "                    validation_steps=stepValidate,\n",
    "                    epochs=1200,callbacks=[early_stopping])#,\n",
    "\n",
    "        \n",
    "        plotHistory(history,folder+modelName,str(l),i)\n",
    "        #  test and save scores\n",
    "        \n",
    "        y = []\n",
    "        for ind,(dataP,label) in enumerate(loadTest(testData)):\n",
    "            y = y+list(np.argmax(label,axis=1))\n",
    "\n",
    "        pred = model.predict_generator(loadTest(testData),verbose=1)\n",
    "\n",
    "        fpr_t , tpr_t , thresholds = roc_curve ( y , pred[:,1])\n",
    "        fpr.append(fpr_t)\n",
    "        tpr.append(tpr_t)\n",
    "\n",
    "        pred = np.argmax(pred, axis = 1)\n",
    "        plotConfusionMatrix(y,pred,folder+str(l)+modelName+\"_\"+str(i[0])+\"_\"+str(i[1]), 'test')\n",
    "        y = np.array(y)\n",
    "        results['Test']['Acc'] = (np.sum(y==pred)/len(y))\n",
    "        results['Test']['Sen'] = (np.sum(y*pred)/sum(y))\n",
    "        results['Test']['Spe'] = np.sum(1*(y == pred)*(y==0))/sum(y==0)\n",
    "        results['Test']['AUC'] = auc(fpr_t, tpr_t)\n",
    "\n",
    "        y = []\n",
    "        for ind,(dataP,label) in enumerate(loadTest(trainData)):\n",
    "            y = y+list(np.argmax(label,axis=1))\n",
    "\n",
    "        pred = model.predict_generator(loadTest(trainData),verbose=1)\n",
    "        pred = np.argmax(pred, axis = 1)\n",
    "\n",
    "        plotConfusionMatrix(y,pred,folder+str(l)+modelName+\"_\"+str(i[0])+\"_\"+str(i[1]), 'train')\n",
    "        y = np.array(y)\n",
    "        results['Train']['Acc'] = (np.sum(y==pred)/len(y))\n",
    "        results['Train']['Sen'] = (np.sum(y*pred)/sum(y))\n",
    "        results['Train']['Spe'] = np.sum(1*(y == pred)*(y==0))/sum(y==0)\n",
    "\n",
    "        y = []\n",
    "        for ind,(dataP,label) in enumerate(loadTest(valData)):\n",
    "            y = y+list(np.argmax(label,axis=1))\n",
    "\n",
    "        pred = model.predict_generator(loadTest(valData),verbose=1)\n",
    "        pred = np.argmax(pred, axis = 1)\n",
    "\n",
    "        plotConfusionMatrix(y,pred,folder+str(l)+modelName+\"_\"+str(i[0])+\"_\"+str(i[1]), 'val')\n",
    "        y = np.array(y)\n",
    "        results['Val']['Acc'] = (np.sum(y==pred)/len(y))\n",
    "        results['Val']['Sen'] = (np.sum(y*pred)/sum(y))\n",
    "        results['Val']['Spe'] = np.sum(1*(y == pred)*(y==0))/sum(y==0)\n",
    "\n",
    "        del model\n",
    "\n",
    "\n",
    "        for spl in ['Test','Train','Val']:\n",
    "            dfrow = pd.DataFrame(results[spl],index=[0])\n",
    "            dfrow['split'] = spl\n",
    "            dfrow['itr'] = l\n",
    "            dfrow['i'] = str(i)\n",
    "            dfrigor = pd.concat([dfrigor,dfrow])\n",
    "            \n",
    "plotROC(fpr,tpr,\"section3_AUC_LFP_retrain\")\n",
    "\n",
    "dfrigor.to_csv(\"E:\\\\NN\\\\results_LFP_retrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "56f73458",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotROC(fpr,tpr,\"section3_AUC_LFP_retrain\")\n",
    "\n",
    "dfrigor.to_csv(\"E:\\\\NN\\\\results_LFP_retrain.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f98596",
   "metadata": {},
   "source": [
    "before that looking at test dataset/split - do a 10 fold cross validation on all data...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c0379e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "438/438 [==============================] - 16s 34ms/step - loss: 0.6925 - accuracy: 0.5122 - val_loss: 0.6927 - val_accuracy: 0.4909\n",
      "Epoch 2/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6902 - accuracy: 0.5319 - val_loss: 0.6930 - val_accuracy: 0.4967\n",
      "Epoch 3/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6853 - accuracy: 0.5539 - val_loss: 0.6955 - val_accuracy: 0.5072\n",
      "Epoch 4/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6792 - accuracy: 0.5627 - val_loss: 0.6920 - val_accuracy: 0.5107- accuracy: 0. - ETA: \n",
      "Epoch 5/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6738 - accuracy: 0.5684 - val_loss: 0.6971 - val_accuracy: 0.5016\n",
      "Epoch 6/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6705 - accuracy: 0.5648 - val_loss: 0.6838 - val_accuracy: 0.5176\n",
      "Epoch 7/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6664 - accuracy: 0.5745 - val_loss: 0.6860 - val_accuracy: 0.5303\n",
      "Epoch 8/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6661 - accuracy: 0.5725 - val_loss: 0.6839 - val_accuracy: 0.5547\n",
      "Epoch 9/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6616 - accuracy: 0.5798 - val_loss: 0.6764 - val_accuracy: 0.5661\n",
      "Epoch 10/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6614 - accuracy: 0.5777 - val_loss: 0.6762 - val_accuracy: 0.5521\n",
      "Epoch 11/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6609 - accuracy: 0.5807 - val_loss: 0.6997 - val_accuracy: 0.5452\n",
      "Epoch 12/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6581 - accuracy: 0.5835 - val_loss: 0.7000 - val_accuracy: 0.522557 - ETA: 0s - loss: 0.6580 - accuracy: 0.58\n",
      "Epoch 13/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6566 - accuracy: 0.5922 - val_loss: 0.6822 - val_accuracy: 0.5378\n",
      "Epoch 14/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6540 - accuracy: 0.5935 - val_loss: 0.6796 - val_accuracy: 0.5628\n",
      "Epoch 15/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6515 - accuracy: 0.5954 - val_loss: 0.6918 - val_accuracy: 0.5459\n",
      "Epoch 16/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6505 - accuracy: 0.5980 - val_loss: 0.6733 - val_accuracy: 0.5417\n",
      "Epoch 17/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6496 - accuracy: 0.5974 - val_loss: 0.6953 - val_accuracy: 0.5042\n",
      "Epoch 18/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6470 - accuracy: 0.5995 - val_loss: 0.7040 - val_accuracy: 0.5176\n",
      "Epoch 19/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6441 - accuracy: 0.6041 - val_loss: 0.6909 - val_accuracy: 0.4997\n",
      "Epoch 20/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6422 - accuracy: 0.6060 - val_loss: 0.7084 - val_accuracy: 0.5088\n",
      "Epoch 21/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6402 - accuracy: 0.6089 - val_loss: 0.6818 - val_accuracy: 0.5544\n",
      "Epoch 22/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6372 - accuracy: 0.6104 - val_loss: 0.7332 - val_accuracy: 0.5033\n",
      "Epoch 23/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6372 - accuracy: 0.6136 - val_loss: 0.6891 - val_accuracy: 0.5469\n",
      "Epoch 24/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6402 - accuracy: 0.6077 - val_loss: 0.7010 - val_accuracy: 0.5153\n",
      "Epoch 25/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6378 - accuracy: 0.6035 - val_loss: 0.6843 - val_accuracy: 0.5339\n",
      "Epoch 26/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6398 - accuracy: 0.6070 - val_loss: 0.6707 - val_accuracy: 0.5527\n",
      "Epoch 27/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6361 - accuracy: 0.6142 - val_loss: 0.6687 - val_accuracy: 0.5573\n",
      "Epoch 28/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6358 - accuracy: 0.6094 - val_loss: 0.6675 - val_accuracy: 0.5788\n",
      "Epoch 29/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6357 - accuracy: 0.6158 - val_loss: 0.6922 - val_accuracy: 0.5277\n",
      "Epoch 30/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6307 - accuracy: 0.6205 - val_loss: 0.6551 - val_accuracy: 0.6016\n",
      "Epoch 31/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6334 - accuracy: 0.6150 - val_loss: 0.6714 - val_accuracy: 0.5602\n",
      "Epoch 32/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6314 - accuracy: 0.6194 - val_loss: 0.6580 - val_accuracy: 0.5869\n",
      "Epoch 33/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6260 - accuracy: 0.6243 - val_loss: 0.6640 - val_accuracy: 0.5684\n",
      "Epoch 34/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6305 - accuracy: 0.6162 - val_loss: 0.6509 - val_accuracy: 0.5859s: 0.6306 -  - ETA: 5s - loss: 0.6309 - accura - ETA\n",
      "Epoch 35/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6269 - accuracy: 0.6165 - val_loss: 0.6482 - val_accuracy: 0.6195\n",
      "Epoch 36/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6235 - accuracy: 0.6270 - val_loss: 0.6464 - val_accuracy: 0.6133\n",
      "Epoch 37/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6239 - accuracy: 0.6219 - val_loss: 0.7243 - val_accuracy: 0.5156\n",
      "Epoch 38/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6229 - accuracy: 0.6236 - val_loss: 0.6431 - val_accuracy: 0.6149\n",
      "Epoch 39/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6236 - accuracy: 0.6236 - val_loss: 0.6268 - val_accuracy: 0.6377\n",
      "Epoch 40/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6223 - accuracy: 0.6249 - val_loss: 0.6502 - val_accuracy: 0.5938\n",
      "Epoch 41/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6211 - accuracy: 0.6322 - val_loss: 0.6451 - val_accuracy: 0.6048\n",
      "Epoch 42/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6196 - accuracy: 0.6256 - val_loss: 0.6519 - val_accuracy: 0.5999\n",
      "Epoch 43/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6141 - accuracy: 0.6284 - val_loss: 0.6495 - val_accuracy: 0.6139\n",
      "Epoch 44/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6161 - accuracy: 0.6340 - val_loss: 0.6494 - val_accuracy: 0.5915\n",
      "Epoch 45/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6140 - accuracy: 0.6343 - val_loss: 0.6294 - val_accuracy: 0.6191\n",
      "Epoch 46/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6140 - accuracy: 0.6320 - val_loss: 0.6671 - val_accuracy: 0.6035\n",
      "Epoch 47/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6137 - accuracy: 0.6335 - val_loss: 0.6179 - val_accuracy: 0.6370\n",
      "Epoch 48/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6073 - accuracy: 0.6363 - val_loss: 0.6305 - val_accuracy: 0.6380\n",
      "Epoch 49/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6106 - accuracy: 0.6396 - val_loss: 0.6306 - val_accuracy: 0.6234\n",
      "Epoch 50/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6075 - accuracy: 0.6399 - val_loss: 0.6312 - val_accuracy: 0.6328\n",
      "Epoch 51/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6069 - accuracy: 0.6366 - val_loss: 0.6530 - val_accuracy: 0.5791\n",
      "Epoch 52/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6080 - accuracy: 0.6358 - val_loss: 0.6126 - val_accuracy: 0.6419\n",
      "Epoch 53/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6052 - accuracy: 0.6392 - val_loss: 0.6602 - val_accuracy: 0.5947\n",
      "Epoch 54/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6025 - accuracy: 0.6424 - val_loss: 0.6341 - val_accuracy: 0.6341\n",
      "Epoch 55/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6069 - accuracy: 0.6410 - val_loss: 0.6419 - val_accuracy: 0.5918\n",
      "Epoch 56/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6000 - accuracy: 0.6423 - val_loss: 0.6026 - val_accuracy: 0.6410\n",
      "Epoch 57/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6004 - accuracy: 0.6459 - val_loss: 0.6227 - val_accuracy: 0.6484\n",
      "Epoch 58/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5956 - accuracy: 0.6447 - val_loss: 0.6354 - val_accuracy: 0.6185\n",
      "Epoch 59/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5919 - accuracy: 0.6551 - val_loss: 0.5870 - val_accuracy: 0.6663\n",
      "Epoch 60/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5935 - accuracy: 0.6470 - val_loss: 0.5895 - val_accuracy: 0.6611\n",
      "Epoch 61/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5899 - accuracy: 0.6489 - val_loss: 0.6290 - val_accuracy: 0.6377\n",
      "Epoch 62/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5904 - accuracy: 0.6491 - val_loss: 0.6124 - val_accuracy: 0.6331\n",
      "Epoch 63/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5891 - accuracy: 0.6513 - val_loss: 0.6174 - val_accuracy: 0.6406\n",
      "Epoch 64/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5863 - accuracy: 0.6538 - val_loss: 0.6065 - val_accuracy: 0.6240 0.5862 - accuracy: 0.\n",
      "Epoch 65/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5831 - accuracy: 0.6574 - val_loss: 0.5956 - val_accuracy: 0.6569\n",
      "Epoch 66/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5808 - accuracy: 0.6586 - val_loss: 0.5923 - val_accuracy: 0.6559\n",
      "Epoch 67/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5782 - accuracy: 0.6570 - val_loss: 0.6385 - val_accuracy: 0.6175\n",
      "Epoch 68/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5798 - accuracy: 0.6584 - val_loss: 0.6189 - val_accuracy: 0.6230\n",
      "Epoch 69/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5758 - accuracy: 0.6617 - val_loss: 0.6090 - val_accuracy: 0.6325\n",
      "Epoch 70/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5796 - accuracy: 0.6603 - val_loss: 0.6207 - val_accuracy: 0.6328\n",
      "Epoch 71/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5728 - accuracy: 0.6642 - val_loss: 0.5995 - val_accuracy: 0.6510\n",
      "Epoch 72/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5761 - accuracy: 0.6623 - val_loss: 0.6441 - val_accuracy: 0.6113\n",
      "Epoch 73/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5729 - accuracy: 0.6673 - val_loss: 0.5962 - val_accuracy: 0.6602\n",
      "Epoch 74/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5695 - accuracy: 0.6658 - val_loss: 0.5846 - val_accuracy: 0.6608\n",
      "Epoch 75/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5652 - accuracy: 0.6735 - val_loss: 0.5837 - val_accuracy: 0.6543\n",
      "Epoch 76/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5665 - accuracy: 0.6709 - val_loss: 0.6102 - val_accuracy: 0.6396\n",
      "Epoch 77/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5670 - accuracy: 0.6732 - val_loss: 0.5902 - val_accuracy: 0.6641\n",
      "Epoch 78/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5617 - accuracy: 0.6769 - val_loss: 0.6472 - val_accuracy: 0.6458\n",
      "Epoch 79/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5597 - accuracy: 0.6782 - val_loss: 0.5808 - val_accuracy: 0.6764 ETA:  - ETA\n",
      "Epoch 80/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5573 - accuracy: 0.6817 - val_loss: 0.6147 - val_accuracy: 0.6403s: 0.5569 - accuracy: 0.68 - ETA: 0s - loss: 0.5571 - accuracy - ETA: 0s - loss: 0.5\n",
      "Epoch 81/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5623 - accuracy: 0.6757 - val_loss: 0.6128 - val_accuracy: 0.6383\n",
      "Epoch 82/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5607 - accuracy: 0.6811 - val_loss: 0.5857 - val_accuracy: 0.6693\n",
      "Epoch 83/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5543 - accuracy: 0.6827 - val_loss: 0.6157 - val_accuracy: 0.6566\n",
      "Epoch 84/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5559 - accuracy: 0.6793 - val_loss: 0.5782 - val_accuracy: 0.6777\n",
      "Epoch 85/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5591 - accuracy: 0.6757 - val_loss: 0.5905 - val_accuracy: 0.6686\n",
      "Epoch 86/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5525 - accuracy: 0.6806 - val_loss: 0.5867 - val_accuracy: 0.6549\n",
      "Epoch 87/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5506 - accuracy: 0.6860 - val_loss: 0.6125 - val_accuracy: 0.6549\n",
      "Epoch 88/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5533 - accuracy: 0.6822 - val_loss: 0.6027 - val_accuracy: 0.6429\n",
      "Epoch 89/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5513 - accuracy: 0.6854 - val_loss: 0.6014 - val_accuracy: 0.6530\n",
      "Epoch 90/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5447 - accuracy: 0.6891 - val_loss: 0.5597 - val_accuracy: 0.6875\n",
      "Epoch 91/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5434 - accuracy: 0.6912 - val_loss: 0.5864 - val_accuracy: 0.6644\n",
      "Epoch 92/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5473 - accuracy: 0.6887 - val_loss: 0.6140 - val_accuracy: 0.6686\n",
      "Epoch 93/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5428 - accuracy: 0.6916 - val_loss: 0.6257 - val_accuracy: 0.6234\n",
      "Epoch 94/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5381 - accuracy: 0.6930 - val_loss: 0.6335 - val_accuracy: 0.5970\n",
      "Epoch 95/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5373 - accuracy: 0.6913 - val_loss: 0.5588 - val_accuracy: 0.6826\n",
      "Epoch 96/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5298 - accuracy: 0.7014 - val_loss: 0.5796 - val_accuracy: 0.6536\n",
      "Epoch 97/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5362 - accuracy: 0.6961 - val_loss: 0.6154 - val_accuracy: 0.6536\n",
      "Epoch 98/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5362 - accuracy: 0.6972 - val_loss: 0.6458 - val_accuracy: 0.6243\n",
      "Epoch 99/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5367 - accuracy: 0.6933 - val_loss: 0.6527 - val_accuracy: 0.6234\n",
      "Epoch 100/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5324 - accuracy: 0.7021 - val_loss: 0.5612 - val_accuracy: 0.6715\n",
      "Epoch 101/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5310 - accuracy: 0.6999 - val_loss: 0.6289 - val_accuracy: 0.6562\n",
      "Epoch 102/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5314 - accuracy: 0.6989 - val_loss: 0.5860 - val_accuracy: 0.6631\n",
      "Epoch 103/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5367 - accuracy: 0.6905 - val_loss: 0.6453 - val_accuracy: 0.6468\n",
      "Epoch 104/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5330 - accuracy: 0.7016 - val_loss: 0.6232 - val_accuracy: 0.6234\n",
      "Epoch 105/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5273 - accuracy: 0.7054 - val_loss: 0.6088 - val_accuracy: 0.6618\n",
      "Epoch 106/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5255 - accuracy: 0.7017 - val_loss: 0.6623 - val_accuracy: 0.6462\n",
      "Epoch 107/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5224 - accuracy: 0.7060 - val_loss: 0.5559 - val_accuracy: 0.6846\n",
      "Epoch 108/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5228 - accuracy: 0.7076 - val_loss: 0.6298 - val_accuracy: 0.6514\n",
      "Epoch 109/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5208 - accuracy: 0.7112 - val_loss: 0.5363 - val_accuracy: 0.6875\n",
      "Epoch 110/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5235 - accuracy: 0.7051 - val_loss: 0.5877 - val_accuracy: 0.6751\n",
      "Epoch 111/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5234 - accuracy: 0.7039 - val_loss: 0.5842 - val_accuracy: 0.6732\n",
      "Epoch 112/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5155 - accuracy: 0.7111 - val_loss: 0.6246 - val_accuracy: 0.6449\n",
      "Epoch 113/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5123 - accuracy: 0.7147 - val_loss: 0.5470 - val_accuracy: 0.7106\n",
      "Epoch 114/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5231 - accuracy: 0.7059 - val_loss: 0.5418 - val_accuracy: 0.6878\n",
      "Epoch 115/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5134 - accuracy: 0.7160 - val_loss: 0.5651 - val_accuracy: 0.6911\n",
      "Epoch 116/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5066 - accuracy: 0.7185 - val_loss: 0.6173 - val_accuracy: 0.6582\n",
      "Epoch 117/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5094 - accuracy: 0.7169 - val_loss: 0.5997 - val_accuracy: 0.6748\n",
      "Epoch 118/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5072 - accuracy: 0.7138 - val_loss: 0.5797 - val_accuracy: 0.6637\n",
      "Epoch 119/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5075 - accuracy: 0.7167 - val_loss: 0.5423 - val_accuracy: 0.6937\n",
      "Epoch 120/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5039 - accuracy: 0.7198 - val_loss: 0.5606 - val_accuracy: 0.7015\n",
      "Epoch 121/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5069 - accuracy: 0.7191 - val_loss: 0.5740 - val_accuracy: 0.6680063 - accuracy: 0.\n",
      "Epoch 122/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5001 - accuracy: 0.7209 - val_loss: 0.6380 - val_accuracy: 0.6592\n",
      "Epoch 123/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5019 - accuracy: 0.7197 - val_loss: 0.5814 - val_accuracy: 0.6872\n",
      "Epoch 124/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4963 - accuracy: 0.7250 - val_loss: 0.6653 - val_accuracy: 0.6507\n",
      "Epoch 125/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4963 - accuracy: 0.7249 - val_loss: 0.5393 - val_accuracy: 0.7191\n",
      "Epoch 126/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4961 - accuracy: 0.7289 - val_loss: 0.5295 - val_accuracy: 0.7041\n",
      "Epoch 127/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5022 - accuracy: 0.7214 - val_loss: 0.5654 - val_accuracy: 0.7015\n",
      "Epoch 128/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4968 - accuracy: 0.7231 - val_loss: 0.5189 - val_accuracy: 0.7077\n",
      "Epoch 129/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4875 - accuracy: 0.7313 - val_loss: 0.5938 - val_accuracy: 0.6784\n",
      "Epoch 130/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4917 - accuracy: 0.7285 - val_loss: 0.5476 - val_accuracy: 0.6937\n",
      "Epoch 131/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5039 - accuracy: 0.7196 - val_loss: 0.5685 - val_accuracy: 0.6872\n",
      "Epoch 132/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4833 - accuracy: 0.7328 - val_loss: 0.5465 - val_accuracy: 0.7074\n",
      "Epoch 133/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4829 - accuracy: 0.7299 - val_loss: 0.6416 - val_accuracy: 0.6387\n",
      "Epoch 134/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4807 - accuracy: 0.7349 - val_loss: 0.5506 - val_accuracy: 0.6777\n",
      "Epoch 135/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4858 - accuracy: 0.7360 - val_loss: 0.5302 - val_accuracy: 0.7129\n",
      "Epoch 136/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4752 - accuracy: 0.7413 - val_loss: 0.5294 - val_accuracy: 0.7122\n",
      "Epoch 137/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4771 - accuracy: 0.7429 - val_loss: 0.6484 - val_accuracy: 0.6208\n",
      "Epoch 138/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4745 - accuracy: 0.7439 - val_loss: 0.5530 - val_accuracy: 0.6943\n",
      "Epoch 139/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4720 - accuracy: 0.7436 - val_loss: 0.5202 - val_accuracy: 0.7246\n",
      "Epoch 140/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4689 - accuracy: 0.7485 - val_loss: 0.5685 - val_accuracy: 0.6950692 - accuracy: 0. - ETA: 0s - loss: 0.4696 - accuracy: \n",
      "Epoch 141/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4698 - accuracy: 0.7456 - val_loss: 0.5057 - val_accuracy: 0.7321\n",
      "Epoch 142/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4680 - accuracy: 0.7466 - val_loss: 0.5205 - val_accuracy: 0.7207\n",
      "Epoch 143/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4705 - accuracy: 0.7479 - val_loss: 0.5596 - val_accuracy: 0.7008\n",
      "Epoch 144/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4678 - accuracy: 0.7451 - val_loss: 0.5263 - val_accuracy: 0.7106\n",
      "Epoch 145/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4678 - accuracy: 0.7447 - val_loss: 0.5693 - val_accuracy: 0.7083\n",
      "Epoch 146/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4633 - accuracy: 0.7486 - val_loss: 0.5004 - val_accuracy: 0.7256\n",
      "Epoch 147/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4619 - accuracy: 0.7534 - val_loss: 0.5515 - val_accuracy: 0.7064\n",
      "Epoch 148/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4653 - accuracy: 0.7482 - val_loss: 0.5563 - val_accuracy: 0.6947\n",
      "Epoch 149/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4650 - accuracy: 0.7507 - val_loss: 0.5729 - val_accuracy: 0.6807\n",
      "Epoch 150/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4601 - accuracy: 0.7532 - val_loss: 0.5564 - val_accuracy: 0.7025\n",
      "Epoch 151/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4559 - accuracy: 0.7566 - val_loss: 0.5619 - val_accuracy: 0.6882\n",
      "Epoch 152/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4547 - accuracy: 0.7587 - val_loss: 0.5716 - val_accuracy: 0.6605\n",
      "Epoch 153/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4436 - accuracy: 0.7659 - val_loss: 0.5668 - val_accuracy: 0.6947\n",
      "Epoch 154/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4460 - accuracy: 0.7598 - val_loss: 0.6579 - val_accuracy: 0.6628\n",
      "Epoch 155/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4575 - accuracy: 0.7562 - val_loss: 0.5924 - val_accuracy: 0.6748\n",
      "Epoch 156/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4483 - accuracy: 0.7609 - val_loss: 0.6031 - val_accuracy: 0.6715\n",
      "Epoch 157/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4518 - accuracy: 0.7616 - val_loss: 0.6091 - val_accuracy: 0.6774\n",
      "Epoch 158/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4438 - accuracy: 0.7647 - val_loss: 0.4964 - val_accuracy: 0.7350\n",
      "Epoch 159/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4445 - accuracy: 0.7640 - val_loss: 0.5615 - val_accuracy: 0.6872\n",
      "Epoch 160/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4438 - accuracy: 0.7619 - val_loss: 0.5527 - val_accuracy: 0.7106\n",
      "Epoch 161/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4381 - accuracy: 0.7637 - val_loss: 0.6224 - val_accuracy: 0.7087 ETA: 4s - loss: 0.4373 - accuracy - ETA: 4s - loss: 0 - ETA: 3s -\n",
      "Epoch 162/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4352 - accuracy: 0.7651 - val_loss: 0.6043 - val_accuracy: 0.6803\n",
      "Epoch 163/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4418 - accuracy: 0.7652 - val_loss: 0.6110 - val_accuracy: 0.6842\n",
      "Epoch 164/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4356 - accuracy: 0.7683 - val_loss: 0.5253 - val_accuracy: 0.7246\n",
      "Epoch 165/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4318 - accuracy: 0.7712 - val_loss: 0.5605 - val_accuracy: 0.7028\n",
      "Epoch 166/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4308 - accuracy: 0.7677 - val_loss: 0.6518 - val_accuracy: 0.6722\n",
      "Epoch 167/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4270 - accuracy: 0.7727 - val_loss: 0.5329 - val_accuracy: 0.7262\n",
      "Epoch 168/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4298 - accuracy: 0.7753 - val_loss: 0.5458 - val_accuracy: 0.7184cu - ETA: 3s - loss: 0.4296 - accuracy - ETA:  - ETA: 0s - loss: 0.4279 - ac\n",
      "Epoch 169/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4251 - accuracy: 0.7760 - val_loss: 0.5439 - val_accuracy: 0.7035\n",
      "Epoch 170/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4204 - accuracy: 0.7803 - val_loss: 0.5106 - val_accuracy: 0.7360\n",
      "Epoch 171/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4265 - accuracy: 0.7760 - val_loss: 0.5513 - val_accuracy: 0.7005\n",
      "Epoch 172/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4209 - accuracy: 0.7777 - val_loss: 0.5606 - val_accuracy: 0.7067\n",
      "Epoch 173/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4252 - accuracy: 0.7777 - val_loss: 0.6385 - val_accuracy: 0.6823\n",
      "Epoch 174/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4097 - accuracy: 0.7836 - val_loss: 0.5508 - val_accuracy: 0.7171\n",
      "Epoch 175/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4203 - accuracy: 0.7814 - val_loss: 0.5951 - val_accuracy: 0.7126\n",
      "Epoch 176/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4199 - accuracy: 0.7787 - val_loss: 0.5738 - val_accuracy: 0.7132\n",
      "Epoch 177/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4142 - accuracy: 0.7822 - val_loss: 0.6071 - val_accuracy: 0.6618\n",
      "Epoch 178/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4195 - accuracy: 0.7762 - val_loss: 0.5849 - val_accuracy: 0.6956\n",
      "Epoch 179/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4079 - accuracy: 0.7861 - val_loss: 0.4950 - val_accuracy: 0.7490\n",
      "Epoch 180/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4047 - accuracy: 0.7885 - val_loss: 0.5597 - val_accuracy: 0.7109\n",
      "Epoch 181/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4058 - accuracy: 0.7902 - val_loss: 0.5636 - val_accuracy: 0.7077\n",
      "Epoch 182/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4042 - accuracy: 0.7867 - val_loss: 0.5675 - val_accuracy: 0.7054\n",
      "Epoch 183/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4078 - accuracy: 0.7850 - val_loss: 0.5451 - val_accuracy: 0.7217\n",
      "Epoch 184/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4010 - accuracy: 0.7902 - val_loss: 0.5650 - val_accuracy: 0.6833\n",
      "Epoch 185/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4020 - accuracy: 0.7901 - val_loss: 0.5040 - val_accuracy: 0.7363 loss: 0.4021 - accuracy: 0. - ETA: 0s -\n",
      "Epoch 186/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3973 - accuracy: 0.7937 - val_loss: 0.5216 - val_accuracy: 0.7220\n",
      "Epoch 187/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4005 - accuracy: 0.7891 - val_loss: 0.6188 - val_accuracy: 0.7031\n",
      "Epoch 188/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3920 - accuracy: 0.7949 - val_loss: 0.6023 - val_accuracy: 0.7077\n",
      "Epoch 189/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3925 - accuracy: 0.7969 - val_loss: 0.5814 - val_accuracy: 0.6953\n",
      "Epoch 190/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3931 - accuracy: 0.7975 - val_loss: 0.6871 - val_accuracy: 0.6924\n",
      "Epoch 191/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3998 - accuracy: 0.7919 - val_loss: 0.5254 - val_accuracy: 0.7393\n",
      "Epoch 192/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3874 - accuracy: 0.8012 - val_loss: 0.6584 - val_accuracy: 0.6895\n",
      "Epoch 193/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3852 - accuracy: 0.7988 - val_loss: 0.5485 - val_accuracy: 0.7480\n",
      "Epoch 194/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3887 - accuracy: 0.8009 - val_loss: 0.5682 - val_accuracy: 0.7188\n",
      "Epoch 195/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3852 - accuracy: 0.8031 - val_loss: 0.6149 - val_accuracy: 0.6999\n",
      "Epoch 196/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3855 - accuracy: 0.8028 - val_loss: 0.5305 - val_accuracy: 0.7181\n",
      "Epoch 197/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3814 - accuracy: 0.8048 - val_loss: 0.8006 - val_accuracy: 0.6367\n",
      "Epoch 198/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3781 - accuracy: 0.8066 - val_loss: 0.5438 - val_accuracy: 0.7327\n",
      "Epoch 199/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3810 - accuracy: 0.8078 - val_loss: 0.5539 - val_accuracy: 0.7321\n",
      "Epoch 200/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3775 - accuracy: 0.8075 - val_loss: 0.8882 - val_accuracy: 0.5954\n",
      "Epoch 201/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3729 - accuracy: 0.8060 - val_loss: 0.5446 - val_accuracy: 0.74581s - loss: - ETA: 0s - loss: 0.3737 - accu\n",
      "Epoch 202/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3737 - accuracy: 0.8086 - val_loss: 0.6091 - val_accuracy: 0.7113\n",
      "Epoch 203/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3749 - accuracy: 0.8092 - val_loss: 0.5613 - val_accuracy: 0.7285\n",
      "Epoch 204/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3680 - accuracy: 0.8147 - val_loss: 0.5806 - val_accuracy: 0.7181\n",
      "Epoch 205/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3700 - accuracy: 0.8071 - val_loss: 0.6012 - val_accuracy: 0.7142\n",
      "Epoch 206/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3642 - accuracy: 0.8143 - val_loss: 0.5460 - val_accuracy: 0.7383\n",
      "Epoch 207/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3664 - accuracy: 0.8132 - val_loss: 0.6004 - val_accuracy: 0.7236\n",
      "Epoch 208/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3673 - accuracy: 0.8125 - val_loss: 0.5408 - val_accuracy: 0.7318\n",
      "Epoch 209/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3671 - accuracy: 0.8118 - val_loss: 0.5393 - val_accuracy: 0.7367\n",
      "Epoch 210/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3585 - accuracy: 0.8181 - val_loss: 0.5501 - val_accuracy: 0.7256\n",
      "Epoch 211/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3577 - accuracy: 0.8195 - val_loss: 0.7205 - val_accuracy: 0.6709oss: 0.3573 - accuracy: \n",
      "Epoch 212/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3560 - accuracy: 0.8165 - val_loss: 0.6377 - val_accuracy: 0.6885\n",
      "Epoch 213/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3599 - accuracy: 0.8153 - val_loss: 0.5531 - val_accuracy: 0.7383\n",
      "Epoch 214/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3541 - accuracy: 0.8175 - val_loss: 0.5548 - val_accuracy: 0.7305\n",
      "Epoch 215/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3565 - accuracy: 0.8179 - val_loss: 0.6456 - val_accuracy: 0.6937\n",
      "Epoch 216/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3549 - accuracy: 0.8169 - val_loss: 0.5359 - val_accuracy: 0.7396\n",
      "Epoch 217/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3576 - accuracy: 0.8211 - val_loss: 0.6574 - val_accuracy: 0.7002\n",
      "Epoch 218/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3491 - accuracy: 0.8266 - val_loss: 0.5782 - val_accuracy: 0.7109\n",
      "Epoch 219/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3472 - accuracy: 0.8253 - val_loss: 0.5537 - val_accuracy: 0.7380 loss: 0.3472 - accuracy\n",
      "Epoch 220/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3516 - accuracy: 0.8206 - val_loss: 0.5961 - val_accuracy: 0.7266\n",
      "Epoch 221/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3381 - accuracy: 0.8287 - val_loss: 0.5920 - val_accuracy: 0.7233\n",
      "Epoch 222/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3650 - accuracy: 0.8124 - val_loss: 0.5983 - val_accuracy: 0.6989\n",
      "Epoch 223/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3533 - accuracy: 0.8226 - val_loss: 0.5804 - val_accuracy: 0.7031 loss: 0.3557 - accuracy: 0.82 - ETA: 5s - loss: 0.3554 - accuracy:  - E -\n",
      "Epoch 224/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3497 - accuracy: 0.8219 - val_loss: 0.6098 - val_accuracy: 0.7253\n",
      "Epoch 225/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3414 - accuracy: 0.8307 - val_loss: 0.6545 - val_accuracy: 0.6875\n",
      "Epoch 226/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3390 - accuracy: 0.8304 - val_loss: 0.6770 - val_accuracy: 0.6836racy: 0. - E\n",
      "Epoch 227/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3375 - accuracy: 0.8295 - val_loss: 0.6722 - val_accuracy: 0.7064oss: 0.3374 - accura\n",
      "Epoch 228/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3417 - accuracy: 0.8295 - val_loss: 0.7000 - val_accuracy: 0.7015\n",
      "Epoch 229/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3325 - accuracy: 0.8314 - val_loss: 0.5858 - val_accuracy: 0.7327\n",
      "Epoch 230/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3333 - accuracy: 0.8323 - val_loss: 0.5841 - val_accuracy: 0.7308\n",
      "Epoch 231/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3331 - accuracy: 0.8327 - val_loss: 0.5263 - val_accuracy: 0.7559\n",
      "Epoch 232/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3365 - accuracy: 0.8312 - val_loss: 0.5873 - val_accuracy: 0.7197\n",
      "Epoch 233/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3228 - accuracy: 0.8381 - val_loss: 0.5983 - val_accuracy: 0.7399\n",
      "Epoch 234/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3271 - accuracy: 0.8364 - val_loss: 0.7378 - val_accuracy: 0.6660\n",
      "Epoch 235/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3290 - accuracy: 0.8372 - val_loss: 0.5882 - val_accuracy: 0.7354\n",
      "Epoch 236/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3246 - accuracy: 0.8387 - val_loss: 0.6069 - val_accuracy: 0.7350\n",
      "Epoch 237/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3236 - accuracy: 0.8396 - val_loss: 0.6360 - val_accuracy: 0.7148\n",
      "Epoch 238/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3214 - accuracy: 0.8426 - val_loss: 0.6906 - val_accuracy: 0.7122\n",
      "Epoch 239/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3221 - accuracy: 0.8382 - val_loss: 0.5463 - val_accuracy: 0.7454\n",
      "Epoch 240/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3167 - accuracy: 0.8414 - val_loss: 0.5699 - val_accuracy: 0.7220\n",
      "Epoch 241/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3186 - accuracy: 0.8386 - val_loss: 0.6231 - val_accuracy: 0.7402\n",
      "Epoch 242/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3181 - accuracy: 0.8439 - val_loss: 0.6871 - val_accuracy: 0.6921\n",
      "Epoch 243/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3149 - accuracy: 0.8424 - val_loss: 0.5524 - val_accuracy: 0.7383\n",
      "Epoch 244/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3157 - accuracy: 0.8413 - val_loss: 0.6099 - val_accuracy: 0.7493\n",
      "Epoch 245/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3140 - accuracy: 0.8444 - val_loss: 0.5552 - val_accuracy: 0.7673\n",
      "Epoch 246/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3120 - accuracy: 0.8456 - val_loss: 0.7440 - val_accuracy: 0.6784\n",
      "Epoch 247/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3131 - accuracy: 0.8441 - val_loss: 0.6437 - val_accuracy: 0.7295\n",
      "Epoch 248/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3179 - accuracy: 0.8407 - val_loss: 0.7620 - val_accuracy: 0.7002\n",
      "Epoch 249/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3072 - accuracy: 0.8450 - val_loss: 0.5936 - val_accuracy: 0.7415\n",
      "Epoch 250/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3035 - accuracy: 0.8491 - val_loss: 0.6119 - val_accuracy: 0.7214\n",
      "Epoch 251/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3124 - accuracy: 0.8441 - val_loss: 0.6120 - val_accuracy: 0.7210\n",
      "Epoch 252/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3033 - accuracy: 0.8500 - val_loss: 0.6956 - val_accuracy: 0.7220\n",
      "Epoch 253/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3053 - accuracy: 0.8470 - val_loss: 0.6115 - val_accuracy: 0.7510\n",
      "Epoch 254/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3060 - accuracy: 0.8487 - val_loss: 0.5595 - val_accuracy: 0.7568\n",
      "Epoch 255/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3008 - accuracy: 0.8517 - val_loss: 0.6356 - val_accuracy: 0.7334\n",
      "Epoch 256/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3015 - accuracy: 0.8516 - val_loss: 0.7550 - val_accuracy: 0.7015\n",
      "Epoch 257/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2962 - accuracy: 0.8539 - val_loss: 0.6106 - val_accuracy: 0.7402\n",
      "Epoch 258/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2979 - accuracy: 0.8530 - val_loss: 0.6608 - val_accuracy: 0.7103\n",
      "Epoch 259/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2937 - accuracy: 0.8536 - val_loss: 0.6442 - val_accuracy: 0.7441\n",
      "Epoch 260/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3031 - accuracy: 0.8503 - val_loss: 0.5896 - val_accuracy: 0.7314\n",
      "Epoch 261/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2946 - accuracy: 0.8525 - val_loss: 0.6455 - val_accuracy: 0.7243 loss: 0.2961 - accura - ETA: 2s -\n",
      "Epoch 262/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2955 - accuracy: 0.8547 - val_loss: 0.6616 - val_accuracy: 0.7269\n",
      "Epoch 263/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2989 - accuracy: 0.8520 - val_loss: 0.5635 - val_accuracy: 0.7660\n",
      "Epoch 264/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2921 - accuracy: 0.8591 - val_loss: 0.7389 - val_accuracy: 0.6989\n",
      "Epoch 265/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2885 - accuracy: 0.8565 - val_loss: 0.8057 - val_accuracy: 0.6761\n",
      "Epoch 266/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2919 - accuracy: 0.8554 - val_loss: 0.6869 - val_accuracy: 0.7461\n",
      "Epoch 267/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2875 - accuracy: 0.8577 - val_loss: 0.6321 - val_accuracy: 0.7461\n",
      "Epoch 268/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2935 - accuracy: 0.8572 - val_loss: 0.6440 - val_accuracy: 0.7389\n",
      "Epoch 269/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2900 - accuracy: 0.8558 - val_loss: 0.7424 - val_accuracy: 0.7288\n",
      "Epoch 270/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2861 - accuracy: 0.8607 - val_loss: 0.6845 - val_accuracy: 0.7126\n",
      "Epoch 271/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2839 - accuracy: 0.8624 - val_loss: 0.6004 - val_accuracy: 0.7360\n",
      "Epoch 272/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2848 - accuracy: 0.8618 - val_loss: 0.7120 - val_accuracy: 0.7158\n",
      "Epoch 273/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2787 - accuracy: 0.8655 - val_loss: 0.5787 - val_accuracy: 0.7646\n",
      "Epoch 274/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2849 - accuracy: 0.8633 - val_loss: 0.7016 - val_accuracy: 0.7070\n",
      "Epoch 275/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2849 - accuracy: 0.8618 - val_loss: 0.6767 - val_accuracy: 0.7057\n",
      "Epoch 276/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2780 - accuracy: 0.8646 - val_loss: 0.6810 - val_accuracy: 0.7194\n",
      "Epoch 277/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2798 - accuracy: 0.8644 - val_loss: 0.7138 - val_accuracy: 0.7201\n",
      "Epoch 278/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2811 - accuracy: 0.8612 - val_loss: 0.5734 - val_accuracy: 0.7614\n",
      "Epoch 279/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2806 - accuracy: 0.8636 - val_loss: 0.6258 - val_accuracy: 0.7438\n",
      "Epoch 280/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2704 - accuracy: 0.8694 - val_loss: 0.6290 - val_accuracy: 0.7490\n",
      "Epoch 281/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2734 - accuracy: 0.8686 - val_loss: 0.6797 - val_accuracy: 0.7272\n",
      "Epoch 282/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2760 - accuracy: 0.8660 - val_loss: 0.7108 - val_accuracy: 0.7197\n",
      "Epoch 283/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2719 - accuracy: 0.8648 - val_loss: 0.6624 - val_accuracy: 0.7262\n",
      "Epoch 284/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2718 - accuracy: 0.8654 - val_loss: 0.6476 - val_accuracy: 0.7493\n",
      "Epoch 285/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2723 - accuracy: 0.8682 - val_loss: 0.7994 - val_accuracy: 0.6846\n",
      "Epoch 286/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2695 - accuracy: 0.8697 - val_loss: 0.7115 - val_accuracy: 0.7077\n",
      "Epoch 287/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2716 - accuracy: 0.8686 - val_loss: 0.7699 - val_accuracy: 0.7041\n",
      "Epoch 288/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2715 - accuracy: 0.8653 - val_loss: 0.8328 - val_accuracy: 0.6911\n",
      "Epoch 289/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2633 - accuracy: 0.8727 - val_loss: 0.6225 - val_accuracy: 0.7471\n",
      "Epoch 290/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2712 - accuracy: 0.8689 - val_loss: 0.7204 - val_accuracy: 0.7087\n",
      "Epoch 291/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2677 - accuracy: 0.8701 - val_loss: 0.6875 - val_accuracy: 0.7363\n",
      "Epoch 292/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2783 - accuracy: 0.8659 - val_loss: 0.5987 - val_accuracy: 0.7520\n",
      "Epoch 293/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2670 - accuracy: 0.8713 - val_loss: 0.6054 - val_accuracy: 0.7360\n",
      "Epoch 294/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2710 - accuracy: 0.8661 - val_loss: 0.7027 - val_accuracy: 0.7256\n",
      "Epoch 295/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2640 - accuracy: 0.8700 - val_loss: 0.6671 - val_accuracy: 0.7253\n",
      "Epoch 296/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2677 - accuracy: 0.8711 - val_loss: 0.6458 - val_accuracy: 0.7282\n",
      "Epoch 297/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2612 - accuracy: 0.8739 - val_loss: 0.7088 - val_accuracy: 0.7236\n",
      "Epoch 298/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2654 - accuracy: 0.8710 - val_loss: 0.7027 - val_accuracy: 0.7288\n",
      "Epoch 299/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2653 - accuracy: 0.8726 - val_loss: 0.6904 - val_accuracy: 0.7008\n",
      "Epoch 300/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2616 - accuracy: 0.8698 - val_loss: 0.6999 - val_accuracy: 0.7194\n",
      "Epoch 301/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2610 - accuracy: 0.8712 - val_loss: 0.8403 - val_accuracy: 0.6709\n",
      "Epoch 302/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2631 - accuracy: 0.8714 - val_loss: 0.6576 - val_accuracy: 0.7497\n",
      "Epoch 303/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2520 - accuracy: 0.8815 - val_loss: 0.6505 - val_accuracy: 0.7458\n",
      "Epoch 304/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2599 - accuracy: 0.8739 - val_loss: 0.6935 - val_accuracy: 0.7314\n",
      "Epoch 305/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2630 - accuracy: 0.8728 - val_loss: 0.8367 - val_accuracy: 0.6820\n",
      "Epoch 306/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2713 - accuracy: 0.8645 - val_loss: 0.7898 - val_accuracy: 0.7174\n",
      "Epoch 307/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2545 - accuracy: 0.8752 - val_loss: 0.6675 - val_accuracy: 0.7432\n",
      "Epoch 308/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2547 - accuracy: 0.8753 - val_loss: 0.6399 - val_accuracy: 0.7305\n",
      "Epoch 309/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2600 - accuracy: 0.8709 - val_loss: 0.6459 - val_accuracy: 0.7393\n",
      "Epoch 310/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2514 - accuracy: 0.8761 - val_loss: 0.7374 - val_accuracy: 0.7139\n",
      "Epoch 311/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2578 - accuracy: 0.8719 - val_loss: 0.6252 - val_accuracy: 0.7266\n",
      "Epoch 312/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2561 - accuracy: 0.8745 - val_loss: 0.6732 - val_accuracy: 0.7399 - ETA: 6s - loss: - ETA: 0s - loss: 0.2566 - accuracy: \n",
      "Epoch 313/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2601 - accuracy: 0.8729 - val_loss: 0.6409 - val_accuracy: 0.7500\n",
      "Epoch 314/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2494 - accuracy: 0.8783 - val_loss: 0.6484 - val_accuracy: 0.7458\n",
      "Epoch 315/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2421 - accuracy: 0.8821 - val_loss: 0.7545 - val_accuracy: 0.70930s - loss: 0.2\n",
      "Epoch 316/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2605 - accuracy: 0.8732 - val_loss: 0.6701 - val_accuracy: 0.7552 ETA: 0s - loss:\n",
      "Epoch 317/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2471 - accuracy: 0.8789 - val_loss: 0.7643 - val_accuracy: 0.7191\n",
      "Epoch 318/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2490 - accuracy: 0.8774 - val_loss: 0.6405 - val_accuracy: 0.7370\n",
      "Epoch 319/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2433 - accuracy: 0.8789 - val_loss: 0.7300 - val_accuracy: 0.7243\n",
      "Epoch 320/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2545 - accuracy: 0.8773 - val_loss: 0.7576 - val_accuracy: 0.7214 - ETA: 0s - loss:\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00320: early stopping\n",
      "      1/Unknown - 0s 172ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121/3121 [==============================] - 15s 5ms/step\n",
      "347/347 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|                                                                    | 1/10 [1:19:48<11:58:17, 4788.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "438/438 [==============================] - 16s 35ms/step - loss: 0.6923 - accuracy: 0.5095 - val_loss: 0.6933 - val_accuracy: 0.5101\n",
      "Epoch 2/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6937 - val_accuracy: 0.5055\n",
      "Epoch 3/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6888 - accuracy: 0.5380 - val_loss: 0.6976 - val_accuracy: 0.5000\n",
      "Epoch 4/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6851 - accuracy: 0.5570 - val_loss: 0.7041 - val_accuracy: 0.5072\n",
      "Epoch 5/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6771 - accuracy: 0.5641 - val_loss: 0.7014 - val_accuracy: 0.5150\n",
      "Epoch 6/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6738 - accuracy: 0.5618 - val_loss: 0.6977 - val_accuracy: 0.5003\n",
      "Epoch 7/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6711 - accuracy: 0.5690 - val_loss: 0.7036 - val_accuracy: 0.5111\n",
      "Epoch 8/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6673 - accuracy: 0.5687 - val_loss: 0.7104 - val_accuracy: 0.5182\n",
      "Epoch 9/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6662 - accuracy: 0.5702 - val_loss: 0.7165 - val_accuracy: 0.5081\n",
      "Epoch 10/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6645 - accuracy: 0.5726 - val_loss: 0.7226 - val_accuracy: 0.5088\n",
      "Epoch 11/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6631 - accuracy: 0.5725 - val_loss: 0.7022 - val_accuracy: 0.5153\n",
      "Epoch 12/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6631 - accuracy: 0.5772 - val_loss: 0.7310 - val_accuracy: 0.5146\n",
      "Epoch 13/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6613 - accuracy: 0.5796 - val_loss: 0.7146 - val_accuracy: 0.5091\n",
      "Epoch 14/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6599 - accuracy: 0.5823 - val_loss: 0.7001 - val_accuracy: 0.5124\n",
      "Epoch 15/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6572 - accuracy: 0.5878 - val_loss: 0.7292 - val_accuracy: 0.5065\n",
      "Epoch 16/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6582 - accuracy: 0.5857 - val_loss: 0.7200 - val_accuracy: 0.5231\n",
      "Epoch 17/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6576 - accuracy: 0.5858 - val_loss: 0.7140 - val_accuracy: 0.5293\n",
      "Epoch 18/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6511 - accuracy: 0.5979 - val_loss: 0.7117 - val_accuracy: 0.5319\n",
      "Epoch 19/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6533 - accuracy: 0.5915 - val_loss: 0.6735 - val_accuracy: 0.5544\n",
      "Epoch 20/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6500 - accuracy: 0.5962 - val_loss: 0.6656 - val_accuracy: 0.5765\n",
      "Epoch 21/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6486 - accuracy: 0.6018 - val_loss: 0.7002 - val_accuracy: 0.5352\n",
      "Epoch 22/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6467 - accuracy: 0.6032 - val_loss: 0.7807 - val_accuracy: 0.5127\n",
      "Epoch 23/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6451 - accuracy: 0.6079 - val_loss: 0.7138 - val_accuracy: 0.5225\n",
      "Epoch 24/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6431 - accuracy: 0.6088 - val_loss: 0.6880 - val_accuracy: 0.5452\n",
      "Epoch 25/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6434 - accuracy: 0.6112 - val_loss: 0.7047 - val_accuracy: 0.5257\n",
      "Epoch 26/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6386 - accuracy: 0.6133 - val_loss: 0.6526 - val_accuracy: 0.5846\n",
      "Epoch 27/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6393 - accuracy: 0.6130 - val_loss: 0.6778 - val_accuracy: 0.5371\n",
      "Epoch 28/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6388 - accuracy: 0.6164 - val_loss: 0.6817 - val_accuracy: 0.5439\n",
      "Epoch 29/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6357 - accuracy: 0.6165 - val_loss: 0.6809 - val_accuracy: 0.5462\n",
      "Epoch 30/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6351 - accuracy: 0.6205 - val_loss: 0.7015 - val_accuracy: 0.5381\n",
      "Epoch 31/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6308 - accuracy: 0.6198 - val_loss: 0.7112 - val_accuracy: 0.5062\n",
      "Epoch 32/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6329 - accuracy: 0.6214 - val_loss: 0.6786 - val_accuracy: 0.5495\n",
      "Epoch 33/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6298 - accuracy: 0.6244 - val_loss: 0.6760 - val_accuracy: 0.5475\n",
      "Epoch 34/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6275 - accuracy: 0.6264 - val_loss: 0.7277 - val_accuracy: 0.5312\n",
      "Epoch 35/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6287 - accuracy: 0.6226 - val_loss: 0.7232 - val_accuracy: 0.5400\n",
      "Epoch 36/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6260 - accuracy: 0.6311 - val_loss: 0.6878 - val_accuracy: 0.5713\n",
      "Epoch 37/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6283 - accuracy: 0.6236 - val_loss: 0.6904 - val_accuracy: 0.5433\n",
      "Epoch 38/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6257 - accuracy: 0.6253 - val_loss: 0.6481 - val_accuracy: 0.5739\n",
      "Epoch 39/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6202 - accuracy: 0.6315 - val_loss: 0.7148 - val_accuracy: 0.5104\n",
      "Epoch 40/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6200 - accuracy: 0.6301 - val_loss: 0.6960 - val_accuracy: 0.5417\n",
      "Epoch 41/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6177 - accuracy: 0.6288 - val_loss: 0.6308 - val_accuracy: 0.6283\n",
      "Epoch 42/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6182 - accuracy: 0.6326 - val_loss: 0.6809 - val_accuracy: 0.5602\n",
      "Epoch 43/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6195 - accuracy: 0.6301 - val_loss: 0.6807 - val_accuracy: 0.5459\n",
      "Epoch 44/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6165 - accuracy: 0.6291 - val_loss: 0.6406 - val_accuracy: 0.5820\n",
      "Epoch 45/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6160 - accuracy: 0.6315 - val_loss: 0.6949 - val_accuracy: 0.5352\n",
      "Epoch 46/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6132 - accuracy: 0.6357 - val_loss: 0.7028 - val_accuracy: 0.5394\n",
      "Epoch 47/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6122 - accuracy: 0.6371 - val_loss: 0.6784 - val_accuracy: 0.5387\n",
      "Epoch 48/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6133 - accuracy: 0.6344 - val_loss: 0.6902 - val_accuracy: 0.5641\n",
      "Epoch 49/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6101 - accuracy: 0.6352 - val_loss: 0.6580 - val_accuracy: 0.5615\n",
      "Epoch 50/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6078 - accuracy: 0.6424 - val_loss: 0.6204 - val_accuracy: 0.6452\n",
      "Epoch 51/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6064 - accuracy: 0.6436 - val_loss: 0.6781 - val_accuracy: 0.5814\n",
      "Epoch 52/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6047 - accuracy: 0.6442 - val_loss: 0.6994 - val_accuracy: 0.5472\n",
      "Epoch 53/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6107 - accuracy: 0.6357 - val_loss: 0.6799 - val_accuracy: 0.5557\n",
      "Epoch 54/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6033 - accuracy: 0.6440 - val_loss: 0.6400 - val_accuracy: 0.5973\n",
      "Epoch 55/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6049 - accuracy: 0.6436 - val_loss: 0.6764 - val_accuracy: 0.5850 loss: 0.6046 -  - ETA: 1s - los - ETA: 0s - loss: 0.6041 - accuracy: \n",
      "Epoch 56/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5989 - accuracy: 0.6492 - val_loss: 0.7370 - val_accuracy: 0.5508\n",
      "Epoch 57/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5991 - accuracy: 0.6477 - val_loss: 0.6717 - val_accuracy: 0.5788\n",
      "Epoch 58/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6000 - accuracy: 0.6495 - val_loss: 0.6789 - val_accuracy: 0.5771\n",
      "Epoch 59/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5942 - accuracy: 0.6524 - val_loss: 0.6476 - val_accuracy: 0.5817\n",
      "Epoch 60/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5989 - accuracy: 0.6511 - val_loss: 0.6122 - val_accuracy: 0.6302\n",
      "Epoch 61/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5924 - accuracy: 0.6566 - val_loss: 0.6645 - val_accuracy: 0.5589\n",
      "Epoch 62/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5918 - accuracy: 0.6529 - val_loss: 0.6625 - val_accuracy: 0.5635\n",
      "Epoch 63/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5943 - accuracy: 0.6551 - val_loss: 0.6731 - val_accuracy: 0.5544\n",
      "Epoch 64/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5863 - accuracy: 0.6604 - val_loss: 0.6366 - val_accuracy: 0.5749 loss: 0.5865 - accuracy: 0.\n",
      "Epoch 65/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5919 - accuracy: 0.6559 - val_loss: 0.6221 - val_accuracy: 0.5921\n",
      "Epoch 66/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5838 - accuracy: 0.6641 - val_loss: 0.6262 - val_accuracy: 0.6032\n",
      "Epoch 67/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5892 - accuracy: 0.6564 - val_loss: 0.6117 - val_accuracy: 0.6214\n",
      "Epoch 68/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5811 - accuracy: 0.6645 - val_loss: 0.6669 - val_accuracy: 0.5820\n",
      "Epoch 69/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5764 - accuracy: 0.6696 - val_loss: 0.5935 - val_accuracy: 0.6549\n",
      "Epoch 70/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5800 - accuracy: 0.6657 - val_loss: 0.6571 - val_accuracy: 0.6250\n",
      "Epoch 71/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5756 - accuracy: 0.6676 - val_loss: 0.5991 - val_accuracy: 0.6289\n",
      "Epoch 72/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5733 - accuracy: 0.6734 - val_loss: 0.6211 - val_accuracy: 0.6165\n",
      "Epoch 73/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5721 - accuracy: 0.6739 - val_loss: 0.5953 - val_accuracy: 0.6517\n",
      "Epoch 74/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5717 - accuracy: 0.6747 - val_loss: 0.6018 - val_accuracy: 0.6247\n",
      "Epoch 75/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5695 - accuracy: 0.6713 - val_loss: 0.6424 - val_accuracy: 0.6211\n",
      "Epoch 76/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5754 - accuracy: 0.6706 - val_loss: 0.6865 - val_accuracy: 0.5684\n",
      "Epoch 77/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5661 - accuracy: 0.6793 - val_loss: 0.6631 - val_accuracy: 0.5788\n",
      "Epoch 78/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5642 - accuracy: 0.6799 - val_loss: 0.5841 - val_accuracy: 0.6445\n",
      "Epoch 79/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5600 - accuracy: 0.6790 - val_loss: 0.6160 - val_accuracy: 0.6263\n",
      "Epoch 80/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5653 - accuracy: 0.6790 - val_loss: 0.6274 - val_accuracy: 0.5954\n",
      "Epoch 81/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5619 - accuracy: 0.6810 - val_loss: 0.6317 - val_accuracy: 0.6211\n",
      "Epoch 82/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5575 - accuracy: 0.6851 - val_loss: 0.5658 - val_accuracy: 0.6755 -\n",
      "Epoch 83/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5596 - accuracy: 0.6816 - val_loss: 0.5760 - val_accuracy: 0.6592\n",
      "Epoch 84/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5623 - accuracy: 0.6775 - val_loss: 0.6352 - val_accuracy: 0.6097\n",
      "Epoch 85/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5588 - accuracy: 0.6832 - val_loss: 0.6232 - val_accuracy: 0.6110\n",
      "Epoch 86/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5556 - accuracy: 0.6864 - val_loss: 0.6681 - val_accuracy: 0.6169\n",
      "Epoch 87/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5522 - accuracy: 0.6902 - val_loss: 0.6221 - val_accuracy: 0.6595\n",
      "Epoch 88/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5493 - accuracy: 0.6915 - val_loss: 0.6252 - val_accuracy: 0.6400\n",
      "Epoch 89/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5460 - accuracy: 0.6941 - val_loss: 0.6633 - val_accuracy: 0.6143\n",
      "Epoch 90/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5497 - accuracy: 0.6947 - val_loss: 0.5990 - val_accuracy: 0.65170s -\n",
      "Epoch 91/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5513 - accuracy: 0.6904 - val_loss: 0.6003 - val_accuracy: 0.6514\n",
      "Epoch 92/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5419 - accuracy: 0.6997 - val_loss: 0.6131 - val_accuracy: 0.6478\n",
      "Epoch 93/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5435 - accuracy: 0.6965 - val_loss: 0.6424 - val_accuracy: 0.5863\n",
      "Epoch 94/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.5389 - accuracy: 0.7000 - val_loss: 0.5644 - val_accuracy: 0.6709\n",
      "Epoch 95/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5445 - accuracy: 0.6963 - val_loss: 0.7006 - val_accuracy: 0.5879\n",
      "Epoch 96/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5382 - accuracy: 0.7001 - val_loss: 0.5952 - val_accuracy: 0.6628\n",
      "Epoch 97/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5390 - accuracy: 0.6998 - val_loss: 0.5838 - val_accuracy: 0.6602\n",
      "Epoch 98/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.5386 - accuracy: 0.7001 - val_loss: 0.6056 - val_accuracy: 0.6390\n",
      "Epoch 99/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.5421 - accuracy: 0.6968 - val_loss: 0.6571 - val_accuracy: 0.5938\n",
      "Epoch 100/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.5409 - accuracy: 0.6982 - val_loss: 0.5667 - val_accuracy: 0.6878\n",
      "Epoch 101/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5407 - accuracy: 0.7021 - val_loss: 0.5963 - val_accuracy: 0.6562\n",
      "Epoch 102/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.5312 - accuracy: 0.7085 - val_loss: 0.5715 - val_accuracy: 0.6712\n",
      "Epoch 103/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5493 - accuracy: 0.6909 - val_loss: 0.6087 - val_accuracy: 0.6449\n",
      "Epoch 104/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5359 - accuracy: 0.6970 - val_loss: 0.5518 - val_accuracy: 0.7038\n",
      "Epoch 105/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5335 - accuracy: 0.7051 - val_loss: 0.5683 - val_accuracy: 0.6683\n",
      "Epoch 106/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5343 - accuracy: 0.7059 - val_loss: 0.5704 - val_accuracy: 0.6829\n",
      "Epoch 107/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5251 - accuracy: 0.7109 - val_loss: 0.5923 - val_accuracy: 0.6803\n",
      "Epoch 108/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5235 - accuracy: 0.7103 - val_loss: 0.5660 - val_accuracy: 0.6732\n",
      "Epoch 109/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5248 - accuracy: 0.7139 - val_loss: 0.5833 - val_accuracy: 0.6452\n",
      "Epoch 110/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5234 - accuracy: 0.7098 - val_loss: 0.5715 - val_accuracy: 0.6774\n",
      "Epoch 111/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5178 - accuracy: 0.7122 - val_loss: 0.5570 - val_accuracy: 0.6878\n",
      "Epoch 112/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5170 - accuracy: 0.7156 - val_loss: 0.6015 - val_accuracy: 0.6410\n",
      "Epoch 113/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5167 - accuracy: 0.7163 - val_loss: 0.5640 - val_accuracy: 0.6823\n",
      "Epoch 114/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5178 - accuracy: 0.7136 - val_loss: 0.6070 - val_accuracy: 0.6530\n",
      "Epoch 115/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5149 - accuracy: 0.7170 - val_loss: 0.5653 - val_accuracy: 0.6891\n",
      "Epoch 116/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5084 - accuracy: 0.7247 - val_loss: 0.5370 - val_accuracy: 0.7096\n",
      "Epoch 117/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5085 - accuracy: 0.7230 - val_loss: 0.5381 - val_accuracy: 0.7025\n",
      "Epoch 118/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5062 - accuracy: 0.7270 - val_loss: 0.5730 - val_accuracy: 0.6950\n",
      "Epoch 119/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5018 - accuracy: 0.7258 - val_loss: 0.5254 - val_accuracy: 0.7275\n",
      "Epoch 120/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5017 - accuracy: 0.7273 - val_loss: 0.5493 - val_accuracy: 0.6813\n",
      "Epoch 121/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5048 - accuracy: 0.7238 - val_loss: 0.5639 - val_accuracy: 0.6647\n",
      "Epoch 122/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5007 - accuracy: 0.7311 - val_loss: 0.5806 - val_accuracy: 0.6536\n",
      "Epoch 123/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4959 - accuracy: 0.7357 - val_loss: 0.5815 - val_accuracy: 0.6689\n",
      "Epoch 124/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4980 - accuracy: 0.7317 - val_loss: 0.6058 - val_accuracy: 0.6507\n",
      "Epoch 125/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.4946 - accuracy: 0.7331 - val_loss: 0.6369 - val_accuracy: 0.6136\n",
      "Epoch 126/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.4963 - accuracy: 0.7321 - val_loss: 0.5428 - val_accuracy: 0.6898\n",
      "Epoch 127/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5053 - accuracy: 0.7234 - val_loss: 0.5541 - val_accuracy: 0.6855\n",
      "Epoch 128/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5071 - accuracy: 0.7248 - val_loss: 0.5664 - val_accuracy: 0.6810\n",
      "Epoch 129/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4960 - accuracy: 0.7315 - val_loss: 0.5059 - val_accuracy: 0.7129\n",
      "Epoch 130/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4995 - accuracy: 0.7282 - val_loss: 0.5719 - val_accuracy: 0.6680\n",
      "Epoch 131/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4931 - accuracy: 0.7332 - val_loss: 0.5694 - val_accuracy: 0.7126\n",
      "Epoch 132/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4949 - accuracy: 0.7326 - val_loss: 0.4951 - val_accuracy: 0.7223\n",
      "Epoch 133/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4912 - accuracy: 0.7358 - val_loss: 0.5434 - val_accuracy: 0.7155\n",
      "Epoch 134/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4874 - accuracy: 0.7381 - val_loss: 0.5901 - val_accuracy: 0.6712\n",
      "Epoch 135/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4826 - accuracy: 0.7392 - val_loss: 0.5373 - val_accuracy: 0.7184\n",
      "Epoch 136/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4831 - accuracy: 0.7394 - val_loss: 0.5627 - val_accuracy: 0.6738\n",
      "Epoch 137/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.4850 - accuracy: 0.7365 - val_loss: 0.5356 - val_accuracy: 0.7038\n",
      "Epoch 138/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4735 - accuracy: 0.7476 - val_loss: 0.5793 - val_accuracy: 0.6816\n",
      "Epoch 139/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.4744 - accuracy: 0.7447 - val_loss: 0.5300 - val_accuracy: 0.7113\n",
      "Epoch 140/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4802 - accuracy: 0.7415 - val_loss: 0.5574 - val_accuracy: 0.6937\n",
      "Epoch 141/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4726 - accuracy: 0.7485 - val_loss: 0.5422 - val_accuracy: 0.7051\n",
      "Epoch 142/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4766 - accuracy: 0.7457 - val_loss: 0.5448 - val_accuracy: 0.6787\n",
      "Epoch 143/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4797 - accuracy: 0.7415 - val_loss: 0.5051 - val_accuracy: 0.7311\n",
      "Epoch 144/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4750 - accuracy: 0.7463 - val_loss: 0.5268 - val_accuracy: 0.7214\n",
      "Epoch 145/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4780 - accuracy: 0.7446 - val_loss: 0.5371 - val_accuracy: 0.7298\n",
      "Epoch 146/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4708 - accuracy: 0.7469 - val_loss: 0.4858 - val_accuracy: 0.7402\n",
      "Epoch 147/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4663 - accuracy: 0.7532 - val_loss: 0.5364 - val_accuracy: 0.7217\n",
      "Epoch 148/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4636 - accuracy: 0.7516 - val_loss: 0.5137 - val_accuracy: 0.7298\n",
      "Epoch 149/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4895 - accuracy: 0.7316 - val_loss: 0.5495 - val_accuracy: 0.6979\n",
      "Epoch 150/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4712 - accuracy: 0.7497 - val_loss: 0.5782 - val_accuracy: 0.6859oss: 0.4708 - \n",
      "Epoch 151/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4719 - accuracy: 0.7470 - val_loss: 0.5581 - val_accuracy: 0.6852\n",
      "Epoch 152/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4722 - accuracy: 0.7491 - val_loss: 0.6032 - val_accuracy: 0.6709\n",
      "Epoch 153/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4669 - accuracy: 0.7533 - val_loss: 0.5274 - val_accuracy: 0.7035\n",
      "Epoch 154/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4584 - accuracy: 0.7574 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
      "Epoch 155/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4599 - accuracy: 0.7566 - val_loss: 0.5806 - val_accuracy: 0.6533\n",
      "Epoch 156/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4624 - accuracy: 0.7548 - val_loss: 0.5786 - val_accuracy: 0.6839\n",
      "Epoch 157/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.4608 - accuracy: 0.7574 - val_loss: 0.5580 - val_accuracy: 0.7171\n",
      "Epoch 158/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4608 - accuracy: 0.7538 - val_loss: 0.5554 - val_accuracy: 0.7152\n",
      "Epoch 159/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.4552 - accuracy: 0.7595 - val_loss: 0.5018 - val_accuracy: 0.7419\n",
      "Epoch 160/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4534 - accuracy: 0.7583 - val_loss: 0.5220 - val_accuracy: 0.7184\n",
      "Epoch 161/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4499 - accuracy: 0.7610 - val_loss: 0.6173 - val_accuracy: 0.6761\n",
      "Epoch 162/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.4515 - accuracy: 0.7628 - val_loss: 0.6429 - val_accuracy: 0.6751\n",
      "Epoch 163/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4550 - accuracy: 0.7571 - val_loss: 0.5031 - val_accuracy: 0.7256\n",
      "Epoch 164/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4539 - accuracy: 0.7631 - val_loss: 0.5953 - val_accuracy: 0.6888\n",
      "Epoch 165/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4481 - accuracy: 0.7616 - val_loss: 0.6434 - val_accuracy: 0.7018\n",
      "Epoch 166/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4477 - accuracy: 0.7621 - val_loss: 0.5989 - val_accuracy: 0.7132\n",
      "Epoch 167/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4524 - accuracy: 0.7591 - val_loss: 0.5279 - val_accuracy: 0.7090\n",
      "Epoch 168/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4457 - accuracy: 0.7648 - val_loss: 0.5765 - val_accuracy: 0.6719\n",
      "Epoch 169/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4432 - accuracy: 0.7667 - val_loss: 0.4808 - val_accuracy: 0.7331\n",
      "Epoch 170/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4418 - accuracy: 0.7705 - val_loss: 0.6204 - val_accuracy: 0.6585\n",
      "Epoch 171/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4462 - accuracy: 0.7651 - val_loss: 0.5594 - val_accuracy: 0.7087\n",
      "Epoch 172/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4418 - accuracy: 0.7684 - val_loss: 0.4807 - val_accuracy: 0.7578\n",
      "Epoch 173/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4376 - accuracy: 0.7708 - val_loss: 0.5941 - val_accuracy: 0.6813\n",
      "Epoch 174/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4396 - accuracy: 0.7683 - val_loss: 0.6431 - val_accuracy: 0.6732\n",
      "Epoch 175/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4342 - accuracy: 0.7730 - val_loss: 0.5928 - val_accuracy: 0.6940\n",
      "Epoch 176/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4314 - accuracy: 0.7708 - val_loss: 0.5561 - val_accuracy: 0.7109\n",
      "Epoch 177/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4375 - accuracy: 0.7695 - val_loss: 0.5572 - val_accuracy: 0.7132\n",
      "Epoch 178/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4331 - accuracy: 0.7736 - val_loss: 0.5064 - val_accuracy: 0.7347\n",
      "Epoch 179/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4307 - accuracy: 0.7727 - val_loss: 0.4946 - val_accuracy: 0.7246\n",
      "Epoch 180/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4316 - accuracy: 0.7759 - val_loss: 0.5187 - val_accuracy: 0.7285\n",
      "Epoch 181/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4344 - accuracy: 0.7735 - val_loss: 0.6121 - val_accuracy: 0.6969\n",
      "Epoch 182/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4204 - accuracy: 0.7822 - val_loss: 0.5422 - val_accuracy: 0.7184\n",
      "Epoch 183/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4206 - accuracy: 0.7803 - val_loss: 0.5152 - val_accuracy: 0.7233\n",
      "Epoch 184/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4279 - accuracy: 0.7765 - val_loss: 0.6978 - val_accuracy: 0.6663\n",
      "Epoch 185/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4266 - accuracy: 0.7779 - val_loss: 0.5360 - val_accuracy: 0.7389\n",
      "Epoch 186/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4258 - accuracy: 0.7815 - val_loss: 0.4646 - val_accuracy: 0.7503\n",
      "Epoch 187/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4249 - accuracy: 0.7819 - val_loss: 0.5250 - val_accuracy: 0.7204\n",
      "Epoch 188/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4284 - accuracy: 0.7790 - val_loss: 0.6005 - val_accuracy: 0.7064\n",
      "Epoch 189/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4263 - accuracy: 0.7756 - val_loss: 0.6114 - val_accuracy: 0.7142\n",
      "Epoch 190/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4172 - accuracy: 0.7805 - val_loss: 0.5375 - val_accuracy: 0.7109\n",
      "Epoch 191/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4194 - accuracy: 0.7815 - val_loss: 0.5569 - val_accuracy: 0.7259- accu\n",
      "Epoch 192/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4144 - accuracy: 0.7872 - val_loss: 0.5647 - val_accuracy: 0.7376\n",
      "Epoch 193/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4130 - accuracy: 0.7904 - val_loss: 0.6093 - val_accuracy: 0.6940\n",
      "Epoch 194/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4176 - accuracy: 0.7828 - val_loss: 0.4655 - val_accuracy: 0.7572\n",
      "Epoch 195/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4158 - accuracy: 0.7862 - val_loss: 0.6174 - val_accuracy: 0.6777\n",
      "Epoch 196/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4113 - accuracy: 0.7891 - val_loss: 0.4489 - val_accuracy: 0.7633\n",
      "Epoch 197/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4138 - accuracy: 0.7878 - val_loss: 0.6593 - val_accuracy: 0.6650\n",
      "Epoch 198/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4118 - accuracy: 0.7931 - val_loss: 0.5060 - val_accuracy: 0.7334\n",
      "Epoch 199/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4082 - accuracy: 0.7896 - val_loss: 0.6480 - val_accuracy: 0.6774\n",
      "Epoch 200/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4187 - accuracy: 0.7887 - val_loss: 0.6205 - val_accuracy: 0.6660\n",
      "Epoch 201/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4085 - accuracy: 0.7909 - val_loss: 0.5538 - val_accuracy: 0.7373\n",
      "Epoch 202/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4044 - accuracy: 0.7943 - val_loss: 0.6827 - val_accuracy: 0.6927\n",
      "Epoch 203/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4008 - accuracy: 0.7987 - val_loss: 0.5717 - val_accuracy: 0.6995\n",
      "Epoch 204/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4002 - accuracy: 0.7979 - val_loss: 0.5465 - val_accuracy: 0.7259\n",
      "Epoch 205/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4008 - accuracy: 0.7989 - val_loss: 0.5706 - val_accuracy: 0.7305\n",
      "Epoch 206/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3965 - accuracy: 0.7984 - val_loss: 0.5971 - val_accuracy: 0.7035\n",
      "Epoch 207/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3953 - accuracy: 0.7996 - val_loss: 0.4412 - val_accuracy: 0.7728\n",
      "Epoch 208/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3921 - accuracy: 0.8032 - val_loss: 0.5298 - val_accuracy: 0.7393\n",
      "Epoch 209/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3908 - accuracy: 0.7998 - val_loss: 0.5373 - val_accuracy: 0.7611\n",
      "Epoch 210/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3926 - accuracy: 0.8023 - val_loss: 0.4508 - val_accuracy: 0.7699\n",
      "Epoch 211/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3983 - accuracy: 0.8008 - val_loss: 0.5545 - val_accuracy: 0.7285\n",
      "Epoch 212/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3961 - accuracy: 0.8004 - val_loss: 0.6369 - val_accuracy: 0.6842\n",
      "Epoch 213/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3938 - accuracy: 0.7998 - val_loss: 0.5540 - val_accuracy: 0.7305\n",
      "Epoch 214/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3781 - accuracy: 0.8100 - val_loss: 0.6137 - val_accuracy: 0.6982\n",
      "Epoch 215/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3814 - accuracy: 0.8089 - val_loss: 0.6398 - val_accuracy: 0.6862\n",
      "Epoch 216/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3820 - accuracy: 0.8104 - val_loss: 0.4996 - val_accuracy: 0.7679\n",
      "Epoch 217/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3833 - accuracy: 0.8098 - val_loss: 0.5779 - val_accuracy: 0.7083\n",
      "Epoch 218/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3839 - accuracy: 0.8083 - val_loss: 0.4796 - val_accuracy: 0.7490\n",
      "Epoch 219/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3768 - accuracy: 0.8115 - val_loss: 0.5692 - val_accuracy: 0.7422\n",
      "Epoch 220/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3756 - accuracy: 0.8149 - val_loss: 0.5157 - val_accuracy: 0.7471\n",
      "Epoch 221/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3727 - accuracy: 0.8109 - val_loss: 0.5776 - val_accuracy: 0.7396\n",
      "Epoch 222/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3903 - accuracy: 0.8065 - val_loss: 0.5371 - val_accuracy: 0.7640\n",
      "Epoch 223/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3729 - accuracy: 0.8142 - val_loss: 0.6022 - val_accuracy: 0.7311\n",
      "Epoch 224/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3721 - accuracy: 0.8131 - val_loss: 0.5445 - val_accuracy: 0.7500\n",
      "Epoch 225/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3700 - accuracy: 0.8159 - val_loss: 0.5603 - val_accuracy: 0.7152\n",
      "Epoch 226/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3655 - accuracy: 0.8189 - val_loss: 0.4720 - val_accuracy: 0.7682\n",
      "Epoch 227/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3754 - accuracy: 0.8154 - val_loss: 0.5537 - val_accuracy: 0.7308\n",
      "Epoch 228/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3610 - accuracy: 0.8231 - val_loss: 0.6938 - val_accuracy: 0.6715\n",
      "Epoch 229/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3711 - accuracy: 0.8181 - val_loss: 0.4477 - val_accuracy: 0.7936\n",
      "Epoch 230/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3552 - accuracy: 0.8233 - val_loss: 0.5550 - val_accuracy: 0.7425\n",
      "Epoch 231/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3678 - accuracy: 0.8196 - val_loss: 0.5678 - val_accuracy: 0.7546\n",
      "Epoch 232/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3609 - accuracy: 0.8219 - val_loss: 0.5701 - val_accuracy: 0.7363 - loss: 0.3611 - accura\n",
      "Epoch 233/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3635 - accuracy: 0.8196 - val_loss: 0.4626 - val_accuracy: 0.7728\n",
      "Epoch 234/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3564 - accuracy: 0.8231 - val_loss: 0.5618 - val_accuracy: 0.7464\n",
      "Epoch 235/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3546 - accuracy: 0.8229 - val_loss: 0.4429 - val_accuracy: 0.7913\n",
      "Epoch 236/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3561 - accuracy: 0.8239 - val_loss: 0.5025 - val_accuracy: 0.7588\n",
      "Epoch 237/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3549 - accuracy: 0.8251 - val_loss: 0.4864 - val_accuracy: 0.7731\n",
      "Epoch 238/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3552 - accuracy: 0.8266 - val_loss: 0.6185 - val_accuracy: 0.7272\n",
      "Epoch 239/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3573 - accuracy: 0.8218 - val_loss: 0.5247 - val_accuracy: 0.7594\n",
      "Epoch 240/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3564 - accuracy: 0.8229 - val_loss: 0.5398 - val_accuracy: 0.7285\n",
      "Epoch 241/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3536 - accuracy: 0.8283 - val_loss: 0.5993 - val_accuracy: 0.7295\n",
      "Epoch 242/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3483 - accuracy: 0.8296 - val_loss: 0.5926 - val_accuracy: 0.7067\n",
      "Epoch 243/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3449 - accuracy: 0.8302 - val_loss: 0.5448 - val_accuracy: 0.7533\n",
      "Epoch 244/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3495 - accuracy: 0.8292 - val_loss: 0.6320 - val_accuracy: 0.7337\n",
      "Epoch 245/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3459 - accuracy: 0.8304 - val_loss: 0.6171 - val_accuracy: 0.7269\n",
      "Epoch 246/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3396 - accuracy: 0.8345 - val_loss: 0.5592 - val_accuracy: 0.7480\n",
      "Epoch 247/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3429 - accuracy: 0.8313 - val_loss: 0.5773 - val_accuracy: 0.7243\n",
      "Epoch 248/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3489 - accuracy: 0.8283 - val_loss: 0.5472 - val_accuracy: 0.7484\n",
      "Epoch 249/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3419 - accuracy: 0.8332 - val_loss: 0.6840 - val_accuracy: 0.6839\n",
      "Epoch 250/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3355 - accuracy: 0.8332 - val_loss: 0.5250 - val_accuracy: 0.7376\n",
      "Epoch 251/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3419 - accuracy: 0.8315 - val_loss: 0.5868 - val_accuracy: 0.7383\n",
      "Epoch 252/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3314 - accuracy: 0.8368 - val_loss: 0.5941 - val_accuracy: 0.7412\n",
      "Epoch 253/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3288 - accuracy: 0.8380 - val_loss: 0.5344 - val_accuracy: 0.7594\n",
      "Epoch 254/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3237 - accuracy: 0.8421 - val_loss: 0.5750 - val_accuracy: 0.7520\n",
      "Epoch 255/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3401 - accuracy: 0.8340 - val_loss: 0.5370 - val_accuracy: 0.7386\n",
      "Epoch 256/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3326 - accuracy: 0.8403 - val_loss: 0.6040 - val_accuracy: 0.7246\n",
      "Epoch 257/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3333 - accuracy: 0.8385 - val_loss: 0.5783 - val_accuracy: 0.7347\n",
      "Epoch 258/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3266 - accuracy: 0.8400 - val_loss: 0.6975 - val_accuracy: 0.6999\n",
      "Epoch 259/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3236 - accuracy: 0.8416 - val_loss: 0.5826 - val_accuracy: 0.7386\n",
      "Epoch 260/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3293 - accuracy: 0.8395 - val_loss: 0.6391 - val_accuracy: 0.6882\n",
      "Epoch 261/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3235 - accuracy: 0.8451 - val_loss: 0.5972 - val_accuracy: 0.7477\n",
      "Epoch 262/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3233 - accuracy: 0.8429 - val_loss: 0.5895 - val_accuracy: 0.7376\n",
      "Epoch 263/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3269 - accuracy: 0.8433 - val_loss: 0.5939 - val_accuracy: 0.7266\n",
      "Epoch 264/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3160 - accuracy: 0.8455 - val_loss: 0.4988 - val_accuracy: 0.7520\n",
      "Epoch 265/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3210 - accuracy: 0.8455 - val_loss: 0.6247 - val_accuracy: 0.7191\n",
      "Epoch 266/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3242 - accuracy: 0.8434 - val_loss: 0.6194 - val_accuracy: 0.7253\n",
      "Epoch 267/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3243 - accuracy: 0.8404 - val_loss: 0.5755 - val_accuracy: 0.7256\n",
      "Epoch 268/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3146 - accuracy: 0.8482 - val_loss: 0.6053 - val_accuracy: 0.7324\n",
      "Epoch 269/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3078 - accuracy: 0.8485 - val_loss: 0.6136 - val_accuracy: 0.7386\n",
      "Epoch 270/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3097 - accuracy: 0.8529 - val_loss: 0.5584 - val_accuracy: 0.7604\n",
      "Epoch 271/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3127 - accuracy: 0.8483 - val_loss: 0.6046 - val_accuracy: 0.7402\n",
      "Epoch 272/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3125 - accuracy: 0.8503 - val_loss: 0.4848 - val_accuracy: 0.7699\n",
      "Epoch 273/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3122 - accuracy: 0.8481 - val_loss: 0.4986 - val_accuracy: 0.7767\n",
      "Epoch 274/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3144 - accuracy: 0.8509 - val_loss: 0.5097 - val_accuracy: 0.7549\n",
      "Epoch 275/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3084 - accuracy: 0.8530 - val_loss: 0.4633 - val_accuracy: 0.7738\n",
      "Epoch 276/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3215 - accuracy: 0.8465 - val_loss: 0.5880 - val_accuracy: 0.7155\n",
      "Epoch 277/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3131 - accuracy: 0.8475 - val_loss: 0.6042 - val_accuracy: 0.7490\n",
      "Epoch 278/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3089 - accuracy: 0.8492 - val_loss: 0.5127 - val_accuracy: 0.7611\n",
      "Epoch 279/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2981 - accuracy: 0.8571 - val_loss: 0.5972 - val_accuracy: 0.7523\n",
      "Epoch 280/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2987 - accuracy: 0.8592 - val_loss: 0.7490 - val_accuracy: 0.6917\n",
      "Epoch 281/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3038 - accuracy: 0.8543 - val_loss: 0.5219 - val_accuracy: 0.7409\n",
      "Epoch 282/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3079 - accuracy: 0.8541 - val_loss: 0.5597 - val_accuracy: 0.7458\n",
      "Epoch 283/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3050 - accuracy: 0.8547 - val_loss: 0.6417 - val_accuracy: 0.7461\n",
      "Epoch 284/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2979 - accuracy: 0.8553 - val_loss: 0.7262 - val_accuracy: 0.7080\n",
      "Epoch 285/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2991 - accuracy: 0.8553 - val_loss: 0.5455 - val_accuracy: 0.7601\n",
      "Epoch 286/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3035 - accuracy: 0.8573 - val_loss: 0.5956 - val_accuracy: 0.7575\n",
      "Epoch 287/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3025 - accuracy: 0.8553 - val_loss: 0.5862 - val_accuracy: 0.7340\n",
      "Epoch 288/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3095 - accuracy: 0.8545 - val_loss: 0.4592 - val_accuracy: 0.7601\n",
      "Epoch 289/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2899 - accuracy: 0.8625 - val_loss: 0.5470 - val_accuracy: 0.7249\n",
      "Epoch 290/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2927 - accuracy: 0.8588 - val_loss: 0.6341 - val_accuracy: 0.7425\n",
      "Epoch 291/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2978 - accuracy: 0.8572 - val_loss: 0.6001 - val_accuracy: 0.7259\n",
      "Epoch 292/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2928 - accuracy: 0.8608 - val_loss: 0.5127 - val_accuracy: 0.7633\n",
      "Epoch 293/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2848 - accuracy: 0.8637 - val_loss: 0.6057 - val_accuracy: 0.7562\n",
      "Epoch 294/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3147 - accuracy: 0.8502 - val_loss: 0.6819 - val_accuracy: 0.7018\n",
      "Epoch 295/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2949 - accuracy: 0.8582 - val_loss: 0.6125 - val_accuracy: 0.7357\n",
      "Epoch 296/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2863 - accuracy: 0.8654 - val_loss: 0.7046 - val_accuracy: 0.7145\n",
      "Epoch 297/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2853 - accuracy: 0.8636 - val_loss: 0.6811 - val_accuracy: 0.7240\n",
      "Epoch 298/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2862 - accuracy: 0.8653 - val_loss: 0.5889 - val_accuracy: 0.7275\n",
      "Epoch 299/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2863 - accuracy: 0.8624 - val_loss: 0.6852 - val_accuracy: 0.7080\n",
      "Epoch 300/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2842 - accuracy: 0.8626 - val_loss: 0.5910 - val_accuracy: 0.7458\n",
      "Epoch 301/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3248 - accuracy: 0.8472 - val_loss: 0.5207 - val_accuracy: 0.7539\n",
      "Epoch 302/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2983 - accuracy: 0.8592 - val_loss: 0.5415 - val_accuracy: 0.7809\n",
      "Epoch 303/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2937 - accuracy: 0.8628 - val_loss: 0.8005 - val_accuracy: 0.6722\n",
      "Epoch 304/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2910 - accuracy: 0.8617 - val_loss: 0.7479 - val_accuracy: 0.6943\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00304: early stopping\n",
      "     12/Unknown - 0s 5ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121/3121 [==============================] - 15s 5ms/step\n",
      "347/347 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|                                                            | 2/10 [2:36:11<10:22:20, 4667.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "438/438 [==============================] - 16s 34ms/step - loss: 0.6925 - accuracy: 0.4997 - val_loss: 0.6926 - val_accuracy: 0.5046\n",
      "Epoch 2/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6906 - accuracy: 0.4874 - val_loss: 0.6923 - val_accuracy: 0.5241\n",
      "Epoch 3/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6863 - accuracy: 0.5318 - val_loss: 0.6934 - val_accuracy: 0.5007\n",
      "Epoch 4/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6761 - accuracy: 0.5656 - val_loss: 0.6975 - val_accuracy: 0.5146\n",
      "Epoch 5/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6740 - accuracy: 0.5619 - val_loss: 0.6901 - val_accuracy: 0.5114\n",
      "Epoch 6/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6677 - accuracy: 0.5689 - val_loss: 0.7207 - val_accuracy: 0.5055\n",
      "Epoch 7/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6652 - accuracy: 0.5711 - val_loss: 0.6809 - val_accuracy: 0.5176\n",
      "Epoch 8/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6620 - accuracy: 0.5784 - val_loss: 0.6975 - val_accuracy: 0.5104\n",
      "Epoch 9/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6597 - accuracy: 0.5797 - val_loss: 0.6911 - val_accuracy: 0.5091\n",
      "Epoch 10/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6583 - accuracy: 0.5832 - val_loss: 0.6905 - val_accuracy: 0.5150\n",
      "Epoch 11/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6581 - accuracy: 0.5817 - val_loss: 0.6773 - val_accuracy: 0.5309s: 0.6582 - accuracy: \n",
      "Epoch 12/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6532 - accuracy: 0.5870 - val_loss: 0.6669 - val_accuracy: 0.5765 ETA: 1s - loss: 0.653 - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.6533 - accu\n",
      "Epoch 13/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6576 - accuracy: 0.5843 - val_loss: 0.6714 - val_accuracy: 0.5452\n",
      "Epoch 14/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6542 - accuracy: 0.5880 - val_loss: 0.6597 - val_accuracy: 0.5602\n",
      "Epoch 15/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6531 - accuracy: 0.5920 - val_loss: 0.6857 - val_accuracy: 0.5745\n",
      "Epoch 16/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6498 - accuracy: 0.5969 - val_loss: 0.6637 - val_accuracy: 0.5941\n",
      "Epoch 17/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6496 - accuracy: 0.5980 - val_loss: 0.6681 - val_accuracy: 0.5846\n",
      "Epoch 18/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6497 - accuracy: 0.5986 - val_loss: 0.6583 - val_accuracy: 0.5723\n",
      "Epoch 19/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6422 - accuracy: 0.6039 - val_loss: 0.6468 - val_accuracy: 0.6077\n",
      "Epoch 20/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6438 - accuracy: 0.5999 - val_loss: 0.6631 - val_accuracy: 0.5768\n",
      "Epoch 21/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6428 - accuracy: 0.6033 - val_loss: 0.6468 - val_accuracy: 0.6211\n",
      "Epoch 22/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6415 - accuracy: 0.6067 - val_loss: 0.6427 - val_accuracy: 0.6117\n",
      "Epoch 23/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6416 - accuracy: 0.6015 - val_loss: 0.6517 - val_accuracy: 0.6149\n",
      "Epoch 24/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6380 - accuracy: 0.6098 - val_loss: 0.6462 - val_accuracy: 0.5775\n",
      "Epoch 25/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6347 - accuracy: 0.6167 - val_loss: 0.6417 - val_accuracy: 0.6396\n",
      "Epoch 26/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6357 - accuracy: 0.6112 - val_loss: 0.6539 - val_accuracy: 0.5752\n",
      "Epoch 27/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6358 - accuracy: 0.6121 - val_loss: 0.6450 - val_accuracy: 0.5843\n",
      "Epoch 28/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6307 - accuracy: 0.6195 - val_loss: 0.6337 - val_accuracy: 0.6335\n",
      "Epoch 29/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6310 - accuracy: 0.6204 - val_loss: 0.6409 - val_accuracy: 0.6126\n",
      "Epoch 30/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6315 - accuracy: 0.6149 - val_loss: 0.6308 - val_accuracy: 0.6497oss: 0.6316 - \n",
      "Epoch 31/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6302 - accuracy: 0.6170 - val_loss: 0.6304 - val_accuracy: 0.6357cy: 0.61\n",
      "Epoch 32/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6286 - accuracy: 0.6147 - val_loss: 0.6382 - val_accuracy: 0.5892\n",
      "Epoch 33/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6278 - accuracy: 0.6237 - val_loss: 0.6316 - val_accuracy: 0.6221\n",
      "Epoch 34/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6239 - accuracy: 0.6267 - val_loss: 0.6390 - val_accuracy: 0.6302\n",
      "Epoch 35/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6227 - accuracy: 0.6278 - val_loss: 0.6314 - val_accuracy: 0.6527\n",
      "Epoch 36/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6211 - accuracy: 0.6267 - val_loss: 0.6376 - val_accuracy: 0.6198\n",
      "Epoch 37/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6194 - accuracy: 0.6291 - val_loss: 0.6258 - val_accuracy: 0.6185\n",
      "Epoch 38/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6219 - accuracy: 0.6219 - val_loss: 0.6227 - val_accuracy: 0.6344\n",
      "Epoch 39/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6223 - accuracy: 0.6243 - val_loss: 0.6225 - val_accuracy: 0.6468\n",
      "Epoch 40/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6180 - accuracy: 0.6271 - val_loss: 0.6321 - val_accuracy: 0.6156\n",
      "Epoch 41/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6158 - accuracy: 0.6340 - val_loss: 0.6281 - val_accuracy: 0.6195\n",
      "Epoch 42/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6158 - accuracy: 0.6273 - val_loss: 0.6423 - val_accuracy: 0.6217\n",
      "Epoch 43/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6171 - accuracy: 0.6301 - val_loss: 0.6186 - val_accuracy: 0.6553\n",
      "Epoch 44/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6120 - accuracy: 0.6366 - val_loss: 0.6257 - val_accuracy: 0.61460s - loss: 0.6130 - accuracy: 0. - ETA: 0s - loss:\n",
      "Epoch 45/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6139 - accuracy: 0.6248 - val_loss: 0.6227 - val_accuracy: 0.6188\n",
      "Epoch 46/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6109 - accuracy: 0.6323 - val_loss: 0.6148 - val_accuracy: 0.6322\n",
      "Epoch 47/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6120 - accuracy: 0.6300 - val_loss: 0.6147 - val_accuracy: 0.6273\n",
      "Epoch 48/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6099 - accuracy: 0.6362 - val_loss: 0.6162 - val_accuracy: 0.6208\n",
      "Epoch 49/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6115 - accuracy: 0.6325 - val_loss: 0.6368 - val_accuracy: 0.6107\n",
      "Epoch 50/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6099 - accuracy: 0.6346 - val_loss: 0.6178 - val_accuracy: 0.6289\n",
      "Epoch 51/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6097 - accuracy: 0.6372 - val_loss: 0.6166 - val_accuracy: 0.6523\n",
      "Epoch 52/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6084 - accuracy: 0.6350 - val_loss: 0.6262 - val_accuracy: 0.6240\n",
      "Epoch 53/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6038 - accuracy: 0.6397 - val_loss: 0.6137 - val_accuracy: 0.6257\n",
      "Epoch 54/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6043 - accuracy: 0.6374 - val_loss: 0.6181 - val_accuracy: 0.6445\n",
      "Epoch 55/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6059 - accuracy: 0.6370 - val_loss: 0.6102 - val_accuracy: 0.6406\n",
      "Epoch 56/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6042 - accuracy: 0.6358 - val_loss: 0.6193 - val_accuracy: 0.6260 - loss: 0.6042 - accuracy: 0.\n",
      "Epoch 57/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5991 - accuracy: 0.6419 - val_loss: 0.6105 - val_accuracy: 0.6445\n",
      "Epoch 58/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6073 - accuracy: 0.6339 - val_loss: 0.6277 - val_accuracy: 0.6286\n",
      "Epoch 59/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6023 - accuracy: 0.6370 - val_loss: 0.6141 - val_accuracy: 0.6442\n",
      "Epoch 60/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6031 - accuracy: 0.6381 - val_loss: 0.6049 - val_accuracy: 0.6400\n",
      "Epoch 61/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6009 - accuracy: 0.6402 - val_loss: 0.6028 - val_accuracy: 0.6530\n",
      "Epoch 62/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6013 - accuracy: 0.6403 - val_loss: 0.6159 - val_accuracy: 0.6426\n",
      "Epoch 63/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5976 - accuracy: 0.6439 - val_loss: 0.6261 - val_accuracy: 0.6403\n",
      "Epoch 64/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5978 - accuracy: 0.6448 - val_loss: 0.6087 - val_accuracy: 0.6234\n",
      "Epoch 65/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5931 - accuracy: 0.6440 - val_loss: 0.6108 - val_accuracy: 0.6572\n",
      "Epoch 66/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5969 - accuracy: 0.6480 - val_loss: 0.6151 - val_accuracy: 0.6208\n",
      "Epoch 67/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5917 - accuracy: 0.6475 - val_loss: 0.6071 - val_accuracy: 0.6344\n",
      "Epoch 68/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5914 - accuracy: 0.6475 - val_loss: 0.6503 - val_accuracy: 0.5957\n",
      "Epoch 69/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5918 - accuracy: 0.6464 - val_loss: 0.6226 - val_accuracy: 0.6279\n",
      "Epoch 70/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5908 - accuracy: 0.6474 - val_loss: 0.6125 - val_accuracy: 0.6335\n",
      "Epoch 71/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5868 - accuracy: 0.6526 - val_loss: 0.6181 - val_accuracy: 0.6204\n",
      "Epoch 72/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5849 - accuracy: 0.6522 - val_loss: 0.6081 - val_accuracy: 0.6481\n",
      "Epoch 73/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5829 - accuracy: 0.6553 - val_loss: 0.6138 - val_accuracy: 0.6149\n",
      "Epoch 74/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5865 - accuracy: 0.6489 - val_loss: 0.6125 - val_accuracy: 0.6292\n",
      "Epoch 75/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5859 - accuracy: 0.6543 - val_loss: 0.6379 - val_accuracy: 0.6077\n",
      "Epoch 76/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5860 - accuracy: 0.6543 - val_loss: 0.6046 - val_accuracy: 0.6462\n",
      "Epoch 77/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5854 - accuracy: 0.6544 - val_loss: 0.6030 - val_accuracy: 0.6361\n",
      "Epoch 78/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5808 - accuracy: 0.6548 - val_loss: 0.6208 - val_accuracy: 0.6257\n",
      "Epoch 79/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5841 - accuracy: 0.6544 - val_loss: 0.5897 - val_accuracy: 0.6624 0.5840 - accu - ETA: 0s - loss: 0.5843 - accuracy\n",
      "Epoch 80/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5803 - accuracy: 0.6580 - val_loss: 0.6028 - val_accuracy: 0.6536\n",
      "Epoch 81/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5773 - accuracy: 0.6576 - val_loss: 0.6069 - val_accuracy: 0.6540\n",
      "Epoch 82/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5803 - accuracy: 0.6556 - val_loss: 0.6196 - val_accuracy: 0.6107\n",
      "Epoch 83/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5759 - accuracy: 0.6576 - val_loss: 0.5962 - val_accuracy: 0.6351\n",
      "Epoch 84/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5774 - accuracy: 0.6548 - val_loss: 0.6270 - val_accuracy: 0.6029\n",
      "Epoch 85/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5770 - accuracy: 0.6586 - val_loss: 0.5930 - val_accuracy: 0.6452- accuracy: 0.657 - ETA: 10s - loss: 0.5774 - ETA: 9s - loss: - ETA: 6s - loss: 0.5762 - accuracy - ETA: 5s - loss: - ETA: \n",
      "Epoch 86/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5768 - accuracy: 0.6592 - val_loss: 0.6058 - val_accuracy: 0.6374\n",
      "Epoch 87/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5782 - accuracy: 0.6527 - val_loss: 0.6106 - val_accuracy: 0.6260\n",
      "Epoch 88/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5744 - accuracy: 0.6622 - val_loss: 0.6227 - val_accuracy: 0.60616 - ac\n",
      "Epoch 89/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5724 - accuracy: 0.6691 - val_loss: 0.6096 - val_accuracy: 0.6465\n",
      "Epoch 90/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5710 - accuracy: 0.6656 - val_loss: 0.6189 - val_accuracy: 0.5951\n",
      "Epoch 91/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5671 - accuracy: 0.6649 - val_loss: 0.6199 - val_accuracy: 0.6208\n",
      "Epoch 92/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5671 - accuracy: 0.6652 - val_loss: 0.5919 - val_accuracy: 0.6774\n",
      "Epoch 93/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5665 - accuracy: 0.6678 - val_loss: 0.6099 - val_accuracy: 0.6536\n",
      "Epoch 94/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5704 - accuracy: 0.6613 - val_loss: 0.6064 - val_accuracy: 0.6374\n",
      "Epoch 95/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5672 - accuracy: 0.6657 - val_loss: 0.6016 - val_accuracy: 0.6416 loss: 0.5673 - accuracy: 0.66\n",
      "Epoch 96/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5626 - accuracy: 0.6681 - val_loss: 0.6045 - val_accuracy: 0.6517\n",
      "Epoch 97/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5587 - accuracy: 0.6724 - val_loss: 0.6127 - val_accuracy: 0.6488\n",
      "Epoch 98/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5597 - accuracy: 0.6708 - val_loss: 0.6245 - val_accuracy: 0.6283\n",
      "Epoch 99/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5566 - accuracy: 0.6785 - val_loss: 0.5905 - val_accuracy: 0.6686\n",
      "Epoch 100/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5571 - accuracy: 0.6734 - val_loss: 0.5916 - val_accuracy: 0.6442\n",
      "Epoch 101/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5558 - accuracy: 0.6751 - val_loss: 0.5904 - val_accuracy: 0.6598\n",
      "Epoch 102/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5497 - accuracy: 0.6831 - val_loss: 0.5809 - val_accuracy: 0.6755\n",
      "Epoch 103/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5516 - accuracy: 0.6834 - val_loss: 0.5989 - val_accuracy: 0.6423\n",
      "Epoch 104/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5536 - accuracy: 0.6786 - val_loss: 0.5664 - val_accuracy: 0.6895\n",
      "Epoch 105/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5456 - accuracy: 0.6849 - val_loss: 0.6130 - val_accuracy: 0.6100\n",
      "Epoch 106/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5456 - accuracy: 0.6846 - val_loss: 0.6069 - val_accuracy: 0.6510\n",
      "Epoch 107/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5454 - accuracy: 0.6885 - val_loss: 0.6085 - val_accuracy: 0.6484\n",
      "Epoch 108/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5363 - accuracy: 0.6937 - val_loss: 0.6023 - val_accuracy: 0.6784\n",
      "Epoch 109/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5344 - accuracy: 0.6972 - val_loss: 0.5717 - val_accuracy: 0.6875\n",
      "Epoch 110/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5372 - accuracy: 0.6926 - val_loss: 0.5741 - val_accuracy: 0.6855\n",
      "Epoch 111/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5330 - accuracy: 0.6974 - val_loss: 0.5645 - val_accuracy: 0.6641\n",
      "Epoch 112/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5374 - accuracy: 0.6925 - val_loss: 0.5588 - val_accuracy: 0.7129\n",
      "Epoch 113/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5279 - accuracy: 0.7001 - val_loss: 0.5610 - val_accuracy: 0.6833\n",
      "Epoch 114/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5268 - accuracy: 0.7060 - val_loss: 0.5760 - val_accuracy: 0.6686\n",
      "Epoch 115/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5265 - accuracy: 0.7051 - val_loss: 0.5949 - val_accuracy: 0.6683\n",
      "Epoch 116/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5273 - accuracy: 0.7014 - val_loss: 0.5655 - val_accuracy: 0.6917\n",
      "Epoch 117/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5177 - accuracy: 0.7114 - val_loss: 0.5536 - val_accuracy: 0.6865\n",
      "Epoch 118/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5239 - accuracy: 0.7065 - val_loss: 0.5681 - val_accuracy: 0.6911\n",
      "Epoch 119/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5163 - accuracy: 0.7113 - val_loss: 0.6152 - val_accuracy: 0.6520\n",
      "Epoch 120/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5155 - accuracy: 0.7122 - val_loss: 0.5334 - val_accuracy: 0.6943\n",
      "Epoch 121/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5142 - accuracy: 0.7100 - val_loss: 0.5693 - val_accuracy: 0.6904s: 0.5112 - accuracy\n",
      "Epoch 122/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5072 - accuracy: 0.7189 - val_loss: 0.5618 - val_accuracy: 0.6758\n",
      "Epoch 123/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5099 - accuracy: 0.7168 - val_loss: 0.5658 - val_accuracy: 0.6862\n",
      "Epoch 124/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5083 - accuracy: 0.7197 - val_loss: 0.5374 - val_accuracy: 0.7100 - loss: 0.5098 - accuracy - ETA: 3s\n",
      "Epoch 125/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5015 - accuracy: 0.7230 - val_loss: 0.5689 - val_accuracy: 0.6895\n",
      "Epoch 126/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5134 - accuracy: 0.7131 - val_loss: 0.5634 - val_accuracy: 0.6976\n",
      "Epoch 127/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5057 - accuracy: 0.7199 - val_loss: 0.5820 - val_accuracy: 0.6829\n",
      "Epoch 128/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4987 - accuracy: 0.7255 - val_loss: 0.5472 - val_accuracy: 0.7204\n",
      "Epoch 129/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5145 - accuracy: 0.7098 - val_loss: 0.5865 - val_accuracy: 0.6966\n",
      "Epoch 130/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.5027 - accuracy: 0.7169 - val_loss: 0.5630 - val_accuracy: 0.6715\n",
      "Epoch 131/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.5059 - accuracy: 0.7176 - val_loss: 0.5542 - val_accuracy: 0.6807\n",
      "Epoch 132/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.5043 - accuracy: 0.7166 - val_loss: 0.6056 - val_accuracy: 0.6647\n",
      "Epoch 133/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.5033 - accuracy: 0.7222 - val_loss: 0.5989 - val_accuracy: 0.6667\n",
      "Epoch 134/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4944 - accuracy: 0.7271 - val_loss: 0.5578 - val_accuracy: 0.7031\n",
      "Epoch 135/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4905 - accuracy: 0.7305 - val_loss: 0.5484 - val_accuracy: 0.6934\n",
      "Epoch 136/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4989 - accuracy: 0.7252 - val_loss: 0.5594 - val_accuracy: 0.7048\n",
      "Epoch 137/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5000 - accuracy: 0.7189 - val_loss: 0.5827 - val_accuracy: 0.6683\n",
      "Epoch 138/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4908 - accuracy: 0.7286 - val_loss: 0.5736 - val_accuracy: 0.6898\n",
      "Epoch 139/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4899 - accuracy: 0.7306 - val_loss: 0.5819 - val_accuracy: 0.6790\n",
      "Epoch 140/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4845 - accuracy: 0.7311 - val_loss: 0.6168 - val_accuracy: 0.6471 - loss: 0.4836 - accuracy: \n",
      "Epoch 141/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4856 - accuracy: 0.7346 - val_loss: 0.5768 - val_accuracy: 0.6755\n",
      "Epoch 142/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4882 - accuracy: 0.7327 - val_loss: 0.5581 - val_accuracy: 0.6868\n",
      "Epoch 143/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4820 - accuracy: 0.7339 - val_loss: 0.5770 - val_accuracy: 0.6784\n",
      "Epoch 144/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4808 - accuracy: 0.7324 - val_loss: 0.5426 - val_accuracy: 0.7025\n",
      "Epoch 145/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4801 - accuracy: 0.7339 - val_loss: 0.5754 - val_accuracy: 0.6924\n",
      "Epoch 146/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4809 - accuracy: 0.7347 - val_loss: 0.5928 - val_accuracy: 0.6849\n",
      "Epoch 147/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4759 - accuracy: 0.7353 - val_loss: 0.5939 - val_accuracy: 0.6810\n",
      "Epoch 148/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4777 - accuracy: 0.7353 - val_loss: 0.5677 - val_accuracy: 0.6689\n",
      "Epoch 149/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4731 - accuracy: 0.7388 - val_loss: 0.6859 - val_accuracy: 0.6410\n",
      "Epoch 150/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4732 - accuracy: 0.7407 - val_loss: 0.5954 - val_accuracy: 0.6683\n",
      "Epoch 151/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4727 - accuracy: 0.7401 - val_loss: 0.5741 - val_accuracy: 0.6696\n",
      "Epoch 152/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4700 - accuracy: 0.7438 - val_loss: 0.5614 - val_accuracy: 0.6924 - ETA: 0s -\n",
      "Epoch 153/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4627 - accuracy: 0.7434 - val_loss: 0.6219 - val_accuracy: 0.6781\n",
      "Epoch 154/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4640 - accuracy: 0.7459 - val_loss: 0.5533 - val_accuracy: 0.6976\n",
      "Epoch 155/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4632 - accuracy: 0.7458 - val_loss: 0.6575 - val_accuracy: 0.6530\n",
      "Epoch 156/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4636 - accuracy: 0.7458 - val_loss: 0.6031 - val_accuracy: 0.6934\n",
      "Epoch 157/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4617 - accuracy: 0.7505 - val_loss: 0.5816 - val_accuracy: 0.6868\n",
      "Epoch 158/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4623 - accuracy: 0.7486 - val_loss: 0.6522 - val_accuracy: 0.6595\n",
      "Epoch 159/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4549 - accuracy: 0.7542 - val_loss: 0.5608 - val_accuracy: 0.7057\n",
      "Epoch 160/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4543 - accuracy: 0.7539 - val_loss: 0.5763 - val_accuracy: 0.6768\n",
      "Epoch 161/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4583 - accuracy: 0.7495 - val_loss: 0.6690 - val_accuracy: 0.6657\n",
      "Epoch 162/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4555 - accuracy: 0.7510 - val_loss: 0.6423 - val_accuracy: 0.6520\n",
      "Epoch 163/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4476 - accuracy: 0.7576 - val_loss: 0.5466 - val_accuracy: 0.7025\n",
      "Epoch 164/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4538 - accuracy: 0.7562 - val_loss: 0.6022 - val_accuracy: 0.6904\n",
      "Epoch 165/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4445 - accuracy: 0.7590 - val_loss: 0.6270 - val_accuracy: 0.6689\n",
      "Epoch 166/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4474 - accuracy: 0.7566 - val_loss: 0.6101 - val_accuracy: 0.6755\n",
      "Epoch 167/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4462 - accuracy: 0.7609 - val_loss: 0.6134 - val_accuracy: 0.6794\n",
      "Epoch 168/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4465 - accuracy: 0.7621 - val_loss: 0.5712 - val_accuracy: 0.6911\n",
      "Epoch 169/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4440 - accuracy: 0.7613 - val_loss: 0.6106 - val_accuracy: 0.6973\n",
      "Epoch 170/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4315 - accuracy: 0.7712 - val_loss: 0.5296 - val_accuracy: 0.7243\n",
      "Epoch 171/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4439 - accuracy: 0.7656 - val_loss: 0.6953 - val_accuracy: 0.6305 - ETA: 0s - loss:\n",
      "Epoch 172/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4357 - accuracy: 0.7686 - val_loss: 0.6299 - val_accuracy: 0.6911\n",
      "Epoch 173/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4342 - accuracy: 0.7666 - val_loss: 0.7372 - val_accuracy: 0.6104\n",
      "Epoch 174/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4346 - accuracy: 0.7675 - val_loss: 0.5720 - val_accuracy: 0.6794\n",
      "Epoch 175/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4424 - accuracy: 0.7605 - val_loss: 0.6369 - val_accuracy: 0.6585\n",
      "Epoch 176/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4320 - accuracy: 0.7698 - val_loss: 0.6084 - val_accuracy: 0.6758\n",
      "Epoch 177/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4453 - accuracy: 0.7606 - val_loss: 0.5965 - val_accuracy: 0.6745\n",
      "Epoch 178/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4352 - accuracy: 0.7670 - val_loss: 0.6303 - val_accuracy: 0.6722\n",
      "Epoch 179/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4459 - accuracy: 0.7629 - val_loss: 0.5797 - val_accuracy: 0.7067\n",
      "Epoch 180/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4408 - accuracy: 0.7668 - val_loss: 0.6698 - val_accuracy: 0.6836\n",
      "Epoch 181/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4306 - accuracy: 0.7717 - val_loss: 0.5372 - val_accuracy: 0.7057\n",
      "Epoch 182/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4214 - accuracy: 0.7749 - val_loss: 0.5912 - val_accuracy: 0.6960\n",
      "Epoch 183/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4277 - accuracy: 0.7738 - val_loss: 0.5769 - val_accuracy: 0.6781\n",
      "Epoch 184/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4321 - accuracy: 0.7712 - val_loss: 0.6413 - val_accuracy: 0.67902 - accuracy\n",
      "Epoch 185/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4190 - accuracy: 0.7793 - val_loss: 0.7034 - val_accuracy: 0.6501\n",
      "Epoch 186/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4224 - accuracy: 0.7779 - val_loss: 0.7057 - val_accuracy: 0.6647\n",
      "Epoch 187/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4245 - accuracy: 0.7740 - val_loss: 0.6902 - val_accuracy: 0.6546\n",
      "Epoch 188/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4221 - accuracy: 0.7776 - val_loss: 0.6376 - val_accuracy: 0.6771\n",
      "Epoch 189/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4208 - accuracy: 0.7789 - val_loss: 0.5788 - val_accuracy: 0.6976\n",
      "Epoch 190/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4228 - accuracy: 0.7793 - val_loss: 0.6037 - val_accuracy: 0.6895\n",
      "Epoch 191/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4153 - accuracy: 0.7795 - val_loss: 0.7239 - val_accuracy: 0.6784\n",
      "Epoch 192/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4155 - accuracy: 0.7812 - val_loss: 0.5679 - val_accuracy: 0.7096\n",
      "Epoch 193/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4156 - accuracy: 0.7828 - val_loss: 0.5874 - val_accuracy: 0.6969 l - ETA: 7s - l - ETA: 4s - loss: 0.412 - ETA: 4s - loss: 0.4131 - accuracy:  - ETA:  - ETA: 2s - loss: 0.4143 - accuracy: 0.78 - ETA:  - ETA: 1s - loss: 0.4 - ETA: 1s - loss: 0.4148 - accuracy: 0.78 - ETA: 0s - loss: 0.4146 - ac - ETA: 0s - loss: 0.4160 \n",
      "Epoch 194/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4083 - accuracy: 0.7857 - val_loss: 0.5893 - val_accuracy: 0.6930\n",
      "Epoch 195/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4091 - accuracy: 0.7866 - val_loss: 0.6266 - val_accuracy: 0.6833\n",
      "Epoch 196/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4122 - accuracy: 0.7841 - val_loss: 0.5954 - val_accuracy: 0.6836\n",
      "Epoch 197/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4067 - accuracy: 0.7903 - val_loss: 0.5789 - val_accuracy: 0.6950\n",
      "Epoch 198/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4018 - accuracy: 0.7916 - val_loss: 0.6256 - val_accuracy: 0.6908 - loss: 0.4022 - accu\n",
      "Epoch 199/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4024 - accuracy: 0.7864 - val_loss: 0.6317 - val_accuracy: 0.6908\n",
      "Epoch 200/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4021 - accuracy: 0.7915 - val_loss: 0.6256 - val_accuracy: 0.67387 - accuracy:  - ETA: 3s - loss: 0.4016 - accuracy - ETA: 3s - loss: 0.4\n",
      "Epoch 201/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4066 - accuracy: 0.7875 - val_loss: 0.5993 - val_accuracy: 0.6846\n",
      "Epoch 202/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4003 - accuracy: 0.7907 - val_loss: 0.6153 - val_accuracy: 0.6797oss: 0.396 - ETA: 3s - - ETA: 2s - loss: 0 - ETA: 1s - ETA: 0s - loss: 0.4006 - ac\n",
      "Epoch 203/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3915 - accuracy: 0.7962 - val_loss: 0.6920 - val_accuracy: 0.6650\n",
      "Epoch 204/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3953 - accuracy: 0.7958 - val_loss: 0.5864 - val_accuracy: 0.7093\n",
      "Epoch 205/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3937 - accuracy: 0.7965 - val_loss: 0.7154 - val_accuracy: 0.6471\n",
      "Epoch 206/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3952 - accuracy: 0.7958 - val_loss: 0.6808 - val_accuracy: 0.6689\n",
      "Epoch 207/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3962 - accuracy: 0.7973 - val_loss: 0.6455 - val_accuracy: 0.6748\n",
      "Epoch 208/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3842 - accuracy: 0.8001 - val_loss: 0.7552 - val_accuracy: 0.6465\n",
      "Epoch 209/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3892 - accuracy: 0.7981 - val_loss: 0.6959 - val_accuracy: 0.6533\n",
      "Epoch 210/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3903 - accuracy: 0.7969 - val_loss: 0.6679 - val_accuracy: 0.6761\n",
      "Epoch 211/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3903 - accuracy: 0.7991 - val_loss: 0.6167 - val_accuracy: 0.6872\n",
      "Epoch 212/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3901 - accuracy: 0.7961 - val_loss: 0.5872 - val_accuracy: 0.7021\n",
      "Epoch 213/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3865 - accuracy: 0.8019 - val_loss: 0.6414 - val_accuracy: 0.6803\n",
      "Epoch 214/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3836 - accuracy: 0.8024 - val_loss: 0.6179 - val_accuracy: 0.6937\n",
      "Epoch 215/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3850 - accuracy: 0.8036 - val_loss: 0.7476 - val_accuracy: 0.6478\n",
      "Epoch 216/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3810 - accuracy: 0.8047 - val_loss: 0.6467 - val_accuracy: 0.6921\n",
      "Epoch 217/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3772 - accuracy: 0.8086 - val_loss: 0.7766 - val_accuracy: 0.6481 loss: 0.3813 - accuracy - ETA: 4s - ETA: 3s - loss: 0.3809 - accuracy - ETA: 1s - loss: 0.3812 -  - ETA: 1s - loss: 0.3801 - ac - ETA: 0s - loss: 0.3790 - accuracy - ETA: 0s - loss: 0.3791 \n",
      "Epoch 218/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3751 - accuracy: 0.8091 - val_loss: 0.6416 - val_accuracy: 0.69140.3791 - ETA: 10s - lo - ETA: 1s\n",
      "Epoch 219/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3750 - accuracy: 0.8095 - val_loss: 0.6199 - val_accuracy: 0.6878\n",
      "Epoch 220/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3736 - accuracy: 0.8081 - val_loss: 0.6966 - val_accuracy: 0.6891\n",
      "Epoch 221/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3729 - accuracy: 0.8108 - val_loss: 0.6602 - val_accuracy: 0.6689\n",
      "Epoch 222/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3752 - accuracy: 0.8071 - val_loss: 0.6188 - val_accuracy: 0.6999\n",
      "Epoch 223/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3718 - accuracy: 0.8098 - val_loss: 0.5915 - val_accuracy: 0.7074\n",
      "Epoch 224/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3644 - accuracy: 0.8145 - val_loss: 0.6205 - val_accuracy: 0.702812s  - ETA: 3s - loss: 0.362 - ETA: 2s - loss: 0.3621 - accuracy: 0. - ETA:  -\n",
      "Epoch 225/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3682 - accuracy: 0.8138 - val_loss: 0.6325 - val_accuracy: 0.6930\n",
      "Epoch 226/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3627 - accuracy: 0.8166 - val_loss: 0.6866 - val_accuracy: 0.6761s: 0.3618 - accuracy: 0.81 - ETA: 0s - los\n",
      "Epoch 227/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3680 - accuracy: 0.8119 - val_loss: 0.6559 - val_accuracy: 0.6634\n",
      "Epoch 228/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3622 - accuracy: 0.8161 - val_loss: 0.6013 - val_accuracy: 0.7041\n",
      "Epoch 229/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3638 - accuracy: 0.8148 - val_loss: 0.6779 - val_accuracy: 0.6976\n",
      "Epoch 230/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3635 - accuracy: 0.8189 - val_loss: 0.6561 - val_accuracy: 0.6862\n",
      "Epoch 231/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3612 - accuracy: 0.8177 - val_loss: 0.6809 - val_accuracy: 0.6761\n",
      "Epoch 232/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3605 - accuracy: 0.8187 - val_loss: 0.6697 - val_accuracy: 0.6816\n",
      "Epoch 233/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3596 - accuracy: 0.8187 - val_loss: 0.7089 - val_accuracy: 0.6663\n",
      "Epoch 234/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3596 - accuracy: 0.8199 - val_loss: 0.6440 - val_accuracy: 0.6839accuracy: 0.82 - ETA: 0s - loss: 0.3589 - accuracy: 0.\n",
      "Epoch 235/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3580 - accuracy: 0.8209 - val_loss: 0.6722 - val_accuracy: 0.6712\n",
      "Epoch 236/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3552 - accuracy: 0.8218 - val_loss: 0.6361 - val_accuracy: 0.6895\n",
      "Epoch 237/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3539 - accuracy: 0.8250 - val_loss: 0.6722 - val_accuracy: 0.6914\n",
      "Epoch 238/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3549 - accuracy: 0.8233 - val_loss: 0.7606 - val_accuracy: 0.6670\n",
      "Epoch 239/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3455 - accuracy: 0.8273 - val_loss: 0.6697 - val_accuracy: 0.6816\n",
      "Epoch 240/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3471 - accuracy: 0.8273 - val_loss: 0.5973 - val_accuracy: 0.7184\n",
      "Epoch 241/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3521 - accuracy: 0.8231 - val_loss: 0.6075 - val_accuracy: 0.7057\n",
      "Epoch 242/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3524 - accuracy: 0.8256 - val_loss: 0.6145 - val_accuracy: 0.7152\n",
      "Epoch 243/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3501 - accuracy: 0.8255 - val_loss: 0.6820 - val_accuracy: 0.6953\n",
      "Epoch 244/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3424 - accuracy: 0.8323 - val_loss: 0.6696 - val_accuracy: 0.6898: 3s - loss: 0.341 - ETA: 3s - loss: 0.3405 - accu - ETA: 2s - loss: 0.3417  - ETA: 2s - los\n",
      "Epoch 245/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3462 - accuracy: 0.8270 - val_loss: 0.6404 - val_accuracy: 0.7188s: 0.3487 -  - ETA: 2s - loss: 0.3477 - accu - ETA: 2s - loss: 0\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00245: early stopping\n",
      "     11/Unknown - 0s 5ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121/3121 [==============================] - 15s 5ms/step\n",
      "347/347 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|                                                      | 3/10 [3:37:30<8:11:52, 4216.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "438/438 [==============================] - 16s 34ms/step - loss: 0.6917 - accuracy: 0.5304 - val_loss: 0.6925 - val_accuracy: 0.5065\n",
      "Epoch 2/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6870 - accuracy: 0.5435 - val_loss: 0.6927 - val_accuracy: 0.50136886 - accuracy:  - ETA: 6s - loss: 0.6885 - accura - ETA: 6s - loss: - ETA: 4s - loss: 0.6880 - accuracy: 0.54 - ETA: 4s - loss: 0.6879 - accuracy: 0.54 - ETA: 3s - loss: 0.6879 - accuracy: 0. - ETA\n",
      "Epoch 3/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6818 - accuracy: 0.5580 - val_loss: 0.6905 - val_accuracy: 0.5085\n",
      "Epoch 4/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6795 - accuracy: 0.5547 - val_loss: 0.6982 - val_accuracy: 0.5130\n",
      "Epoch 5/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6775 - accuracy: 0.5595 - val_loss: 0.6988 - val_accuracy: 0.5186\n",
      "Epoch 6/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6745 - accuracy: 0.5617 - val_loss: 0.6906 - val_accuracy: 0.5010\n",
      "Epoch 7/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6693 - accuracy: 0.5706 - val_loss: 0.6838 - val_accuracy: 0.51990s - loss: 0.6693 - accura\n",
      "Epoch 8/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6654 - accuracy: 0.5713 - val_loss: 0.6863 - val_accuracy: 0.5218\n",
      "Epoch 9/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6610 - accuracy: 0.5813 - val_loss: 0.6776 - val_accuracy: 0.5446\n",
      "Epoch 10/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6603 - accuracy: 0.5814 - val_loss: 0.6695 - val_accuracy: 0.5794\n",
      "Epoch 11/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6576 - accuracy: 0.5889 - val_loss: 0.6566 - val_accuracy: 0.5882\n",
      "Epoch 12/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6555 - accuracy: 0.5915 - val_loss: 0.6598 - val_accuracy: 0.6042\n",
      "Epoch 13/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6565 - accuracy: 0.5850 - val_loss: 0.6545 - val_accuracy: 0.5762- accuracy\n",
      "Epoch 14/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6547 - accuracy: 0.5884 - val_loss: 0.6627 - val_accuracy: 0.5641\n",
      "Epoch 15/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6527 - accuracy: 0.5913 - val_loss: 0.6794 - val_accuracy: 0.5856\n",
      "Epoch 16/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6505 - accuracy: 0.5964 - val_loss: 0.6553 - val_accuracy: 0.5697\n",
      "Epoch 17/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6481 - accuracy: 0.5981 - val_loss: 0.6660 - val_accuracy: 0.5433\n",
      "Epoch 18/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6450 - accuracy: 0.5994 - val_loss: 0.6647 - val_accuracy: 0.5645\n",
      "Epoch 19/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6479 - accuracy: 0.5982 - val_loss: 0.6546 - val_accuracy: 0.5977TA: 0s - loss: 0.6473 - \n",
      "Epoch 20/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6425 - accuracy: 0.6021 - val_loss: 0.6486 - val_accuracy: 0.5924\n",
      "Epoch 21/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6427 - accuracy: 0.6024 - val_loss: 0.6630 - val_accuracy: 0.5417\n",
      "Epoch 22/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6405 - accuracy: 0.6069 - val_loss: 0.6517 - val_accuracy: 0.6003\n",
      "Epoch 23/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6396 - accuracy: 0.6087 - val_loss: 0.6792 - val_accuracy: 0.5283\n",
      "Epoch 24/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6379 - accuracy: 0.6111 - val_loss: 0.6395 - val_accuracy: 0.6012\n",
      "Epoch 25/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6380 - accuracy: 0.6128 - val_loss: 0.6381 - val_accuracy: 0.6074\n",
      "Epoch 26/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6354 - accuracy: 0.6130 - val_loss: 0.6302 - val_accuracy: 0.6221\n",
      "Epoch 27/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6327 - accuracy: 0.6153 - val_loss: 0.6458 - val_accuracy: 0.5850\n",
      "Epoch 28/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6331 - accuracy: 0.6138 - val_loss: 0.6509 - val_accuracy: 0.6156\n",
      "Epoch 29/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6320 - accuracy: 0.6181 - val_loss: 0.6500 - val_accuracy: 0.6113\n",
      "Epoch 30/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6266 - accuracy: 0.6193 - val_loss: 0.6241 - val_accuracy: 0.6055\n",
      "Epoch 31/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6290 - accuracy: 0.6196 - val_loss: 0.6223 - val_accuracy: 0.6325\n",
      "Epoch 32/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6262 - accuracy: 0.6205 - val_loss: 0.6177 - val_accuracy: 0.6296\n",
      "Epoch 33/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6196 - accuracy: 0.6310 - val_loss: 0.6184 - val_accuracy: 0.6341\n",
      "Epoch 34/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6166 - accuracy: 0.6319 - val_loss: 0.6224 - val_accuracy: 0.6507\n",
      "Epoch 35/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6160 - accuracy: 0.6290 - val_loss: 0.6285 - val_accuracy: 0.6172\n",
      "Epoch 36/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.6147 - accuracy: 0.6323 - val_loss: 0.6009 - val_accuracy: 0.6322\n",
      "Epoch 37/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.6122 - accuracy: 0.6362 - val_loss: 0.5999 - val_accuracy: 0.6452\n",
      "Epoch 38/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.6105 - accuracy: 0.6371 - val_loss: 0.5912 - val_accuracy: 0.6530\n",
      "Epoch 39/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6040 - accuracy: 0.6427 - val_loss: 0.6113 - val_accuracy: 0.6331\n",
      "Epoch 40/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6049 - accuracy: 0.6480 - val_loss: 0.5994 - val_accuracy: 0.6488\n",
      "Epoch 41/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6047 - accuracy: 0.6491 - val_loss: 0.6088 - val_accuracy: 0.6406\n",
      "Epoch 42/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6018 - accuracy: 0.6505 - val_loss: 0.6033 - val_accuracy: 0.6351\n",
      "Epoch 43/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5991 - accuracy: 0.6550 - val_loss: 0.6227 - val_accuracy: 0.6071\n",
      "Epoch 44/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5977 - accuracy: 0.6543 - val_loss: 0.5900 - val_accuracy: 0.6481\n",
      "Epoch 45/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5931 - accuracy: 0.6594 - val_loss: 0.5752 - val_accuracy: 0.6693\n",
      "Epoch 46/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5940 - accuracy: 0.6562 - val_loss: 0.5824 - val_accuracy: 0.6670\n",
      "Epoch 47/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5921 - accuracy: 0.6567 - val_loss: 0.6368 - val_accuracy: 0.6009\n",
      "Epoch 48/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5900 - accuracy: 0.6653 - val_loss: 0.6171 - val_accuracy: 0.6585\n",
      "Epoch 49/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5867 - accuracy: 0.6641 - val_loss: 0.5900 - val_accuracy: 0.6566\n",
      "Epoch 50/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5835 - accuracy: 0.6721 - val_loss: 0.6294 - val_accuracy: 0.6113\n",
      "Epoch 51/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5799 - accuracy: 0.6721 - val_loss: 0.6399 - val_accuracy: 0.6136\n",
      "Epoch 52/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5801 - accuracy: 0.6703 - val_loss: 0.5557 - val_accuracy: 0.6911\n",
      "Epoch 53/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5803 - accuracy: 0.6731 - val_loss: 0.5865 - val_accuracy: 0.6868\n",
      "Epoch 54/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5777 - accuracy: 0.6744 - val_loss: 0.5662 - val_accuracy: 0.6823\n",
      "Epoch 55/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5704 - accuracy: 0.6829 - val_loss: 0.5752 - val_accuracy: 0.6764\n",
      "Epoch 56/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5709 - accuracy: 0.6764 - val_loss: 0.5471 - val_accuracy: 0.6911\n",
      "Epoch 57/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5828 - accuracy: 0.6627 - val_loss: 0.5993 - val_accuracy: 0.6436\n",
      "Epoch 58/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5685 - accuracy: 0.6787 - val_loss: 0.5552 - val_accuracy: 0.6852\n",
      "Epoch 59/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5691 - accuracy: 0.6774 - val_loss: 0.5823 - val_accuracy: 0.6598\n",
      "Epoch 60/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5676 - accuracy: 0.6784 - val_loss: 0.5873 - val_accuracy: 0.6582\n",
      "Epoch 61/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5624 - accuracy: 0.6838 - val_loss: 0.5838 - val_accuracy: 0.6644\n",
      "Epoch 62/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5611 - accuracy: 0.6865 - val_loss: 0.5616 - val_accuracy: 0.6794\n",
      "Epoch 63/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5663 - accuracy: 0.6796 - val_loss: 0.5672 - val_accuracy: 0.6787 - loss: 0.563 - ETA: 9s - loss: - ETA:  - ETA: 7s - loss: 0.567\n",
      "Epoch 64/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5653 - accuracy: 0.6780 - val_loss: 0.5930 - val_accuracy: 0.6507racy: 0.\n",
      "Epoch 65/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5630 - accuracy: 0.6828 - val_loss: 0.5586 - val_accuracy: 0.6732\n",
      "Epoch 66/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5617 - accuracy: 0.6822 - val_loss: 0.6311 - val_accuracy: 0.6387\n",
      "Epoch 67/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5559 - accuracy: 0.6864 - val_loss: 0.5554 - val_accuracy: 0.66700s - loss: 0.5568 - accuracy: 0. - ETA: 0s - loss: 0.5563 - accura - ETA: 0s - loss: 0.5563 - accuracy: 0.\n",
      "Epoch 68/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5551 - accuracy: 0.6830 - val_loss: 0.5891 - val_accuracy: 0.6680\n",
      "Epoch 69/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5488 - accuracy: 0.6921 - val_loss: 0.5746 - val_accuracy: 0.6501\n",
      "Epoch 70/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5482 - accuracy: 0.6913 - val_loss: 0.5732 - val_accuracy: 0.6706TA: 6s - loss: 0.544 - ETA: 5s - ETA: 4s - loss: 0.546 - ETA: 3s - loss: 0.5475 - accuracy: 0.69 - - ETA: \n",
      "Epoch 71/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5477 - accuracy: 0.6872 - val_loss: 0.5831 - val_accuracy: 0.6689482 - accuracy: 0.68 - ETA: 0s - loss: 0.5481 - accu\n",
      "Epoch 72/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5456 - accuracy: 0.6935 - val_loss: 0.6516 - val_accuracy: 0.6478s: 0.5457 - accu\n",
      "Epoch 73/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5410 - accuracy: 0.6982 - val_loss: 0.5749 - val_accuracy: 0.6735420 - accuracy - ETA: 1s\n",
      "Epoch 74/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5460 - accuracy: 0.6978 - val_loss: 0.5449 - val_accuracy: 0.6895\n",
      "Epoch 75/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5423 - accuracy: 0.6993 - val_loss: 0.5415 - val_accuracy: 0.6764: 0s - loss: 0.5421 - accuracy\n",
      "Epoch 76/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5410 - accuracy: 0.6986 - val_loss: 0.5506 - val_accuracy: 0.6800\n",
      "Epoch 77/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5455 - accuracy: 0.6977 - val_loss: 0.5508 - val_accuracy: 0.6800\n",
      "Epoch 78/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5335 - accuracy: 0.7068 - val_loss: 0.6542 - val_accuracy: 0.6380\n",
      "Epoch 79/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5350 - accuracy: 0.7068 - val_loss: 0.5401 - val_accuracy: 0.6986loss: 0.5\n",
      "Epoch 80/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5367 - accuracy: 0.7073 - val_loss: 0.5474 - val_accuracy: 0.6758\n",
      "Epoch 81/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5305 - accuracy: 0.7079 - val_loss: 0.5478 - val_accuracy: 0.6761\n",
      "Epoch 82/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5306 - accuracy: 0.7098 - val_loss: 0.5844 - val_accuracy: 0.6540\n",
      "Epoch 83/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5314 - accuracy: 0.7053 - val_loss: 0.5257 - val_accuracy: 0.6820accuracy:  - ETA: 0s - loss: 0.5319 - ac\n",
      "Epoch 84/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5258 - accuracy: 0.7103 - val_loss: 0.5824 - val_accuracy: 0.6803\n",
      "Epoch 85/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5220 - accuracy: 0.7150 - val_loss: 0.5451 - val_accuracy: 0.6914\n",
      "Epoch 86/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5213 - accuracy: 0.7149 - val_loss: 0.5348 - val_accuracy: 0.6810\n",
      "Epoch 87/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5203 - accuracy: 0.7154 - val_loss: 0.5369 - val_accuracy: 0.6901\n",
      "Epoch 88/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5222 - accuracy: 0.7148 - val_loss: 0.5374 - val_accuracy: 0.6895\n",
      "Epoch 89/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5151 - accuracy: 0.7184 - val_loss: 0.5025 - val_accuracy: 0.7181\n",
      "Epoch 90/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5268 - accuracy: 0.7079 - val_loss: 0.5311 - val_accuracy: 0.7161\n",
      "Epoch 91/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5099 - accuracy: 0.7241 - val_loss: 0.5282 - val_accuracy: 0.6982\n",
      "Epoch 92/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5220 - accuracy: 0.7128 - val_loss: 0.5683 - val_accuracy: 0.6689\n",
      "Epoch 93/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5178 - accuracy: 0.7206 - val_loss: 0.5997 - val_accuracy: 0.6478\n",
      "Epoch 94/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5075 - accuracy: 0.7252 - val_loss: 0.5527 - val_accuracy: 0.6803\n",
      "Epoch 95/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5028 - accuracy: 0.7267 - val_loss: 0.5280 - val_accuracy: 0.6930\n",
      "Epoch 96/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5082 - accuracy: 0.7195 - val_loss: 0.5271 - val_accuracy: 0.7048\n",
      "Epoch 97/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5026 - accuracy: 0.7262 - val_loss: 0.6003 - val_accuracy: 0.6546\n",
      "Epoch 98/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5020 - accuracy: 0.7290 - val_loss: 0.5232 - val_accuracy: 0.6963\n",
      "Epoch 99/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5182 - accuracy: 0.7112 - val_loss: 0.5384 - val_accuracy: 0.7074\n",
      "Epoch 100/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5178 - accuracy: 0.7186 - val_loss: 0.5610 - val_accuracy: 0.6715\n",
      "Epoch 101/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5077 - accuracy: 0.7222 - val_loss: 0.5381 - val_accuracy: 0.6842\n",
      "Epoch 102/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4905 - accuracy: 0.7353 - val_loss: 0.5078 - val_accuracy: 0.7236\n",
      "Epoch 103/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4917 - accuracy: 0.7393 - val_loss: 0.5497 - val_accuracy: 0.6761\n",
      "Epoch 104/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4926 - accuracy: 0.7345 - val_loss: 0.5803 - val_accuracy: 0.6898\n",
      "Epoch 105/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5041 - accuracy: 0.7289 - val_loss: 0.5597 - val_accuracy: 0.6846\n",
      "Epoch 106/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4971 - accuracy: 0.7312 - val_loss: 0.5316 - val_accuracy: 0.6862\n",
      "Epoch 107/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4952 - accuracy: 0.7309 - val_loss: 0.6155 - val_accuracy: 0.6660\n",
      "Epoch 108/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4891 - accuracy: 0.7369 - val_loss: 0.5734 - val_accuracy: 0.6608\n",
      "Epoch 109/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4879 - accuracy: 0.7385 - val_loss: 0.5378 - val_accuracy: 0.6995\n",
      "Epoch 110/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4872 - accuracy: 0.7393 - val_loss: 0.6189 - val_accuracy: 0.6738\n",
      "Epoch 111/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4817 - accuracy: 0.7442 - val_loss: 0.5854 - val_accuracy: 0.6761\n",
      "Epoch 112/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4835 - accuracy: 0.7413 - val_loss: 0.5385 - val_accuracy: 0.6940\n",
      "Epoch 113/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4784 - accuracy: 0.7474 - val_loss: 0.4967 - val_accuracy: 0.7305\n",
      "Epoch 114/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4782 - accuracy: 0.7469 - val_loss: 0.5144 - val_accuracy: 0.7165\n",
      "Epoch 115/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4793 - accuracy: 0.7445 - val_loss: 0.5549 - val_accuracy: 0.7074\n",
      "Epoch 116/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4779 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.6849\n",
      "Epoch 117/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4730 - accuracy: 0.7498 - val_loss: 0.5175 - val_accuracy: 0.7269\n",
      "Epoch 118/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4756 - accuracy: 0.7479 - val_loss: 0.5199 - val_accuracy: 0.6986\n",
      "Epoch 119/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4805 - accuracy: 0.7414 - val_loss: 0.5093 - val_accuracy: 0.7201\n",
      "Epoch 120/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4642 - accuracy: 0.7545 - val_loss: 0.5404 - val_accuracy: 0.7002\n",
      "Epoch 121/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4708 - accuracy: 0.7511 - val_loss: 0.5355 - val_accuracy: 0.6976\n",
      "Epoch 122/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4631 - accuracy: 0.7539 - val_loss: 0.4912 - val_accuracy: 0.7471\n",
      "Epoch 123/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4851 - accuracy: 0.7375 - val_loss: 0.5392 - val_accuracy: 0.6813\n",
      "Epoch 124/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4778 - accuracy: 0.7484 - val_loss: 0.5534 - val_accuracy: 0.6774\n",
      "Epoch 125/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4748 - accuracy: 0.7496 - val_loss: 0.5380 - val_accuracy: 0.6862curacy:  - ETA: 0s - loss: 0.4751 - accuracy: \n",
      "Epoch 126/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4650 - accuracy: 0.7571 - val_loss: 0.5157 - val_accuracy: 0.7008 loss: 0.4619 - ac - ETA: 5s - loss: 0.4637 - accuracy:  - ETA: 5s - l - ETA: 4s - loss: - ETA: 2s - loss: 0.4646 - accuracy: 0.75 - ETA: 2s - loss: 0.4647 - accuracy:  - ETA: 2s - loss: 0.4645 - accuracy:  - ETA:  - ETA: 0s - loss: 0.4646  - ETA: 0s - loss: 0.4653 - accuracy\n",
      "Epoch 127/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4544 - accuracy: 0.7631 - val_loss: 0.5878 - val_accuracy: 0.6667 - loss: 0.4\n",
      "Epoch 128/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4563 - accuracy: 0.7590 - val_loss: 0.5056 - val_accuracy: 0.7145 0.4659 -  - ETA: 7s - loss: 0.4604 - accuracy: 0.75 - ETA: 7s - ETA: 6s - los - ETA: 5s - loss: 0.4582 - accura - ETA: 5s - loss: 0 - ETA: 3s - loss: 0.4\n",
      "Epoch 129/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4466 - accuracy: 0.7693 - val_loss: 0.5123 - val_accuracy: 0.7246507 - accuracy: 0.76 - ET - ETA: 8s - loss: 0.448 - ETA: 4s - - ETA: 3s - loss: 0.446\n",
      "Epoch 130/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4473 - accuracy: 0.7652 - val_loss: 0.5389 - val_accuracy: 0.6862\n",
      "Epoch 131/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4481 - accuracy: 0.7663 - val_loss: 0.4825 - val_accuracy: 0.7412\n",
      "Epoch 132/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4488 - accuracy: 0.7684 - val_loss: 0.5722 - val_accuracy: 0.6833\n",
      "Epoch 133/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4428 - accuracy: 0.7672 - val_loss: 0.5226 - val_accuracy: 0.7103\n",
      "Epoch 134/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4373 - accuracy: 0.7729 - val_loss: 0.5619 - val_accuracy: 0.6995\n",
      "Epoch 135/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4511 - accuracy: 0.7623 - val_loss: 0.5454 - val_accuracy: 0.6930: \n",
      "Epoch 136/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4677 - accuracy: 0.7546 - val_loss: 0.5587 - val_accuracy: 0.6738 - loss: 0.4 - ETA: 3s - loss: 0.4676 - accuracy: 0.75 - ETA: 3s - loss: 0.4 - ETA: 1s - l - ETA: 0s - loss: 0.4678 - accura\n",
      "Epoch 137/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4332 - accuracy: 0.7771 - val_loss: 0.4927 - val_accuracy: 0.7132cy: \n",
      "Epoch 138/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4332 - accuracy: 0.7745 - val_loss: 0.5219 - val_accuracy: 0.7360\n",
      "Epoch 139/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4351 - accuracy: 0.7750 - val_loss: 0.5138 - val_accuracy: 0.7158\n",
      "Epoch 140/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4316 - accuracy: 0.7796 - val_loss: 0.5246 - val_accuracy: 0.6960\n",
      "Epoch 141/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4429 - accuracy: 0.7701 - val_loss: 0.5199 - val_accuracy: 0.7210\n",
      "Epoch 142/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4226 - accuracy: 0.7850 - val_loss: 0.6129 - val_accuracy: 0.6641- accuracy: 0.\n",
      "Epoch 143/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4348 - accuracy: 0.7723 - val_loss: 0.5727 - val_accuracy: 0.7142\n",
      "Epoch 144/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4268 - accuracy: 0.7783 - val_loss: 0.5014 - val_accuracy: 0.7207\n",
      "Epoch 145/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4239 - accuracy: 0.7820 - val_loss: 0.5067 - val_accuracy: 0.7497\n",
      "Epoch 146/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4193 - accuracy: 0.7826 - val_loss: 0.5102 - val_accuracy: 0.7318\n",
      "Epoch 147/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4108 - accuracy: 0.7904 - val_loss: 0.5682 - val_accuracy: 0.68001s - loss: 0.410 - ETA: 1s - loss: 0.4110 - accuracy:  - E\n",
      "Epoch 148/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4180 - accuracy: 0.7867 - val_loss: 0.5737 - val_accuracy: 0.6960\n",
      "Epoch 149/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4063 - accuracy: 0.7921 - val_loss: 0.5112 - val_accuracy: 0.7318\n",
      "Epoch 150/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4143 - accuracy: 0.7883 - val_loss: 0.5071 - val_accuracy: 0.7279\n",
      "Epoch 151/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4119 - accuracy: 0.7892 - val_loss: 0.5575 - val_accuracy: 0.7018\n",
      "Epoch 152/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4128 - accuracy: 0.7882 - val_loss: 0.5398 - val_accuracy: 0.7188\n",
      "Epoch 153/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4069 - accuracy: 0.7932 - val_loss: 0.4907 - val_accuracy: 0.7386 -\n",
      "Epoch 154/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3988 - accuracy: 0.7964 - val_loss: 0.5157 - val_accuracy: 0.7422\n",
      "Epoch 155/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4006 - accuracy: 0.7932 - val_loss: 0.5461 - val_accuracy: 0.7070\n",
      "Epoch 156/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4272 - accuracy: 0.7808 - val_loss: 0.4984 - val_accuracy: 0.7285\n",
      "Epoch 157/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4288 - accuracy: 0.7763 - val_loss: 0.5443 - val_accuracy: 0.6963\n",
      "Epoch 158/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4240 - accuracy: 0.7832 - val_loss: 0.5227 - val_accuracy: 0.7090\n",
      "Epoch 159/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3973 - accuracy: 0.8029 - val_loss: 0.5739 - val_accuracy: 0.6797\n",
      "Epoch 160/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3934 - accuracy: 0.8022 - val_loss: 0.5164 - val_accuracy: 0.7279\n",
      "Epoch 161/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3971 - accuracy: 0.7996 - val_loss: 0.5039 - val_accuracy: 0.7471\n",
      "Epoch 162/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3848 - accuracy: 0.8075 - val_loss: 0.8264 - val_accuracy: 0.6022\n",
      "Epoch 163/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3963 - accuracy: 0.7998 - val_loss: 0.4859 - val_accuracy: 0.7487\n",
      "Epoch 164/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3824 - accuracy: 0.8070 - val_loss: 0.4835 - val_accuracy: 0.7354\n",
      "Epoch 165/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3778 - accuracy: 0.8131 - val_loss: 0.6577 - val_accuracy: 0.6572\n",
      "Epoch 166/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3905 - accuracy: 0.8041 - val_loss: 0.5353 - val_accuracy: 0.7061\n",
      "Epoch 167/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3823 - accuracy: 0.8094 - val_loss: 0.5051 - val_accuracy: 0.7507\n",
      "Epoch 168/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3823 - accuracy: 0.8094 - val_loss: 0.5663 - val_accuracy: 0.7103\n",
      "Epoch 169/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3824 - accuracy: 0.8085 - val_loss: 0.6154 - val_accuracy: 0.6787\n",
      "Epoch 170/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3771 - accuracy: 0.8123 - val_loss: 0.5436 - val_accuracy: 0.7311\n",
      "Epoch 171/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3737 - accuracy: 0.8157 - val_loss: 0.4796 - val_accuracy: 0.7578\n",
      "Epoch 172/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3747 - accuracy: 0.8124 - val_loss: 0.6070 - val_accuracy: 0.6908\n",
      "Epoch 173/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3782 - accuracy: 0.8142 - val_loss: 0.7217 - val_accuracy: 0.6214\n",
      "Epoch 174/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3690 - accuracy: 0.8160 - val_loss: 0.5203 - val_accuracy: 0.7093\n",
      "Epoch 175/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3698 - accuracy: 0.8144 - val_loss: 0.5698 - val_accuracy: 0.6940\n",
      "Epoch 176/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3672 - accuracy: 0.8185 - val_loss: 0.4831 - val_accuracy: 0.7409\n",
      "Epoch 177/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3863 - accuracy: 0.8063 - val_loss: 0.5773 - val_accuracy: 0.6771\n",
      "Epoch 178/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3642 - accuracy: 0.8179 - val_loss: 0.4727 - val_accuracy: 0.7689\n",
      "Epoch 179/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3691 - accuracy: 0.8139 - val_loss: 0.5798 - val_accuracy: 0.6865\n",
      "Epoch 180/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3569 - accuracy: 0.8246 - val_loss: 0.5553 - val_accuracy: 0.7184\n",
      "Epoch 181/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3581 - accuracy: 0.8223 - val_loss: 0.4563 - val_accuracy: 0.7783\n",
      "Epoch 182/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3511 - accuracy: 0.8297 - val_loss: 0.5103 - val_accuracy: 0.7526\n",
      "Epoch 183/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3586 - accuracy: 0.8236 - val_loss: 0.5201 - val_accuracy: 0.7412\n",
      "Epoch 184/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3547 - accuracy: 0.8244 - val_loss: 0.5584 - val_accuracy: 0.7204\n",
      "Epoch 185/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3486 - accuracy: 0.8297 - val_loss: 0.5201 - val_accuracy: 0.7311\n",
      "Epoch 186/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3595 - accuracy: 0.8225 - val_loss: 0.5544 - val_accuracy: 0.7139\n",
      "Epoch 187/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3485 - accuracy: 0.8299 - val_loss: 0.4977 - val_accuracy: 0.7376\n",
      "Epoch 188/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3500 - accuracy: 0.8274 - val_loss: 0.5331 - val_accuracy: 0.7262\n",
      "Epoch 189/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3451 - accuracy: 0.8284 - val_loss: 0.6268 - val_accuracy: 0.7103\n",
      "Epoch 190/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3472 - accuracy: 0.8320 - val_loss: 0.4900 - val_accuracy: 0.7376 loss: 0.3487 - accuracy:  - ETA: 1s - l - ETA: 0s - loss: 0.3471 - accuracy: 0. - ETA: 0s - loss: 0.3468 - accu\n",
      "Epoch 191/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3420 - accuracy: 0.8346 - val_loss: 0.6052 - val_accuracy: 0.6969\n",
      "Epoch 192/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3417 - accuracy: 0.8349 - val_loss: 0.5653 - val_accuracy: 0.7279\n",
      "Epoch 193/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3450 - accuracy: 0.8312 - val_loss: 0.5065 - val_accuracy: 0.7344s - loss: 0.3393 - accuracy - ETA: 7s - loss: 0.3452 - accu -\n",
      "Epoch 194/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3400 - accuracy: 0.8333 - val_loss: 0.5657 - val_accuracy: 0.7116: 0.\n",
      "Epoch 195/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3352 - accuracy: 0.8380 - val_loss: 0.4888 - val_accuracy: 0.7578\n",
      "Epoch 196/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3380 - accuracy: 0.8379 - val_loss: 0.5025 - val_accuracy: 0.7493 l - ETA: 0s - loss: 0.3390 - accuracy: 0. - ETA: 0s - loss: 0.3386 - \n",
      "Epoch 197/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3315 - accuracy: 0.8415 - val_loss: 0.4942 - val_accuracy: 0.7520\n",
      "Epoch 198/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3262 - accuracy: 0.8390 - val_loss: 0.5734 - val_accuracy: 0.7275- ETA: 5s - loss: 0.3291 - accuracy:  - ETA:  - ETA: 3s - - ETA: 2s - loss: 0.3271 - accuracy: 0. - ETA: 2s - loss: - ETA - ETA: 0s - loss: 0.3256 -  - ETA: 0s - loss: 0.3261 - accura\n",
      "Epoch 199/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3306 - accuracy: 0.8395 - val_loss: 0.5019 - val_accuracy: 0.748712s - loss: 0.3395 - accuracy: 0 - ETA: 12s - loss: 0.3382 - accuracy: 0. - ETA: 12s  - ETA: 7s - loss: 0.3 - ETA: 6s - loss: 0.3320 - accu - ETA: 6s - loss: 0.3336 - accuracy: 0. - ETA: 6s - loss: 0.3328 - accuracy: 0.83 - ETA: 6s - loss: 0.3317 -  - ETA: 5s - loss: 0.3 - ETA: 4s - loss: 0.3316 - accuracy: 0. - ETA - ETA: 0s - l\n",
      "Epoch 200/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3442 - accuracy: 0.8344 - val_loss: 0.5013 - val_accuracy: 0.7441s: 0.3424 - accu\n",
      "Epoch 201/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3301 - accuracy: 0.8403 - val_loss: 0.5285 - val_accuracy: 0.7454\n",
      "Epoch 202/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3425 - accuracy: 0.8326 - val_loss: 0.5809 - val_accuracy: 0.7083\n",
      "Epoch 203/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3382 - accuracy: 0.8344 - val_loss: 0.5023 - val_accuracy: 0.7575cu - ETA: 1s - loss: 0.3423 \n",
      "Epoch 204/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3283 - accuracy: 0.8419 - val_loss: 0.5173 - val_accuracy: 0.7399\n",
      "Epoch 205/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3273 - accuracy: 0.8458 - val_loss: 0.4749 - val_accuracy: 0.7559\n",
      "Epoch 206/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3237 - accuracy: 0.8448 - val_loss: 0.5656 - val_accuracy: 0.7113\n",
      "Epoch 207/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3220 - accuracy: 0.8469 - val_loss: 0.5102 - val_accuracy: 0.7513\n",
      "Epoch 208/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3168 - accuracy: 0.8492 - val_loss: 0.4863 - val_accuracy: 0.7653\n",
      "Epoch 209/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3245 - accuracy: 0.8426 - val_loss: 0.5098 - val_accuracy: 0.7425\n",
      "Epoch 210/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3163 - accuracy: 0.8490 - val_loss: 0.5490 - val_accuracy: 0.7295\n",
      "Epoch 211/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3092 - accuracy: 0.8525 - val_loss: 0.5473 - val_accuracy: 0.7380\n",
      "Epoch 212/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3153 - accuracy: 0.8493 - val_loss: 0.4781 - val_accuracy: 0.7643\n",
      "Epoch 213/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3096 - accuracy: 0.8547 - val_loss: 0.4684 - val_accuracy: 0.7734\n",
      "Epoch 214/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3166 - accuracy: 0.8519 - val_loss: 0.5316 - val_accuracy: 0.7477\n",
      "Epoch 215/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3082 - accuracy: 0.8500 - val_loss: 0.4893 - val_accuracy: 0.7572\n",
      "Epoch 216/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3064 - accuracy: 0.8566 - val_loss: 0.4866 - val_accuracy: 0.7751\n",
      "Epoch 217/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3069 - accuracy: 0.8539 - val_loss: 0.5141 - val_accuracy: 0.7376\n",
      "Epoch 218/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3034 - accuracy: 0.8569 - val_loss: 0.5362 - val_accuracy: 0.7321\n",
      "Epoch 219/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3141 - accuracy: 0.8540 - val_loss: 0.5760 - val_accuracy: 0.73603158 -  - ETA: 0s - loss: 0.315\n",
      "Epoch 220/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3037 - accuracy: 0.8570 - val_loss: 0.6742 - val_accuracy: 0.6836\n",
      "Epoch 221/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3097 - accuracy: 0.8539 - val_loss: 0.7294 - val_accuracy: 0.6833\n",
      "Epoch 222/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2970 - accuracy: 0.8603 - val_loss: 0.6257 - val_accuracy: 0.7018\n",
      "Epoch 223/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3048 - accuracy: 0.8552 - val_loss: 0.5427 - val_accuracy: 0.7425\n",
      "Epoch 224/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3027 - accuracy: 0.8567 - val_loss: 0.4958 - val_accuracy: 0.7637\n",
      "Epoch 225/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3003 - accuracy: 0.8574 - val_loss: 0.5018 - val_accuracy: 0.7588\n",
      "Epoch 226/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2900 - accuracy: 0.8654 - val_loss: 0.5947 - val_accuracy: 0.7516\n",
      "Epoch 227/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2946 - accuracy: 0.8604 - val_loss: 0.5564 - val_accuracy: 0.7428\n",
      "Epoch 228/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2992 - accuracy: 0.8603 - val_loss: 0.5119 - val_accuracy: 0.7484\n",
      "Epoch 229/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2894 - accuracy: 0.8639 - val_loss: 0.4803 - val_accuracy: 0.7620\n",
      "Epoch 230/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2985 - accuracy: 0.8606 - val_loss: 0.6866 - val_accuracy: 0.7119- loss: 0.3055 - accu - ETA: 2s - loss: 0.3042 - accuracy - ETA: 1s - loss: 0.3032  - ETA: 0s - loss: 0\n",
      "Epoch 231/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2924 - accuracy: 0.8642 - val_loss: 0.6852 - val_accuracy: 0.6950s: 0.2929 - accuracy: \n",
      "Epoch 232/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2958 - accuracy: 0.8633 - val_loss: 0.5243 - val_accuracy: 0.7445\n",
      "Epoch 233/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2886 - accuracy: 0.8632 - val_loss: 0.5361 - val_accuracy: 0.7536\n",
      "Epoch 234/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2905 - accuracy: 0.8656 - val_loss: 0.5278 - val_accuracy: 0.7419903 - accuracy: 0.\n",
      "Epoch 235/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2879 - accuracy: 0.8648 - val_loss: 0.4864 - val_accuracy: 0.7705\n",
      "Epoch 236/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2832 - accuracy: 0.8665 - val_loss: 0.5218 - val_accuracy: 0.7503\n",
      "Epoch 237/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2877 - accuracy: 0.8640 - val_loss: 0.5862 - val_accuracy: 0.7292\n",
      "Epoch 238/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2778 - accuracy: 0.8705 - val_loss: 0.4838 - val_accuracy: 0.7819.2777 - accuracy: 0.87\n",
      "Epoch 239/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2812 - accuracy: 0.8719 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 240/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2952 - accuracy: 0.8607 - val_loss: 0.7760 - val_accuracy: 0.6947\n",
      "Epoch 241/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2836 - accuracy: 0.8664 - val_loss: 0.5995 - val_accuracy: 0.7415\n",
      "Epoch 242/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2913 - accuracy: 0.8635 - val_loss: 0.5208 - val_accuracy: 0.7598\n",
      "Epoch 243/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2788 - accuracy: 0.8709 - val_loss: 0.5858 - val_accuracy: 0.7227\n",
      "Epoch 244/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2842 - accuracy: 0.8637 - val_loss: 0.5703 - val_accuracy: 0.7393\n",
      "Epoch 245/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2776 - accuracy: 0.8669 - val_loss: 0.5058 - val_accuracy: 0.7601\n",
      "Epoch 246/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2775 - accuracy: 0.8693 - val_loss: 0.4988 - val_accuracy: 0.7718\n",
      "Epoch 247/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2817 - accuracy: 0.8658 - val_loss: 0.5144 - val_accuracy: 0.7513\n",
      "Epoch 248/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2745 - accuracy: 0.8690 - val_loss: 0.5651 - val_accuracy: 0.7513\n",
      "Epoch 249/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2669 - accuracy: 0.8735 - val_loss: 0.5772 - val_accuracy: 0.7536\n",
      "Epoch 250/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2708 - accuracy: 0.8754 - val_loss: 0.6203 - val_accuracy: 0.7347\n",
      "Epoch 251/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2691 - accuracy: 0.8752 - val_loss: 0.5360 - val_accuracy: 0.7565\n",
      "Epoch 252/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2655 - accuracy: 0.8787 - val_loss: 0.4941 - val_accuracy: 0.7741\n",
      "Epoch 253/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2667 - accuracy: 0.8782 - val_loss: 0.6096 - val_accuracy: 0.7308\n",
      "Epoch 254/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2722 - accuracy: 0.8750 - val_loss: 0.7037 - val_accuracy: 0.7139\n",
      "Epoch 255/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2581 - accuracy: 0.8812 - val_loss: 0.5605 - val_accuracy: 0.7402.2589 \n",
      "Epoch 256/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2648 - accuracy: 0.8791 - val_loss: 0.5560 - val_accuracy: 0.7484\n",
      "Epoch 257/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2542 - accuracy: 0.8821 - val_loss: 0.6317 - val_accuracy: 0.7240\n",
      "Epoch 258/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2560 - accuracy: 0.8835 - val_loss: 0.5409 - val_accuracy: 0.7474\n",
      "Epoch 259/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2588 - accuracy: 0.8811 - val_loss: 0.4915 - val_accuracy: 0.7959\n",
      "Epoch 260/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2519 - accuracy: 0.8873 - val_loss: 0.5586 - val_accuracy: 0.7380\n",
      "Epoch 261/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2576 - accuracy: 0.8811 - val_loss: 0.6362 - val_accuracy: 0.7321\n",
      "Epoch 262/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2595 - accuracy: 0.8826 - val_loss: 0.6032 - val_accuracy: 0.7409\n",
      "Epoch 263/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2531 - accuracy: 0.8840 - val_loss: 0.6006 - val_accuracy: 0.7347\n",
      "Epoch 264/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2459 - accuracy: 0.8865 - val_loss: 0.6771 - val_accuracy: 0.7106\n",
      "Epoch 265/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2525 - accuracy: 0.8829 - val_loss: 0.6015 - val_accuracy: 0.7308\n",
      "Epoch 266/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2733 - accuracy: 0.8785 - val_loss: 0.5814 - val_accuracy: 0.7380\n",
      "Epoch 267/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2519 - accuracy: 0.8852 - val_loss: 0.6253 - val_accuracy: 0.7373\n",
      "Epoch 268/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2492 - accuracy: 0.8893 - val_loss: 0.5805 - val_accuracy: 0.7327\n",
      "Epoch 269/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2444 - accuracy: 0.8883 - val_loss: 0.5230 - val_accuracy: 0.7715\n",
      "Epoch 270/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2417 - accuracy: 0.8900 - val_loss: 0.6593 - val_accuracy: 0.7282\n",
      "Epoch 271/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2496 - accuracy: 0.8879 - val_loss: 0.5823 - val_accuracy: 0.7588\n",
      "Epoch 272/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2395 - accuracy: 0.8933 - val_loss: 0.5788 - val_accuracy: 0.7337\n",
      "Epoch 273/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2428 - accuracy: 0.8944 - val_loss: 0.5481 - val_accuracy: 0.7529\n",
      "Epoch 274/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2401 - accuracy: 0.8929 - val_loss: 0.6210 - val_accuracy: 0.7406\n",
      "Epoch 275/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2402 - accuracy: 0.8927 - val_loss: 0.5711 - val_accuracy: 0.7702\n",
      "Epoch 276/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2365 - accuracy: 0.8928 - val_loss: 0.5057 - val_accuracy: 0.7952\n",
      "Epoch 277/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2402 - accuracy: 0.8914 - val_loss: 0.7084 - val_accuracy: 0.7269\n",
      "Epoch 278/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2424 - accuracy: 0.8922 - val_loss: 0.5268 - val_accuracy: 0.7699\n",
      "Epoch 279/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2359 - accuracy: 0.8928 - val_loss: 0.6162 - val_accuracy: 0.7292\n",
      "Epoch 280/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2391 - accuracy: 0.8926 - val_loss: 0.5447 - val_accuracy: 0.7692\n",
      "Epoch 281/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2405 - accuracy: 0.8927 - val_loss: 0.5139 - val_accuracy: 0.7575\n",
      "Epoch 282/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2392 - accuracy: 0.8934 - val_loss: 0.5846 - val_accuracy: 0.7594\n",
      "Epoch 283/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2351 - accuracy: 0.8960 - val_loss: 0.6314 - val_accuracy: 0.7311\n",
      "Epoch 284/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2349 - accuracy: 0.8961 - val_loss: 0.7116 - val_accuracy: 0.71650s - loss: 0.2356 - accura\n",
      "Epoch 285/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2406 - accuracy: 0.8929 - val_loss: 0.5843 - val_accuracy: 0.7526\n",
      "Epoch 286/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2418 - accuracy: 0.8863 - val_loss: 0.6026 - val_accuracy: 0.7503\n",
      "Epoch 287/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2391 - accuracy: 0.8903 - val_loss: 0.5667 - val_accuracy: 0.7695\n",
      "Epoch 288/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2433 - accuracy: 0.8860 - val_loss: 0.6347 - val_accuracy: 0.7308\n",
      "Epoch 289/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2317 - accuracy: 0.8944 - val_loss: 0.6044 - val_accuracy: 0.7383\n",
      "Epoch 290/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2303 - accuracy: 0.8974 - val_loss: 0.6146 - val_accuracy: 0.7275\n",
      "Epoch 291/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2282 - accuracy: 0.9004 - val_loss: 0.6315 - val_accuracy: 0.7236\n",
      "Epoch 292/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2275 - accuracy: 0.8985 - val_loss: 0.6829 - val_accuracy: 0.7119\n",
      "Epoch 293/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2220 - accuracy: 0.9016 - val_loss: 0.6984 - val_accuracy: 0.7370\n",
      "Epoch 294/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2207 - accuracy: 0.9032 - val_loss: 0.5740 - val_accuracy: 0.7679\n",
      "Epoch 295/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2263 - accuracy: 0.9010 - val_loss: 0.5319 - val_accuracy: 0.7812\n",
      "Epoch 296/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2273 - accuracy: 0.9009 - val_loss: 0.7306 - val_accuracy: 0.7301\n",
      "Epoch 297/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2172 - accuracy: 0.9056 - val_loss: 0.6704 - val_accuracy: 0.7340\n",
      "Epoch 298/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2284 - accuracy: 0.8991 - val_loss: 0.5737 - val_accuracy: 0.7594\n",
      "Epoch 299/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2194 - accuracy: 0.9030 - val_loss: 0.6201 - val_accuracy: 0.7464\n",
      "Epoch 300/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2234 - accuracy: 0.9013 - val_loss: 0.6570 - val_accuracy: 0.7360\n",
      "Epoch 301/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2209 - accuracy: 0.9039 - val_loss: 0.6341 - val_accuracy: 0.7467\n",
      "Epoch 302/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2121 - accuracy: 0.9086 - val_loss: 0.5160 - val_accuracy: 0.7884\n",
      "Epoch 303/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2185 - accuracy: 0.9035 - val_loss: 0.7088 - val_accuracy: 0.7259\n",
      "Epoch 304/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2098 - accuracy: 0.9091 - val_loss: 0.5656 - val_accuracy: 0.7588\n",
      "Epoch 305/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2142 - accuracy: 0.9071 - val_loss: 0.6440 - val_accuracy: 0.7210\n",
      "Epoch 306/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2102 - accuracy: 0.9072 - val_loss: 0.6595 - val_accuracy: 0.7275\n",
      "Epoch 307/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2057 - accuracy: 0.9097 - val_loss: 0.6674 - val_accuracy: 0.7279\n",
      "Epoch 308/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2232 - accuracy: 0.9045 - val_loss: 0.5945 - val_accuracy: 0.7207\n",
      "Epoch 309/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2192 - accuracy: 0.9016 - val_loss: 0.5751 - val_accuracy: 0.7682\n",
      "Epoch 310/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2082 - accuracy: 0.9097 - val_loss: 0.6956 - val_accuracy: 0.7458\n",
      "Epoch 311/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2154 - accuracy: 0.9065 - val_loss: 0.7906 - val_accuracy: 0.7106\n",
      "Epoch 312/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2125 - accuracy: 0.9066 - val_loss: 0.6238 - val_accuracy: 0.7477\n",
      "Epoch 313/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2117 - accuracy: 0.9099 - val_loss: 0.6231 - val_accuracy: 0.7640\n",
      "Epoch 314/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2021 - accuracy: 0.9125 - val_loss: 0.8009 - val_accuracy: 0.6735\n",
      "Epoch 315/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2082 - accuracy: 0.9100 - val_loss: 0.5882 - val_accuracy: 0.7493\n",
      "Epoch 316/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2058 - accuracy: 0.9095 - val_loss: 0.5526 - val_accuracy: 0.7679\n",
      "Epoch 317/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2097 - accuracy: 0.9094 - val_loss: 0.6503 - val_accuracy: 0.7389\n",
      "Epoch 318/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2016 - accuracy: 0.9122 - val_loss: 0.7999 - val_accuracy: 0.7074\n",
      "Epoch 319/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2076 - accuracy: 0.9105 - val_loss: 0.6427 - val_accuracy: 0.7445\n",
      "Epoch 320/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2014 - accuracy: 0.9116 - val_loss: 0.7416 - val_accuracy: 0.7074\n",
      "Epoch 321/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2104 - accuracy: 0.9077 - val_loss: 0.5822 - val_accuracy: 0.7458\n",
      "Epoch 322/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1992 - accuracy: 0.9142 - val_loss: 0.6060 - val_accuracy: 0.7497\n",
      "Epoch 323/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2019 - accuracy: 0.9133 - val_loss: 0.7285 - val_accuracy: 0.7129\n",
      "Epoch 324/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1960 - accuracy: 0.9159 - val_loss: 0.6408 - val_accuracy: 0.7484\n",
      "Epoch 325/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1989 - accuracy: 0.9148 - val_loss: 0.6757 - val_accuracy: 0.7327\n",
      "Epoch 326/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2034 - accuracy: 0.9118 - val_loss: 0.7029 - val_accuracy: 0.7477\n",
      "Epoch 327/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2045 - accuracy: 0.9151 - val_loss: 0.7522 - val_accuracy: 0.7210\n",
      "Epoch 328/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1927 - accuracy: 0.9147 - val_loss: 0.5847 - val_accuracy: 0.7588\n",
      "Epoch 329/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2035 - accuracy: 0.9137 - val_loss: 0.6319 - val_accuracy: 0.7480\n",
      "Epoch 330/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1915 - accuracy: 0.9172 - val_loss: 0.6205 - val_accuracy: 0.7533\n",
      "Epoch 331/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2013 - accuracy: 0.9130 - val_loss: 0.6658 - val_accuracy: 0.7380\n",
      "Epoch 332/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1919 - accuracy: 0.9191 - val_loss: 0.6484 - val_accuracy: 0.7409\n",
      "Epoch 333/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1922 - accuracy: 0.9169 - val_loss: 0.6993 - val_accuracy: 0.7230\n",
      "Epoch 334/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1966 - accuracy: 0.9133 - val_loss: 0.6932 - val_accuracy: 0.7227\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00334: early stopping\n",
      "      1/Unknown - 0s 117ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121/3121 [==============================] - 15s 5ms/step\n",
      "347/347 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|                                              | 4/10 [5:00:32<7:31:52, 4518.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "438/438 [==============================] - 16s 35ms/step - loss: 0.6932 - accuracy: 0.4894 - val_loss: 0.6931 - val_accuracy: 0.4997\n",
      "Epoch 2/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6931 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5055\n",
      "Epoch 3/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6931 - accuracy: 0.5092 - val_loss: 0.6931 - val_accuracy: 0.5010\n",
      "Epoch 4/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6930 - accuracy: 0.5321 - val_loss: 0.6931 - val_accuracy: 0.50000 - accuracy: 0 - ETA: 11s - loss: 0.6930 - accuracy:  - ETA: 11s - loss: 0.6930 - accurac - ETA: 10s - loss: 0.6930 - accuracy: 0.52 - ETA: 10s - l - ETA: 5s - loss: 0.6930 - accuracy: 0.53 - ETA - ETA: 3s - loss: 0.6930 - ac - ETA: 0s - loss: 0.6\n",
      "Epoch 5/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6928 - accuracy: 0.5398 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 6/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6926 - accuracy: 0.5506 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 7/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6921 - accuracy: 0.5548 - val_loss: 0.6927 - val_accuracy: 0.4909\n",
      "Epoch 8/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6915 - accuracy: 0.5609 - val_loss: 0.6921 - val_accuracy: 0.4977\n",
      "Epoch 9/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6895 - accuracy: 0.5680 - val_loss: 0.6913 - val_accuracy: 0.4919\n",
      "Epoch 10/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6878 - accuracy: 0.5562 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 11/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6837 - accuracy: 0.5607 - val_loss: 0.6891 - val_accuracy: 0.5075\n",
      "Epoch 12/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6813 - accuracy: 0.5546 - val_loss: 0.6878 - val_accuracy: 0.5088cy: 0.\n",
      "Epoch 13/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6761 - accuracy: 0.5594 - val_loss: 0.6818 - val_accuracy: 0.5251\n",
      "Epoch 14/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6728 - accuracy: 0.5607 - val_loss: 0.6790 - val_accuracy: 0.5316\n",
      "Epoch 15/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6723 - accuracy: 0.5595 - val_loss: 0.6812 - val_accuracy: 0.5293\n",
      "Epoch 16/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6683 - accuracy: 0.5680 - val_loss: 0.6878 - val_accuracy: 0.5234\n",
      "Epoch 17/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6665 - accuracy: 0.5699 - val_loss: 0.6849 - val_accuracy: 0.5156\n",
      "Epoch 18/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6637 - accuracy: 0.5717 - val_loss: 0.7087 - val_accuracy: 0.5098\n",
      "Epoch 19/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6613 - accuracy: 0.5774 - val_loss: 0.7022 - val_accuracy: 0.5091\n",
      "Epoch 20/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6591 - accuracy: 0.5806 - val_loss: 0.7056 - val_accuracy: 0.5160\n",
      "Epoch 21/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6572 - accuracy: 0.5813 - val_loss: 0.6954 - val_accuracy: 0.5117\n",
      "Epoch 22/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6554 - accuracy: 0.5806 - val_loss: 0.7056 - val_accuracy: 0.4990\n",
      "Epoch 23/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6557 - accuracy: 0.5849 - val_loss: 0.6918 - val_accuracy: 0.5101racy - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.6\n",
      "Epoch 24/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6560 - accuracy: 0.5806 - val_loss: 0.7039 - val_accuracy: 0.4958\n",
      "Epoch 25/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6536 - accuracy: 0.5865 - val_loss: 0.6891 - val_accuracy: 0.5173\n",
      "Epoch 26/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6561 - accuracy: 0.5837 - val_loss: 0.6921 - val_accuracy: 0.5016\n",
      "Epoch 27/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6522 - accuracy: 0.5895 - val_loss: 0.6781 - val_accuracy: 0.5241\n",
      "Epoch 28/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6550 - accuracy: 0.5833 - val_loss: 0.6721 - val_accuracy: 0.5426\n",
      "Epoch 29/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6536 - accuracy: 0.5864 - val_loss: 0.6718 - val_accuracy: 0.5319\n",
      "Epoch 30/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6524 - accuracy: 0.5952 - val_loss: 0.6592 - val_accuracy: 0.5527\n",
      "Epoch 31/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6497 - accuracy: 0.5946 - val_loss: 0.6799 - val_accuracy: 0.5293\n",
      "Epoch 32/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6503 - accuracy: 0.5992 - val_loss: 0.6958 - val_accuracy: 0.5029\n",
      "Epoch 33/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6478 - accuracy: 0.6034 - val_loss: 0.6770 - val_accuracy: 0.5374\n",
      "Epoch 34/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6480 - accuracy: 0.6031 - val_loss: 0.7075 - val_accuracy: 0.5153\n",
      "Epoch 35/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6434 - accuracy: 0.6104 - val_loss: 0.6566 - val_accuracy: 0.5749\n",
      "Epoch 36/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6424 - accuracy: 0.6091 - val_loss: 0.6434 - val_accuracy: 0.6361\n",
      "Epoch 37/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6387 - accuracy: 0.6145 - val_loss: 0.6405 - val_accuracy: 0.6094\n",
      "Epoch 38/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6353 - accuracy: 0.6209 - val_loss: 0.6442 - val_accuracy: 0.6143\n",
      "Epoch 39/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6328 - accuracy: 0.6219 - val_loss: 0.6127 - val_accuracy: 0.6667\n",
      "Epoch 40/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6285 - accuracy: 0.6260 - val_loss: 0.6656 - val_accuracy: 0.5596\n",
      "Epoch 41/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6290 - accuracy: 0.6210 - val_loss: 0.6236 - val_accuracy: 0.6517\n",
      "Epoch 42/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6221 - accuracy: 0.6309 - val_loss: 0.6189 - val_accuracy: 0.6374\n",
      "Epoch 43/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6211 - accuracy: 0.6322 - val_loss: 0.6203 - val_accuracy: 0.6273\n",
      "Epoch 44/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6217 - accuracy: 0.6327 - val_loss: 0.6681 - val_accuracy: 0.5560\n",
      "Epoch 45/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6176 - accuracy: 0.6402 - val_loss: 0.6413 - val_accuracy: 0.6068\n",
      "Epoch 46/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6149 - accuracy: 0.6378 - val_loss: 0.6084 - val_accuracy: 0.6475\n",
      "Epoch 47/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6136 - accuracy: 0.6377 - val_loss: 0.6240 - val_accuracy: 0.6217\n",
      "Epoch 48/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6091 - accuracy: 0.6414 - val_loss: 0.6065 - val_accuracy: 0.6393\n",
      "Epoch 49/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6056 - accuracy: 0.6489 - val_loss: 0.6138 - val_accuracy: 0.6520\n",
      "Epoch 50/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6049 - accuracy: 0.6474 - val_loss: 0.6325 - val_accuracy: 0.6058 0.6058 - accuracy: 0.64 - ETA: 3s - l\n",
      "Epoch 51/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6050 - accuracy: 0.6503 - val_loss: 0.6169 - val_accuracy: 0.6396\n",
      "Epoch 52/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5962 - accuracy: 0.6546 - val_loss: 0.6252 - val_accuracy: 0.6175\n",
      "Epoch 53/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5989 - accuracy: 0.6520 - val_loss: 0.6068 - val_accuracy: 0.6442\n",
      "Epoch 54/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5925 - accuracy: 0.6582 - val_loss: 0.6309 - val_accuracy: 0.6276\n",
      "Epoch 55/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5943 - accuracy: 0.6580 - val_loss: 0.5895 - val_accuracy: 0.6582\n",
      "Epoch 56/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5886 - accuracy: 0.6637 - val_loss: 0.5889 - val_accuracy: 0.6722\n",
      "Epoch 57/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5913 - accuracy: 0.6625 - val_loss: 0.5812 - val_accuracy: 0.6878\n",
      "Epoch 58/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5865 - accuracy: 0.6632 - val_loss: 0.6160 - val_accuracy: 0.6341 los - ETA: 0s -\n",
      "Epoch 59/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5814 - accuracy: 0.6685 - val_loss: 0.5867 - val_accuracy: 0.6579\n",
      "Epoch 60/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5784 - accuracy: 0.6692 - val_loss: 0.5843 - val_accuracy: 0.6484\n",
      "Epoch 61/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5816 - accuracy: 0.6706 - val_loss: 0.5996 - val_accuracy: 0.6517\n",
      "Epoch 62/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5761 - accuracy: 0.6721 - val_loss: 0.5950 - val_accuracy: 0.6217\n",
      "Epoch 63/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5808 - accuracy: 0.6682 - val_loss: 0.6419 - val_accuracy: 0.6094\n",
      "Epoch 64/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5808 - accuracy: 0.6698 - val_loss: 0.6564 - val_accuracy: 0.5970\n",
      "Epoch 65/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5712 - accuracy: 0.6752 - val_loss: 0.6173 - val_accuracy: 0.6198\n",
      "Epoch 66/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5715 - accuracy: 0.6760 - val_loss: 0.5738 - val_accuracy: 0.6966\n",
      "Epoch 67/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5741 - accuracy: 0.6750 - val_loss: 0.5857 - val_accuracy: 0.6553\n",
      "Epoch 68/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5666 - accuracy: 0.6797 - val_loss: 0.5655 - val_accuracy: 0.6820\n",
      "Epoch 69/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5645 - accuracy: 0.6832 - val_loss: 0.6476 - val_accuracy: 0.6133\n",
      "Epoch 70/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5676 - accuracy: 0.6787 - val_loss: 0.5631 - val_accuracy: 0.7012\n",
      "Epoch 71/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5646 - accuracy: 0.6826 - val_loss: 0.5887 - val_accuracy: 0.6650\n",
      "Epoch 72/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5622 - accuracy: 0.6815 - val_loss: 0.6177 - val_accuracy: 0.6237\n",
      "Epoch 73/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5672 - accuracy: 0.6791 - val_loss: 0.5768 - val_accuracy: 0.6732\n",
      "Epoch 74/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5598 - accuracy: 0.6856 - val_loss: 0.5687 - val_accuracy: 0.6833\n",
      "Epoch 75/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5568 - accuracy: 0.6886 - val_loss: 0.5973 - val_accuracy: 0.6413\n",
      "Epoch 76/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5580 - accuracy: 0.6829 - val_loss: 0.5780 - val_accuracy: 0.6888 ETA: 3s - loss: - ETA: \n",
      "Epoch 77/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5559 - accuracy: 0.6902 - val_loss: 0.5932 - val_accuracy: 0.6562TA: 0s -\n",
      "Epoch 78/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5548 - accuracy: 0.6870 - val_loss: 0.6045 - val_accuracy: 0.6348\n",
      "Epoch 79/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5516 - accuracy: 0.6926 - val_loss: 0.5348 - val_accuracy: 0.7171\n",
      "Epoch 80/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5517 - accuracy: 0.6950 - val_loss: 0.5826 - val_accuracy: 0.6546\n",
      "Epoch 81/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5478 - accuracy: 0.6921 - val_loss: 0.5536 - val_accuracy: 0.6781\n",
      "Epoch 82/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5512 - accuracy: 0.6908 - val_loss: 0.5818 - val_accuracy: 0.6696s: 0.5504  - ETA: 4s - loss: 0.5497 - accuracy:  - ETA: 3s - loss: 0.5489 - ac - ETA: 3s - loss: 0\n",
      "Epoch 83/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5430 - accuracy: 0.6981 - val_loss: 0.5897 - val_accuracy: 0.6735\n",
      "Epoch 84/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5500 - accuracy: 0.6938 - val_loss: 0.5940 - val_accuracy: 0.6536\n",
      "Epoch 85/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5397 - accuracy: 0.7004 - val_loss: 0.5945 - val_accuracy: 0.6556\n",
      "Epoch 86/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5489 - accuracy: 0.6954 - val_loss: 0.5746 - val_accuracy: 0.6803\n",
      "Epoch 87/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5404 - accuracy: 0.6991 - val_loss: 0.5772 - val_accuracy: 0.6813\n",
      "Epoch 88/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5410 - accuracy: 0.7007 - val_loss: 0.5451 - val_accuracy: 0.6982\n",
      "Epoch 89/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5339 - accuracy: 0.7034 - val_loss: 0.5485 - val_accuracy: 0.7106\n",
      "Epoch 90/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5356 - accuracy: 0.7070 - val_loss: 0.5988 - val_accuracy: 0.6852\n",
      "Epoch 91/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5384 - accuracy: 0.7008 - val_loss: 0.5538 - val_accuracy: 0.7025\n",
      "Epoch 92/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5337 - accuracy: 0.7077 - val_loss: 0.5861 - val_accuracy: 0.6702\n",
      "Epoch 93/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5350 - accuracy: 0.7050 - val_loss: 0.6221 - val_accuracy: 0.6159\n",
      "Epoch 94/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5316 - accuracy: 0.7066 - val_loss: 0.5565 - val_accuracy: 0.6722\n",
      "Epoch 95/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5275 - accuracy: 0.7077 - val_loss: 0.5731 - val_accuracy: 0.6605\n",
      "Epoch 96/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5309 - accuracy: 0.7107 - val_loss: 0.5601 - val_accuracy: 0.6868\n",
      "Epoch 97/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5254 - accuracy: 0.7112 - val_loss: 0.5552 - val_accuracy: 0.7103\n",
      "Epoch 98/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5257 - accuracy: 0.7117 - val_loss: 0.6374 - val_accuracy: 0.6120\n",
      "Epoch 99/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5186 - accuracy: 0.7191 - val_loss: 0.5748 - val_accuracy: 0.6979\n",
      "Epoch 100/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5180 - accuracy: 0.7174 - val_loss: 0.5789 - val_accuracy: 0.6572\n",
      "Epoch 101/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5236 - accuracy: 0.7135 - val_loss: 0.5534 - val_accuracy: 0.6823\n",
      "Epoch 102/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5165 - accuracy: 0.7192 - val_loss: 0.5091 - val_accuracy: 0.72202s - l\n",
      "Epoch 103/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5130 - accuracy: 0.7223 - val_loss: 0.5818 - val_accuracy: 0.6556\n",
      "Epoch 104/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5123 - accuracy: 0.7217 - val_loss: 0.5877 - val_accuracy: 0.6689\n",
      "Epoch 105/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5120 - accuracy: 0.7237 - val_loss: 0.6048 - val_accuracy: 0.6657\n",
      "Epoch 106/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5113 - accuracy: 0.7213 - val_loss: 0.5318 - val_accuracy: 0.7031\n",
      "Epoch 107/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5061 - accuracy: 0.7253 - val_loss: 0.5444 - val_accuracy: 0.6943\n",
      "Epoch 108/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5087 - accuracy: 0.7240 - val_loss: 0.5178 - val_accuracy: 0.7324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4997 - accuracy: 0.7299 - val_loss: 0.5174 - val_accuracy: 0.7350\n",
      "Epoch 110/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5012 - accuracy: 0.7298 - val_loss: 0.5164 - val_accuracy: 0.7214\n",
      "Epoch 111/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5142 - accuracy: 0.7224 - val_loss: 0.5592 - val_accuracy: 0.71094s - loss: 0.5179 - accura - ETA: 3s -\n",
      "Epoch 112/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5109 - accuracy: 0.7221 - val_loss: 0.5510 - val_accuracy: 0.6992s: 0.5109 - accuracy: 0. - ETA\n",
      "Epoch 113/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5031 - accuracy: 0.7301 - val_loss: 0.5577 - val_accuracy: 0.6794\n",
      "Epoch 114/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4987 - accuracy: 0.7337 - val_loss: 0.5344 - val_accuracy: 0.6960\n",
      "Epoch 115/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4957 - accuracy: 0.7327 - val_loss: 0.5674 - val_accuracy: 0.6901\n",
      "Epoch 116/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4960 - accuracy: 0.7324 - val_loss: 0.6055 - val_accuracy: 0.6543\n",
      "Epoch 117/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4939 - accuracy: 0.7346 - val_loss: 0.5277 - val_accuracy: 0.7061\n",
      "Epoch 118/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5016 - accuracy: 0.7311 - val_loss: 0.6143 - val_accuracy: 0.6667\n",
      "Epoch 119/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4993 - accuracy: 0.7336 - val_loss: 0.5214 - val_accuracy: 0.7096\n",
      "Epoch 120/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5006 - accuracy: 0.7327 - val_loss: 0.4982 - val_accuracy: 0.7425s: 0.5006 - accuracy\n",
      "Epoch 121/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4928 - accuracy: 0.7344 - val_loss: 0.5256 - val_accuracy: 0.7106\n",
      "Epoch 122/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4885 - accuracy: 0.7402 - val_loss: 0.5245 - val_accuracy: 0.71061s\n",
      "Epoch 123/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4883 - accuracy: 0.7410 - val_loss: 0.5295 - val_accuracy: 0.7109\n",
      "Epoch 124/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4782 - accuracy: 0.7469 - val_loss: 0.4858 - val_accuracy: 0.7210\n",
      "Epoch 125/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4861 - accuracy: 0.7386 - val_loss: 0.5428 - val_accuracy: 0.7015\n",
      "Epoch 126/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4768 - accuracy: 0.7460 - val_loss: 0.5114 - val_accuracy: 0.7288\n",
      "Epoch 127/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4793 - accuracy: 0.7453 - val_loss: 0.5885 - val_accuracy: 0.6680\n",
      "Epoch 128/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4885 - accuracy: 0.7422 - val_loss: 0.5860 - val_accuracy: 0.668310s - loss: 0 - ETA: 9s - loss: 0 - ETA: 8s - loss: 0 - ETA: 1s - loss: 0.487 - ETA: 0s - loss: 0.4\n",
      "Epoch 129/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4835 - accuracy: 0.7445 - val_loss: 0.5562 - val_accuracy: 0.7005\n",
      "Epoch 130/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4889 - accuracy: 0.7438 - val_loss: 0.5004 - val_accuracy: 0.7383\n",
      "Epoch 131/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4813 - accuracy: 0.7477 - val_loss: 0.5048 - val_accuracy: 0.7422 loss: - ETA: 0s - loss:\n",
      "Epoch 132/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4781 - accuracy: 0.7513 - val_loss: 0.5795 - val_accuracy: 0.6973\n",
      "Epoch 133/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4749 - accuracy: 0.7503 - val_loss: 0.5490 - val_accuracy: 0.7093\n",
      "Epoch 134/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4693 - accuracy: 0.7526 - val_loss: 0.5284 - val_accuracy: 0.7122\n",
      "Epoch 135/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4624 - accuracy: 0.7601 - val_loss: 0.5790 - val_accuracy: 0.6904\n",
      "Epoch 136/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4655 - accuracy: 0.7542 - val_loss: 0.5074 - val_accuracy: 0.7269\n",
      "Epoch 137/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4560 - accuracy: 0.7641 - val_loss: 0.6162 - val_accuracy: 0.6921\n",
      "Epoch 138/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4570 - accuracy: 0.7612 - val_loss: 0.5556 - val_accuracy: 0.7148\n",
      "Epoch 139/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4568 - accuracy: 0.7636 - val_loss: 0.5474 - val_accuracy: 0.7181\n",
      "Epoch 140/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4591 - accuracy: 0.7597 - val_loss: 0.5169 - val_accuracy: 0.7318\n",
      "Epoch 141/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4601 - accuracy: 0.7583 - val_loss: 0.5580 - val_accuracy: 0.6976\n",
      "Epoch 142/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4611 - accuracy: 0.7600 - val_loss: 0.5061 - val_accuracy: 0.7178\n",
      "Epoch 143/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4502 - accuracy: 0.7647 - val_loss: 0.5515 - val_accuracy: 0.6826\n",
      "Epoch 144/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4514 - accuracy: 0.7649 - val_loss: 0.5809 - val_accuracy: 0.7201\n",
      "Epoch 145/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4483 - accuracy: 0.7684 - val_loss: 0.5544 - val_accuracy: 0.7025\n",
      "Epoch 146/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4541 - accuracy: 0.7626 - val_loss: 0.5895 - val_accuracy: 0.6823\n",
      "Epoch 147/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4523 - accuracy: 0.7631 - val_loss: 0.5449 - val_accuracy: 0.7204\n",
      "Epoch 148/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4404 - accuracy: 0.7715 - val_loss: 0.5163 - val_accuracy: 0.7243\n",
      "Epoch 149/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4411 - accuracy: 0.7732 - val_loss: 0.6142 - val_accuracy: 0.6982\n",
      "Epoch 150/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4417 - accuracy: 0.7709 - val_loss: 0.4882 - val_accuracy: 0.7480\n",
      "Epoch 151/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4353 - accuracy: 0.7755 - val_loss: 0.5175 - val_accuracy: 0.7161\n",
      "Epoch 152/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4439 - accuracy: 0.7714 - val_loss: 0.6615 - val_accuracy: 0.6715\n",
      "Epoch 153/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4366 - accuracy: 0.7722 - val_loss: 0.6171 - val_accuracy: 0.6709- ETA:  - ETA: 8s - loss: 0.436\n",
      "Epoch 154/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4316 - accuracy: 0.7801 - val_loss: 0.5493 - val_accuracy: 0.7126\n",
      "Epoch 155/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4338 - accuracy: 0.7770 - val_loss: 0.4490 - val_accuracy: 0.7692\n",
      "Epoch 156/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.4315 - accuracy: 0.7800 - val_loss: 0.4704 - val_accuracy: 0.7493 loss: 0 - ETA: 0s - loss: 0.4319 - accuracy: 0.77\n",
      "Epoch 157/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4265 - accuracy: 0.7826 - val_loss: 0.4755 - val_accuracy: 0.7409\n",
      "Epoch 158/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4313 - accuracy: 0.7769 - val_loss: 0.6511 - val_accuracy: 0.6491\n",
      "Epoch 159/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4376 - accuracy: 0.7801 - val_loss: 0.5749 - val_accuracy: 0.7080\n",
      "Epoch 160/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4370 - accuracy: 0.7784 - val_loss: 0.5467 - val_accuracy: 0.7311\n",
      "Epoch 161/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4300 - accuracy: 0.7835 - val_loss: 0.5673 - val_accuracy: 0.7057\n",
      "Epoch 162/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4275 - accuracy: 0.7834 - val_loss: 0.4813 - val_accuracy: 0.7396 - loss:\n",
      "Epoch 163/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4256 - accuracy: 0.7848 - val_loss: 0.4375 - val_accuracy: 0.7695\n",
      "Epoch 164/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4244 - accuracy: 0.7841 - val_loss: 0.5380 - val_accuracy: 0.7044\n",
      "Epoch 165/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4216 - accuracy: 0.7892 - val_loss: 0.4637 - val_accuracy: 0.7536- ETA: - ETA: 9s - loss: 0.4107  - ETA: 8s - loss: 0.4116 - accu - ETA: 6s - loss: 0.4138 - accura - ETA: 6s - loss: 0.414 - ETA: 5s - loss: 0.4140 - ac - ETA: 5s - loss: 0.4153 - accuracy: 0. - ETA: 5s - los - ETA:  - ETA: 0s - loss: 0.420\n",
      "Epoch 166/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4145 - accuracy: 0.7887 - val_loss: 0.5700 - val_accuracy: 0.7054 ETA: 1 - ETA: 9s - ETA: 5s - loss: 0.4115 -  - ETA: 4s - loss: 0.4103 - accuracy: 0.79 - ETA: 4s - los - ETA: 2s\n",
      "Epoch 167/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4169 - accuracy: 0.7886 - val_loss: 0.5138 - val_accuracy: 0.7288  - ETA: 10s - loss: 0.4210 - accuracy: 0.7 - ETA:  - ETA: 9s - loss: 0 - ETA: 8s - loss: 0.4157 - accura - ETA: 8s - loss: 0.4160 - accuracy: 0.78 - ETA:  - ETA: 6s - loss: 0.414 - ETA: 6s - loss: 0 - ETA: 5s - loss: 0.4117 - accuracy:  - ETA: 5s - l - ETA: 4s - loss: 0.4173 - ac - ETA: 4s - ETA:  - ETA: 1s - l - ETA: 0s - loss: 0.4 - ETA: 0s - loss: 0.4170 - accuracy\n",
      "Epoch 168/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4309 - accuracy: 0.7822 - val_loss: 0.5050 - val_accuracy: 0.7301309 - accuracy: 0.78\n",
      "Epoch 169/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4154 - accuracy: 0.7912 - val_loss: 0.5194 - val_accuracy: 0.7210.4 - - ETA: 0s - loss: 0.4\n",
      "Epoch 170/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4130 - accuracy: 0.7912 - val_loss: 0.5159 - val_accuracy: 0.7236loss: 0.4177 - accuracy: 0.78 - ETA: 10s - loss: 0.4163 - accuracy: 0. - ETA: 10s - loss: 0.4155 - accur - ETA: 9s - loss: 0.4248  - - ETA: 7s - ETA - ETA: 5s - loss: 0 - ETA: 3s - loss: 0.4114 - accuracy: 0. - E - ETA: 2s - loss: 0.4116 -  - ETA - ETA: 0s - loss: 0.4102 \n",
      "Epoch 171/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3984 - accuracy: 0.8006 - val_loss: 0.6168 - val_accuracy: 0.6510TA: 12s - - ETA:  - ETA: 0s - loss:\n",
      "Epoch 172/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4089 - accuracy: 0.7944 - val_loss: 0.6088 - val_accuracy: 0.64713s - loss:  - ETA: 11s - loss: 0.417 - ETA: 10s - loss: 0.4057 - accuracy: 0 - ETA: 9s - loss: 0.4103 - ac - ETA: 9s - los - ETA: 8s - loss: 0.4034 - ac - ETA: 8s - ETA: 0s - loss: 0.4055 - accura\n",
      "Epoch 173/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.4475 - val_accuracy: 0.7653\n",
      "Epoch 174/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3985 - accuracy: 0.7993 - val_loss: 0.6566 - val_accuracy: 0.6859\n",
      "Epoch 175/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4039 - accuracy: 0.7995 - val_loss: 0.4811 - val_accuracy: 0.750304 - ETA: 0s - loss: 0.403\n",
      "Epoch 176/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4030 - accuracy: 0.7975 - val_loss: 0.5412 - val_accuracy: 0.7305\n",
      "Epoch 177/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3966 - accuracy: 0.8022 - val_loss: 0.5129 - val_accuracy: 0.7214- accurac - ETA: 11s - loss: 0.3889 - accuracy - - ETA: 9s - los - ETA: 1s - loss: 0.3950 - accuracy: 0.80 -\n",
      "Epoch 178/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4021 - accuracy: 0.8004 - val_loss: 0.5391 - val_accuracy: 0.7116s: 0.4078  - ETA: 3s - loss: 0.4056 - accuracy - ETA: 2s - loss: 0.4 - ETA: 2s - loss:\n",
      "Epoch 179/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4058 - accuracy: 0.7966 - val_loss: 0.5060 - val_accuracy: 0.7435\n",
      "Epoch 180/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4005 - accuracy: 0.7976 - val_loss: 0.5323 - val_accuracy: 0.72661s - loss: 0.3868 - acc - ETA: 3s - loss: - ETA\n",
      "Epoch 181/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3941 - accuracy: 0.8033 - val_loss: 0.5257 - val_accuracy: 0.7253.393\n",
      "Epoch 182/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3887 - accuracy: 0.8063 - val_loss: 0.4869 - val_accuracy: 0.7526 0. - ETA: 6s - loss: 0.3922 - accuracy: 0. - ETA: 5s - loss: 0.3 - ETA: 3s - loss: 0.3895 - accuracy: 0. - ETA: \n",
      "Epoch 183/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3927 - accuracy: 0.8060 - val_loss: 0.4388 - val_accuracy: 0.7620\n",
      "Epoch 184/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3890 - accuracy: 0.8060 - val_loss: 0.5712 - val_accuracy: 0.7021.3923 - accuracy: 0.80 - E - E - ETA: 5s - loss: 0 - ETA: 4s - loss: 0.389 - ETA: 4s - loss: 0.3888 - accuracy: 0. - ETA: 4s - - ETA: 0s - loss: 0.3889 - accura\n",
      "Epoch 185/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3862 - accuracy: 0.8099 - val_loss: 0.4797 - val_accuracy: 0.7386\n",
      "Epoch 186/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3840 - accuracy: 0.8118 - val_loss: 0.5324 - val_accuracy: 0.7272\n",
      "Epoch 187/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3927 - accuracy: 0.8080 - val_loss: 0.4847 - val_accuracy: 0.7712\n",
      "Epoch 188/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3943 - accuracy: 0.8028 - val_loss: 0.5042 - val_accuracy: 0.7386\n",
      "Epoch 189/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3810 - accuracy: 0.8149 - val_loss: 0.4734 - val_accuracy: 0.7650\n",
      "Epoch 190/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3891 - accuracy: 0.8087 - val_loss: 0.5547 - val_accuracy: 0.7035 - ETA - ETA: 1s - loss: 0.3885 - accu - ETA: 0s - loss: 0.3\n",
      "Epoch 191/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3829 - accuracy: 0.8148 - val_loss: 0.5253 - val_accuracy: 0.7292\n",
      "Epoch 192/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3805 - accuracy: 0.8153 - val_loss: 0.4657 - val_accuracy: 0.7542\n",
      "Epoch 193/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3863 - accuracy: 0.8149 - val_loss: 0.6186 - val_accuracy: 0.6816.3891 - ac - ETA: 0s - loss: 0.3885 - accuracy - ETA: 0s - loss: 0.387\n",
      "Epoch 194/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3821 - accuracy: 0.8135 - val_loss: 0.6381 - val_accuracy: 0.6878\n",
      "Epoch 195/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3823 - accuracy: 0.8156 - val_loss: 0.4591 - val_accuracy: 0.7669\n",
      "Epoch 196/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3731 - accuracy: 0.8203 - val_loss: 0.4977 - val_accuracy: 0.7474\n",
      "Epoch 197/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3836 - accuracy: 0.8120 - val_loss: 0.4317 - val_accuracy: 0.7725\n",
      "Epoch 198/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3754 - accuracy: 0.8141 - val_loss: 0.5501 - val_accuracy: 0.7363\n",
      "Epoch 199/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3710 - accuracy: 0.8200 - val_loss: 0.4646 - val_accuracy: 0.7835\n",
      "Epoch 200/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3729 - accuracy: 0.8208 - val_loss: 0.5748 - val_accuracy: 0.7197\n",
      "Epoch 201/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3746 - accuracy: 0.8154 - val_loss: 0.4939 - val_accuracy: 0.7445\n",
      "Epoch 202/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3625 - accuracy: 0.8244 - val_loss: 0.5039 - val_accuracy: 0.7308\n",
      "Epoch 203/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3664 - accuracy: 0.8235 - val_loss: 0.4884 - val_accuracy: 0.7399\n",
      "Epoch 204/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3605 - accuracy: 0.8252 - val_loss: 0.5321 - val_accuracy: 0.7201\n",
      "Epoch 205/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3746 - accuracy: 0.8189 - val_loss: 0.6979 - val_accuracy: 0.6683\n",
      "Epoch 206/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3591 - accuracy: 0.8264 - val_loss: 0.4649 - val_accuracy: 0.7783s: 0.3\n",
      "Epoch 207/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3683 - accuracy: 0.8231 - val_loss: 0.6373 - val_accuracy: 0.6764\n",
      "Epoch 208/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3668 - accuracy: 0.8237 - val_loss: 0.4917 - val_accuracy: 0.7321\n",
      "Epoch 209/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3506 - accuracy: 0.8305 - val_loss: 0.7336 - val_accuracy: 0.6755\n",
      "Epoch 210/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3613 - accuracy: 0.8236 - val_loss: 0.5898 - val_accuracy: 0.6794\n",
      "Epoch 211/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3536 - accuracy: 0.8305 - val_loss: 0.5223 - val_accuracy: 0.7591\n",
      "Epoch 212/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3511 - accuracy: 0.8326 - val_loss: 0.6041 - val_accuracy: 0.7044\n",
      "Epoch 213/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3571 - accuracy: 0.8326 - val_loss: 0.5303 - val_accuracy: 0.7354\n",
      "Epoch 214/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3594 - accuracy: 0.8263 - val_loss: 0.5256 - val_accuracy: 0.7314\n",
      "Epoch 215/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3547 - accuracy: 0.8315 - val_loss: 0.4730 - val_accuracy: 0.7617\n",
      "Epoch 216/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3471 - accuracy: 0.8344 - val_loss: 0.6243 - val_accuracy: 0.7152oss: 0.3469 - accu - ETA: 0s - loss: 0.3475 - accu\n",
      "Epoch 217/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3468 - accuracy: 0.8350 - val_loss: 0.4961 - val_accuracy: 0.7503\n",
      "Epoch 218/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3426 - accuracy: 0.8385 - val_loss: 0.4854 - val_accuracy: 0.7617\n",
      "Epoch 219/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3467 - accuracy: 0.8353 - val_loss: 0.5269 - val_accuracy: 0.7399\n",
      "Epoch 220/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3462 - accuracy: 0.8346 - val_loss: 0.5420 - val_accuracy: 0.7396\n",
      "Epoch 221/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3530 - accuracy: 0.8323 - val_loss: 0.4395 - val_accuracy: 0.7718\n",
      "Epoch 222/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3389 - accuracy: 0.8397 - val_loss: 0.6130 - val_accuracy: 0.7188\n",
      "Epoch 223/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3366 - accuracy: 0.8420 - val_loss: 0.5300 - val_accuracy: 0.74510s - loss: 0.3365 - accuracy\n",
      "Epoch 224/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3388 - accuracy: 0.8397 - val_loss: 0.5568 - val_accuracy: 0.7230\n",
      "Epoch 225/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3345 - accuracy: 0.8438 - val_loss: 0.5697 - val_accuracy: 0.7181\n",
      "Epoch 226/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3312 - accuracy: 0.8414 - val_loss: 0.5005 - val_accuracy: 0.7467\n",
      "Epoch 227/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3296 - accuracy: 0.8432 - val_loss: 0.4810 - val_accuracy: 0.7406\n",
      "Epoch 228/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3320 - accuracy: 0.8435 - val_loss: 0.4686 - val_accuracy: 0.7747\n",
      "Epoch 229/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3231 - accuracy: 0.8470 - val_loss: 0.4799 - val_accuracy: 0.7620\n",
      "Epoch 230/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3171 - accuracy: 0.8517 - val_loss: 0.6697 - val_accuracy: 0.6862\n",
      "Epoch 231/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3323 - accuracy: 0.8447 - val_loss: 0.5103 - val_accuracy: 0.7689\n",
      "Epoch 232/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3237 - accuracy: 0.8479 - val_loss: 0.4604 - val_accuracy: 0.7650\n",
      "Epoch 233/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3259 - accuracy: 0.8458 - val_loss: 0.5938 - val_accuracy: 0.7220\n",
      "Epoch 234/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3180 - accuracy: 0.8504 - val_loss: 0.4688 - val_accuracy: 0.7712\n",
      "Epoch 235/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3216 - accuracy: 0.8504 - val_loss: 0.4825 - val_accuracy: 0.7666\n",
      "Epoch 236/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3269 - accuracy: 0.8497 - val_loss: 0.4848 - val_accuracy: 0.7598\n",
      "Epoch 237/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3212 - accuracy: 0.8478 - val_loss: 0.4834 - val_accuracy: 0.76335s - loss: 0.3240 - ac - ETA: 4s - ETA: 2s - loss: 0.3249 - accuracy - ETA: 2s - loss: 0\n",
      "Epoch 238/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3201 - accuracy: 0.8470 - val_loss: 0.4958 - val_accuracy: 0.7611\n",
      "Epoch 239/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3197 - accuracy: 0.8494 - val_loss: 0.4697 - val_accuracy: 0.7598TA: 0s - loss: 0.3203 - accuracy: \n",
      "Epoch 240/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3072 - accuracy: 0.8577 - val_loss: 0.4594 - val_accuracy: 0.7741\n",
      "Epoch 241/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3081 - accuracy: 0.8564 - val_loss: 0.4946 - val_accuracy: 0.7477\n",
      "Epoch 242/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3009 - accuracy: 0.8604 - val_loss: 0.5066 - val_accuracy: 0.7591\n",
      "Epoch 243/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3130 - accuracy: 0.8559 - val_loss: 0.6268 - val_accuracy: 0.7152\n",
      "Epoch 244/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3128 - accuracy: 0.8551 - val_loss: 0.5316 - val_accuracy: 0.7620\n",
      "Epoch 245/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3112 - accuracy: 0.8557 - val_loss: 0.6093 - val_accuracy: 0.6940 - loss: 0.3037  - ETA: 2s - loss: 0.3057 - ac - ETA: 1s - loss: 0.308\n",
      "Epoch 246/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3105 - accuracy: 0.8560 - val_loss: 0.4951 - val_accuracy: 0.7646 E\n",
      "Epoch 247/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3011 - accuracy: 0.8605 - val_loss: 0.5881 - val_accuracy: 0.7334\n",
      "Epoch 248/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2984 - accuracy: 0.8638 - val_loss: 0.4479 - val_accuracy: 0.7829\n",
      "Epoch 249/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3013 - accuracy: 0.8594 - val_loss: 0.5306 - val_accuracy: 0.7321\n",
      "Epoch 250/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3138 - accuracy: 0.8540 - val_loss: 0.5764 - val_accuracy: 0.7246\n",
      "Epoch 251/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3018 - accuracy: 0.8607 - val_loss: 0.4593 - val_accuracy: 0.7757\n",
      "Epoch 252/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3071 - accuracy: 0.8573 - val_loss: 0.5086 - val_accuracy: 0.7513\n",
      "Epoch 253/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2963 - accuracy: 0.8616 - val_loss: 0.6466 - val_accuracy: 0.6790\n",
      "Epoch 254/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2970 - accuracy: 0.8629 - val_loss: 0.4776 - val_accuracy: 0.7627\n",
      "Epoch 255/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2970 - accuracy: 0.8645 - val_loss: 0.5211 - val_accuracy: 0.7438000 - accuracy:  - ETA: 1s - loss: 0.2997 - accuracy -\n",
      "Epoch 256/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2955 - accuracy: 0.8628 - val_loss: 0.5246 - val_accuracy: 0.7669\n",
      "Epoch 257/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2987 - accuracy: 0.8635 - val_loss: 0.5252 - val_accuracy: 0.7533\n",
      "Epoch 258/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2932 - accuracy: 0.8670 - val_loss: 0.5002 - val_accuracy: 0.7454 0.3014 - accura - ETA: 8s - loss: 0.3011 - accuracy: 0. - ETA: 7s - los - ETA: 7s - loss: 0.2994  - ETA: 5s - loss: - ETA: 4s - loss: 0.2 - ETA: 3s - - E\n",
      "Epoch 259/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2958 - accuracy: 0.8648 - val_loss: 0.5063 - val_accuracy: 0.7601\n",
      "Epoch 260/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2905 - accuracy: 0.8686 - val_loss: 0.4937 - val_accuracy: 0.7712\n",
      "Epoch 261/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2969 - accuracy: 0.8659 - val_loss: 0.5784 - val_accuracy: 0.7122\n",
      "Epoch 262/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2892 - accuracy: 0.8685 - val_loss: 0.5915 - val_accuracy: 0.7445\n",
      "Epoch 263/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2897 - accuracy: 0.8679 - val_loss: 0.5711 - val_accuracy: 0.7142\n",
      "Epoch 264/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2888 - accuracy: 0.8698 - val_loss: 0.9476 - val_accuracy: 0.6370curacy - E\n",
      "Epoch 265/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2968 - accuracy: 0.8634 - val_loss: 0.5115 - val_accuracy: 0.7454\n",
      "Epoch 266/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2923 - accuracy: 0.8660 - val_loss: 0.5346 - val_accuracy: 0.7585\n",
      "Epoch 267/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2870 - accuracy: 0.8701 - val_loss: 0.5614 - val_accuracy: 0.7337\n",
      "Epoch 268/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2777 - accuracy: 0.8740 - val_loss: 0.5251 - val_accuracy: 0.7487\n",
      "Epoch 269/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2815 - accuracy: 0.8746 - val_loss: 0.4423 - val_accuracy: 0.7878\n",
      "Epoch 270/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2767 - accuracy: 0.8742 - val_loss: 0.5364 - val_accuracy: 0.7526\n",
      "Epoch 271/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2940 - accuracy: 0.8685 - val_loss: 0.5645 - val_accuracy: 0.7412\n",
      "Epoch 272/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2812 - accuracy: 0.8711 - val_loss: 0.5623 - val_accuracy: 0.7350\n",
      "Epoch 273/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2803 - accuracy: 0.8724 - val_loss: 0.6492 - val_accuracy: 0.7308\n",
      "Epoch 274/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2772 - accuracy: 0.8750 - val_loss: 0.5862 - val_accuracy: 0.7477\n",
      "Epoch 275/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2792 - accuracy: 0.8744 - val_loss: 0.5493 - val_accuracy: 0.7490\n",
      "Epoch 276/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2791 - accuracy: 0.8745 - val_loss: 0.7746 - val_accuracy: 0.6950\n",
      "Epoch 277/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2695 - accuracy: 0.8785 - val_loss: 0.5830 - val_accuracy: 0.7334\n",
      "Epoch 278/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2759 - accuracy: 0.8748 - val_loss: 0.4935 - val_accuracy: 0.7503\n",
      "Epoch 279/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2706 - accuracy: 0.8773 - val_loss: 0.5691 - val_accuracy: 0.7572\n",
      "Epoch 280/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2728 - accuracy: 0.8780 - val_loss: 0.5815 - val_accuracy: 0.7393\n",
      "Epoch 281/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2704 - accuracy: 0.8788 - val_loss: 0.4814 - val_accuracy: 0.7663\n",
      "Epoch 282/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2631 - accuracy: 0.8820 - val_loss: 0.6812 - val_accuracy: 0.7067oss: 0.2622 - \n",
      "Epoch 283/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2685 - accuracy: 0.8792 - val_loss: 0.5109 - val_accuracy: 0.7549\n",
      "Epoch 284/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2695 - accuracy: 0.8810 - val_loss: 0.6095 - val_accuracy: 0.6947\n",
      "Epoch 285/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2744 - accuracy: 0.8773 - val_loss: 0.5784 - val_accuracy: 0.7448\n",
      "Epoch 286/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2639 - accuracy: 0.8825 - val_loss: 0.4942 - val_accuracy: 0.7695\n",
      "Epoch 287/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2616 - accuracy: 0.8839 - val_loss: 0.5917 - val_accuracy: 0.7318oss: 0.2618 - accuracy: 0.88\n",
      "Epoch 288/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2521 - accuracy: 0.8894 - val_loss: 0.5873 - val_accuracy: 0.7301\n",
      "Epoch 289/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2598 - accuracy: 0.8855 - val_loss: 0.6039 - val_accuracy: 0.7350\n",
      "Epoch 290/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2555 - accuracy: 0.8873 - val_loss: 0.6039 - val_accuracy: 0.7314\n",
      "Epoch 291/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2638 - accuracy: 0.8821 - val_loss: 0.5017 - val_accuracy: 0.7666\n",
      "Epoch 292/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2600 - accuracy: 0.8854 - val_loss: 0.6235 - val_accuracy: 0.7344\n",
      "Epoch 293/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2561 - accuracy: 0.8855 - val_loss: 0.5243 - val_accuracy: 0.7588\n",
      "Epoch 294/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2549 - accuracy: 0.8865 - val_loss: 0.5598 - val_accuracy: 0.7474oss: 0.2539 - \n",
      "Epoch 295/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2451 - accuracy: 0.8917 - val_loss: 0.8410 - val_accuracy: 0.6719\n",
      "Epoch 296/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2505 - accuracy: 0.8896 - val_loss: 0.7924 - val_accuracy: 0.7031\n",
      "Epoch 297/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2533 - accuracy: 0.8881 - val_loss: 0.5275 - val_accuracy: 0.7601\n",
      "Epoch 298/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2483 - accuracy: 0.8891 - val_loss: 0.5680 - val_accuracy: 0.7396\n",
      "Epoch 299/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2527 - accuracy: 0.8866 - val_loss: 0.4786 - val_accuracy: 0.7819\n",
      "Epoch 300/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2492 - accuracy: 0.8902 - val_loss: 0.5413 - val_accuracy: 0.7539\n",
      "Epoch 301/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2530 - accuracy: 0.8877 - val_loss: 0.6230 - val_accuracy: 0.7135\n",
      "Epoch 302/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2470 - accuracy: 0.8906 - val_loss: 0.4860 - val_accuracy: 0.7930\n",
      "Epoch 303/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2399 - accuracy: 0.8955 - val_loss: 0.6329 - val_accuracy: 0.7077 - loss: 0.2378 - accuracy: 0.89 - ETA: 1s - loss: 0.2379 - accuracy: 0. - ETA: 1s - loss: 0.2379 - accuracy: 0. - ETA: 1s - loss: 0.2386  - ETA: 0s - los\n",
      "Epoch 304/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2470 - accuracy: 0.8894 - val_loss: 0.7274 - val_accuracy: 0.6696\n",
      "Epoch 305/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2493 - accuracy: 0.8881 - val_loss: 0.5201 - val_accuracy: 0.7767\n",
      "Epoch 306/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2414 - accuracy: 0.8931 - val_loss: 0.5907 - val_accuracy: 0.7578\n",
      "Epoch 307/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2384 - accuracy: 0.8932 - val_loss: 0.6594 - val_accuracy: 0.7158\n",
      "Epoch 308/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2423 - accuracy: 0.8939 - val_loss: 0.6393 - val_accuracy: 0.7132\n",
      "Epoch 309/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2408 - accuracy: 0.8933 - val_loss: 0.5600 - val_accuracy: 0.7536\n",
      "Epoch 310/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2403 - accuracy: 0.8949 - val_loss: 0.5627 - val_accuracy: 0.7448\n",
      "Epoch 311/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2441 - accuracy: 0.8934 - val_loss: 0.5894 - val_accuracy: 0.7298\n",
      "Epoch 312/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2342 - accuracy: 0.8956 - val_loss: 0.6129 - val_accuracy: 0.7376\n",
      "Epoch 313/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2373 - accuracy: 0.8962 - val_loss: 0.5795 - val_accuracy: 0.7721\n",
      "Epoch 314/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2403 - accuracy: 0.8954 - val_loss: 0.5807 - val_accuracy: 0.7380\n",
      "Epoch 315/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2389 - accuracy: 0.8937 - val_loss: 0.6611 - val_accuracy: 0.7214\n",
      "Epoch 316/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2320 - accuracy: 0.8989 - val_loss: 0.5230 - val_accuracy: 0.7705\n",
      "Epoch 317/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2360 - accuracy: 0.8960 - val_loss: 0.5869 - val_accuracy: 0.7467TA: 7s -\n",
      "Epoch 318/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2297 - accuracy: 0.8983 - val_loss: 0.6045 - val_accuracy: 0.7425\n",
      "Epoch 319/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2444 - accuracy: 0.8917 - val_loss: 0.6057 - val_accuracy: 0.7288\n",
      "Epoch 320/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2386 - accuracy: 0.8970 - val_loss: 0.6517 - val_accuracy: 0.7380\n",
      "Epoch 321/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2299 - accuracy: 0.8988 - val_loss: 0.6569 - val_accuracy: 0.7288\n",
      "Epoch 322/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2303 - accuracy: 0.8990 - val_loss: 0.6910 - val_accuracy: 0.7207\n",
      "Epoch 323/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2289 - accuracy: 0.8991 - val_loss: 0.6298 - val_accuracy: 0.7331\n",
      "Epoch 324/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2213 - accuracy: 0.9039 - val_loss: 0.4979 - val_accuracy: 0.7812\n",
      "Epoch 325/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2295 - accuracy: 0.9007 - val_loss: 0.5857 - val_accuracy: 0.7562\n",
      "Epoch 326/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2274 - accuracy: 0.9008 - val_loss: 0.7251 - val_accuracy: 0.7028\n",
      "Epoch 327/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2302 - accuracy: 0.9012 - val_loss: 0.6620 - val_accuracy: 0.7109\n",
      "Epoch 328/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2206 - accuracy: 0.9049 - val_loss: 0.5057 - val_accuracy: 0.7715\n",
      "Epoch 329/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2315 - accuracy: 0.8972 - val_loss: 0.7097 - val_accuracy: 0.7188\n",
      "Epoch 330/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2275 - accuracy: 0.9013 - val_loss: 0.5734 - val_accuracy: 0.7516\n",
      "Epoch 331/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2265 - accuracy: 0.8989 - val_loss: 0.5194 - val_accuracy: 0.7630\n",
      "Epoch 332/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2241 - accuracy: 0.9022 - val_loss: 0.6065 - val_accuracy: 0.7321\n",
      "Epoch 333/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2262 - accuracy: 0.9012 - val_loss: 0.6912 - val_accuracy: 0.7233\n",
      "Epoch 334/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2211 - accuracy: 0.9052 - val_loss: 0.5861 - val_accuracy: 0.7493\n",
      "Epoch 335/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2198 - accuracy: 0.9037 - val_loss: 0.5888 - val_accuracy: 0.7552\n",
      "Epoch 336/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2140 - accuracy: 0.9059 - val_loss: 0.6257 - val_accuracy: 0.7350s - loss: 0.2237 \n",
      "Epoch 337/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2195 - accuracy: 0.9044 - val_loss: 0.6289 - val_accuracy: 0.7464\n",
      "Epoch 338/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2131 - accuracy: 0.9066 - val_loss: 0.6869 - val_accuracy: 0.7168\n",
      "Epoch 339/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2196 - accuracy: 0.9063 - val_loss: 0.5921 - val_accuracy: 0.7432\n",
      "Epoch 340/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2134 - accuracy: 0.9067 - val_loss: 0.5818 - val_accuracy: 0.7559\n",
      "Epoch 341/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2133 - accuracy: 0.9069 - val_loss: 0.7748 - val_accuracy: 0.7279\n",
      "Epoch 342/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2193 - accuracy: 0.9037 - val_loss: 0.6109 - val_accuracy: 0.7568\n",
      "Epoch 343/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2134 - accuracy: 0.9072 - val_loss: 0.5595 - val_accuracy: 0.7699\n",
      "Epoch 344/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2017 - accuracy: 0.9137 - val_loss: 0.5528 - val_accuracy: 0.7614\n",
      "Epoch 345/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2154 - accuracy: 0.9080 - val_loss: 0.6932 - val_accuracy: 0.7285\n",
      "Epoch 346/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2106 - accuracy: 0.9075 - val_loss: 0.5789 - val_accuracy: 0.7568\n",
      "Epoch 347/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2133 - accuracy: 0.9075 - val_loss: 0.5675 - val_accuracy: 0.7594\n",
      "Epoch 348/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2028 - accuracy: 0.9129 - val_loss: 0.6802 - val_accuracy: 0.7119\n",
      "Epoch 349/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2096 - accuracy: 0.9087 - val_loss: 0.8827 - val_accuracy: 0.6732\n",
      "Epoch 350/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2030 - accuracy: 0.9127 - val_loss: 0.6580 - val_accuracy: 0.7490\n",
      "Epoch 351/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2048 - accuracy: 0.9110 - val_loss: 0.6263 - val_accuracy: 0.7415\n",
      "Epoch 352/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2103 - accuracy: 0.9087 - val_loss: 0.6863 - val_accuracy: 0.7318\n",
      "Epoch 353/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2082 - accuracy: 0.9092 - val_loss: 0.6181 - val_accuracy: 0.7611\n",
      "Epoch 354/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2086 - accuracy: 0.9112 - val_loss: 0.6452 - val_accuracy: 0.7588\n",
      "Epoch 355/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2051 - accuracy: 0.9105 - val_loss: 0.6218 - val_accuracy: 0.7507\n",
      "Epoch 356/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2088 - accuracy: 0.9106 - val_loss: 0.5893 - val_accuracy: 0.7533\n",
      "Epoch 357/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2041 - accuracy: 0.9111 - val_loss: 0.5793 - val_accuracy: 0.7578\n",
      "Epoch 358/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2005 - accuracy: 0.9143 - val_loss: 0.6003 - val_accuracy: 0.7510\n",
      "Epoch 359/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1963 - accuracy: 0.9150 - val_loss: 0.7573 - val_accuracy: 0.7197\n",
      "Epoch 360/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2006 - accuracy: 0.9144 - val_loss: 0.6756 - val_accuracy: 0.7467\n",
      "Epoch 361/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2032 - accuracy: 0.9125 - val_loss: 0.6359 - val_accuracy: 0.7324\n",
      "Epoch 362/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2033 - accuracy: 0.9131 - val_loss: 0.5587 - val_accuracy: 0.7757\n",
      "Epoch 363/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1994 - accuracy: 0.9141 - val_loss: 0.5751 - val_accuracy: 0.7780\n",
      "Epoch 364/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.1959 - accuracy: 0.9151 - val_loss: 0.6861 - val_accuracy: 0.7373\n",
      "Epoch 365/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1953 - accuracy: 0.9156 - val_loss: 0.6675 - val_accuracy: 0.7393\n",
      "Epoch 366/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1978 - accuracy: 0.9155 - val_loss: 0.6515 - val_accuracy: 0.7432\n",
      "Epoch 367/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.1921 - accuracy: 0.9181 - val_loss: 0.6742 - val_accuracy: 0.7428\n",
      "Epoch 368/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2022 - accuracy: 0.9138 - val_loss: 0.6006 - val_accuracy: 0.7607\n",
      "Epoch 369/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2007 - accuracy: 0.9143 - val_loss: 0.6326 - val_accuracy: 0.7536\n",
      "Epoch 370/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2011 - accuracy: 0.9151 - val_loss: 0.6535 - val_accuracy: 0.7474\n",
      "Epoch 371/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1913 - accuracy: 0.9182 - val_loss: 0.6859 - val_accuracy: 0.7266\n",
      "Epoch 372/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1964 - accuracy: 0.9163 - val_loss: 0.6417 - val_accuracy: 0.7373\n",
      "Epoch 373/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1916 - accuracy: 0.9184 - val_loss: 0.6753 - val_accuracy: 0.7135\n",
      "Epoch 374/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1980 - accuracy: 0.9133 - val_loss: 0.5889 - val_accuracy: 0.7845\n",
      "Epoch 375/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2019 - accuracy: 0.9127 - val_loss: 0.7968 - val_accuracy: 0.7210\n",
      "Epoch 376/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1948 - accuracy: 0.9177 - val_loss: 0.7593 - val_accuracy: 0.7083\n",
      "Epoch 377/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1925 - accuracy: 0.9186 - val_loss: 0.6780 - val_accuracy: 0.7425\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00377: early stopping\n",
      "     12/Unknown - 0s 5ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121/3121 [==============================] - 14s 5ms/step\n",
      "347/347 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|                                      | 5/10 [6:34:52<6:50:51, 4930.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "438/438 [==============================] - 16s 35ms/step - loss: 0.6903 - accuracy: 0.5306 - val_loss: 0.6947 - val_accuracy: 0.5036\n",
      "Epoch 2/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6850 - accuracy: 0.5513 - val_loss: 0.6973 - val_accuracy: 0.5065\n",
      "Epoch 3/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6809 - accuracy: 0.5545 - val_loss: 0.6992 - val_accuracy: 0.5127\n",
      "Epoch 4/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6769 - accuracy: 0.5591 - val_loss: 0.6974 - val_accuracy: 0.5000\n",
      "Epoch 5/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6742 - accuracy: 0.5628 - val_loss: 0.6971 - val_accuracy: 0.4919\n",
      "Epoch 6/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6695 - accuracy: 0.5721 - val_loss: 0.6923 - val_accuracy: 0.5049\n",
      "Epoch 7/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6656 - accuracy: 0.5767 - val_loss: 0.6882 - val_accuracy: 0.5156\n",
      "Epoch 8/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6628 - accuracy: 0.5788 - val_loss: 0.7015 - val_accuracy: 0.5104\n",
      "Epoch 9/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6616 - accuracy: 0.5837 - val_loss: 0.6844 - val_accuracy: 0.5518\n",
      "Epoch 10/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6577 - accuracy: 0.5888 - val_loss: 0.6869 - val_accuracy: 0.5407\n",
      "Epoch 11/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6573 - accuracy: 0.5883 - val_loss: 0.6883 - val_accuracy: 0.5234\n",
      "Epoch 12/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6556 - accuracy: 0.5911 - val_loss: 0.6668 - val_accuracy: 0.5771\n",
      "Epoch 13/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6540 - accuracy: 0.5920 - val_loss: 0.6798 - val_accuracy: 0.5244\n",
      "Epoch 14/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6492 - accuracy: 0.5982 - val_loss: 0.6815 - val_accuracy: 0.5335\n",
      "Epoch 15/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6495 - accuracy: 0.5951 - val_loss: 0.6736 - val_accuracy: 0.5641\n",
      "Epoch 16/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6459 - accuracy: 0.6032 - val_loss: 0.6766 - val_accuracy: 0.5479\n",
      "Epoch 17/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6420 - accuracy: 0.6106 - val_loss: 0.6846 - val_accuracy: 0.5397\n",
      "Epoch 18/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6440 - accuracy: 0.6017 - val_loss: 0.6661 - val_accuracy: 0.5417\n",
      "Epoch 19/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6417 - accuracy: 0.6134 - val_loss: 0.6697 - val_accuracy: 0.5602\n",
      "Epoch 20/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6385 - accuracy: 0.6142 - val_loss: 0.6770 - val_accuracy: 0.5524\n",
      "Epoch 21/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6403 - accuracy: 0.6123 - val_loss: 0.6460 - val_accuracy: 0.6074\n",
      "Epoch 22/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6366 - accuracy: 0.6170 - val_loss: 0.6637 - val_accuracy: 0.5827\n",
      "Epoch 23/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6338 - accuracy: 0.6223 - val_loss: 0.6837 - val_accuracy: 0.5443\n",
      "Epoch 24/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6327 - accuracy: 0.6232 - val_loss: 0.7088 - val_accuracy: 0.5342\n",
      "Epoch 25/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6281 - accuracy: 0.6252 - val_loss: 0.6434 - val_accuracy: 0.6143\n",
      "Epoch 26/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6275 - accuracy: 0.6265 - val_loss: 0.6507 - val_accuracy: 0.5931\n",
      "Epoch 27/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6265 - accuracy: 0.6289 - val_loss: 0.6476 - val_accuracy: 0.6185\n",
      "Epoch 28/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6241 - accuracy: 0.6309 - val_loss: 0.6836 - val_accuracy: 0.5492\n",
      "Epoch 29/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6232 - accuracy: 0.6328 - val_loss: 0.6430 - val_accuracy: 0.5980\n",
      "Epoch 30/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6198 - accuracy: 0.6354 - val_loss: 0.6705 - val_accuracy: 0.5648\n",
      "Epoch 31/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6166 - accuracy: 0.6370 - val_loss: 0.6677 - val_accuracy: 0.5859\n",
      "Epoch 32/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6139 - accuracy: 0.6377 - val_loss: 0.6614 - val_accuracy: 0.5706\n",
      "Epoch 33/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6088 - accuracy: 0.6454 - val_loss: 0.6322 - val_accuracy: 0.62347 - ac\n",
      "Epoch 34/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6120 - accuracy: 0.6404 - val_loss: 0.6470 - val_accuracy: 0.5970\n",
      "Epoch 35/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6077 - accuracy: 0.6451 - val_loss: 0.6343 - val_accuracy: 0.6188\n",
      "Epoch 36/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6019 - accuracy: 0.6517 - val_loss: 0.6494 - val_accuracy: 0.6087\n",
      "Epoch 37/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6039 - accuracy: 0.6447 - val_loss: 0.6150 - val_accuracy: 0.6471\n",
      "Epoch 38/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6022 - accuracy: 0.6487 - val_loss: 0.6212 - val_accuracy: 0.6211\n",
      "Epoch 39/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6017 - accuracy: 0.6437 - val_loss: 0.6432 - val_accuracy: 0.6156\n",
      "Epoch 40/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5973 - accuracy: 0.6469 - val_loss: 0.6285 - val_accuracy: 0.6237\n",
      "Epoch 41/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5950 - accuracy: 0.6490 - val_loss: 0.6497 - val_accuracy: 0.5843\n",
      "Epoch 42/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5888 - accuracy: 0.6557 - val_loss: 0.6070 - val_accuracy: 0.6393\n",
      "Epoch 43/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5856 - accuracy: 0.6580 - val_loss: 0.6329 - val_accuracy: 0.5990\n",
      "Epoch 44/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5891 - accuracy: 0.6546 - val_loss: 0.6258 - val_accuracy: 0.6094\n",
      "Epoch 45/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5846 - accuracy: 0.6574 - val_loss: 0.6542 - val_accuracy: 0.6029\n",
      "Epoch 46/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5822 - accuracy: 0.6587 - val_loss: 0.6158 - val_accuracy: 0.6077\n",
      "Epoch 47/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5825 - accuracy: 0.6580 - val_loss: 0.6213 - val_accuracy: 0.6230\n",
      "Epoch 48/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5783 - accuracy: 0.6630 - val_loss: 0.6119 - val_accuracy: 0.6182\n",
      "Epoch 49/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5819 - accuracy: 0.6621 - val_loss: 0.6029 - val_accuracy: 0.6514\n",
      "Epoch 50/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5761 - accuracy: 0.6696 - val_loss: 0.7015 - val_accuracy: 0.5983\n",
      "Epoch 51/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5809 - accuracy: 0.6623 - val_loss: 0.6183 - val_accuracy: 0.6357\n",
      "Epoch 52/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5729 - accuracy: 0.6640 - val_loss: 0.6012 - val_accuracy: 0.6315\n",
      "Epoch 53/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5758 - accuracy: 0.6640 - val_loss: 0.6114 - val_accuracy: 0.6094\n",
      "Epoch 54/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5722 - accuracy: 0.6667 - val_loss: 0.6084 - val_accuracy: 0.6370\n",
      "Epoch 55/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5666 - accuracy: 0.6697 - val_loss: 0.5837 - val_accuracy: 0.6553\n",
      "Epoch 56/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5667 - accuracy: 0.6742 - val_loss: 0.6209 - val_accuracy: 0.6416\n",
      "Epoch 57/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5619 - accuracy: 0.6758 - val_loss: 0.5991 - val_accuracy: 0.6540\n",
      "Epoch 58/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5662 - accuracy: 0.6715 - val_loss: 0.5969 - val_accuracy: 0.6432\n",
      "Epoch 59/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5672 - accuracy: 0.6768 - val_loss: 0.6155 - val_accuracy: 0.6377\n",
      "Epoch 60/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5665 - accuracy: 0.6746 - val_loss: 0.6094 - val_accuracy: 0.6468\n",
      "Epoch 61/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5643 - accuracy: 0.6774 - val_loss: 0.6021 - val_accuracy: 0.6357\n",
      "Epoch 62/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5651 - accuracy: 0.6778 - val_loss: 0.6610 - val_accuracy: 0.6113\n",
      "Epoch 63/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5643 - accuracy: 0.6656 - val_loss: 0.5758 - val_accuracy: 0.6514\n",
      "Epoch 64/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5637 - accuracy: 0.6698 - val_loss: 0.6111 - val_accuracy: 0.6481\n",
      "Epoch 65/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5612 - accuracy: 0.6750 - val_loss: 0.6245 - val_accuracy: 0.6455\n",
      "Epoch 66/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5581 - accuracy: 0.6807 - val_loss: 0.6012 - val_accuracy: 0.6478\n",
      "Epoch 67/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5558 - accuracy: 0.6818 - val_loss: 0.5806 - val_accuracy: 0.6641\n",
      "Epoch 68/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5530 - accuracy: 0.6799 - val_loss: 0.6063 - val_accuracy: 0.6471\n",
      "Epoch 69/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5491 - accuracy: 0.6865 - val_loss: 0.6249 - val_accuracy: 0.6117\n",
      "Epoch 70/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5474 - accuracy: 0.6919 - val_loss: 0.5594 - val_accuracy: 0.6852\n",
      "Epoch 71/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5435 - accuracy: 0.6974 - val_loss: 0.5766 - val_accuracy: 0.6836\n",
      "Epoch 72/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5436 - accuracy: 0.6961 - val_loss: 0.5609 - val_accuracy: 0.6579\n",
      "Epoch 73/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5483 - accuracy: 0.6947 - val_loss: 0.5797 - val_accuracy: 0.6562\n",
      "Epoch 74/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5474 - accuracy: 0.6922 - val_loss: 0.5574 - val_accuracy: 0.6621\n",
      "Epoch 75/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5469 - accuracy: 0.6919 - val_loss: 0.5964 - val_accuracy: 0.6553\n",
      "Epoch 76/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5398 - accuracy: 0.6973 - val_loss: 0.6692 - val_accuracy: 0.6315 0.5\n",
      "Epoch 77/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5436 - accuracy: 0.6793 - val_loss: 0.5714 - val_accuracy: 0.6449\n",
      "Epoch 78/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5390 - accuracy: 0.6865 - val_loss: 0.6217 - val_accuracy: 0.6615\n",
      "Epoch 79/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5468 - accuracy: 0.6799 - val_loss: 0.5648 - val_accuracy: 0.6543\n",
      "Epoch 80/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5413 - accuracy: 0.6907 - val_loss: 0.5676 - val_accuracy: 0.6530\n",
      "Epoch 81/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5432 - accuracy: 0.6923 - val_loss: 0.5802 - val_accuracy: 0.6608 ETA: 4s - loss: 0.5400 - ac\n",
      "Epoch 82/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5356 - accuracy: 0.7030 - val_loss: 0.5600 - val_accuracy: 0.6735\n",
      "Epoch 83/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5350 - accuracy: 0.6986 - val_loss: 0.6115 - val_accuracy: 0.6546 - loss: 0.5359 - accu\n",
      "Epoch 84/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5264 - accuracy: 0.7052 - val_loss: 0.5612 - val_accuracy: 0.6569\n",
      "Epoch 85/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5338 - accuracy: 0.6954 - val_loss: 0.5537 - val_accuracy: 0.6800\n",
      "Epoch 86/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5283 - accuracy: 0.7000 - val_loss: 0.5646 - val_accuracy: 0.6647 - loss: 0.5301 -  - E\n",
      "Epoch 87/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5207 - accuracy: 0.7108 - val_loss: 0.6390 - val_accuracy: 0.6452\n",
      "Epoch 88/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5334 - accuracy: 0.7053 - val_loss: 0.5761 - val_accuracy: 0.6494\n",
      "Epoch 89/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5317 - accuracy: 0.7040 - val_loss: 0.5931 - val_accuracy: 0.6709\n",
      "Epoch 90/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5239 - accuracy: 0.7122 - val_loss: 0.5631 - val_accuracy: 0.6615\n",
      "Epoch 91/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5152 - accuracy: 0.7167 - val_loss: 0.6488 - val_accuracy: 0.6553\n",
      "Epoch 92/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5230 - accuracy: 0.7096 - val_loss: 0.5233 - val_accuracy: 0.6862\n",
      "Epoch 93/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5168 - accuracy: 0.7083 - val_loss: 0.5651 - val_accuracy: 0.6696\n",
      "Epoch 94/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5226 - accuracy: 0.6989 - val_loss: 0.5399 - val_accuracy: 0.6924\n",
      "Epoch 95/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5151 - accuracy: 0.7119 - val_loss: 0.5320 - val_accuracy: 0.6865\n",
      "Epoch 96/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5124 - accuracy: 0.7114 - val_loss: 0.5254 - val_accuracy: 0.6960\n",
      "Epoch 97/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5168 - accuracy: 0.7085 - val_loss: 0.5413 - val_accuracy: 0.6960\n",
      "Epoch 98/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5142 - accuracy: 0.7129 - val_loss: 0.5472 - val_accuracy: 0.7015\n",
      "Epoch 99/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5124 - accuracy: 0.7125 - val_loss: 0.5432 - val_accuracy: 0.7025\n",
      "Epoch 100/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5101 - accuracy: 0.7201 - val_loss: 0.5477 - val_accuracy: 0.6878\n",
      "Epoch 101/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5054 - accuracy: 0.7196 - val_loss: 0.5507 - val_accuracy: 0.7048\n",
      "Epoch 102/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5022 - accuracy: 0.7232 - val_loss: 0.5243 - val_accuracy: 0.6872\n",
      "Epoch 103/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5023 - accuracy: 0.7219 - val_loss: 0.5583 - val_accuracy: 0.6966\n",
      "Epoch 104/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5084 - accuracy: 0.7193 - val_loss: 0.5339 - val_accuracy: 0.6940\n",
      "Epoch 105/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5033 - accuracy: 0.7189 - val_loss: 0.5103 - val_accuracy: 0.7064\n",
      "Epoch 106/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4992 - accuracy: 0.7287 - val_loss: 0.6461 - val_accuracy: 0.6559\n",
      "Epoch 107/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4999 - accuracy: 0.7231 - val_loss: 0.5559 - val_accuracy: 0.7093\n",
      "Epoch 108/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4964 - accuracy: 0.7267 - val_loss: 0.5673 - val_accuracy: 0.6771\n",
      "Epoch 109/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5020 - accuracy: 0.7281 - val_loss: 0.5719 - val_accuracy: 0.6872\n",
      "Epoch 110/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4939 - accuracy: 0.7314 - val_loss: 0.5470 - val_accuracy: 0.7116\n",
      "Epoch 111/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4961 - accuracy: 0.7310 - val_loss: 0.5060 - val_accuracy: 0.7214\n",
      "Epoch 112/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4938 - accuracy: 0.7330 - val_loss: 0.5223 - val_accuracy: 0.7174\n",
      "Epoch 113/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4844 - accuracy: 0.7376 - val_loss: 0.5114 - val_accuracy: 0.7168\n",
      "Epoch 114/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4807 - accuracy: 0.7412 - val_loss: 0.5122 - val_accuracy: 0.7301\n",
      "Epoch 115/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4860 - accuracy: 0.7378 - val_loss: 0.5197 - val_accuracy: 0.7249\n",
      "Epoch 116/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4851 - accuracy: 0.7399 - val_loss: 0.5265 - val_accuracy: 0.7168\n",
      "Epoch 117/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4842 - accuracy: 0.7350 - val_loss: 0.5180 - val_accuracy: 0.7327\n",
      "Epoch 118/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4814 - accuracy: 0.7385 - val_loss: 0.5177 - val_accuracy: 0.7275\n",
      "Epoch 119/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4891 - accuracy: 0.7291 - val_loss: 0.5834 - val_accuracy: 0.6676\n",
      "Epoch 120/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4849 - accuracy: 0.7334 - val_loss: 0.5237 - val_accuracy: 0.7230\n",
      "Epoch 121/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4831 - accuracy: 0.7384 - val_loss: 0.5362 - val_accuracy: 0.7054\n",
      "Epoch 122/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4808 - accuracy: 0.7411 - val_loss: 0.4893 - val_accuracy: 0.7432\n",
      "Epoch 123/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4701 - accuracy: 0.7418 - val_loss: 0.4929 - val_accuracy: 0.7331\n",
      "Epoch 124/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4745 - accuracy: 0.7463 - val_loss: 0.5535 - val_accuracy: 0.6940\n",
      "Epoch 125/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4694 - accuracy: 0.7478 - val_loss: 0.5229 - val_accuracy: 0.7204\n",
      "Epoch 126/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4728 - accuracy: 0.7440 - val_loss: 0.5132 - val_accuracy: 0.7240\n",
      "Epoch 127/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4620 - accuracy: 0.7543 - val_loss: 0.5271 - val_accuracy: 0.7077\n",
      "Epoch 128/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4749 - accuracy: 0.7439 - val_loss: 0.5030 - val_accuracy: 0.7148\n",
      "Epoch 129/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4679 - accuracy: 0.7502 - val_loss: 0.5321 - val_accuracy: 0.7012\n",
      "Epoch 130/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4654 - accuracy: 0.7490 - val_loss: 0.5620 - val_accuracy: 0.6995\n",
      "Epoch 131/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4606 - accuracy: 0.7542 - val_loss: 0.4887 - val_accuracy: 0.7347\n",
      "Epoch 132/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4792 - accuracy: 0.7469 - val_loss: 0.5156 - val_accuracy: 0.7367\n",
      "Epoch 133/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4773 - accuracy: 0.7457 - val_loss: 0.5103 - val_accuracy: 0.7227\n",
      "Epoch 134/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4595 - accuracy: 0.7594 - val_loss: 0.5186 - val_accuracy: 0.6963\n",
      "Epoch 135/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4639 - accuracy: 0.7526 - val_loss: 0.4669 - val_accuracy: 0.7633: 3s - loss: 0.4683 - accuracy: 0.74 - ETA: 2s - loss: 0.4675 - accuracy: 0.75 - - ETA: 1s - loss: 0.4654 - ac - ETA: 0s - loss: 0.4\n",
      "Epoch 136/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4613 - accuracy: 0.7547 - val_loss: 0.5444 - val_accuracy: 0.6940\n",
      "Epoch 137/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4641 - accuracy: 0.7531 - val_loss: 0.5378 - val_accuracy: 0.6839\n",
      "Epoch 138/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4578 - accuracy: 0.7601 - val_loss: 0.5179 - val_accuracy: 0.7197\n",
      "Epoch 139/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4524 - accuracy: 0.7627 - val_loss: 0.5185 - val_accuracy: 0.7090\n",
      "Epoch 140/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4451 - accuracy: 0.7671 - val_loss: 0.4873 - val_accuracy: 0.7337\n",
      "Epoch 141/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4620 - accuracy: 0.7571 - val_loss: 0.5123 - val_accuracy: 0.7236\n",
      "Epoch 142/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4538 - accuracy: 0.7600 - val_loss: 0.5360 - val_accuracy: 0.6953539 - accuracy: 0.75\n",
      "Epoch 143/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4518 - accuracy: 0.7603 - val_loss: 0.5203 - val_accuracy: 0.7178\n",
      "Epoch 144/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4474 - accuracy: 0.7637 - val_loss: 0.5132 - val_accuracy: 0.7214oss: 0.4476 - accuracy: \n",
      "Epoch 145/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4451 - accuracy: 0.7694 - val_loss: 0.4891 - val_accuracy: 0.7259\n",
      "Epoch 146/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4555 - accuracy: 0.7586 - val_loss: 0.5182 - val_accuracy: 0.6820\n",
      "Epoch 147/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4555 - accuracy: 0.7623 - val_loss: 0.5054 - val_accuracy: 0.7305\n",
      "Epoch 148/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4452 - accuracy: 0.7698 - val_loss: 0.5253 - val_accuracy: 0.7028\n",
      "Epoch 149/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4481 - accuracy: 0.7655 - val_loss: 0.5007 - val_accuracy: 0.7292\n",
      "Epoch 150/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4458 - accuracy: 0.7688 - val_loss: 0.5507 - val_accuracy: 0.7168\n",
      "Epoch 151/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4375 - accuracy: 0.7716 - val_loss: 0.5201 - val_accuracy: 0.7145\n",
      "Epoch 152/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4466 - accuracy: 0.7682 - val_loss: 0.5824 - val_accuracy: 0.6745\n",
      "Epoch 153/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4359 - accuracy: 0.7757 - val_loss: 0.5029 - val_accuracy: 0.7393\n",
      "Epoch 154/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4291 - accuracy: 0.7806 - val_loss: 0.5222 - val_accuracy: 0.7005\n",
      "Epoch 155/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4330 - accuracy: 0.7779 - val_loss: 0.4828 - val_accuracy: 0.7624\n",
      "Epoch 156/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4306 - accuracy: 0.7803 - val_loss: 0.5418 - val_accuracy: 0.6839\n",
      "Epoch 157/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4263 - accuracy: 0.7823 - val_loss: 0.4802 - val_accuracy: 0.7559\n",
      "Epoch 158/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4369 - accuracy: 0.7754 - val_loss: 0.5637 - val_accuracy: 0.6836\n",
      "Epoch 159/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4351 - accuracy: 0.7743 - val_loss: 0.4961 - val_accuracy: 0.7331\n",
      "Epoch 160/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4247 - accuracy: 0.7820 - val_loss: 0.4773 - val_accuracy: 0.7507\n",
      "Epoch 161/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4534 - accuracy: 0.7628 - val_loss: 0.4982 - val_accuracy: 0.7337\n",
      "Epoch 162/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4327 - accuracy: 0.7776 - val_loss: 0.5698 - val_accuracy: 0.7070\n",
      "Epoch 163/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4280 - accuracy: 0.7810 - val_loss: 0.4611 - val_accuracy: 0.7581\n",
      "Epoch 164/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4305 - accuracy: 0.7788 - val_loss: 0.5108 - val_accuracy: 0.7031\n",
      "Epoch 165/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4310 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7227\n",
      "Epoch 166/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4253 - accuracy: 0.7814 - val_loss: 0.4784 - val_accuracy: 0.7412\n",
      "Epoch 167/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4177 - accuracy: 0.7852 - val_loss: 0.5017 - val_accuracy: 0.7373\n",
      "Epoch 168/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4129 - accuracy: 0.7885 - val_loss: 0.4701 - val_accuracy: 0.7572\n",
      "Epoch 169/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4144 - accuracy: 0.7921 - val_loss: 0.5188 - val_accuracy: 0.7311\n",
      "Epoch 170/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4092 - accuracy: 0.7946 - val_loss: 0.5014 - val_accuracy: 0.7214\n",
      "Epoch 171/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4150 - accuracy: 0.7918 - val_loss: 0.5132 - val_accuracy: 0.7210\n",
      "Epoch 172/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4197 - accuracy: 0.7855 - val_loss: 0.5048 - val_accuracy: 0.7197\n",
      "Epoch 173/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4134 - accuracy: 0.7930 - val_loss: 0.4839 - val_accuracy: 0.7367\n",
      "Epoch 174/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4045 - accuracy: 0.7943 - val_loss: 0.4968 - val_accuracy: 0.7575\n",
      "Epoch 175/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4186 - accuracy: 0.7839 - val_loss: 0.5299 - val_accuracy: 0.7028\n",
      "Epoch 176/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4044 - accuracy: 0.7973 - val_loss: 0.4497 - val_accuracy: 0.7663\n",
      "Epoch 177/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4105 - accuracy: 0.7926 - val_loss: 0.5430 - val_accuracy: 0.7087\n",
      "Epoch 178/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4006 - accuracy: 0.7999 - val_loss: 0.5131 - val_accuracy: 0.7507\n",
      "Epoch 179/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3919 - accuracy: 0.8035 - val_loss: 0.4640 - val_accuracy: 0.7842\n",
      "Epoch 180/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4005 - accuracy: 0.8001 - val_loss: 0.4914 - val_accuracy: 0.7516\n",
      "Epoch 181/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4131 - accuracy: 0.7948 - val_loss: 0.4956 - val_accuracy: 0.7415\n",
      "Epoch 182/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4150 - accuracy: 0.7914 - val_loss: 0.4743 - val_accuracy: 0.7572\n",
      "Epoch 183/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4144 - accuracy: 0.7916 - val_loss: 0.5957 - val_accuracy: 0.6768\n",
      "Epoch 184/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3961 - accuracy: 0.8026 - val_loss: 0.4990 - val_accuracy: 0.7448\n",
      "Epoch 185/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3838 - accuracy: 0.8111 - val_loss: 0.5045 - val_accuracy: 0.7340\n",
      "Epoch 186/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3921 - accuracy: 0.8027 - val_loss: 0.4921 - val_accuracy: 0.7275\n",
      "Epoch 187/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3955 - accuracy: 0.8025 - val_loss: 0.5191 - val_accuracy: 0.7197\n",
      "Epoch 188/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3837 - accuracy: 0.8076 - val_loss: 0.5721 - val_accuracy: 0.7051\n",
      "Epoch 189/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3883 - accuracy: 0.8050 - val_loss: 0.5104 - val_accuracy: 0.7288\n",
      "Epoch 190/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3801 - accuracy: 0.8090 - val_loss: 0.5338 - val_accuracy: 0.7122\n",
      "Epoch 191/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3851 - accuracy: 0.8103 - val_loss: 0.4615 - val_accuracy: 0.7546\n",
      "Epoch 192/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3800 - accuracy: 0.8136 - val_loss: 0.4806 - val_accuracy: 0.7679\n",
      "Epoch 193/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3793 - accuracy: 0.8130 - val_loss: 0.5244 - val_accuracy: 0.7067\n",
      "Epoch 194/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3904 - accuracy: 0.8077 - val_loss: 0.5214 - val_accuracy: 0.7373\n",
      "Epoch 195/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3890 - accuracy: 0.8096 - val_loss: 0.4929 - val_accuracy: 0.7490\n",
      "Epoch 196/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3793 - accuracy: 0.8110 - val_loss: 0.4590 - val_accuracy: 0.7637\n",
      "Epoch 197/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3820 - accuracy: 0.8099 - val_loss: 0.4855 - val_accuracy: 0.7578\n",
      "Epoch 198/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3834 - accuracy: 0.8100 - val_loss: 0.4881 - val_accuracy: 0.7454\n",
      "Epoch 199/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3861 - accuracy: 0.8076 - val_loss: 0.5266 - val_accuracy: 0.7373\n",
      "Epoch 200/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3776 - accuracy: 0.8132 - val_loss: 0.5246 - val_accuracy: 0.7139\n",
      "Epoch 201/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3687 - accuracy: 0.8178 - val_loss: 0.5455 - val_accuracy: 0.7454\n",
      "Epoch 202/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3735 - accuracy: 0.8153 - val_loss: 0.5211 - val_accuracy: 0.7165\n",
      "Epoch 203/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3678 - accuracy: 0.8187 - val_loss: 0.4826 - val_accuracy: 0.7699\n",
      "Epoch 204/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3670 - accuracy: 0.8197 - val_loss: 0.4947 - val_accuracy: 0.7363\n",
      "Epoch 205/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3572 - accuracy: 0.8279 - val_loss: 0.5532 - val_accuracy: 0.7096\n",
      "Epoch 206/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3693 - accuracy: 0.8213 - val_loss: 0.5096 - val_accuracy: 0.7526\n",
      "Epoch 207/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3648 - accuracy: 0.8230 - val_loss: 0.5359 - val_accuracy: 0.7230\n",
      "Epoch 208/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3551 - accuracy: 0.8300 - val_loss: 0.5728 - val_accuracy: 0.7070\n",
      "Epoch 209/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3662 - accuracy: 0.8217 - val_loss: 0.5292 - val_accuracy: 0.7340\n",
      "Epoch 210/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3756 - accuracy: 0.8147 - val_loss: 0.4953 - val_accuracy: 0.7135\n",
      "Epoch 211/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3613 - accuracy: 0.8263 - val_loss: 0.4909 - val_accuracy: 0.7536\n",
      "Epoch 212/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3521 - accuracy: 0.8301 - val_loss: 0.5397 - val_accuracy: 0.7165\n",
      "Epoch 213/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3541 - accuracy: 0.8253 - val_loss: 0.4879 - val_accuracy: 0.7301\n",
      "Epoch 214/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3493 - accuracy: 0.8312 - val_loss: 0.5917 - val_accuracy: 0.7461\n",
      "Epoch 215/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3514 - accuracy: 0.8316 - val_loss: 0.5894 - val_accuracy: 0.7191\n",
      "Epoch 216/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3510 - accuracy: 0.8290 - val_loss: 0.4668 - val_accuracy: 0.7702\n",
      "Epoch 217/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3526 - accuracy: 0.8270 - val_loss: 0.5718 - val_accuracy: 0.7051\n",
      "Epoch 218/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3502 - accuracy: 0.8289 - val_loss: 0.4870 - val_accuracy: 0.7516\n",
      "Epoch 219/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3486 - accuracy: 0.8345 - val_loss: 0.4986 - val_accuracy: 0.7790\n",
      "Epoch 220/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3511 - accuracy: 0.8334 - val_loss: 0.5017 - val_accuracy: 0.7497\n",
      "Epoch 221/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.3499 - accuracy: 0.8318 - val_loss: 0.4977 - val_accuracy: 0.7438\n",
      "Epoch 222/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.3456 - accuracy: 0.8331 - val_loss: 0.5026 - val_accuracy: 0.7536\n",
      "Epoch 223/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.3387 - accuracy: 0.8401 - val_loss: 0.6229 - val_accuracy: 0.6686os\n",
      "Epoch 224/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3437 - accuracy: 0.8345 - val_loss: 0.5127 - val_accuracy: 0.7373s: 0.3439 - ac\n",
      "Epoch 225/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3454 - accuracy: 0.8354 - val_loss: 0.5404 - val_accuracy: 0.7243\n",
      "Epoch 226/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3453 - accuracy: 0.8325 - val_loss: 0.4892 - val_accuracy: 0.7562\n",
      "Epoch 227/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3424 - accuracy: 0.8361 - val_loss: 0.6547 - val_accuracy: 0.6628\n",
      "Epoch 228/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3461 - accuracy: 0.8330 - val_loss: 0.5396 - val_accuracy: 0.7402\n",
      "Epoch 229/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3366 - accuracy: 0.8400 - val_loss: 0.5165 - val_accuracy: 0.7630\n",
      "Epoch 230/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3349 - accuracy: 0.8397 - val_loss: 0.5967 - val_accuracy: 0.6976\n",
      "Epoch 231/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3442 - accuracy: 0.8348 - val_loss: 0.5912 - val_accuracy: 0.6937\n",
      "Epoch 232/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3336 - accuracy: 0.8414 - val_loss: 0.5265 - val_accuracy: 0.7288\n",
      "Epoch 233/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3360 - accuracy: 0.8402 - val_loss: 0.5215 - val_accuracy: 0.7334\n",
      "Epoch 234/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3324 - accuracy: 0.8419 - val_loss: 0.5039 - val_accuracy: 0.7474\n",
      "Epoch 235/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3187 - accuracy: 0.8459 - val_loss: 0.5260 - val_accuracy: 0.7301\n",
      "Epoch 236/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3213 - accuracy: 0.8451 - val_loss: 0.5872 - val_accuracy: 0.6882\n",
      "Epoch 237/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3206 - accuracy: 0.8494 - val_loss: 0.5426 - val_accuracy: 0.7474\n",
      "Epoch 238/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3312 - accuracy: 0.8422 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 239/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3223 - accuracy: 0.8454 - val_loss: 0.5608 - val_accuracy: 0.7201\n",
      "Epoch 240/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3253 - accuracy: 0.8465 - val_loss: 0.5744 - val_accuracy: 0.7308\n",
      "Epoch 241/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3251 - accuracy: 0.8472 - val_loss: 0.4833 - val_accuracy: 0.7653\n",
      "Epoch 242/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3244 - accuracy: 0.8474 - val_loss: 0.4929 - val_accuracy: 0.7734\n",
      "Epoch 243/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3131 - accuracy: 0.8528 - val_loss: 0.5124 - val_accuracy: 0.7542\n",
      "Epoch 244/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3144 - accuracy: 0.8538 - val_loss: 0.5690 - val_accuracy: 0.7360\n",
      "Epoch 245/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3083 - accuracy: 0.8554 - val_loss: 0.5287 - val_accuracy: 0.7301\n",
      "Epoch 246/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3158 - accuracy: 0.8519 - val_loss: 0.6820 - val_accuracy: 0.6862\n",
      "Epoch 247/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3091 - accuracy: 0.8535 - val_loss: 0.5982 - val_accuracy: 0.7214\n",
      "Epoch 248/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3103 - accuracy: 0.8542 - val_loss: 0.6162 - val_accuracy: 0.7048\n",
      "Epoch 249/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3215 - accuracy: 0.8482 - val_loss: 0.5569 - val_accuracy: 0.7292\n",
      "Epoch 250/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3060 - accuracy: 0.8552 - val_loss: 0.5734 - val_accuracy: 0.7292\n",
      "Epoch 251/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3117 - accuracy: 0.8522 - val_loss: 0.5792 - val_accuracy: 0.7327\n",
      "Epoch 252/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3044 - accuracy: 0.8564 - val_loss: 0.5202 - val_accuracy: 0.7887\n",
      "Epoch 253/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3090 - accuracy: 0.8557 - val_loss: 0.6063 - val_accuracy: 0.7012\n",
      "Epoch 254/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3018 - accuracy: 0.8584 - val_loss: 0.5833 - val_accuracy: 0.7399\n",
      "Epoch 255/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2984 - accuracy: 0.8606 - val_loss: 0.5254 - val_accuracy: 0.7376\n",
      "Epoch 256/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2953 - accuracy: 0.8652 - val_loss: 0.7677 - val_accuracy: 0.6875\n",
      "Epoch 257/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3154 - accuracy: 0.8527 - val_loss: 0.6194 - val_accuracy: 0.7057\n",
      "Epoch 258/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2943 - accuracy: 0.8634 - val_loss: 0.6429 - val_accuracy: 0.6950\n",
      "Epoch 259/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2949 - accuracy: 0.8639 - val_loss: 0.5093 - val_accuracy: 0.7660\n",
      "Epoch 260/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2958 - accuracy: 0.8623 - val_loss: 0.5773 - val_accuracy: 0.7246\n",
      "Epoch 261/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3017 - accuracy: 0.8614 - val_loss: 0.6399 - val_accuracy: 0.7327\n",
      "Epoch 262/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2916 - accuracy: 0.8645 - val_loss: 0.5206 - val_accuracy: 0.7676\n",
      "Epoch 263/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2880 - accuracy: 0.8670 - val_loss: 0.5924 - val_accuracy: 0.7142\n",
      "Epoch 264/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2901 - accuracy: 0.8668 - val_loss: 0.5546 - val_accuracy: 0.7633\n",
      "Epoch 265/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2831 - accuracy: 0.8705 - val_loss: 0.6242 - val_accuracy: 0.7181\n",
      "Epoch 266/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2898 - accuracy: 0.8650 - val_loss: 0.5015 - val_accuracy: 0.7871\n",
      "Epoch 267/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2868 - accuracy: 0.8679 - val_loss: 0.5659 - val_accuracy: 0.7630\n",
      "Epoch 268/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2811 - accuracy: 0.8715 - val_loss: 0.6616 - val_accuracy: 0.68720s - loss: 0\n",
      "Epoch 269/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2869 - accuracy: 0.8676 - val_loss: 0.6510 - val_accuracy: 0.7282\n",
      "Epoch 270/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2837 - accuracy: 0.8731 - val_loss: 0.5495 - val_accuracy: 0.7816\n",
      "Epoch 271/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2800 - accuracy: 0.8703 - val_loss: 0.6473 - val_accuracy: 0.7106\n",
      "Epoch 272/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2889 - accuracy: 0.8685 - val_loss: 0.5696 - val_accuracy: 0.7396\n",
      "Epoch 273/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2739 - accuracy: 0.8743 - val_loss: 0.5562 - val_accuracy: 0.7454\n",
      "Epoch 274/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2802 - accuracy: 0.8711 - val_loss: 0.6451 - val_accuracy: 0.7194\n",
      "Epoch 275/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2861 - accuracy: 0.8669 - val_loss: 0.5836 - val_accuracy: 0.7682\n",
      "Epoch 276/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2804 - accuracy: 0.8724 - val_loss: 0.5818 - val_accuracy: 0.7350\n",
      "Epoch 277/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2793 - accuracy: 0.8705 - val_loss: 0.6184 - val_accuracy: 0.7301\n",
      "Epoch 278/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2800 - accuracy: 0.8727 - val_loss: 0.6966 - val_accuracy: 0.7223\n",
      "Epoch 279/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2861 - accuracy: 0.8660 - val_loss: 0.7093 - val_accuracy: 0.6960\n",
      "Epoch 280/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2883 - accuracy: 0.8639 - val_loss: 0.5755 - val_accuracy: 0.7500\n",
      "Epoch 281/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2776 - accuracy: 0.8754 - val_loss: 0.6407 - val_accuracy: 0.7207\n",
      "Epoch 282/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2684 - accuracy: 0.8774 - val_loss: 0.5509 - val_accuracy: 0.7510\n",
      "Epoch 283/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2728 - accuracy: 0.8754 - val_loss: 0.6525 - val_accuracy: 0.7093\n",
      "Epoch 284/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2757 - accuracy: 0.8736 - val_loss: 0.5459 - val_accuracy: 0.7523\n",
      "Epoch 285/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2702 - accuracy: 0.8771 - val_loss: 0.5211 - val_accuracy: 0.7692\n",
      "Epoch 286/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2722 - accuracy: 0.8753 - val_loss: 0.6920 - val_accuracy: 0.7100\n",
      "Epoch 287/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2750 - accuracy: 0.8764 - val_loss: 0.6015 - val_accuracy: 0.7484\n",
      "Epoch 288/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2715 - accuracy: 0.8765 - val_loss: 0.5888 - val_accuracy: 0.7282\n",
      "Epoch 289/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2656 - accuracy: 0.8790 - val_loss: 0.6283 - val_accuracy: 0.7184\n",
      "Epoch 290/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2669 - accuracy: 0.8803 - val_loss: 0.5737 - val_accuracy: 0.7477\n",
      "Epoch 291/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2630 - accuracy: 0.8795 - val_loss: 0.5339 - val_accuracy: 0.7656\n",
      "Epoch 292/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2665 - accuracy: 0.8780 - val_loss: 0.6701 - val_accuracy: 0.7503\n",
      "Epoch 293/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2680 - accuracy: 0.8764 - val_loss: 0.8145 - val_accuracy: 0.6680\n",
      "Epoch 294/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2627 - accuracy: 0.8816 - val_loss: 0.5737 - val_accuracy: 0.7350\n",
      "Epoch 295/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2611 - accuracy: 0.8828 - val_loss: 0.5742 - val_accuracy: 0.7493\n",
      "Epoch 296/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2562 - accuracy: 0.8837 - val_loss: 0.5217 - val_accuracy: 0.7848\n",
      "Epoch 297/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2571 - accuracy: 0.8834 - val_loss: 0.5581 - val_accuracy: 0.7399\n",
      "Epoch 298/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2566 - accuracy: 0.8868 - val_loss: 0.6299 - val_accuracy: 0.7445\n",
      "Epoch 299/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2575 - accuracy: 0.8827 - val_loss: 0.5841 - val_accuracy: 0.7487\n",
      "Epoch 300/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2618 - accuracy: 0.8810 - val_loss: 0.6020 - val_accuracy: 0.7340\n",
      "Epoch 301/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2468 - accuracy: 0.8894 - val_loss: 0.6547 - val_accuracy: 0.7360\n",
      "Epoch 302/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2552 - accuracy: 0.8854 - val_loss: 0.5710 - val_accuracy: 0.7601\n",
      "Epoch 303/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2536 - accuracy: 0.8872 - val_loss: 0.6739 - val_accuracy: 0.7119\n",
      "Epoch 304/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2516 - accuracy: 0.8877 - val_loss: 0.7156 - val_accuracy: 0.7207\n",
      "Epoch 305/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2553 - accuracy: 0.8838 - val_loss: 0.6308 - val_accuracy: 0.7357\n",
      "Epoch 306/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2506 - accuracy: 0.8886 - val_loss: 0.6788 - val_accuracy: 0.7181\n",
      "Epoch 307/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2545 - accuracy: 0.8868 - val_loss: 0.5456 - val_accuracy: 0.7760\n",
      "Epoch 308/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2484 - accuracy: 0.8877 - val_loss: 0.6786 - val_accuracy: 0.7282\n",
      "Epoch 309/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2512 - accuracy: 0.8879 - val_loss: 0.5706 - val_accuracy: 0.7611\n",
      "Epoch 310/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2434 - accuracy: 0.8917 - val_loss: 0.5767 - val_accuracy: 0.7591\n",
      "Epoch 311/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2452 - accuracy: 0.8900 - val_loss: 0.5685 - val_accuracy: 0.7448- accura\n",
      "Epoch 312/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2490 - accuracy: 0.8879 - val_loss: 0.5669 - val_accuracy: 0.7627\n",
      "Epoch 313/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2402 - accuracy: 0.8926 - val_loss: 0.6219 - val_accuracy: 0.7428\n",
      "Epoch 314/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2482 - accuracy: 0.8907 - val_loss: 0.5900 - val_accuracy: 0.7754s: 0.2482 - accuracy: 0.89\n",
      "Epoch 315/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2416 - accuracy: 0.8908 - val_loss: 0.5754 - val_accuracy: 0.7513\n",
      "Epoch 316/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2591 - accuracy: 0.8823 - val_loss: 0.6351 - val_accuracy: 0.7493\n",
      "Epoch 317/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2449 - accuracy: 0.8911 - val_loss: 0.5658 - val_accuracy: 0.7591\n",
      "Epoch 318/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2449 - accuracy: 0.8898 - val_loss: 0.7015 - val_accuracy: 0.7181\n",
      "Epoch 319/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2329 - accuracy: 0.8958 - val_loss: 0.5581 - val_accuracy: 0.7630\n",
      "Epoch 320/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2367 - accuracy: 0.8944 - val_loss: 0.6293 - val_accuracy: 0.7568\n",
      "Epoch 321/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2426 - accuracy: 0.8916 - val_loss: 0.7912 - val_accuracy: 0.6999\n",
      "Epoch 322/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2342 - accuracy: 0.8983 - val_loss: 0.7563 - val_accuracy: 0.6947\n",
      "Epoch 323/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2379 - accuracy: 0.8951 - val_loss: 0.6047 - val_accuracy: 0.7744\n",
      "Epoch 324/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2379 - accuracy: 0.8922 - val_loss: 0.6838 - val_accuracy: 0.7448\n",
      "Epoch 325/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2357 - accuracy: 0.8957 - val_loss: 0.6971 - val_accuracy: 0.7295\n",
      "Epoch 326/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2427 - accuracy: 0.8932 - val_loss: 0.6443 - val_accuracy: 0.7445\n",
      "Epoch 327/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2410 - accuracy: 0.8931 - val_loss: 0.6980 - val_accuracy: 0.7148\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00327: early stopping\n",
      "      1/Unknown - 0s 117ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121/3121 [==============================] - 14s 5ms/step\n",
      "347/347 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|                              | 6/10 [7:54:54<5:25:45, 4886.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6931 - accuracy: 0.5061 - val_loss: 0.6927 - val_accuracy: 0.5052\n",
      "Epoch 2/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6903 - accuracy: 0.5350 - val_loss: 0.6883 - val_accuracy: 0.5277\n",
      "Epoch 3/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6832 - accuracy: 0.5566 - val_loss: 0.6829 - val_accuracy: 0.5221\n",
      "Epoch 4/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6729 - accuracy: 0.5657 - val_loss: 0.6856 - val_accuracy: 0.5443\n",
      "Epoch 5/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6683 - accuracy: 0.5692 - val_loss: 0.6643 - val_accuracy: 0.5410\n",
      "Epoch 6/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6653 - accuracy: 0.5725 - val_loss: 0.6706 - val_accuracy: 0.5465\n",
      "Epoch 7/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6611 - accuracy: 0.5819 - val_loss: 0.6555 - val_accuracy: 0.5814\n",
      "Epoch 8/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6609 - accuracy: 0.5842 - val_loss: 0.6568 - val_accuracy: 0.5986\n",
      "Epoch 9/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6579 - accuracy: 0.5875 - val_loss: 0.6557 - val_accuracy: 0.5557\n",
      "Epoch 10/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6561 - accuracy: 0.5937 - val_loss: 0.6662 - val_accuracy: 0.5700\n",
      "Epoch 11/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6512 - accuracy: 0.5935 - val_loss: 0.6473 - val_accuracy: 0.5931\n",
      "Epoch 12/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6487 - accuracy: 0.6017 - val_loss: 0.6593 - val_accuracy: 0.592148\n",
      "Epoch 13/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6463 - accuracy: 0.6048 - val_loss: 0.6539 - val_accuracy: 0.5889\n",
      "Epoch 14/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6482 - accuracy: 0.5996 - val_loss: 0.6637 - val_accuracy: 0.5700\n",
      "Epoch 15/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6454 - accuracy: 0.6054 - val_loss: 0.6497 - val_accuracy: 0.5931\n",
      "Epoch 16/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6438 - accuracy: 0.6064 - val_loss: 0.6399 - val_accuracy: 0.6110\n",
      "Epoch 17/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6419 - accuracy: 0.6035 - val_loss: 0.6553 - val_accuracy: 0.5765\n",
      "Epoch 18/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6426 - accuracy: 0.6081 - val_loss: 0.6526 - val_accuracy: 0.5719\n",
      "Epoch 19/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6400 - accuracy: 0.6139 - val_loss: 0.6620 - val_accuracy: 0.5827\n",
      "Epoch 20/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6402 - accuracy: 0.6137 - val_loss: 0.6245 - val_accuracy: 0.6191 0s - loss: 0.6402 - accuracy: 0. - ETA: 0s - loss: 0.6403 - accuracy: \n",
      "Epoch 21/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6370 - accuracy: 0.6152 - val_loss: 0.6527 - val_accuracy: 0.5645\n",
      "Epoch 22/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6365 - accuracy: 0.6192 - val_loss: 0.6454 - val_accuracy: 0.5612\n",
      "Epoch 23/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6337 - accuracy: 0.6242 - val_loss: 0.6209 - val_accuracy: 0.6195\n",
      "Epoch 24/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6353 - accuracy: 0.6177 - val_loss: 0.6357 - val_accuracy: 0.5658\n",
      "Epoch 25/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6297 - accuracy: 0.6229 - val_loss: 0.6397 - val_accuracy: 0.6289\n",
      "Epoch 26/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6310 - accuracy: 0.6230 - val_loss: 0.6449 - val_accuracy: 0.5781\n",
      "Epoch 27/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6279 - accuracy: 0.6231 - val_loss: 0.6212 - val_accuracy: 0.6426\n",
      "Epoch 28/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6255 - accuracy: 0.6275 - val_loss: 0.6257 - val_accuracy: 0.6276\n",
      "Epoch 29/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6257 - accuracy: 0.6304 - val_loss: 0.6189 - val_accuracy: 0.6201\n",
      "Epoch 30/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6236 - accuracy: 0.6325 - val_loss: 0.6649 - val_accuracy: 0.5521\n",
      "Epoch 31/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6231 - accuracy: 0.6282 - val_loss: 0.6108 - val_accuracy: 0.6452\n",
      "Epoch 32/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6187 - accuracy: 0.6332 - val_loss: 0.6100 - val_accuracy: 0.6631\n",
      "Epoch 33/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6166 - accuracy: 0.6357 - val_loss: 0.6288 - val_accuracy: 0.6136\n",
      "Epoch 34/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6167 - accuracy: 0.6373 - val_loss: 0.6129 - val_accuracy: 0.6331\n",
      "Epoch 35/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6160 - accuracy: 0.6388 - val_loss: 0.6045 - val_accuracy: 0.6719\n",
      "Epoch 36/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6112 - accuracy: 0.6371 - val_loss: 0.6053 - val_accuracy: 0.6432\n",
      "Epoch 37/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6114 - accuracy: 0.6398 - val_loss: 0.6019 - val_accuracy: 0.6719\n",
      "Epoch 38/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6045 - accuracy: 0.6473 - val_loss: 0.6107 - val_accuracy: 0.6175\n",
      "Epoch 39/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6073 - accuracy: 0.6439 - val_loss: 0.6014 - val_accuracy: 0.6426\n",
      "Epoch 40/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6017 - accuracy: 0.6459 - val_loss: 0.6196 - val_accuracy: 0.6019\n",
      "Epoch 41/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6030 - accuracy: 0.6478 - val_loss: 0.6145 - val_accuracy: 0.6361\n",
      "Epoch 42/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5969 - accuracy: 0.6536 - val_loss: 0.5792 - val_accuracy: 0.6624\n",
      "Epoch 43/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5955 - accuracy: 0.6523 - val_loss: 0.6356 - val_accuracy: 0.6387\n",
      "Epoch 44/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5931 - accuracy: 0.6558 - val_loss: 0.5991 - val_accuracy: 0.6598\n",
      "Epoch 45/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5853 - accuracy: 0.6628 - val_loss: 0.5819 - val_accuracy: 0.6458\n",
      "Epoch 46/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5899 - accuracy: 0.6579 - val_loss: 0.5809 - val_accuracy: 0.6803\n",
      "Epoch 47/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5865 - accuracy: 0.6616 - val_loss: 0.6151 - val_accuracy: 0.6436\n",
      "Epoch 48/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5847 - accuracy: 0.6590 - val_loss: 0.5952 - val_accuracy: 0.6624\n",
      "Epoch 49/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5822 - accuracy: 0.6632 - val_loss: 0.5833 - val_accuracy: 0.6533\n",
      "Epoch 50/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5743 - accuracy: 0.6683 - val_loss: 0.7902 - val_accuracy: 0.5378\n",
      "Epoch 51/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5748 - accuracy: 0.6678 - val_loss: 0.6056 - val_accuracy: 0.6436\n",
      "Epoch 52/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5777 - accuracy: 0.6672 - val_loss: 0.5576 - val_accuracy: 0.6979\n",
      "Epoch 53/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5723 - accuracy: 0.6689 - val_loss: 0.5754 - val_accuracy: 0.6663\n",
      "Epoch 54/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5743 - accuracy: 0.6667 - val_loss: 0.5956 - val_accuracy: 0.6455\n",
      "Epoch 55/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5692 - accuracy: 0.6761 - val_loss: 0.5588 - val_accuracy: 0.6914\n",
      "Epoch 56/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5671 - accuracy: 0.6779 - val_loss: 0.5632 - val_accuracy: 0.6901\n",
      "Epoch 57/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5657 - accuracy: 0.6772 - val_loss: 0.5807 - val_accuracy: 0.6315\n",
      "Epoch 58/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5611 - accuracy: 0.6758 - val_loss: 0.5528 - val_accuracy: 0.6953\n",
      "Epoch 59/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5641 - accuracy: 0.6785 - val_loss: 0.6154 - val_accuracy: 0.6084\n",
      "Epoch 60/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5610 - accuracy: 0.6786 - val_loss: 0.5493 - val_accuracy: 0.6930\n",
      "Epoch 61/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5583 - accuracy: 0.6797 - val_loss: 0.5661 - val_accuracy: 0.6768\n",
      "Epoch 62/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5565 - accuracy: 0.6800 - val_loss: 0.5609 - val_accuracy: 0.6702584 -  - E - ETA: 0s - loss:\n",
      "Epoch 63/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5595 - accuracy: 0.6769 - val_loss: 0.5968 - val_accuracy: 0.6445\n",
      "Epoch 64/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5562 - accuracy: 0.6837 - val_loss: 0.5575 - val_accuracy: 0.6702\n",
      "Epoch 65/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5517 - accuracy: 0.6854 - val_loss: 0.5522 - val_accuracy: 0.6852\n",
      "Epoch 66/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5535 - accuracy: 0.6829 - val_loss: 0.6196 - val_accuracy: 0.6243\n",
      "Epoch 67/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5503 - accuracy: 0.6852 - val_loss: 0.5532 - val_accuracy: 0.6875\n",
      "Epoch 68/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5524 - accuracy: 0.6818 - val_loss: 0.5421 - val_accuracy: 0.6908 - loss: 0.5516 - accu\n",
      "Epoch 69/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5412 - accuracy: 0.6938 - val_loss: 0.5385 - val_accuracy: 0.6800\n",
      "Epoch 70/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5503 - accuracy: 0.6806 - val_loss: 0.5486 - val_accuracy: 0.6966\n",
      "Epoch 71/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5481 - accuracy: 0.6864 - val_loss: 0.6104 - val_accuracy: 0.6755\n",
      "Epoch 72/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5398 - accuracy: 0.6950 - val_loss: 0.5553 - val_accuracy: 0.6859\n",
      "Epoch 73/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5424 - accuracy: 0.6901 - val_loss: 0.5458 - val_accuracy: 0.6950\n",
      "Epoch 74/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5365 - accuracy: 0.6984 - val_loss: 0.5397 - val_accuracy: 0.6895\n",
      "Epoch 75/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5398 - accuracy: 0.6938 - val_loss: 0.5508 - val_accuracy: 0.6823\n",
      "Epoch 76/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5347 - accuracy: 0.6970 - val_loss: 0.5369 - val_accuracy: 0.6842\n",
      "Epoch 77/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5347 - accuracy: 0.6949 - val_loss: 0.5425 - val_accuracy: 0.6904\n",
      "Epoch 78/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5361 - accuracy: 0.6957 - val_loss: 0.5364 - val_accuracy: 0.7015\n",
      "Epoch 79/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5333 - accuracy: 0.7021 - val_loss: 0.5728 - val_accuracy: 0.6800\n",
      "Epoch 80/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5379 - accuracy: 0.6960 - val_loss: 0.5548 - val_accuracy: 0.6953\n",
      "Epoch 81/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5259 - accuracy: 0.7002 - val_loss: 0.6307 - val_accuracy: 0.671210s - lo\n",
      "Epoch 82/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5319 - accuracy: 0.7007 - val_loss: 0.5998 - val_accuracy: 0.6237\n",
      "Epoch 83/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5248 - accuracy: 0.7054 - val_loss: 0.5562 - val_accuracy: 0.6855\n",
      "Epoch 84/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5253 - accuracy: 0.7057 - val_loss: 0.5211 - val_accuracy: 0.7119\n",
      "Epoch 85/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5347 - accuracy: 0.6986 - val_loss: 0.6086 - val_accuracy: 0.6576\n",
      "Epoch 86/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5304 - accuracy: 0.6996 - val_loss: 0.5639 - val_accuracy: 0.6927\n",
      "Epoch 87/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5302 - accuracy: 0.7034 - val_loss: 0.5248 - val_accuracy: 0.7057\n",
      "Epoch 88/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5172 - accuracy: 0.7099 - val_loss: 0.5251 - val_accuracy: 0.7165\n",
      "Epoch 89/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5197 - accuracy: 0.7107 - val_loss: 0.6192 - val_accuracy: 0.6637\n",
      "Epoch 90/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5198 - accuracy: 0.7066 - val_loss: 0.5249 - val_accuracy: 0.7184\n",
      "Epoch 91/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5185 - accuracy: 0.7095 - val_loss: 0.5586 - val_accuracy: 0.6947\n",
      "Epoch 92/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5181 - accuracy: 0.7122 - val_loss: 0.5586 - val_accuracy: 0.6921\n",
      "Epoch 93/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5169 - accuracy: 0.7145 - val_loss: 0.5442 - val_accuracy: 0.7174\n",
      "Epoch 94/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5110 - accuracy: 0.7165 - val_loss: 0.5839 - val_accuracy: 0.6852\n",
      "Epoch 95/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5163 - accuracy: 0.7148 - val_loss: 0.5366 - val_accuracy: 0.6999\n",
      "Epoch 96/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5199 - accuracy: 0.7058 - val_loss: 0.5787 - val_accuracy: 0.6992\n",
      "Epoch 97/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5120 - accuracy: 0.7113 - val_loss: 0.5011 - val_accuracy: 0.7288\n",
      "Epoch 98/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5175 - accuracy: 0.7109 - val_loss: 0.5690 - val_accuracy: 0.6758\n",
      "Epoch 99/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5049 - accuracy: 0.7214 - val_loss: 0.5132 - val_accuracy: 0.7139\n",
      "Epoch 100/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5043 - accuracy: 0.7211 - val_loss: 0.5232 - val_accuracy: 0.7067\n",
      "Epoch 101/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5050 - accuracy: 0.7217 - val_loss: 0.5332 - val_accuracy: 0.6901\n",
      "Epoch 102/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5012 - accuracy: 0.7226 - val_loss: 0.5061 - val_accuracy: 0.7158\n",
      "Epoch 103/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5071 - accuracy: 0.7221 - val_loss: 0.5210 - val_accuracy: 0.7087\n",
      "Epoch 104/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4985 - accuracy: 0.7247 - val_loss: 0.5234 - val_accuracy: 0.7223\n",
      "Epoch 105/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4987 - accuracy: 0.7255 - val_loss: 0.4892 - val_accuracy: 0.7288\n",
      "Epoch 106/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5007 - accuracy: 0.7264 - val_loss: 0.5453 - val_accuracy: 0.6966\n",
      "Epoch 107/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4963 - accuracy: 0.7264 - val_loss: 0.4838 - val_accuracy: 0.7389\n",
      "Epoch 108/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4885 - accuracy: 0.7307 - val_loss: 0.5249 - val_accuracy: 0.7122\n",
      "Epoch 109/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4941 - accuracy: 0.7305 - val_loss: 0.5146 - val_accuracy: 0.7340\n",
      "Epoch 110/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5018 - accuracy: 0.7265 - val_loss: 0.5213 - val_accuracy: 0.7178\n",
      "Epoch 111/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4907 - accuracy: 0.7318 - val_loss: 0.5061 - val_accuracy: 0.7041\n",
      "Epoch 112/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4906 - accuracy: 0.7329 - val_loss: 0.5328 - val_accuracy: 0.6956\n",
      "Epoch 113/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4885 - accuracy: 0.7383 - val_loss: 0.4908 - val_accuracy: 0.7438\n",
      "Epoch 114/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4926 - accuracy: 0.7337 - val_loss: 0.5306 - val_accuracy: 0.6865\n",
      "Epoch 115/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4912 - accuracy: 0.7333 - val_loss: 0.5279 - val_accuracy: 0.7184\n",
      "Epoch 116/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4825 - accuracy: 0.7331 - val_loss: 0.5105 - val_accuracy: 0.7334\n",
      "Epoch 117/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4781 - accuracy: 0.7401 - val_loss: 0.5319 - val_accuracy: 0.7275\n",
      "Epoch 118/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4786 - accuracy: 0.7386 - val_loss: 0.5189 - val_accuracy: 0.7214\n",
      "Epoch 119/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4811 - accuracy: 0.7389 - val_loss: 0.5158 - val_accuracy: 0.7041\n",
      "Epoch 120/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4854 - accuracy: 0.7360 - val_loss: 0.4950 - val_accuracy: 0.7298\n",
      "Epoch 121/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4736 - accuracy: 0.7394 - val_loss: 0.4644 - val_accuracy: 0.7565\n",
      "Epoch 122/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4721 - accuracy: 0.7438 - val_loss: 0.5676 - val_accuracy: 0.7051\n",
      "Epoch 123/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4777 - accuracy: 0.7411 - val_loss: 0.4893 - val_accuracy: 0.7230\n",
      "Epoch 124/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4749 - accuracy: 0.7413 - val_loss: 0.5192 - val_accuracy: 0.7246\n",
      "Epoch 125/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4742 - accuracy: 0.7446 - val_loss: 0.5082 - val_accuracy: 0.7240\n",
      "Epoch 126/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4674 - accuracy: 0.7445 - val_loss: 0.5016 - val_accuracy: 0.7191\n",
      "Epoch 127/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4639 - accuracy: 0.7518 - val_loss: 0.4929 - val_accuracy: 0.7425\n",
      "Epoch 128/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4622 - accuracy: 0.7524 - val_loss: 0.5322 - val_accuracy: 0.7119\n",
      "Epoch 129/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4639 - accuracy: 0.7492 - val_loss: 0.5945 - val_accuracy: 0.6777\n",
      "Epoch 130/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4654 - accuracy: 0.7481 - val_loss: 0.4936 - val_accuracy: 0.7275TA: 2s - l - ETA: 0s - loss: 0.4657 - accuracy: 0.\n",
      "Epoch 131/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4588 - accuracy: 0.7521 - val_loss: 0.5260 - val_accuracy: 0.7165\n",
      "Epoch 132/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4611 - accuracy: 0.7531 - val_loss: 0.6028 - val_accuracy: 0.7054\n",
      "Epoch 133/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4551 - accuracy: 0.7578 - val_loss: 0.5568 - val_accuracy: 0.7129\n",
      "Epoch 134/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4557 - accuracy: 0.7552 - val_loss: 0.5294 - val_accuracy: 0.7188\n",
      "Epoch 135/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4551 - accuracy: 0.7580 - val_loss: 0.5394 - val_accuracy: 0.7129\n",
      "Epoch 136/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4588 - accuracy: 0.7547 - val_loss: 0.5980 - val_accuracy: 0.6820A: 12s - loss: 0.4322 - acc - ETA: 7s - l - ETA: 0s - loss: 0.4588 - accuracy: 0.75 - ETA: 0s - loss: 0.4588 - accura - ETA: 0s - loss: 0.4586 - accuracy: 0.75\n",
      "Epoch 137/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4528 - accuracy: 0.7586 - val_loss: 0.5388 - val_accuracy: 0.7249\n",
      "Epoch 138/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4551 - accuracy: 0.7572 - val_loss: 0.5681 - val_accuracy: 0.7148\n",
      "Epoch 139/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4489 - accuracy: 0.7596 - val_loss: 0.5055 - val_accuracy: 0.7201\n",
      "Epoch 140/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4463 - accuracy: 0.7626 - val_loss: 0.4683 - val_accuracy: 0.7673s:\n",
      "Epoch 141/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4514 - accuracy: 0.7618 - val_loss: 0.5143 - val_accuracy: 0.7064\n",
      "Epoch 142/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4476 - accuracy: 0.7591 - val_loss: 0.5368 - val_accuracy: 0.7080\n",
      "Epoch 143/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4500 - accuracy: 0.7623 - val_loss: 0.5343 - val_accuracy: 0.6807 0.4514 - accu - ETA: 1s - loss: 0.4506 - accuracy: 0.76 - ETA: 1s - loss: 0.450 - ETA: 0s - loss: 0\n",
      "Epoch 144/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4447 - accuracy: 0.7627 - val_loss: 0.4926 - val_accuracy: 0.7513\n",
      "Epoch 145/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4430 - accuracy: 0.7672 - val_loss: 0.5111 - val_accuracy: 0.7243\n",
      "Epoch 146/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4361 - accuracy: 0.7692 - val_loss: 0.5205 - val_accuracy: 0.7135\n",
      "Epoch 147/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4415 - accuracy: 0.7664 - val_loss: 0.5443 - val_accuracy: 0.7142\n",
      "Epoch 148/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4380 - accuracy: 0.7705 - val_loss: 0.4770 - val_accuracy: 0.7604\n",
      "Epoch 149/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4354 - accuracy: 0.7710 - val_loss: 0.6393 - val_accuracy: 0.6683\n",
      "Epoch 150/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4345 - accuracy: 0.7688 - val_loss: 0.5240 - val_accuracy: 0.7168\n",
      "Epoch 151/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4310 - accuracy: 0.7737 - val_loss: 0.4936 - val_accuracy: 0.7555\n",
      "Epoch 152/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4241 - accuracy: 0.7766 - val_loss: 0.5781 - val_accuracy: 0.7188\n",
      "Epoch 153/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4272 - accuracy: 0.7708 - val_loss: 0.5375 - val_accuracy: 0.7214\n",
      "Epoch 154/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4259 - accuracy: 0.7740 - val_loss: 0.4851 - val_accuracy: 0.76075s - loss: 0.4222 - ac -\n",
      "Epoch 155/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4306 - accuracy: 0.7771 - val_loss: 0.6901 - val_accuracy: 0.6582\n",
      "Epoch 156/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4231 - accuracy: 0.7774 - val_loss: 0.4986 - val_accuracy: 0.7415 ETA: 9s - loss: 0.418 - ETA: 8s - loss: 0 - ETA: 6s - los - E - - ETA: 3s - loss: 0.4254 - \n",
      "Epoch 157/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4315 - accuracy: 0.7734 - val_loss: 0.4899 - val_accuracy: 0.7533\n",
      "Epoch 158/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4226 - accuracy: 0.7806 - val_loss: 0.5236 - val_accuracy: 0.7324A: 11s - loss: 0.42 - ETA: 8s - loss: 0.4264 - ac - ETA: 8s - loss: 0.4 - E - E\n",
      "Epoch 159/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4193 - accuracy: 0.7822 - val_loss: 0.5155 - val_accuracy: 0.7376\n",
      "Epoch 160/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4234 - accuracy: 0.7805 - val_loss: 0.5027 - val_accuracy: 0.7406\n",
      "Epoch 161/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4121 - accuracy: 0.7855 - val_loss: 0.4976 - val_accuracy: 0.7354\n",
      "Epoch 162/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4148 - accuracy: 0.7805 - val_loss: 0.4936 - val_accuracy: 0.7594\n",
      "Epoch 163/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4179 - accuracy: 0.7805 - val_loss: 0.5290 - val_accuracy: 0.7487\n",
      "Epoch 164/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4135 - accuracy: 0.7840 - val_loss: 0.5161 - val_accuracy: 0.7259\n",
      "Epoch 165/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4093 - accuracy: 0.7868 - val_loss: 0.5296 - val_accuracy: 0.7259\n",
      "Epoch 166/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4083 - accuracy: 0.7872 - val_loss: 0.4951 - val_accuracy: 0.75626s - ETA: 4s - loss: 0.4100 - ac - ETA: 4s - loss: 0.4093 - accura - ETA: 3s - loss: 0.4 - ETA: 1s - loss: 0.408 - ETA - ETA: 0s - loss: 0.4082 - accuracy: 0.78\n",
      "Epoch 167/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4088 - accuracy: 0.7849 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 168/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4143 - accuracy: 0.7855 - val_loss: 0.5103 - val_accuracy: 0.7461\n",
      "Epoch 169/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4062 - accuracy: 0.7921 - val_loss: 0.5121 - val_accuracy: 0.7370\n",
      "Epoch 170/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4000 - accuracy: 0.7925 - val_loss: 0.5619 - val_accuracy: 0.71710. - ETA: 0s - loss: 0.399\n",
      "Epoch 171/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4028 - accuracy: 0.7902 - val_loss: 0.5408 - val_accuracy: 0.71880s - loss: 0.4022 - accuracy: \n",
      "Epoch 172/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4026 - accuracy: 0.7914 - val_loss: 0.4988 - val_accuracy: 0.7461\n",
      "Epoch 173/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3953 - accuracy: 0.7971 - val_loss: 0.5613 - val_accuracy: 0.71420s - loss: 0.3965 -  - ETA: 0s - loss: 0.3959 - accura\n",
      "Epoch 174/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3962 - accuracy: 0.7959 - val_loss: 0.5616 - val_accuracy: 0.7454\n",
      "Epoch 175/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3994 - accuracy: 0.7939 - val_loss: 0.5620 - val_accuracy: 0.7057\n",
      "Epoch 176/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4005 - accuracy: 0.7956 - val_loss: 0.6148 - val_accuracy: 0.6986\n",
      "Epoch 177/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3936 - accuracy: 0.7995 - val_loss: 0.4940 - val_accuracy: 0.7383\n",
      "Epoch 178/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3940 - accuracy: 0.7947 - val_loss: 0.4809 - val_accuracy: 0.7601\n",
      "Epoch 179/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3944 - accuracy: 0.8003 - val_loss: 0.5293 - val_accuracy: 0.7194\n",
      "Epoch 180/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3868 - accuracy: 0.7987 - val_loss: 0.4965 - val_accuracy: 0.7354 loss: 0.3871 - ac\n",
      "Epoch 181/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3946 - accuracy: 0.7994 - val_loss: 0.5111 - val_accuracy: 0.7243\n",
      "Epoch 182/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3888 - accuracy: 0.8018 - val_loss: 0.6070 - val_accuracy: 0.7103\n",
      "Epoch 183/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3895 - accuracy: 0.8006 - val_loss: 0.5330 - val_accuracy: 0.7285\n",
      "Epoch 184/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3839 - accuracy: 0.8017 - val_loss: 0.5003 - val_accuracy: 0.74772s - loss: 0.4006 - ETA: 5s - - ETA: 4s - loss: 0.3819 - accuracy: 0. - ETA: 4s - loss: 0.3819 - accuracy: 0. - - ETA: 0s - loss: 0.3840 - accuracy: 0.80\n",
      "Epoch 185/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3863 - accuracy: 0.7987 - val_loss: 0.5558 - val_accuracy: 0.7168\n",
      "Epoch 186/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3775 - accuracy: 0.8083 - val_loss: 0.5571 - val_accuracy: 0.7282\n",
      "Epoch 187/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3842 - accuracy: 0.8022 - val_loss: 0.4724 - val_accuracy: 0.77341s - ETA: 0s - loss: 0.3840 - accura\n",
      "Epoch 188/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3779 - accuracy: 0.8043 - val_loss: 0.5128 - val_accuracy: 0.7503\n",
      "Epoch 189/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3736 - accuracy: 0.8088 - val_loss: 0.6408 - val_accuracy: 0.6758\n",
      "Epoch 190/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3803 - accuracy: 0.8057 - val_loss: 0.6559 - val_accuracy: 0.70965s - loss: - ETA: 2s - loss: 0.3832 - accura - ETA: 2s - loss: - ETA: 0s - loss: 0.3820 \n",
      "Epoch 191/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3748 - accuracy: 0.8065 - val_loss: 0.4940 - val_accuracy: 0.7585\n",
      "Epoch 192/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3821 - accuracy: 0.8027 - val_loss: 0.4995 - val_accuracy: 0.7386\n",
      "Epoch 193/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3775 - accuracy: 0.8052 - val_loss: 0.5133 - val_accuracy: 0.7624\n",
      "Epoch 194/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3781 - accuracy: 0.8056 - val_loss: 0.5576 - val_accuracy: 0.7262\n",
      "Epoch 195/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3721 - accuracy: 0.8102 - val_loss: 0.5111 - val_accuracy: 0.7555: 1s - l - ETA: 0s -\n",
      "Epoch 196/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3622 - accuracy: 0.8172 - val_loss: 0.6792 - val_accuracy: 0.6820\n",
      "Epoch 197/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3721 - accuracy: 0.8097 - val_loss: 0.5361 - val_accuracy: 0.7155\n",
      "Epoch 198/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3666 - accuracy: 0.8103 - val_loss: 0.5405 - val_accuracy: 0.7230\n",
      "Epoch 199/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3649 - accuracy: 0.8151 - val_loss: 0.5401 - val_accuracy: 0.71880.81 - ETA: 0s - loss: 0.3625 - accuracy: 0.81 - ETA: 0s - los\n",
      "Epoch 200/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3612 - accuracy: 0.8150 - val_loss: 0.5642 - val_accuracy: 0.7546\n",
      "Epoch 201/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3569 - accuracy: 0.8212 - val_loss: 0.5042 - val_accuracy: 0.7536 - ETA: 0s - loss: 0.3574 - accuracy\n",
      "Epoch 202/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3593 - accuracy: 0.8208 - val_loss: 0.5524 - val_accuracy: 0.7253 ETA: 2s - loss: 0.3583 - ac - ETA: 2s - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.3584 \n",
      "Epoch 203/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3583 - accuracy: 0.8230 - val_loss: 0.5447 - val_accuracy: 0.7230accura - ETA: 2s - l\n",
      "Epoch 204/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3558 - accuracy: 0.8230 - val_loss: 0.5014 - val_accuracy: 0.7640- ETA: 9s - loss: 0.3628 - accu - ETA\n",
      "Epoch 205/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3553 - accuracy: 0.8247 - val_loss: 0.5884 - val_accuracy: 0.73444 - accuracy: 0.82 - ETA: 5s - loss: 0 - ETA: 2s - loss: 0\n",
      "Epoch 206/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3513 - accuracy: 0.8261 - val_loss: 0.6231 - val_accuracy: 0.7021\n",
      "Epoch 207/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3503 - accuracy: 0.8274 - val_loss: 0.5644 - val_accuracy: 0.7243  - ETA: 9s - loss: 0.3486 - accuracy: 0.82 - ETA: 9s - l - ETA: 8s - loss: 0.3454 - accuracy:  - ETA: 8s - loss: 0.3454 -  - - ETA: 3s - l - ETA: 2s - loss: 0.3483 - accura - ETA: 2s - loss: 0.3480 - accuracy: 0.82 - E\n",
      "Epoch 208/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3489 - accuracy: 0.8267 - val_loss: 0.5054 - val_accuracy: 0.7536 0.3531 - ac - ETA: 3s - los - ETA: 2s - loss: 0.3510 - ac - ETA: 1s - loss: 0 - ETA: 1s - loss: 0.3489 - accu - ETA: 0s - loss: 0.3\n",
      "Epoch 209/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3619 - accuracy: 0.8233 - val_loss: 0.5005 - val_accuracy: 0.7546\n",
      "Epoch 210/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3519 - accuracy: 0.8248 - val_loss: 0.6096 - val_accuracy: 0.7057\n",
      "Epoch 211/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3329 - accuracy: 0.8368 - val_loss: 0.5237 - val_accuracy: 0.7510curacy: 0.83 - ETA: 3s - loss: 0.3333 - accura - ETA: 2s - loss: 0.3328 - accuracy\n",
      "Epoch 212/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3519 - accuracy: 0.8262 - val_loss: 0.5476 - val_accuracy: 0.7256\n",
      "Epoch 213/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3433 - accuracy: 0.8304 - val_loss: 0.6325 - val_accuracy: 0.6927\n",
      "Epoch 214/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3447 - accuracy: 0.8296 - val_loss: 0.5721 - val_accuracy: 0.7148\n",
      "Epoch 215/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3415 - accuracy: 0.8304 - val_loss: 0.5529 - val_accuracy: 0.7259s: 0.3440 - accuracy: 0. - ETA: 3s - loss: - E\n",
      "Epoch 216/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3420 - accuracy: 0.8306 - val_loss: 0.6258 - val_accuracy: 0.7269 - loss: 0.3421 - accuracy: 0.\n",
      "Epoch 217/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3333 - accuracy: 0.8382 - val_loss: 0.5831 - val_accuracy: 0.7451\n",
      "Epoch 218/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3372 - accuracy: 0.8365 - val_loss: 0.5771 - val_accuracy: 0.7148\n",
      "Epoch 219/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3318 - accuracy: 0.8373 - val_loss: 0.5477 - val_accuracy: 0.7233\n",
      "Epoch 220/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3330 - accuracy: 0.8369 - val_loss: 0.5343 - val_accuracy: 0.73500s - loss: 0.3327 - accuracy: 0.83\n",
      "Epoch 221/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3251 - accuracy: 0.8415 - val_loss: 0.5132 - val_accuracy: 0.7477\n",
      "Epoch 222/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3321 - accuracy: 0.8392 - val_loss: 0.6052 - val_accuracy: 0.7096\n",
      "Epoch 223/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3296 - accuracy: 0.8372 - val_loss: 0.5457 - val_accuracy: 0.7425 - loss: 0.330 - ETA: 0s - loss: 0.330\n",
      "Epoch 224/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3335 - accuracy: 0.8402 - val_loss: 0.6288 - val_accuracy: 0.7272\n",
      "Epoch 225/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3300 - accuracy: 0.8409 - val_loss: 0.8110 - val_accuracy: 0.6377\n",
      "Epoch 226/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3345 - accuracy: 0.8375 - val_loss: 0.6070 - val_accuracy: 0.7096: 2s - loss: 0.3350 - accu - ETA - ETA: 0s - los - ETA: 0s - loss: 0.3345 - accuracy: 0.\n",
      "Epoch 227/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3276 - accuracy: 0.8405 - val_loss: 0.6413 - val_accuracy: 0.7090-  - ETA: \n",
      "Epoch 228/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3174 - accuracy: 0.8444 - val_loss: 0.5316 - val_accuracy: 0.7523\n",
      "Epoch 229/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3188 - accuracy: 0.8450 - val_loss: 0.6071 - val_accuracy: 0.7161 loss: 0.3234 - accuracy: 0.84 - ETA: 7s - loss: 0.323 - ETA: 7s - loss: 0.3242 - accu - ETA: 4s - loss: 0.3186 -  - ETA:  - ETA: 1s - loss: 0.3203 - accuracy: 0.84 - ETA: 1s - l - ETA: 0s - loss: 0.3188 - accura\n",
      "Epoch 230/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3161 - accuracy: 0.8460 - val_loss: 0.5066 - val_accuracy: 0.7757\n",
      "Epoch 231/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3228 - accuracy: 0.8425 - val_loss: 0.5425 - val_accuracy: 0.7380\n",
      "Epoch 232/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3242 - accuracy: 0.8417 - val_loss: 0.5866 - val_accuracy: 0.7292 - loss: 0.3221  - ETA: 1s - loss: 0.3234 - accuracy: 0.84 - ETA: 0s - l - ETA: 0s - loss: 0.3244 - accuracy: 0.\n",
      "Epoch 233/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3160 - accuracy: 0.8459 - val_loss: 0.5231 - val_accuracy: 0.7516\n",
      "Epoch 234/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3149 - accuracy: 0.8457 - val_loss: 0.5747 - val_accuracy: 0.7308\n",
      "Epoch 235/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3163 - accuracy: 0.8461 - val_loss: 0.5135 - val_accuracy: 0.7451\n",
      "Epoch 236/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3115 - accuracy: 0.8469 - val_loss: 0.6155 - val_accuracy: 0.7161cy - ETA: 0s - loss: 0.312\n",
      "Epoch 237/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3056 - accuracy: 0.8504 - val_loss: 0.5643 - val_accuracy: 0.7272 - ETA: 0s - loss: 0.3\n",
      "Epoch 238/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3121 - accuracy: 0.8499 - val_loss: 0.5815 - val_accuracy: 0.7318\n",
      "Epoch 239/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3072 - accuracy: 0.8507 - val_loss: 0.5311 - val_accuracy: 0.7337s: 0.3073 - accuracy\n",
      "Epoch 240/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3063 - accuracy: 0.8531 - val_loss: 0.6617 - val_accuracy: 0.69211s - loss: 0.3073 - accu - ETA: 10s - loss: 0.3033 - accuracy - ETA: 10s - loss: 0.3040 - accuracy: 0.8 - ETA: 9s - loss: 0.3042 - accuracy: 0.8 - ETA: 9s - loss: 0.3047 - accura - ETA: 9s - loss: 0.3033 - accu - - ETA: 6s - loss: 0.3 - ETA: 0s - loss: 0.3\n",
      "Epoch 241/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2993 - accuracy: 0.8539 - val_loss: 0.5097 - val_accuracy: 0.7546\n",
      "Epoch 242/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3101 - accuracy: 0.8484 - val_loss: 0.5729 - val_accuracy: 0.7354\n",
      "Epoch 243/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3017 - accuracy: 0.8522 - val_loss: 0.5818 - val_accuracy: 0.7165\n",
      "Epoch 244/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3053 - accuracy: 0.8544 - val_loss: 0.5602 - val_accuracy: 0.7503loss: 0.2902 - accu - - ETA - ETA: 1s - loss: 0.3035 - accuracy - ETA: 0s - loss: 0.3041 - accuracy - ETA: 0s - loss: 0.304\n",
      "Epoch 245/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3022 - accuracy: 0.8531 - val_loss: 0.5698 - val_accuracy: 0.7275\n",
      "Epoch 246/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2995 - accuracy: 0.8565 - val_loss: 0.7004 - val_accuracy: 0.6637\n",
      "Epoch 247/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2987 - accuracy: 0.8556 - val_loss: 0.6181 - val_accuracy: 0.7070\n",
      "Epoch 248/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2969 - accuracy: 0.8567 - val_loss: 0.5582 - val_accuracy: 0.7380\n",
      "Epoch 249/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2946 - accuracy: 0.8576 - val_loss: 0.6717 - val_accuracy: 0.7018: 0.2898 - accuracy: - ETA:\n",
      "Epoch 250/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3005 - accuracy: 0.8556 - val_loss: 0.6198 - val_accuracy: 0.6914\n",
      "Epoch 251/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2899 - accuracy: 0.8609 - val_loss: 0.6587 - val_accuracy: 0.7044\n",
      "Epoch 252/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2931 - accuracy: 0.8583 - val_loss: 0.6076 - val_accuracy: 0.7279\n",
      "Epoch 253/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2975 - accuracy: 0.8572 - val_loss: 0.5675 - val_accuracy: 0.7227- accu\n",
      "Epoch 254/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2856 - accuracy: 0.8647 - val_loss: 0.6377 - val_accuracy: 0.7087\n",
      "Epoch 255/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2925 - accuracy: 0.8600 - val_loss: 0.6582 - val_accuracy: 0.6904\n",
      "Epoch 256/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2971 - accuracy: 0.8584 - val_loss: 0.6758 - val_accuracy: 0.6888\n",
      "Epoch 257/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2931 - accuracy: 0.8611 - val_loss: 0.5570 - val_accuracy: 0.7367\n",
      "Epoch 258/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2845 - accuracy: 0.8628 - val_loss: 0.5997 - val_accuracy: 0.7253TA: 0s - loss: 0.2850 - \n",
      "Epoch 259/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2834 - accuracy: 0.8632 - val_loss: 0.6478 - val_accuracy: 0.7109 0.2807 - accura - E\n",
      "Epoch 260/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2888 - accuracy: 0.8627 - val_loss: 0.5846 - val_accuracy: 0.7324\n",
      "Epoch 261/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2913 - accuracy: 0.8601 - val_loss: 0.6005 - val_accuracy: 0.7171\n",
      "Epoch 262/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2850 - accuracy: 0.8619 - val_loss: 0.6371 - val_accuracy: 0.7057\n",
      "Epoch 263/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2830 - accuracy: 0.8639 - val_loss: 0.6012 - val_accuracy: 0.7266\n",
      "Epoch 264/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2695 - accuracy: 0.8733 - val_loss: 0.5922 - val_accuracy: 0.7474\n",
      "Epoch 265/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2766 - accuracy: 0.8677 - val_loss: 0.6853 - val_accuracy: 0.7233\n",
      "Epoch 266/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2778 - accuracy: 0.8675 - val_loss: 0.5770 - val_accuracy: 0.7298\n",
      "Epoch 267/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2822 - accuracy: 0.8626 - val_loss: 0.5241 - val_accuracy: 0.7581\n",
      "Epoch 268/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2719 - accuracy: 0.8710 - val_loss: 0.6503 - val_accuracy: 0.7217\n",
      "Epoch 269/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2738 - accuracy: 0.8720 - val_loss: 0.6641 - val_accuracy: 0.7197 loss: 0.2824 - accurac - ETA: 12s - loss: 0.2924 - acc - ETA: 11s - loss: 0.2809 - acc - ETA: 10s - loss: 0.2750 - accur - ETA: 9s - loss: 0.284 - ETA\n",
      "Epoch 270/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2836 - accuracy: 0.8636 - val_loss: 0.6346 - val_accuracy: 0.7480 ETA: 0s - loss: 0.2837 - accuracy - ETA: 0s - loss: 0.2837 - accuracy: 0.86\n",
      "Epoch 271/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2761 - accuracy: 0.8693 - val_loss: 0.6119 - val_accuracy: 0.7354\n",
      "Epoch 272/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2754 - accuracy: 0.8684 - val_loss: 0.6122 - val_accuracy: 0.7311\n",
      "Epoch 273/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2710 - accuracy: 0.8703 - val_loss: 0.6311 - val_accuracy: 0.7487\n",
      "Epoch 274/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2650 - accuracy: 0.8760 - val_loss: 0.5498 - val_accuracy: 0.7572\n",
      "Epoch 275/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2664 - accuracy: 0.8756 - val_loss: 0.6836 - val_accuracy: 0.7223\n",
      "Epoch 276/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2619 - accuracy: 0.8772 - val_loss: 0.6383 - val_accuracy: 0.7135 - loss: 0.2627 - accuracy\n",
      "Epoch 277/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2703 - accuracy: 0.8725 - val_loss: 0.5581 - val_accuracy: 0.7500\n",
      "Epoch 278/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2696 - accuracy: 0.8713 - val_loss: 0.6178 - val_accuracy: 0.7217\n",
      "Epoch 279/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2761 - accuracy: 0.8701 - val_loss: 0.6148 - val_accuracy: 0.71682s - loss: 0.2734 - ac - ETA: 1s - loss: 0.2728 - accura - ETA: 1s - loss: 0.2728 - accuracy: \n",
      "Epoch 280/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2637 - accuracy: 0.8751 - val_loss: 0.6092 - val_accuracy: 0.7493\n",
      "Epoch 281/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2658 - accuracy: 0.8767 - val_loss: 0.6390 - val_accuracy: 0.7210\n",
      "Epoch 282/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2608 - accuracy: 0.8759 - val_loss: 0.6739 - val_accuracy: 0.7432\n",
      "Epoch 283/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.2643 - accuracy: 0.8746 - val_loss: 0.7773 - val_accuracy: 0.7135\n",
      "Epoch 284/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2567 - accuracy: 0.8805 - val_loss: 0.5679 - val_accuracy: 0.7510\n",
      "Epoch 285/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2526 - accuracy: 0.8831 - val_loss: 0.6313 - val_accuracy: 0.7438oss: 0.2512 \n",
      "Epoch 286/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2629 - accuracy: 0.8749 - val_loss: 0.6482 - val_accuracy: 0.7249\n",
      "Epoch 287/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2567 - accuracy: 0.8813 - val_loss: 0.6195 - val_accuracy: 0.7223 ETA: 4s - loss: 0.2525  - ETA: 4s - loss: 0.2525 - accu - ETA - ETA: 2s - los - - ETA: 0s - loss: 0.2\n",
      "Epoch 288/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2623 - accuracy: 0.8797 - val_loss: 0.6894 - val_accuracy: 0.7057\n",
      "Epoch 289/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2621 - accuracy: 0.8792 - val_loss: 0.5688 - val_accuracy: 0.7523oss: 0.2707 - accuracy: 0.87 - E -\n",
      "Epoch 290/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2561 - accuracy: 0.8791 - val_loss: 0.6938 - val_accuracy: 0.7100\n",
      "Epoch 291/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2495 - accuracy: 0.8836 - val_loss: 0.6479 - val_accuracy: 0.71422464 - accuracy: - ETA: 11s - loss:  - ETA: 10s - loss: 0.2465 - ETA: 1s - loss: 0.2472 - accura - ETA: 0s - loss: 0.2473 - accuracy: 0.88 - ETA: 0s - l\n",
      "Epoch 292/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2613 - accuracy: 0.8792 - val_loss: 0.6669 - val_accuracy: 0.7448.2613 - accuracy: 0.87\n",
      "Epoch 293/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2561 - accuracy: 0.8797 - val_loss: 0.5855 - val_accuracy: 0.7363 - ETA: 2s - ETA: 1s - loss: 0.2574 - accuracy: 0.87 - ETA: 0s - loss: 0.2574 - accuracy: 0. - ETA: 0s - loss: 0.2574 - accuracy - ETA: 0s - loss: 0.2\n",
      "Epoch 294/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2516 - accuracy: 0.8814 - val_loss: 0.6856 - val_accuracy: 0.7233\n",
      "Epoch 295/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2521 - accuracy: 0.8820 - val_loss: 0.5802 - val_accuracy: 0.7402\n",
      "Epoch 296/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2478 - accuracy: 0.8847 - val_loss: 0.6544 - val_accuracy: 0.7135\n",
      "Epoch 297/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2534 - accuracy: 0.8808 - val_loss: 0.5766 - val_accuracy: 0.7214\n",
      "Epoch 298/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2588 - accuracy: 0.8801 - val_loss: 0.6810 - val_accuracy: 0.7321\n",
      "Epoch 299/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2446 - accuracy: 0.8839 - val_loss: 0.6283 - val_accuracy: 0.7207\n",
      "Epoch 300/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2453 - accuracy: 0.8853 - val_loss: 0.6663 - val_accuracy: 0.7174\n",
      "Epoch 301/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2457 - accuracy: 0.8845 - val_loss: 0.6924 - val_accuracy: 0.7249\n",
      "Epoch 302/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2492 - accuracy: 0.8851 - val_loss: 0.7083 - val_accuracy: 0.7194\n",
      "Epoch 303/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2535 - accuracy: 0.8813 - val_loss: 0.6207 - val_accuracy: 0.73633s - loss: 0.2536 \n",
      "Epoch 304/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2531 - accuracy: 0.8826 - val_loss: 0.6345 - val_accuracy: 0.7419\n",
      "Epoch 305/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2492 - accuracy: 0.8820 - val_loss: 0.6511 - val_accuracy: 0.7337\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00305: early stopping\n",
      "      1/Unknown - 0s 125ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121/3121 [==============================] - 14s 4ms/step\n",
      "347/347 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|                       | 7/10 [9:09:06<3:57:13, 4744.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "438/438 [==============================] - 16s 34ms/step - loss: 0.6930 - accuracy: 0.5103 - val_loss: 0.6931 - val_accuracy: 0.4997\n",
      "Epoch 2/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6918 - accuracy: 0.5602 - val_loss: 0.6930 - val_accuracy: 0.4964\n",
      "Epoch 3/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6898 - accuracy: 0.5610 - val_loss: 0.6927 - val_accuracy: 0.4945\n",
      "Epoch 4/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6863 - accuracy: 0.5631 - val_loss: 0.6912 - val_accuracy: 0.5062\n",
      "Epoch 5/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6832 - accuracy: 0.5594 - val_loss: 0.6910 - val_accuracy: 0.5215\n",
      "Epoch 6/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6796 - accuracy: 0.5627 - val_loss: 0.6949 - val_accuracy: 0.5212\n",
      "Epoch 7/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6782 - accuracy: 0.5558 - val_loss: 0.6983 - val_accuracy: 0.5036\n",
      "Epoch 8/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6742 - accuracy: 0.5632 - val_loss: 0.7007 - val_accuracy: 0.5107\n",
      "Epoch 9/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6705 - accuracy: 0.5678 - val_loss: 0.7028 - val_accuracy: 0.5264\n",
      "Epoch 10/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6664 - accuracy: 0.5742 - val_loss: 0.6877 - val_accuracy: 0.5244\n",
      "Epoch 11/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6647 - accuracy: 0.5736 - val_loss: 0.7039 - val_accuracy: 0.5143\n",
      "Epoch 12/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6599 - accuracy: 0.5820 - val_loss: 0.6789 - val_accuracy: 0.5355\n",
      "Epoch 13/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6617 - accuracy: 0.5789 - val_loss: 0.6792 - val_accuracy: 0.5495\n",
      "Epoch 14/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6594 - accuracy: 0.5809 - val_loss: 0.7350 - val_accuracy: 0.5215\n",
      "Epoch 15/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6585 - accuracy: 0.5826 - val_loss: 0.7308 - val_accuracy: 0.5312\n",
      "Epoch 16/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6548 - accuracy: 0.5901 - val_loss: 0.7147 - val_accuracy: 0.5299\n",
      "Epoch 17/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6541 - accuracy: 0.5909 - val_loss: 0.7095 - val_accuracy: 0.5202536 - accura\n",
      "Epoch 18/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6529 - accuracy: 0.5919 - val_loss: 0.6906 - val_accuracy: 0.5426\n",
      "Epoch 19/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6509 - accuracy: 0.5915 - val_loss: 0.7175 - val_accuracy: 0.5244\n",
      "Epoch 20/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6519 - accuracy: 0.5917 - val_loss: 0.6922 - val_accuracy: 0.5462\n",
      "Epoch 21/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6503 - accuracy: 0.5927 - val_loss: 0.6955 - val_accuracy: 0.5339\n",
      "Epoch 22/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6490 - accuracy: 0.5972 - val_loss: 0.7093 - val_accuracy: 0.5335\n",
      "Epoch 23/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6482 - accuracy: 0.5985 - val_loss: 0.6900 - val_accuracy: 0.5413\n",
      "Epoch 24/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6486 - accuracy: 0.5977 - val_loss: 0.7263 - val_accuracy: 0.5257\n",
      "Epoch 25/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6443 - accuracy: 0.5964 - val_loss: 0.6655 - val_accuracy: 0.5527\n",
      "Epoch 26/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6448 - accuracy: 0.6001 - val_loss: 0.6651 - val_accuracy: 0.5482\n",
      "Epoch 27/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6448 - accuracy: 0.5992 - val_loss: 0.6632 - val_accuracy: 0.5371\n",
      "Epoch 28/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6465 - accuracy: 0.5972 - val_loss: 0.7690 - val_accuracy: 0.5290\n",
      "Epoch 29/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6425 - accuracy: 0.6056 - val_loss: 0.6924 - val_accuracy: 0.5345\n",
      "Epoch 30/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6410 - accuracy: 0.6060 - val_loss: 0.6860 - val_accuracy: 0.5495\n",
      "Epoch 31/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6425 - accuracy: 0.6056 - val_loss: 0.6783 - val_accuracy: 0.5465\n",
      "Epoch 32/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6413 - accuracy: 0.6058 - val_loss: 0.6917 - val_accuracy: 0.5309\n",
      "Epoch 33/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6455 - accuracy: 0.5974 - val_loss: 0.6387 - val_accuracy: 0.5609\n",
      "Epoch 34/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6423 - accuracy: 0.5994 - val_loss: 0.6578 - val_accuracy: 0.5404\n",
      "Epoch 35/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6398 - accuracy: 0.6071 - val_loss: 0.6599 - val_accuracy: 0.5651- ac - ETA: \n",
      "Epoch 36/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6392 - accuracy: 0.6058 - val_loss: 0.6907 - val_accuracy: 0.5277\n",
      "Epoch 37/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6385 - accuracy: 0.6063 - val_loss: 0.6584 - val_accuracy: 0.5667\n",
      "Epoch 38/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6357 - accuracy: 0.6115 - val_loss: 0.6747 - val_accuracy: 0.5378\n",
      "Epoch 39/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6368 - accuracy: 0.6122 - val_loss: 0.6605 - val_accuracy: 0.5521s: 0.6372 - accuracy\n",
      "Epoch 40/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6399 - accuracy: 0.6034 - val_loss: 0.6482 - val_accuracy: 0.5498\n",
      "Epoch 41/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6348 - accuracy: 0.6131 - val_loss: 0.6866 - val_accuracy: 0.5410\n",
      "Epoch 42/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6370 - accuracy: 0.6061 - val_loss: 0.6436 - val_accuracy: 0.5602\n",
      "Epoch 43/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6349 - accuracy: 0.6141 - val_loss: 0.6822 - val_accuracy: 0.5339\n",
      "Epoch 44/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6362 - accuracy: 0.6076 - val_loss: 0.6553 - val_accuracy: 0.5524\n",
      "Epoch 45/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6343 - accuracy: 0.6106 - val_loss: 0.6631 - val_accuracy: 0.5472\n",
      "Epoch 46/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6305 - accuracy: 0.6192 - val_loss: 0.6504 - val_accuracy: 0.5589\n",
      "Epoch 47/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6274 - accuracy: 0.6259 - val_loss: 0.6367 - val_accuracy: 0.5827\n",
      "Epoch 48/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6261 - accuracy: 0.6249 - val_loss: 0.6699 - val_accuracy: 0.5602\n",
      "Epoch 49/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6262 - accuracy: 0.6249 - val_loss: 0.6966 - val_accuracy: 0.5335\n",
      "Epoch 50/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6239 - accuracy: 0.6257 - val_loss: 0.6667 - val_accuracy: 0.5671\n",
      "Epoch 51/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6241 - accuracy: 0.6265 - val_loss: 0.6555 - val_accuracy: 0.5632\n",
      "Epoch 52/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6218 - accuracy: 0.6310 - val_loss: 0.6631 - val_accuracy: 0.5775\n",
      "Epoch 53/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6224 - accuracy: 0.6301 - val_loss: 0.6541 - val_accuracy: 0.5892\n",
      "Epoch 54/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6170 - accuracy: 0.6371 - val_loss: 0.6609 - val_accuracy: 0.5732\n",
      "Epoch 55/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6140 - accuracy: 0.6380 - val_loss: 0.6286 - val_accuracy: 0.5938\n",
      "Epoch 56/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6151 - accuracy: 0.6392 - val_loss: 0.7236 - val_accuracy: 0.5335\n",
      "Epoch 57/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6140 - accuracy: 0.6324 - val_loss: 0.6798 - val_accuracy: 0.5850\n",
      "Epoch 58/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6145 - accuracy: 0.6359 - val_loss: 0.6587 - val_accuracy: 0.5856\n",
      "Epoch 59/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6129 - accuracy: 0.6381 - val_loss: 0.6406 - val_accuracy: 0.5778\n",
      "Epoch 60/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6123 - accuracy: 0.6387 - val_loss: 0.6403 - val_accuracy: 0.5788\n",
      "Epoch 61/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6092 - accuracy: 0.6422 - val_loss: 0.6309 - val_accuracy: 0.6191\n",
      "Epoch 62/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6112 - accuracy: 0.6372 - val_loss: 0.6205 - val_accuracy: 0.6130\n",
      "Epoch 63/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6060 - accuracy: 0.6454 - val_loss: 0.6151 - val_accuracy: 0.6357\n",
      "Epoch 64/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6039 - accuracy: 0.6441 - val_loss: 0.6481 - val_accuracy: 0.5811\n",
      "Epoch 65/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6071 - accuracy: 0.6399 - val_loss: 0.6201 - val_accuracy: 0.6077\n",
      "Epoch 66/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6034 - accuracy: 0.6487 - val_loss: 0.6385 - val_accuracy: 0.5755\n",
      "Epoch 67/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5968 - accuracy: 0.6509 - val_loss: 0.6130 - val_accuracy: 0.6354\n",
      "Epoch 68/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6004 - accuracy: 0.6478 - val_loss: 0.5961 - val_accuracy: 0.6214\n",
      "Epoch 69/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6000 - accuracy: 0.6472 - val_loss: 0.6094 - val_accuracy: 0.6302\n",
      "Epoch 70/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5967 - accuracy: 0.6497 - val_loss: 0.6427 - val_accuracy: 0.6139\n",
      "Epoch 71/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5958 - accuracy: 0.6478 - val_loss: 0.5845 - val_accuracy: 0.6354\n",
      "Epoch 72/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5919 - accuracy: 0.6527 - val_loss: 0.6256 - val_accuracy: 0.5924\n",
      "Epoch 73/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5969 - accuracy: 0.6516 - val_loss: 0.5962 - val_accuracy: 0.6439\n",
      "Epoch 74/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5889 - accuracy: 0.6557 - val_loss: 0.6095 - val_accuracy: 0.6097\n",
      "Epoch 75/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5886 - accuracy: 0.6513 - val_loss: 0.5904 - val_accuracy: 0.6507\n",
      "Epoch 76/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5906 - accuracy: 0.6545 - val_loss: 0.5970 - val_accuracy: 0.6107\n",
      "Epoch 77/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5879 - accuracy: 0.6546 - val_loss: 0.5935 - val_accuracy: 0.6615\n",
      "Epoch 78/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5857 - accuracy: 0.6600 - val_loss: 0.5768 - val_accuracy: 0.6328\n",
      "Epoch 79/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5909 - accuracy: 0.6524 - val_loss: 0.6308 - val_accuracy: 0.5859\n",
      "Epoch 80/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5874 - accuracy: 0.6556 - val_loss: 0.6007 - val_accuracy: 0.6276\n",
      "Epoch 81/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5795 - accuracy: 0.6633 - val_loss: 0.5699 - val_accuracy: 0.6790\n",
      "Epoch 82/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5848 - accuracy: 0.6545 - val_loss: 0.5726 - val_accuracy: 0.6602\n",
      "Epoch 83/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5800 - accuracy: 0.6564 - val_loss: 0.5823 - val_accuracy: 0.6491\n",
      "Epoch 84/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5801 - accuracy: 0.6596 - val_loss: 0.6332 - val_accuracy: 0.5924\n",
      "Epoch 85/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5741 - accuracy: 0.6629 - val_loss: 0.6329 - val_accuracy: 0.5814\n",
      "Epoch 86/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5730 - accuracy: 0.6604 - val_loss: 0.5974 - val_accuracy: 0.6266\n",
      "Epoch 87/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5779 - accuracy: 0.6604 - val_loss: 0.6112 - val_accuracy: 0.6253s:\n",
      "Epoch 88/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5730 - accuracy: 0.6596 - val_loss: 0.6055 - val_accuracy: 0.6234\n",
      "Epoch 89/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5702 - accuracy: 0.6663 - val_loss: 0.6116 - val_accuracy: 0.6006\n",
      "Epoch 90/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5611 - accuracy: 0.6724 - val_loss: 0.5499 - val_accuracy: 0.6624\n",
      "Epoch 91/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5664 - accuracy: 0.6712 - val_loss: 0.5818 - val_accuracy: 0.6543\n",
      "Epoch 92/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5685 - accuracy: 0.6632 - val_loss: 0.5653 - val_accuracy: 0.6543\n",
      "Epoch 93/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5668 - accuracy: 0.6639 - val_loss: 0.5792 - val_accuracy: 0.6452\n",
      "Epoch 94/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5650 - accuracy: 0.6689 - val_loss: 0.5849 - val_accuracy: 0.6325\n",
      "Epoch 95/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5727 - accuracy: 0.6645 - val_loss: 0.5938 - val_accuracy: 0.6589\n",
      "Epoch 96/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5574 - accuracy: 0.6790 - val_loss: 0.6018 - val_accuracy: 0.6410\n",
      "Epoch 97/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5645 - accuracy: 0.6713 - val_loss: 0.5488 - val_accuracy: 0.6875\n",
      "Epoch 98/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5576 - accuracy: 0.6795 - val_loss: 0.5813 - val_accuracy: 0.6543\n",
      "Epoch 99/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5593 - accuracy: 0.6761 - val_loss: 0.5718 - val_accuracy: 0.6787\n",
      "Epoch 100/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5554 - accuracy: 0.6832 - val_loss: 0.5587 - val_accuracy: 0.6914\n",
      "Epoch 101/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5531 - accuracy: 0.6860 - val_loss: 0.5422 - val_accuracy: 0.7054\n",
      "Epoch 102/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5469 - accuracy: 0.6916 - val_loss: 0.5693 - val_accuracy: 0.6732\n",
      "Epoch 103/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5500 - accuracy: 0.6877 - val_loss: 0.5825 - val_accuracy: 0.6335\n",
      "Epoch 104/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5455 - accuracy: 0.6922 - val_loss: 0.6403 - val_accuracy: 0.6172\n",
      "Epoch 105/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5475 - accuracy: 0.6919 - val_loss: 0.5276 - val_accuracy: 0.7152\n",
      "Epoch 106/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5437 - accuracy: 0.6961 - val_loss: 0.6451 - val_accuracy: 0.6178\n",
      "Epoch 107/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5409 - accuracy: 0.6976 - val_loss: 0.5683 - val_accuracy: 0.6637\n",
      "Epoch 108/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5412 - accuracy: 0.6935 - val_loss: 0.5459 - val_accuracy: 0.6823\n",
      "Epoch 109/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5350 - accuracy: 0.6986 - val_loss: 0.5966 - val_accuracy: 0.6696\n",
      "Epoch 110/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5341 - accuracy: 0.7039 - val_loss: 0.5831 - val_accuracy: 0.6797\n",
      "Epoch 111/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5383 - accuracy: 0.6980 - val_loss: 0.5829 - val_accuracy: 0.6380\n",
      "Epoch 112/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5288 - accuracy: 0.7068 - val_loss: 0.5237 - val_accuracy: 0.7028\n",
      "Epoch 113/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5346 - accuracy: 0.7041 - val_loss: 0.5465 - val_accuracy: 0.6995\n",
      "Epoch 114/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5288 - accuracy: 0.7081 - val_loss: 0.5687 - val_accuracy: 0.6634\n",
      "Epoch 115/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5257 - accuracy: 0.7115 - val_loss: 0.5369 - val_accuracy: 0.7008\n",
      "Epoch 116/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5245 - accuracy: 0.7121 - val_loss: 0.5764 - val_accuracy: 0.6794\n",
      "Epoch 117/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5355 - accuracy: 0.7007 - val_loss: 0.5386 - val_accuracy: 0.6969\n",
      "Epoch 118/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5240 - accuracy: 0.7140 - val_loss: 0.5460 - val_accuracy: 0.7025\n",
      "Epoch 119/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5207 - accuracy: 0.7171 - val_loss: 0.5308 - val_accuracy: 0.7021\n",
      "Epoch 120/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5171 - accuracy: 0.7174 - val_loss: 0.5653 - val_accuracy: 0.6611\n",
      "Epoch 121/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5290 - accuracy: 0.7103 - val_loss: 0.6075 - val_accuracy: 0.6507\n",
      "Epoch 122/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5136 - accuracy: 0.7247 - val_loss: 0.5467 - val_accuracy: 0.6849\n",
      "Epoch 123/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5138 - accuracy: 0.7198 - val_loss: 0.5313 - val_accuracy: 0.7191\n",
      "Epoch 124/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5128 - accuracy: 0.7230 - val_loss: 0.5196 - val_accuracy: 0.7256\n",
      "Epoch 125/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5101 - accuracy: 0.7207 - val_loss: 0.5219 - val_accuracy: 0.7194\n",
      "Epoch 126/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5061 - accuracy: 0.7275 - val_loss: 0.5144 - val_accuracy: 0.7119\n",
      "Epoch 127/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5095 - accuracy: 0.7228 - val_loss: 0.5624 - val_accuracy: 0.6725\n",
      "Epoch 128/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4998 - accuracy: 0.7318 - val_loss: 0.4931 - val_accuracy: 0.7324\n",
      "Epoch 129/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5021 - accuracy: 0.7281 - val_loss: 0.5648 - val_accuracy: 0.6689\n",
      "Epoch 130/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5055 - accuracy: 0.7306 - val_loss: 0.5409 - val_accuracy: 0.7083\n",
      "Epoch 131/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4993 - accuracy: 0.7329 - val_loss: 0.5479 - val_accuracy: 0.7025\n",
      "Epoch 132/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4967 - accuracy: 0.7341 - val_loss: 0.4780 - val_accuracy: 0.7523\n",
      "Epoch 133/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4961 - accuracy: 0.7371 - val_loss: 0.4818 - val_accuracy: 0.7425\n",
      "Epoch 134/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4924 - accuracy: 0.7390 - val_loss: 0.5809 - val_accuracy: 0.6911\n",
      "Epoch 135/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4909 - accuracy: 0.7382 - val_loss: 0.4842 - val_accuracy: 0.7474\n",
      "Epoch 136/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5131 - accuracy: 0.7224 - val_loss: 0.5601 - val_accuracy: 0.6764\n",
      "Epoch 137/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5234 - accuracy: 0.7141 - val_loss: 0.5419 - val_accuracy: 0.7074\n",
      "Epoch 138/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5105 - accuracy: 0.7266 - val_loss: 0.5252 - val_accuracy: 0.7080\n",
      "Epoch 139/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5091 - accuracy: 0.7250 - val_loss: 0.4963 - val_accuracy: 0.7373\n",
      "Epoch 140/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4998 - accuracy: 0.7286 - val_loss: 0.5157 - val_accuracy: 0.7201\n",
      "Epoch 141/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4958 - accuracy: 0.7351 - val_loss: 0.5321 - val_accuracy: 0.6982\n",
      "Epoch 142/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4897 - accuracy: 0.7353 - val_loss: 0.5114 - val_accuracy: 0.7406\n",
      "Epoch 143/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4865 - accuracy: 0.7425 - val_loss: 0.5576 - val_accuracy: 0.6709\n",
      "Epoch 144/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4994 - accuracy: 0.7317 - val_loss: 0.5029 - val_accuracy: 0.7139\n",
      "Epoch 145/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4931 - accuracy: 0.7352 - val_loss: 0.4999 - val_accuracy: 0.7334s: 0.493\n",
      "Epoch 146/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4826 - accuracy: 0.7448 - val_loss: 0.4790 - val_accuracy: 0.7555\n",
      "Epoch 147/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4807 - accuracy: 0.7464 - val_loss: 0.5020 - val_accuracy: 0.7197\n",
      "Epoch 148/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4895 - accuracy: 0.7405 - val_loss: 0.5260 - val_accuracy: 0.6999\n",
      "Epoch 149/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5001 - accuracy: 0.7347 - val_loss: 0.5151 - val_accuracy: 0.7282\n",
      "Epoch 150/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4965 - accuracy: 0.7382 - val_loss: 0.4871 - val_accuracy: 0.7438\n",
      "Epoch 151/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4939 - accuracy: 0.7331 - val_loss: 0.4922 - val_accuracy: 0.7383\n",
      "Epoch 152/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4882 - accuracy: 0.7385 - val_loss: 0.4800 - val_accuracy: 0.7406\n",
      "Epoch 153/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4815 - accuracy: 0.7456 - val_loss: 0.5042 - val_accuracy: 0.7230\n",
      "Epoch 154/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4721 - accuracy: 0.7496 - val_loss: 0.4998 - val_accuracy: 0.7275\n",
      "Epoch 155/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4705 - accuracy: 0.7514 - val_loss: 0.4897 - val_accuracy: 0.7402\n",
      "Epoch 156/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4764 - accuracy: 0.7476 - val_loss: 0.5035 - val_accuracy: 0.7256\n",
      "Epoch 157/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4658 - accuracy: 0.7543 - val_loss: 0.5677 - val_accuracy: 0.6979\n",
      "Epoch 158/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4615 - accuracy: 0.7547 - val_loss: 0.5176 - val_accuracy: 0.7083\n",
      "Epoch 159/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4716 - accuracy: 0.7545 - val_loss: 0.4831 - val_accuracy: 0.7373\n",
      "Epoch 160/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4672 - accuracy: 0.7543 - val_loss: 0.5265 - val_accuracy: 0.7038\n",
      "Epoch 161/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4640 - accuracy: 0.7567 - val_loss: 0.4653 - val_accuracy: 0.7428\n",
      "Epoch 162/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4585 - accuracy: 0.7596 - val_loss: 0.5007 - val_accuracy: 0.7301\n",
      "Epoch 163/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4651 - accuracy: 0.7546 - val_loss: 0.5180 - val_accuracy: 0.7070\n",
      "Epoch 164/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4778 - accuracy: 0.7449 - val_loss: 0.5006 - val_accuracy: 0.7399\n",
      "Epoch 165/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4791 - accuracy: 0.7452 - val_loss: 0.4832 - val_accuracy: 0.7425\n",
      "Epoch 166/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4810 - accuracy: 0.7470 - val_loss: 0.5022 - val_accuracy: 0.7350\n",
      "Epoch 167/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4872 - accuracy: 0.7420 - val_loss: 0.5009 - val_accuracy: 0.7305\n",
      "Epoch 168/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4757 - accuracy: 0.7515 - val_loss: 0.4861 - val_accuracy: 0.7380\n",
      "Epoch 169/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4718 - accuracy: 0.7553 - val_loss: 0.4913 - val_accuracy: 0.7240\n",
      "Epoch 170/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4681 - accuracy: 0.7526 - val_loss: 0.4721 - val_accuracy: 0.7513\n",
      "Epoch 171/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4652 - accuracy: 0.7531 - val_loss: 0.5090 - val_accuracy: 0.7301\n",
      "Epoch 172/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4604 - accuracy: 0.7612 - val_loss: 0.4983 - val_accuracy: 0.7292\n",
      "Epoch 173/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4688 - accuracy: 0.7563 - val_loss: 0.5047 - val_accuracy: 0.7223\n",
      "Epoch 174/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4558 - accuracy: 0.7660 - val_loss: 0.4882 - val_accuracy: 0.7217\n",
      "Epoch 175/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4544 - accuracy: 0.7649 - val_loss: 0.4820 - val_accuracy: 0.7458\n",
      "Epoch 176/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4499 - accuracy: 0.7688 - val_loss: 0.4652 - val_accuracy: 0.7555\n",
      "Epoch 177/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4479 - accuracy: 0.7718 - val_loss: 0.6489 - val_accuracy: 0.6328\n",
      "Epoch 178/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4690 - accuracy: 0.7583 - val_loss: 0.4475 - val_accuracy: 0.7682\n",
      "Epoch 179/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4470 - accuracy: 0.7677 - val_loss: 0.5174 - val_accuracy: 0.7021\n",
      "Epoch 180/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4509 - accuracy: 0.7671 - val_loss: 0.4986 - val_accuracy: 0.7435\n",
      "Epoch 181/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4461 - accuracy: 0.7673 - val_loss: 0.4676 - val_accuracy: 0.7536\n",
      "Epoch 182/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4371 - accuracy: 0.7771 - val_loss: 0.5067 - val_accuracy: 0.7161\n",
      "Epoch 183/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4341 - accuracy: 0.7783 - val_loss: 0.4562 - val_accuracy: 0.7546\n",
      "Epoch 184/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4319 - accuracy: 0.7814 - val_loss: 0.4794 - val_accuracy: 0.7490\n",
      "Epoch 185/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4522 - accuracy: 0.7649 - val_loss: 0.4916 - val_accuracy: 0.7441\n",
      "Epoch 186/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4515 - accuracy: 0.7676 - val_loss: 0.4786 - val_accuracy: 0.7484\n",
      "Epoch 187/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4664 - accuracy: 0.7557 - val_loss: 0.5221 - val_accuracy: 0.7184\n",
      "Epoch 188/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4719 - accuracy: 0.7559 - val_loss: 0.4917 - val_accuracy: 0.7327\n",
      "Epoch 189/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4563 - accuracy: 0.7654 - val_loss: 0.5023 - val_accuracy: 0.7256\n",
      "Epoch 190/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4446 - accuracy: 0.7710 - val_loss: 0.5044 - val_accuracy: 0.7174\n",
      "Epoch 191/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4362 - accuracy: 0.7744 - val_loss: 0.4836 - val_accuracy: 0.7318\n",
      "Epoch 192/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4365 - accuracy: 0.7793 - val_loss: 0.5142 - val_accuracy: 0.7165\n",
      "Epoch 193/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4332 - accuracy: 0.7793 - val_loss: 0.6325 - val_accuracy: 0.6527\n",
      "Epoch 194/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4319 - accuracy: 0.7773 - val_loss: 0.4757 - val_accuracy: 0.7467\n",
      "Epoch 195/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4259 - accuracy: 0.7848 - val_loss: 0.4559 - val_accuracy: 0.7458\n",
      "Epoch 196/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4353 - accuracy: 0.7731 - val_loss: 0.5468 - val_accuracy: 0.6829\n",
      "Epoch 197/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4446 - accuracy: 0.7635 - val_loss: 0.4659 - val_accuracy: 0.7347\n",
      "Epoch 198/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4292 - accuracy: 0.7810 - val_loss: 0.5003 - val_accuracy: 0.7311\n",
      "Epoch 199/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4250 - accuracy: 0.7832 - val_loss: 0.4862 - val_accuracy: 0.7334\n",
      "Epoch 200/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4306 - accuracy: 0.7810 - val_loss: 0.4875 - val_accuracy: 0.7327\n",
      "Epoch 201/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4188 - accuracy: 0.7848 - val_loss: 0.4933 - val_accuracy: 0.7259\n",
      "Epoch 202/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4217 - accuracy: 0.7817 - val_loss: 0.5020 - val_accuracy: 0.7243\n",
      "Epoch 203/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4138 - accuracy: 0.7898 - val_loss: 0.4692 - val_accuracy: 0.7412\n",
      "Epoch 204/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4139 - accuracy: 0.7948 - val_loss: 0.4589 - val_accuracy: 0.7588\n",
      "Epoch 205/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4099 - accuracy: 0.7910 - val_loss: 0.4701 - val_accuracy: 0.7448\n",
      "Epoch 206/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4101 - accuracy: 0.7925 - val_loss: 0.4546 - val_accuracy: 0.7666\n",
      "Epoch 207/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4072 - accuracy: 0.7930 - val_loss: 0.4382 - val_accuracy: 0.7591\n",
      "Epoch 208/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4153 - accuracy: 0.7911 - val_loss: 0.4759 - val_accuracy: 0.7419\n",
      "Epoch 209/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4075 - accuracy: 0.7951 - val_loss: 0.4692 - val_accuracy: 0.7393\n",
      "Epoch 210/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4063 - accuracy: 0.7940 - val_loss: 0.4682 - val_accuracy: 0.7513curacy: 0.\n",
      "Epoch 211/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4024 - accuracy: 0.7948 - val_loss: 0.4805 - val_accuracy: 0.7230\n",
      "Epoch 212/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4008 - accuracy: 0.7972 - val_loss: 0.4444 - val_accuracy: 0.7640\n",
      "Epoch 213/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3936 - accuracy: 0.8026 - val_loss: 0.4543 - val_accuracy: 0.7542\n",
      "Epoch 214/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3934 - accuracy: 0.8049 - val_loss: 0.4745 - val_accuracy: 0.7393\n",
      "Epoch 215/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3966 - accuracy: 0.7978 - val_loss: 0.4373 - val_accuracy: 0.7728\n",
      "Epoch 216/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3954 - accuracy: 0.8021 - val_loss: 0.4604 - val_accuracy: 0.7383s: 0.3941 \n",
      "Epoch 217/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3920 - accuracy: 0.8010 - val_loss: 0.5147 - val_accuracy: 0.7188\n",
      "Epoch 218/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3857 - accuracy: 0.8059 - val_loss: 0.4606 - val_accuracy: 0.7520\n",
      "Epoch 219/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3881 - accuracy: 0.8073 - val_loss: 0.4622 - val_accuracy: 0.7588\n",
      "Epoch 220/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3834 - accuracy: 0.8064 - val_loss: 0.4430 - val_accuracy: 0.7721\n",
      "Epoch 221/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4004 - accuracy: 0.7983 - val_loss: 0.5324 - val_accuracy: 0.7184\n",
      "Epoch 222/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3850 - accuracy: 0.8079 - val_loss: 0.4773 - val_accuracy: 0.7480\n",
      "Epoch 223/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3798 - accuracy: 0.8105 - val_loss: 0.4571 - val_accuracy: 0.7695\n",
      "Epoch 224/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3896 - accuracy: 0.8058 - val_loss: 0.4792 - val_accuracy: 0.7448\n",
      "Epoch 225/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3781 - accuracy: 0.8078 - val_loss: 0.4446 - val_accuracy: 0.7731\n",
      "Epoch 226/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3805 - accuracy: 0.8105 - val_loss: 0.4540 - val_accuracy: 0.7536\n",
      "Epoch 227/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3818 - accuracy: 0.8113 - val_loss: 0.4513 - val_accuracy: 0.7744\n",
      "Epoch 228/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3751 - accuracy: 0.8143 - val_loss: 0.6679 - val_accuracy: 0.6735\n",
      "Epoch 229/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3760 - accuracy: 0.8129 - val_loss: 0.5173 - val_accuracy: 0.7555\n",
      "Epoch 230/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3715 - accuracy: 0.8159 - val_loss: 0.4756 - val_accuracy: 0.7546\n",
      "Epoch 231/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3687 - accuracy: 0.8182 - val_loss: 0.5006 - val_accuracy: 0.7288\n",
      "Epoch 232/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3673 - accuracy: 0.8176 - val_loss: 0.4578 - val_accuracy: 0.7565\n",
      "Epoch 233/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3695 - accuracy: 0.8172 - val_loss: 0.4628 - val_accuracy: 0.7594\n",
      "Epoch 234/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3727 - accuracy: 0.8147 - val_loss: 0.4411 - val_accuracy: 0.7601\n",
      "Epoch 235/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3686 - accuracy: 0.8154 - val_loss: 0.4884 - val_accuracy: 0.7266\n",
      "Epoch 236/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3708 - accuracy: 0.8182 - val_loss: 0.4605 - val_accuracy: 0.7598\n",
      "Epoch 237/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3601 - accuracy: 0.8258 - val_loss: 0.5454 - val_accuracy: 0.6963\n",
      "Epoch 238/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3611 - accuracy: 0.8195 - val_loss: 0.4532 - val_accuracy: 0.7581\n",
      "Epoch 239/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3664 - accuracy: 0.8192 - val_loss: 0.4723 - val_accuracy: 0.7526\n",
      "Epoch 240/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3675 - accuracy: 0.8194 - val_loss: 0.4674 - val_accuracy: 0.7637\n",
      "Epoch 241/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3637 - accuracy: 0.8259 - val_loss: 0.4330 - val_accuracy: 0.7819\n",
      "Epoch 242/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3659 - accuracy: 0.8200 - val_loss: 0.4596 - val_accuracy: 0.7614\n",
      "Epoch 243/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3605 - accuracy: 0.8254 - val_loss: 0.4904 - val_accuracy: 0.7480\n",
      "Epoch 244/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3564 - accuracy: 0.8261 - val_loss: 0.4378 - val_accuracy: 0.7760\n",
      "Epoch 245/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3589 - accuracy: 0.8263 - val_loss: 0.5096 - val_accuracy: 0.7415\n",
      "Epoch 246/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3578 - accuracy: 0.8279 - val_loss: 0.4726 - val_accuracy: 0.7432\n",
      "Epoch 247/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3585 - accuracy: 0.8238 - val_loss: 0.4912 - val_accuracy: 0.7448\n",
      "Epoch 248/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3595 - accuracy: 0.8253 - val_loss: 0.4628 - val_accuracy: 0.7588\n",
      "Epoch 249/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3503 - accuracy: 0.8300 - val_loss: 0.4872 - val_accuracy: 0.7542\n",
      "Epoch 250/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3436 - accuracy: 0.8314 - val_loss: 0.4345 - val_accuracy: 0.7790\n",
      "Epoch 251/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3453 - accuracy: 0.8352 - val_loss: 0.5321 - val_accuracy: 0.7012\n",
      "Epoch 252/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3428 - accuracy: 0.8317 - val_loss: 0.4520 - val_accuracy: 0.7708\n",
      "Epoch 253/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3403 - accuracy: 0.8350 - val_loss: 0.4904 - val_accuracy: 0.7380\n",
      "Epoch 254/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3375 - accuracy: 0.8381 - val_loss: 0.4493 - val_accuracy: 0.7793\n",
      "Epoch 255/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3459 - accuracy: 0.8310 - val_loss: 0.4554 - val_accuracy: 0.7666\n",
      "Epoch 256/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3395 - accuracy: 0.8363 - val_loss: 0.5294 - val_accuracy: 0.7298\n",
      "Epoch 257/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3430 - accuracy: 0.8356 - val_loss: 0.4735 - val_accuracy: 0.7604\n",
      "Epoch 258/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3455 - accuracy: 0.8302 - val_loss: 0.4445 - val_accuracy: 0.7842\n",
      "Epoch 259/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3354 - accuracy: 0.8374 - val_loss: 0.4776 - val_accuracy: 0.7454\n",
      "Epoch 260/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3364 - accuracy: 0.8381 - val_loss: 0.5115 - val_accuracy: 0.7285\n",
      "Epoch 261/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3408 - accuracy: 0.8339 - val_loss: 0.5261 - val_accuracy: 0.7207\n",
      "Epoch 262/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3360 - accuracy: 0.8421 - val_loss: 0.4621 - val_accuracy: 0.7539\n",
      "Epoch 263/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3330 - accuracy: 0.8399 - val_loss: 0.4345 - val_accuracy: 0.7734\n",
      "Epoch 264/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3265 - accuracy: 0.8416 - val_loss: 0.4442 - val_accuracy: 0.7777\n",
      "Epoch 265/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3350 - accuracy: 0.8400 - val_loss: 0.5171 - val_accuracy: 0.7188\n",
      "Epoch 266/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3278 - accuracy: 0.8414 - val_loss: 0.4731 - val_accuracy: 0.7513\n",
      "Epoch 267/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3289 - accuracy: 0.8411 - val_loss: 0.4706 - val_accuracy: 0.7572\n",
      "Epoch 268/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3252 - accuracy: 0.8440 - val_loss: 0.4525 - val_accuracy: 0.7839\n",
      "Epoch 269/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3312 - accuracy: 0.8405 - val_loss: 0.4359 - val_accuracy: 0.7812\n",
      "Epoch 270/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3237 - accuracy: 0.8453 - val_loss: 0.4321 - val_accuracy: 0.7822\n",
      "Epoch 271/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3204 - accuracy: 0.8459 - val_loss: 0.4399 - val_accuracy: 0.7741\n",
      "Epoch 272/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3242 - accuracy: 0.8464 - val_loss: 0.4386 - val_accuracy: 0.7852\n",
      "Epoch 273/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3299 - accuracy: 0.8425 - val_loss: 0.4795 - val_accuracy: 0.7702\n",
      "Epoch 274/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3223 - accuracy: 0.8452 - val_loss: 0.5039 - val_accuracy: 0.7585\n",
      "Epoch 275/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3272 - accuracy: 0.8445 - val_loss: 0.4371 - val_accuracy: 0.7686 loss: 0.3\n",
      "Epoch 276/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3227 - accuracy: 0.8468 - val_loss: 0.6094 - val_accuracy: 0.6742\n",
      "Epoch 277/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3190 - accuracy: 0.8478 - val_loss: 0.4664 - val_accuracy: 0.7568\n",
      "Epoch 278/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3169 - accuracy: 0.8508 - val_loss: 0.4847 - val_accuracy: 0.7559\n",
      "Epoch 279/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3140 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
      "Epoch 280/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3097 - accuracy: 0.8526 - val_loss: 0.5145 - val_accuracy: 0.7386\n",
      "Epoch 281/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3085 - accuracy: 0.8552 - val_loss: 0.5116 - val_accuracy: 0.7653\n",
      "Epoch 282/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3103 - accuracy: 0.8547 - val_loss: 0.5116 - val_accuracy: 0.7432\n",
      "Epoch 283/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3127 - accuracy: 0.8523 - val_loss: 0.4756 - val_accuracy: 0.7725\n",
      "Epoch 284/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3101 - accuracy: 0.8532 - val_loss: 0.4420 - val_accuracy: 0.7852\n",
      "Epoch 285/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3127 - accuracy: 0.8527 - val_loss: 0.5065 - val_accuracy: 0.7386\n",
      "Epoch 286/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3050 - accuracy: 0.8574 - val_loss: 0.4720 - val_accuracy: 0.7865\n",
      "Epoch 287/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2999 - accuracy: 0.8578 - val_loss: 0.4557 - val_accuracy: 0.7777\n",
      "Epoch 288/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3061 - accuracy: 0.8587 - val_loss: 0.4684 - val_accuracy: 0.7705\n",
      "Epoch 289/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3002 - accuracy: 0.8602 - val_loss: 0.4551 - val_accuracy: 0.7904\n",
      "Epoch 290/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3012 - accuracy: 0.8583 - val_loss: 0.6010 - val_accuracy: 0.7445\n",
      "Epoch 291/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3082 - accuracy: 0.8548 - val_loss: 0.4659 - val_accuracy: 0.7806\n",
      "Epoch 292/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3059 - accuracy: 0.8578 - val_loss: 0.4464 - val_accuracy: 0.7809\n",
      "Epoch 293/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3007 - accuracy: 0.8600 - val_loss: 0.5549 - val_accuracy: 0.7236\n",
      "Epoch 294/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2955 - accuracy: 0.8631 - val_loss: 0.4759 - val_accuracy: 0.7673\n",
      "Epoch 295/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3014 - accuracy: 0.8572 - val_loss: 0.5526 - val_accuracy: 0.7314\n",
      "Epoch 296/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3021 - accuracy: 0.8599 - val_loss: 0.4605 - val_accuracy: 0.7663\n",
      "Epoch 297/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2927 - accuracy: 0.8635 - val_loss: 0.4988 - val_accuracy: 0.7471\n",
      "Epoch 298/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2941 - accuracy: 0.8639 - val_loss: 0.4462 - val_accuracy: 0.7923\n",
      "Epoch 299/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2985 - accuracy: 0.8616 - val_loss: 0.5373 - val_accuracy: 0.7630\n",
      "Epoch 300/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2944 - accuracy: 0.8614 - val_loss: 0.5301 - val_accuracy: 0.7487\n",
      "Epoch 301/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2897 - accuracy: 0.8657 - val_loss: 0.5085 - val_accuracy: 0.7617\n",
      "Epoch 302/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2918 - accuracy: 0.8643 - val_loss: 0.4972 - val_accuracy: 0.7575\n",
      "Epoch 303/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2861 - accuracy: 0.8667 - val_loss: 0.4864 - val_accuracy: 0.7591\n",
      "Epoch 304/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2946 - accuracy: 0.8606 - val_loss: 0.5482 - val_accuracy: 0.7217\n",
      "Epoch 305/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2886 - accuracy: 0.8669 - val_loss: 0.4840 - val_accuracy: 0.7767\n",
      "Epoch 306/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2826 - accuracy: 0.8672 - val_loss: 0.4727 - val_accuracy: 0.7653\n",
      "Epoch 307/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2982 - accuracy: 0.8617 - val_loss: 0.5027 - val_accuracy: 0.7721\n",
      "Epoch 308/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2849 - accuracy: 0.8688 - val_loss: 0.4848 - val_accuracy: 0.7565\n",
      "Epoch 309/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2840 - accuracy: 0.8662 - val_loss: 0.4803 - val_accuracy: 0.7454\n",
      "Epoch 310/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2808 - accuracy: 0.8704 - val_loss: 0.5432 - val_accuracy: 0.7464\n",
      "Epoch 311/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2779 - accuracy: 0.8723 - val_loss: 0.4628 - val_accuracy: 0.7816\n",
      "Epoch 312/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2781 - accuracy: 0.8707 - val_loss: 0.4958 - val_accuracy: 0.7734\n",
      "Epoch 313/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2832 - accuracy: 0.8698 - val_loss: 0.5079 - val_accuracy: 0.7734\n",
      "Epoch 314/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2774 - accuracy: 0.8734 - val_loss: 0.4951 - val_accuracy: 0.7728\n",
      "Epoch 315/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2755 - accuracy: 0.8735 - val_loss: 0.5149 - val_accuracy: 0.7585\n",
      "Epoch 316/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2809 - accuracy: 0.8702 - val_loss: 0.4677 - val_accuracy: 0.7826\n",
      "Epoch 317/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2836 - accuracy: 0.8690 - val_loss: 0.5119 - val_accuracy: 0.7559\n",
      "Epoch 318/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2681 - accuracy: 0.8753 - val_loss: 0.5096 - val_accuracy: 0.7555\n",
      "Epoch 319/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2848 - accuracy: 0.8700 - val_loss: 0.4848 - val_accuracy: 0.7816\n",
      "Epoch 320/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2746 - accuracy: 0.8743 - val_loss: 0.5034 - val_accuracy: 0.7682\n",
      "Epoch 321/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2698 - accuracy: 0.8769 - val_loss: 0.5389 - val_accuracy: 0.7666\n",
      "Epoch 322/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3162 - accuracy: 0.8516 - val_loss: 0.5473 - val_accuracy: 0.7383\n",
      "Epoch 323/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2978 - accuracy: 0.8603 - val_loss: 0.6389 - val_accuracy: 0.7148\n",
      "Epoch 324/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2834 - accuracy: 0.8716 - val_loss: 0.5397 - val_accuracy: 0.7594\n",
      "Epoch 325/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2661 - accuracy: 0.8778 - val_loss: 0.5284 - val_accuracy: 0.7614\n",
      "Epoch 326/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2730 - accuracy: 0.8760 - val_loss: 0.5216 - val_accuracy: 0.7380\n",
      "Epoch 327/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2745 - accuracy: 0.8727 - val_loss: 0.5429 - val_accuracy: 0.7637\n",
      "Epoch 328/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2700 - accuracy: 0.8765 - val_loss: 0.5508 - val_accuracy: 0.7484\n",
      "Epoch 329/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2705 - accuracy: 0.8790 - val_loss: 0.4950 - val_accuracy: 0.7689\n",
      "Epoch 330/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2657 - accuracy: 0.8780 - val_loss: 0.5315 - val_accuracy: 0.7588\n",
      "Epoch 331/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2640 - accuracy: 0.8802 - val_loss: 0.5309 - val_accuracy: 0.7572\n",
      "Epoch 332/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2613 - accuracy: 0.8820 - val_loss: 0.4961 - val_accuracy: 0.7832\n",
      "Epoch 333/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2594 - accuracy: 0.8813 - val_loss: 0.5299 - val_accuracy: 0.7790\n",
      "Epoch 334/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2678 - accuracy: 0.8770 - val_loss: 0.5269 - val_accuracy: 0.7660\n",
      "Epoch 335/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2593 - accuracy: 0.8799 - val_loss: 0.5407 - val_accuracy: 0.7484\n",
      "Epoch 336/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2602 - accuracy: 0.8809 - val_loss: 0.5224 - val_accuracy: 0.7676\n",
      "Epoch 337/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2601 - accuracy: 0.8846 - val_loss: 0.5158 - val_accuracy: 0.7594\n",
      "Epoch 338/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2639 - accuracy: 0.8822 - val_loss: 0.5475 - val_accuracy: 0.7624\n",
      "Epoch 339/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2566 - accuracy: 0.8825 - val_loss: 0.5274 - val_accuracy: 0.7712\n",
      "Epoch 340/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2526 - accuracy: 0.8873 - val_loss: 0.5320 - val_accuracy: 0.7542\n",
      "Epoch 341/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2522 - accuracy: 0.8862 - val_loss: 0.5531 - val_accuracy: 0.7624\n",
      "Epoch 342/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2494 - accuracy: 0.8881 - val_loss: 0.6738 - val_accuracy: 0.7064\n",
      "Epoch 343/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2511 - accuracy: 0.8872 - val_loss: 0.5120 - val_accuracy: 0.7826\n",
      "Epoch 344/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2557 - accuracy: 0.8846 - val_loss: 0.5443 - val_accuracy: 0.7682\n",
      "Epoch 345/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2516 - accuracy: 0.8878 - val_loss: 0.5220 - val_accuracy: 0.7777\n",
      "Epoch 346/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2549 - accuracy: 0.8841 - val_loss: 0.6087 - val_accuracy: 0.7419\n",
      "Epoch 347/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2542 - accuracy: 0.8835 - val_loss: 0.6392 - val_accuracy: 0.7288\n",
      "Epoch 348/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2519 - accuracy: 0.8869 - val_loss: 0.5452 - val_accuracy: 0.7555\n",
      "Epoch 349/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2485 - accuracy: 0.8867 - val_loss: 0.6278 - val_accuracy: 0.7347\n",
      "Epoch 350/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2476 - accuracy: 0.8888 - val_loss: 0.5320 - val_accuracy: 0.7555\n",
      "Epoch 351/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2479 - accuracy: 0.8907 - val_loss: 0.5437 - val_accuracy: 0.7575\n",
      "Epoch 352/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2469 - accuracy: 0.8888 - val_loss: 0.6407 - val_accuracy: 0.7197\n",
      "Epoch 353/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2529 - accuracy: 0.8875 - val_loss: 0.5455 - val_accuracy: 0.7507\n",
      "Epoch 354/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2411 - accuracy: 0.8921 - val_loss: 0.5204 - val_accuracy: 0.7728\n",
      "Epoch 355/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2489 - accuracy: 0.8927 - val_loss: 0.5527 - val_accuracy: 0.7581\n",
      "Epoch 356/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2432 - accuracy: 0.8916 - val_loss: 0.4891 - val_accuracy: 0.7650\n",
      "Epoch 357/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2420 - accuracy: 0.8926 - val_loss: 0.6087 - val_accuracy: 0.7555\n",
      "Epoch 358/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2397 - accuracy: 0.8921 - val_loss: 0.6907 - val_accuracy: 0.7174\n",
      "Epoch 359/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2435 - accuracy: 0.8907 - val_loss: 0.6102 - val_accuracy: 0.7399\n",
      "Epoch 360/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2545 - accuracy: 0.8873 - val_loss: 0.5604 - val_accuracy: 0.7337\n",
      "Epoch 361/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2612 - accuracy: 0.8815 - val_loss: 0.4755 - val_accuracy: 0.7900\n",
      "Epoch 362/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2319 - accuracy: 0.8966 - val_loss: 0.5031 - val_accuracy: 0.7777\n",
      "Epoch 363/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2434 - accuracy: 0.8913 - val_loss: 0.5778 - val_accuracy: 0.7676\n",
      "Epoch 364/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2413 - accuracy: 0.8903 - val_loss: 0.6278 - val_accuracy: 0.7230\n",
      "Epoch 365/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2351 - accuracy: 0.8973 - val_loss: 0.5867 - val_accuracy: 0.7598\n",
      "Epoch 366/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2346 - accuracy: 0.8945 - val_loss: 0.5189 - val_accuracy: 0.7679\n",
      "Epoch 367/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2321 - accuracy: 0.8970 - val_loss: 0.5800 - val_accuracy: 0.7415\n",
      "Epoch 368/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2412 - accuracy: 0.8914 - val_loss: 0.4845 - val_accuracy: 0.7982\n",
      "Epoch 369/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2388 - accuracy: 0.8936 - val_loss: 0.5345 - val_accuracy: 0.7731\n",
      "Epoch 370/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2294 - accuracy: 0.8998 - val_loss: 0.5502 - val_accuracy: 0.7715\n",
      "Epoch 371/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2336 - accuracy: 0.8974 - val_loss: 0.5556 - val_accuracy: 0.7565\n",
      "Epoch 372/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2287 - accuracy: 0.8958 - val_loss: 0.5269 - val_accuracy: 0.7695\n",
      "Epoch 373/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2369 - accuracy: 0.8947 - val_loss: 0.5134 - val_accuracy: 0.7751\n",
      "Epoch 374/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2289 - accuracy: 0.8974 - val_loss: 0.5504 - val_accuracy: 0.7633\n",
      "Epoch 375/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2321 - accuracy: 0.8963 - val_loss: 0.5260 - val_accuracy: 0.7591\n",
      "Epoch 376/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2266 - accuracy: 0.9005 - val_loss: 0.4806 - val_accuracy: 0.7926\n",
      "Epoch 377/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2339 - accuracy: 0.8981 - val_loss: 0.5249 - val_accuracy: 0.7783\n",
      "Epoch 378/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2261 - accuracy: 0.9009 - val_loss: 0.6332 - val_accuracy: 0.7230\n",
      "Epoch 379/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2259 - accuracy: 0.9010 - val_loss: 0.5767 - val_accuracy: 0.7786\n",
      "Epoch 380/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2261 - accuracy: 0.8994 - val_loss: 0.5535 - val_accuracy: 0.7812\n",
      "Epoch 381/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2294 - accuracy: 0.9012 - val_loss: 0.5457 - val_accuracy: 0.7663\n",
      "Epoch 382/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2285 - accuracy: 0.8995 - val_loss: 0.6243 - val_accuracy: 0.7529\n",
      "Epoch 383/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2235 - accuracy: 0.9028 - val_loss: 0.5528 - val_accuracy: 0.7725\n",
      "Epoch 384/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2222 - accuracy: 0.9018 - val_loss: 0.5470 - val_accuracy: 0.7689\n",
      "Epoch 385/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2159 - accuracy: 0.9052 - val_loss: 0.5148 - val_accuracy: 0.7695\n",
      "Epoch 386/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2232 - accuracy: 0.9010 - val_loss: 0.6108 - val_accuracy: 0.7487\n",
      "Epoch 387/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2291 - accuracy: 0.8994 - val_loss: 0.5169 - val_accuracy: 0.7852\n",
      "Epoch 388/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2202 - accuracy: 0.9046 - val_loss: 0.5779 - val_accuracy: 0.7562\n",
      "Epoch 389/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2177 - accuracy: 0.9046 - val_loss: 0.6485 - val_accuracy: 0.7386\n",
      "Epoch 390/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2231 - accuracy: 0.9028 - val_loss: 0.5552 - val_accuracy: 0.7725\n",
      "Epoch 391/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2236 - accuracy: 0.9030 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
      "Epoch 392/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2162 - accuracy: 0.9069 - val_loss: 0.6998 - val_accuracy: 0.7142 loss: 0.2161 - accu\n",
      "Epoch 393/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2228 - accuracy: 0.9035 - val_loss: 0.5938 - val_accuracy: 0.7614\n",
      "Epoch 394/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2143 - accuracy: 0.9066 - val_loss: 0.6406 - val_accuracy: 0.7533\n",
      "Epoch 395/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2118 - accuracy: 0.9072 - val_loss: 0.6108 - val_accuracy: 0.7686\n",
      "Epoch 396/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2112 - accuracy: 0.9065 - val_loss: 0.6480 - val_accuracy: 0.7464\n",
      "Epoch 397/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2170 - accuracy: 0.9055 - val_loss: 0.5575 - val_accuracy: 0.7663\n",
      "Epoch 398/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2165 - accuracy: 0.9067 - val_loss: 0.5803 - val_accuracy: 0.7721\n",
      "Epoch 399/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2119 - accuracy: 0.9075 - val_loss: 0.7508 - val_accuracy: 0.6999\n",
      "Epoch 400/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2102 - accuracy: 0.9086 - val_loss: 0.5377 - val_accuracy: 0.7783\n",
      "Epoch 401/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2156 - accuracy: 0.9061 - val_loss: 0.6347 - val_accuracy: 0.7686\n",
      "Epoch 402/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2198 - accuracy: 0.9038 - val_loss: 0.6514 - val_accuracy: 0.7256\n",
      "Epoch 403/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2169 - accuracy: 0.9065 - val_loss: 0.5725 - val_accuracy: 0.7601\n",
      "Epoch 404/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2141 - accuracy: 0.9052 - val_loss: 0.6370 - val_accuracy: 0.7448\n",
      "Epoch 405/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2093 - accuracy: 0.9094 - val_loss: 0.6489 - val_accuracy: 0.7445\n",
      "Epoch 406/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2113 - accuracy: 0.9107 - val_loss: 0.5692 - val_accuracy: 0.7728\n",
      "Epoch 407/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2081 - accuracy: 0.9097 - val_loss: 0.5499 - val_accuracy: 0.7725\n",
      "Epoch 408/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2039 - accuracy: 0.9119 - val_loss: 0.6765 - val_accuracy: 0.7441\n",
      "Epoch 409/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2133 - accuracy: 0.9093 - val_loss: 0.7181 - val_accuracy: 0.7380\n",
      "Epoch 410/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2071 - accuracy: 0.9124 - val_loss: 0.6376 - val_accuracy: 0.7383\n",
      "Epoch 411/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2088 - accuracy: 0.9093 - val_loss: 0.6680 - val_accuracy: 0.7503\n",
      "Epoch 412/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2052 - accuracy: 0.9118 - val_loss: 0.6703 - val_accuracy: 0.7428\n",
      "Epoch 413/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2066 - accuracy: 0.9099 - val_loss: 0.5657 - val_accuracy: 0.7617\n",
      "Epoch 414/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2002 - accuracy: 0.9134 - val_loss: 0.6053 - val_accuracy: 0.7435\n",
      "Epoch 415/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2120 - accuracy: 0.9089 - val_loss: 0.5905 - val_accuracy: 0.7747\n",
      "Epoch 416/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2057 - accuracy: 0.9108 - val_loss: 0.6070 - val_accuracy: 0.7454\n",
      "Epoch 417/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1977 - accuracy: 0.9152 - val_loss: 0.5810 - val_accuracy: 0.7718\n",
      "Epoch 418/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2048 - accuracy: 0.9111 - val_loss: 0.6634 - val_accuracy: 0.7536\n",
      "Epoch 419/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2004 - accuracy: 0.9149 - val_loss: 0.6777 - val_accuracy: 0.7445\n",
      "Epoch 420/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2075 - accuracy: 0.9087 - val_loss: 0.5980 - val_accuracy: 0.7611\n",
      "Epoch 421/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2101 - accuracy: 0.9110 - val_loss: 0.5696 - val_accuracy: 0.7643\n",
      "Epoch 422/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2021 - accuracy: 0.9143 - val_loss: 0.6195 - val_accuracy: 0.7620\n",
      "Epoch 423/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.1978 - accuracy: 0.9156 - val_loss: 0.5254 - val_accuracy: 0.7614\n",
      "Epoch 424/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.1957 - accuracy: 0.9165 - val_loss: 0.6322 - val_accuracy: 0.7497\n",
      "Epoch 425/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1972 - accuracy: 0.9144 - val_loss: 0.6216 - val_accuracy: 0.7633\n",
      "Epoch 426/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2002 - accuracy: 0.9158 - val_loss: 0.5854 - val_accuracy: 0.7725\n",
      "Epoch 427/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.1988 - accuracy: 0.9144 - val_loss: 0.6085 - val_accuracy: 0.7692\n",
      "Epoch 428/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.1912 - accuracy: 0.9176 - val_loss: 0.6043 - val_accuracy: 0.7630\n",
      "Epoch 429/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1980 - accuracy: 0.9159 - val_loss: 0.6416 - val_accuracy: 0.7692\n",
      "Epoch 430/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1907 - accuracy: 0.9176 - val_loss: 0.5751 - val_accuracy: 0.7764\n",
      "Epoch 431/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1939 - accuracy: 0.9173 - val_loss: 0.6767 - val_accuracy: 0.7458\n",
      "Epoch 432/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1984 - accuracy: 0.9151 - val_loss: 0.7024 - val_accuracy: 0.7269\n",
      "Epoch 433/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1937 - accuracy: 0.9193 - val_loss: 0.5960 - val_accuracy: 0.7663\n",
      "Epoch 434/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2058 - accuracy: 0.9112 - val_loss: 0.6953 - val_accuracy: 0.7503\n",
      "Epoch 435/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1913 - accuracy: 0.9195 - val_loss: 0.7131 - val_accuracy: 0.7454\n",
      "Epoch 436/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1903 - accuracy: 0.9180 - val_loss: 0.7411 - val_accuracy: 0.7292\n",
      "Epoch 437/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.1996 - accuracy: 0.9152 - val_loss: 0.6258 - val_accuracy: 0.7598\n",
      "Epoch 438/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1909 - accuracy: 0.9189 - val_loss: 0.6012 - val_accuracy: 0.7643\n",
      "Epoch 439/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.1891 - accuracy: 0.9207 - val_loss: 0.5838 - val_accuracy: 0.7588\n",
      "Epoch 440/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.1950 - accuracy: 0.9163 - val_loss: 0.6516 - val_accuracy: 0.7480\n",
      "Epoch 441/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1922 - accuracy: 0.9185 - val_loss: 0.6353 - val_accuracy: 0.7503\n",
      "Epoch 442/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.1843 - accuracy: 0.9222 - val_loss: 0.6753 - val_accuracy: 0.7350\n",
      "Epoch 443/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.1891 - accuracy: 0.9205 - val_loss: 0.6818 - val_accuracy: 0.7526\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00443: early stopping\n",
      "      1/Unknown - 0s 125ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121/3121 [==============================] - 14s 5ms/step\n",
      "347/347 [==============================] - 2s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|               | 8/10 [10:57:08<2:56:35, 5297.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6913 - accuracy: 0.5183 - val_loss: 0.6924 - val_accuracy: 0.5140\n",
      "Epoch 2/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6871 - accuracy: 0.5452 - val_loss: 0.6916 - val_accuracy: 0.5228\n",
      "Epoch 3/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6831 - accuracy: 0.5538 - val_loss: 0.6962 - val_accuracy: 0.5156\n",
      "Epoch 4/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6797 - accuracy: 0.5554 - val_loss: 0.6846 - val_accuracy: 0.5391\n",
      "Epoch 5/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6753 - accuracy: 0.5591 - val_loss: 0.6799 - val_accuracy: 0.5355\n",
      "Epoch 6/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6729 - accuracy: 0.5652 - val_loss: 0.6817 - val_accuracy: 0.5322\n",
      "Epoch 7/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6692 - accuracy: 0.5714 - val_loss: 0.6761 - val_accuracy: 0.5326\n",
      "Epoch 8/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6657 - accuracy: 0.5752 - val_loss: 0.6871 - val_accuracy: 0.5260\n",
      "Epoch 9/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6635 - accuracy: 0.5809 - val_loss: 0.6901 - val_accuracy: 0.5078\n",
      "Epoch 10/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6608 - accuracy: 0.5824 - val_loss: 0.6871 - val_accuracy: 0.5335\n",
      "Epoch 11/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6590 - accuracy: 0.5857 - val_loss: 0.6672 - val_accuracy: 0.5557\n",
      "Epoch 12/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6583 - accuracy: 0.5865 - val_loss: 0.6597 - val_accuracy: 0.5381s: 0.6 - ETA: 0s - loss: 0.6\n",
      "Epoch 13/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6550 - accuracy: 0.5863 - val_loss: 0.6781 - val_accuracy: 0.5085\n",
      "Epoch 14/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6550 - accuracy: 0.5863 - val_loss: 0.6792 - val_accuracy: 0.5247\n",
      "Epoch 15/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6550 - accuracy: 0.5885 - val_loss: 0.6565 - val_accuracy: 0.5407\n",
      "Epoch 16/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6522 - accuracy: 0.5936 - val_loss: 0.6381 - val_accuracy: 0.6019\n",
      "Epoch 17/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6491 - accuracy: 0.5965 - val_loss: 0.6617 - val_accuracy: 0.5426\n",
      "Epoch 18/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6500 - accuracy: 0.5952 - val_loss: 0.6734 - val_accuracy: 0.5238\n",
      "Epoch 19/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6492 - accuracy: 0.6002 - val_loss: 0.6747 - val_accuracy: 0.5238\n",
      "Epoch 20/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6443 - accuracy: 0.6093 - val_loss: 0.6599 - val_accuracy: 0.5719\n",
      "Epoch 21/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6456 - accuracy: 0.6102 - val_loss: 0.6427 - val_accuracy: 0.6481\n",
      "Epoch 22/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6420 - accuracy: 0.6140 - val_loss: 0.6579 - val_accuracy: 0.55404 - ac\n",
      "Epoch 23/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6408 - accuracy: 0.6172 - val_loss: 0.6509 - val_accuracy: 0.5876\n",
      "Epoch 24/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6369 - accuracy: 0.6196 - val_loss: 0.6694 - val_accuracy: 0.5710\n",
      "Epoch 25/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6388 - accuracy: 0.6194 - val_loss: 0.6191 - val_accuracy: 0.6589\n",
      "Epoch 26/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6360 - accuracy: 0.6230 - val_loss: 0.6546 - val_accuracy: 0.5615\n",
      "Epoch 27/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6361 - accuracy: 0.6212 - val_loss: 0.6329 - val_accuracy: 0.6344\n",
      "Epoch 28/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6309 - accuracy: 0.6274 - val_loss: 0.6234 - val_accuracy: 0.6406\n",
      "Epoch 29/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6329 - accuracy: 0.6237 - val_loss: 0.6289 - val_accuracy: 0.6227\n",
      "Epoch 30/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6269 - accuracy: 0.6321 - val_loss: 0.6641 - val_accuracy: 0.5804 - loss: 0.6271 - accuracy\n",
      "Epoch 31/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6288 - accuracy: 0.6291 - val_loss: 0.6486 - val_accuracy: 0.6117\n",
      "Epoch 32/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6247 - accuracy: 0.6362 - val_loss: 0.6445 - val_accuracy: 0.6081\n",
      "Epoch 33/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6215 - accuracy: 0.6375 - val_loss: 0.6301 - val_accuracy: 0.6260\n",
      "Epoch 34/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6181 - accuracy: 0.6415 - val_loss: 0.6159 - val_accuracy: 0.6445\n",
      "Epoch 35/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6183 - accuracy: 0.6413 - val_loss: 0.6262 - val_accuracy: 0.6305\n",
      "Epoch 36/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6105 - accuracy: 0.6479 - val_loss: 0.6303 - val_accuracy: 0.6283\n",
      "Epoch 37/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6142 - accuracy: 0.6417 - val_loss: 0.6328 - val_accuracy: 0.6243\n",
      "Epoch 38/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6080 - accuracy: 0.6454 - val_loss: 0.6074 - val_accuracy: 0.6647\n",
      "Epoch 39/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6092 - accuracy: 0.6430 - val_loss: 0.6534 - val_accuracy: 0.6077\n",
      "Epoch 40/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6088 - accuracy: 0.6429 - val_loss: 0.6199 - val_accuracy: 0.6286\n",
      "Epoch 41/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6002 - accuracy: 0.6534 - val_loss: 0.6265 - val_accuracy: 0.6117\n",
      "Epoch 42/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5983 - accuracy: 0.6528 - val_loss: 0.6151 - val_accuracy: 0.6400\n",
      "Epoch 43/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5970 - accuracy: 0.6557 - val_loss: 0.6030 - val_accuracy: 0.6442\n",
      "Epoch 44/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5981 - accuracy: 0.6555 - val_loss: 0.6170 - val_accuracy: 0.6445\n",
      "Epoch 45/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5920 - accuracy: 0.6609 - val_loss: 0.6104 - val_accuracy: 0.6488\n",
      "Epoch 46/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5890 - accuracy: 0.6623 - val_loss: 0.6047 - val_accuracy: 0.6413\n",
      "Epoch 47/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5912 - accuracy: 0.6646 - val_loss: 0.6007 - val_accuracy: 0.6722\n",
      "Epoch 48/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5845 - accuracy: 0.6679 - val_loss: 0.6008 - val_accuracy: 0.6660\n",
      "Epoch 49/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5862 - accuracy: 0.6692 - val_loss: 0.6030 - val_accuracy: 0.6585\n",
      "Epoch 50/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5825 - accuracy: 0.6650 - val_loss: 0.6016 - val_accuracy: 0.6504\n",
      "Epoch 51/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5823 - accuracy: 0.6698 - val_loss: 0.6304 - val_accuracy: 0.6354\n",
      "Epoch 52/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5788 - accuracy: 0.6757 - val_loss: 0.6097 - val_accuracy: 0.6654\n",
      "Epoch 53/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5773 - accuracy: 0.6740 - val_loss: 0.5835 - val_accuracy: 0.6738\n",
      "Epoch 54/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5763 - accuracy: 0.6720 - val_loss: 0.6521 - val_accuracy: 0.6061\n",
      "Epoch 55/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5747 - accuracy: 0.6757 - val_loss: 0.5902 - val_accuracy: 0.6761\n",
      "Epoch 56/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5745 - accuracy: 0.6734 - val_loss: 0.6300 - val_accuracy: 0.6237\n",
      "Epoch 57/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5726 - accuracy: 0.6765 - val_loss: 0.5717 - val_accuracy: 0.6865\n",
      "Epoch 58/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5685 - accuracy: 0.6794 - val_loss: 0.6186 - val_accuracy: 0.6312\n",
      "Epoch 59/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5653 - accuracy: 0.6819 - val_loss: 0.5712 - val_accuracy: 0.6833\n",
      "Epoch 60/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5614 - accuracy: 0.6866 - val_loss: 0.6032 - val_accuracy: 0.6478\n",
      "Epoch 61/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5647 - accuracy: 0.6840 - val_loss: 0.6254 - val_accuracy: 0.6549\n",
      "Epoch 62/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5626 - accuracy: 0.6870 - val_loss: 0.5727 - val_accuracy: 0.6787\n",
      "Epoch 63/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5583 - accuracy: 0.6895 - val_loss: 0.6063 - val_accuracy: 0.6628\n",
      "Epoch 64/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5632 - accuracy: 0.6838 - val_loss: 0.5860 - val_accuracy: 0.6774\n",
      "Epoch 65/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5615 - accuracy: 0.6844 - val_loss: 0.6400 - val_accuracy: 0.6224\n",
      "Epoch 66/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5521 - accuracy: 0.6951 - val_loss: 0.5902 - val_accuracy: 0.6540\n",
      "Epoch 67/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5576 - accuracy: 0.6905 - val_loss: 0.5742 - val_accuracy: 0.6764\n",
      "Epoch 68/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5505 - accuracy: 0.6945 - val_loss: 0.5885 - val_accuracy: 0.6709\n",
      "Epoch 69/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5525 - accuracy: 0.6937 - val_loss: 0.5437 - val_accuracy: 0.6986\n",
      "Epoch 70/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5483 - accuracy: 0.6983 - val_loss: 0.5598 - val_accuracy: 0.6816\n",
      "Epoch 71/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5478 - accuracy: 0.6975 - val_loss: 0.5597 - val_accuracy: 0.6813\n",
      "Epoch 72/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5440 - accuracy: 0.6964 - val_loss: 0.5802 - val_accuracy: 0.6657\n",
      "Epoch 73/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5422 - accuracy: 0.7008 - val_loss: 0.6498 - val_accuracy: 0.6084\n",
      "Epoch 74/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5369 - accuracy: 0.7045 - val_loss: 0.5507 - val_accuracy: 0.6898\n",
      "Epoch 75/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5360 - accuracy: 0.7087 - val_loss: 0.5728 - val_accuracy: 0.6787\n",
      "Epoch 76/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5353 - accuracy: 0.7044 - val_loss: 0.5492 - val_accuracy: 0.6852\n",
      "Epoch 77/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5330 - accuracy: 0.7069 - val_loss: 0.5372 - val_accuracy: 0.6989\n",
      "Epoch 78/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5429 - accuracy: 0.7016 - val_loss: 0.5520 - val_accuracy: 0.6973\n",
      "Epoch 79/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5319 - accuracy: 0.7089 - val_loss: 0.6013 - val_accuracy: 0.6497\n",
      "Epoch 80/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5324 - accuracy: 0.7075 - val_loss: 0.5577 - val_accuracy: 0.6846\n",
      "Epoch 81/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5283 - accuracy: 0.7135 - val_loss: 0.5532 - val_accuracy: 0.6787\n",
      "Epoch 82/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5282 - accuracy: 0.7095 - val_loss: 0.5392 - val_accuracy: 0.6963\n",
      "Epoch 83/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5321 - accuracy: 0.7079 - val_loss: 0.5614 - val_accuracy: 0.6947\n",
      "Epoch 84/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5196 - accuracy: 0.7176 - val_loss: 0.5459 - val_accuracy: 0.6901\n",
      "Epoch 85/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5233 - accuracy: 0.7130 - val_loss: 0.5443 - val_accuracy: 0.7028\n",
      "Epoch 86/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5183 - accuracy: 0.7230 - val_loss: 0.5714 - val_accuracy: 0.6862\n",
      "Epoch 87/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5180 - accuracy: 0.7170 - val_loss: 0.5634 - val_accuracy: 0.6862\n",
      "Epoch 88/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5197 - accuracy: 0.7160 - val_loss: 0.5437 - val_accuracy: 0.6833\n",
      "Epoch 89/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5206 - accuracy: 0.7165 - val_loss: 0.5342 - val_accuracy: 0.6940\n",
      "Epoch 90/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5124 - accuracy: 0.7207 - val_loss: 0.5628 - val_accuracy: 0.6891\n",
      "Epoch 91/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5065 - accuracy: 0.7254 - val_loss: 0.5704 - val_accuracy: 0.6686\n",
      "Epoch 92/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5165 - accuracy: 0.7206 - val_loss: 0.6094 - val_accuracy: 0.6699\n",
      "Epoch 93/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5047 - accuracy: 0.7268 - val_loss: 0.6372 - val_accuracy: 0.6764\n",
      "Epoch 94/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5033 - accuracy: 0.7308 - val_loss: 0.5341 - val_accuracy: 0.6878\n",
      "Epoch 95/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5036 - accuracy: 0.7262 - val_loss: 0.5935 - val_accuracy: 0.6742\n",
      "Epoch 96/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5017 - accuracy: 0.7293 - val_loss: 0.5349 - val_accuracy: 0.7080\n",
      "Epoch 97/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5052 - accuracy: 0.7301 - val_loss: 0.5316 - val_accuracy: 0.7194\n",
      "Epoch 98/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5024 - accuracy: 0.7293 - val_loss: 0.5421 - val_accuracy: 0.7038\n",
      "Epoch 99/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5025 - accuracy: 0.7330 - val_loss: 0.5646 - val_accuracy: 0.6693\n",
      "Epoch 100/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5068 - accuracy: 0.7247 - val_loss: 0.5424 - val_accuracy: 0.6891\n",
      "Epoch 101/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5046 - accuracy: 0.7300 - val_loss: 0.5568 - val_accuracy: 0.6794\n",
      "Epoch 102/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4978 - accuracy: 0.7317 - val_loss: 0.5178 - val_accuracy: 0.7194\n",
      "Epoch 103/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4923 - accuracy: 0.7365 - val_loss: 0.5429 - val_accuracy: 0.6969\n",
      "Epoch 104/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4971 - accuracy: 0.7360 - val_loss: 0.5381 - val_accuracy: 0.7087\n",
      "Epoch 105/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4897 - accuracy: 0.7418 - val_loss: 0.5292 - val_accuracy: 0.7064ss: 0.4900 - accuracy: 0.736 - ETA: 11s - loss: 0.4890 - accuracy: 0.734 - ETA: 11s - loss: 0.4903 - - E - ETA: 0s - loss: 0.4911  - ETA: 0s - loss: 0.4898 - ac\n",
      "Epoch 106/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4888 - accuracy: 0.7422 - val_loss: 0.5292 - val_accuracy: 0.7113\n",
      "Epoch 107/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4966 - accuracy: 0.7364 - val_loss: 0.5049 - val_accuracy: 0.7383TA: 12s - loss: 0 - ETA: 0s - loss: 0.4966 - accuracy: 0.73\n",
      "Epoch 108/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4801 - accuracy: 0.7478 - val_loss: 0.5180 - val_accuracy: 0.7178 8s - loss: 0 - ETA: 7s - loss:\n",
      "Epoch 109/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4924 - accuracy: 0.7370 - val_loss: 0.5292 - val_accuracy: 0.7139\n",
      "Epoch 110/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4802 - accuracy: 0.7476 - val_loss: 0.4998 - val_accuracy: 0.7220\n",
      "Epoch 111/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4818 - accuracy: 0.7457 - val_loss: 0.5249 - val_accuracy: 0.7292\n",
      "Epoch 112/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4809 - accuracy: 0.7502 - val_loss: 0.5464 - val_accuracy: 0.7005 0.4790 - accuracy:  - ETA - ETA: 1s - - ETA: 0s - loss: 0.481\n",
      "Epoch 113/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4728 - accuracy: 0.7534 - val_loss: 0.5053 - val_accuracy: 0.7031\n",
      "Epoch 114/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4857 - accuracy: 0.7413 - val_loss: 0.5655 - val_accuracy: 0.7005\n",
      "Epoch 115/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4708 - accuracy: 0.7549 - val_loss: 0.5252 - val_accuracy: 0.7184\n",
      "Epoch 116/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4794 - accuracy: 0.7501 - val_loss: 0.5237 - val_accuracy: 0.7096 ETA: 0s - loss: 0.4776 - \n",
      "Epoch 117/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4836 - accuracy: 0.7446 - val_loss: 0.5713 - val_accuracy: 0.6507\n",
      "Epoch 118/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4763 - accuracy: 0.7544 - val_loss: 0.5249 - val_accuracy: 0.7214\n",
      "Epoch 119/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4876 - accuracy: 0.7445 - val_loss: 0.6144 - val_accuracy: 0.6797 0.4876  - ETA: 1s - loss: 0.4876 - accura - ETA\n",
      "Epoch 120/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4780 - accuracy: 0.7542 - val_loss: 0.6401 - val_accuracy: 0.6709\n",
      "Epoch 121/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4771 - accuracy: 0.7544 - val_loss: 0.5328 - val_accuracy: 0.7100\n",
      "Epoch 122/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4744 - accuracy: 0.7545 - val_loss: 0.5601 - val_accuracy: 0.7051\n",
      "Epoch 123/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4650 - accuracy: 0.7591 - val_loss: 0.5323 - val_accuracy: 0.7191\n",
      "Epoch 124/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4645 - accuracy: 0.7614 - val_loss: 0.5004 - val_accuracy: 0.7474\n",
      "Epoch 125/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4740 - accuracy: 0.7529 - val_loss: 0.5261 - val_accuracy: 0.6908\n",
      "Epoch 126/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4678 - accuracy: 0.7550 - val_loss: 0.5823 - val_accuracy: 0.6882accura - ETA:  - E\n",
      "Epoch 127/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4613 - accuracy: 0.7627 - val_loss: 0.5325 - val_accuracy: 0.7083\n",
      "Epoch 128/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4677 - accuracy: 0.7598 - val_loss: 0.5642 - val_accuracy: 0.7116\n",
      "Epoch 129/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4624 - accuracy: 0.7647 - val_loss: 0.6050 - val_accuracy: 0.6689\n",
      "Epoch 130/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4569 - accuracy: 0.7649 - val_loss: 0.5139 - val_accuracy: 0.7197\n",
      "Epoch 131/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4606 - accuracy: 0.7646 - val_loss: 0.6036 - val_accuracy: 0.6576\n",
      "Epoch 132/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4596 - accuracy: 0.7658 - val_loss: 0.5457 - val_accuracy: 0.7093\n",
      "Epoch 133/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4517 - accuracy: 0.7700 - val_loss: 0.5087 - val_accuracy: 0.7409 0.4558 - accuracy - ETA - ETA: 1s - loss: 0.4530 - ac - ETA: 0s - loss: 0.4530 - ac - ETA: 0s - loss: 0.4519 - ac\n",
      "Epoch 134/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4605 - accuracy: 0.7620 - val_loss: 0.5471 - val_accuracy: 0.7061.4560 - accu - ETA:  - ETA: 5s - loss: 0.4551 - accuracy:  - ETA: 5s - loss: - ETA: 4s - loss: 0.4548  - ETA:  - ETA: 0s - loss: 0.4\n",
      "Epoch 135/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4517 - accuracy: 0.7678 - val_loss: 0.4962 - val_accuracy: 0.74092s - l - ETA: 1s - loss: - ETA: 1s - loss: 0.4511 - accuracy: 0.76 - ETA: \n",
      "Epoch 136/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4615 - accuracy: 0.7626 - val_loss: 0.5263 - val_accuracy: 0.70963 - accu - ETA: 0s - loss: 0.4616 - accuracy: 0.76\n",
      "Epoch 137/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4524 - accuracy: 0.7691 - val_loss: 0.4984 - val_accuracy: 0.72790s - loss: 0.4523 - accuracy: \n",
      "Epoch 138/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4495 - accuracy: 0.7703 - val_loss: 0.5151 - val_accuracy: 0.7210\n",
      "Epoch 139/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4471 - accuracy: 0.7714 - val_loss: 0.5356 - val_accuracy: 0.7002TA: 1s - loss: 0.4454 - ac - ETA\n",
      "Epoch 140/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4446 - accuracy: 0.7726 - val_loss: 0.5718 - val_accuracy: 0.7061\n",
      "Epoch 141/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4467 - accuracy: 0.7753 - val_loss: 0.5650 - val_accuracy: 0.7067\n",
      "Epoch 142/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4455 - accuracy: 0.7742 - val_loss: 0.5203 - val_accuracy: 0.7191\n",
      "Epoch 143/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4385 - accuracy: 0.7757 - val_loss: 0.4920 - val_accuracy: 0.7451loss: 0 - ETA: 7s - loss: 0.4351 - ac - ETA: 7s - loss: 0.4 - ETA: 6s - loss: 0 - ETA: 4s - loss: - ETA\n",
      "Epoch 144/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4387 - accuracy: 0.7798 - val_loss: 0.5157 - val_accuracy: 0.7334\n",
      "Epoch 145/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4418 - accuracy: 0.7759 - val_loss: 0.5253 - val_accuracy: 0.7256\n",
      "Epoch 146/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4416 - accuracy: 0.7764 - val_loss: 0.5166 - val_accuracy: 0.7347\n",
      "Epoch 147/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4333 - accuracy: 0.7832 - val_loss: 0.4918 - val_accuracy: 0.7507 loss:\n",
      "Epoch 148/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4404 - accuracy: 0.7779 - val_loss: 0.6904 - val_accuracy: 0.640374 - accuracy: - ETA: 10s - ETA: 2s - loss: 0.4391 -  - ETA: 2s - loss: 0\n",
      "Epoch 149/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4335 - accuracy: 0.7825 - val_loss: 0.5438 - val_accuracy: 0.7184\n",
      "Epoch 150/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4333 - accuracy: 0.7826 - val_loss: 0.4742 - val_accuracy: 0.7516\n",
      "Epoch 151/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4249 - accuracy: 0.7877 - val_loss: 0.4905 - val_accuracy: 0.7562\n",
      "Epoch 152/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4334 - accuracy: 0.7822 - val_loss: 0.5970 - val_accuracy: 0.6826\n",
      "Epoch 153/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4313 - accuracy: 0.7831 - val_loss: 0.5842 - val_accuracy: 0.6719\n",
      "Epoch 154/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4318 - accuracy: 0.7838 - val_loss: 0.4942 - val_accuracy: 0.7409\n",
      "Epoch 155/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4234 - accuracy: 0.7877 - val_loss: 0.5587 - val_accuracy: 0.7230\n",
      "Epoch 156/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4242 - accuracy: 0.7901 - val_loss: 0.4802 - val_accuracy: 0.7292 - ETA: 6s - loss: 0.4170 -  - ETA: \n",
      "Epoch 157/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4155 - accuracy: 0.7928 - val_loss: 0.7246 - val_accuracy: 0.6374\n",
      "Epoch 158/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4258 - accuracy: 0.7838 - val_loss: 0.5491 - val_accuracy: 0.7077\n",
      "Epoch 159/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4214 - accuracy: 0.7898 - val_loss: 0.5080 - val_accuracy: 0.7441racy: \n",
      "Epoch 160/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4229 - accuracy: 0.7873 - val_loss: 0.5129 - val_accuracy: 0.7354\n",
      "Epoch 161/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4200 - accuracy: 0.7897 - val_loss: 0.4768 - val_accuracy: 0.7396s: 0\n",
      "Epoch 162/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4134 - accuracy: 0.7976 - val_loss: 0.4967 - val_accuracy: 0.7451\n",
      "Epoch 163/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4113 - accuracy: 0.7948 - val_loss: 0.5587 - val_accuracy: 0.7054\n",
      "Epoch 164/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4017 - accuracy: 0.8016 - val_loss: 0.4904 - val_accuracy: 0.74580s - loss: 0.4015 - accuracy: 0.80\n",
      "Epoch 165/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4062 - accuracy: 0.8009 - val_loss: 0.4923 - val_accuracy: 0.7344\n",
      "Epoch 166/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4087 - accuracy: 0.7984 - val_loss: 0.5849 - val_accuracy: 0.7074oss: 0.4 - ETA: 0s - loss: 0.4086 - accuracy: 0.79 - ETA: 0s - loss: 0.4084 - \n",
      "Epoch 167/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4129 - accuracy: 0.7983 - val_loss: 0.5031 - val_accuracy: 0.7445\n",
      "Epoch 168/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4008 - accuracy: 0.8043 - val_loss: 0.6115 - val_accuracy: 0.7139\n",
      "Epoch 169/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4062 - accuracy: 0.7966 - val_loss: 0.5283 - val_accuracy: 0.7435\n",
      "Epoch 170/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4018 - accuracy: 0.8050 - val_loss: 0.4935 - val_accuracy: 0.7458\n",
      "Epoch 171/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3934 - accuracy: 0.8081 - val_loss: 0.6275 - val_accuracy: 0.6999\n",
      "Epoch 172/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4005 - accuracy: 0.8036 - val_loss: 0.4952 - val_accuracy: 0.7386\n",
      "Epoch 173/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3992 - accuracy: 0.8055 - val_loss: 0.6599 - val_accuracy: 0.6348\n",
      "Epoch 174/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4004 - accuracy: 0.8042 - val_loss: 0.5482 - val_accuracy: 0.71970 - accuracy: 0. - ETA: 1s - loss: 0.4016 - accu - ETA: 1s - loss: 0.4002 - accu -\n",
      "Epoch 175/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3945 - accuracy: 0.8079 - val_loss: 0.4787 - val_accuracy: 0.7480\n",
      "Epoch 176/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.3991 - accuracy: 0.8065 - val_loss: 0.5282 - val_accuracy: 0.7129\n",
      "Epoch 177/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.3912 - accuracy: 0.8073 - val_loss: 0.5452 - val_accuracy: 0.7168\n",
      "Epoch 178/1200\n",
      "438/438 [==============================] - 15s 35ms/step - loss: 0.3853 - accuracy: 0.8145 - val_loss: 0.5329 - val_accuracy: 0.7399\n",
      "Epoch 179/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3891 - accuracy: 0.8127 - val_loss: 0.4824 - val_accuracy: 0.754957 - accuracy: 0.81 - ETA: 6s - loss: 0.3860 - accuracy: 0.81 - ETA: 6s - loss:\n",
      "Epoch 180/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3895 - accuracy: 0.8109 - val_loss: 0.4938 - val_accuracy: 0.7464\n",
      "Epoch 181/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3832 - accuracy: 0.8139 - val_loss: 0.5255 - val_accuracy: 0.7347\n",
      "Epoch 182/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3827 - accuracy: 0.8190 - val_loss: 0.5735 - val_accuracy: 0.7077\n",
      "Epoch 183/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3887 - accuracy: 0.8115 - val_loss: 0.5693 - val_accuracy: 0.7090\n",
      "Epoch 184/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3796 - accuracy: 0.8162 - val_loss: 0.5084 - val_accuracy: 0.7546\n",
      "Epoch 185/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3773 - accuracy: 0.8140 - val_loss: 0.5171 - val_accuracy: 0.7380\n",
      "Epoch 186/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3888 - accuracy: 0.8113 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
      "Epoch 187/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3713 - accuracy: 0.8205 - val_loss: 0.5064 - val_accuracy: 0.7451\n",
      "Epoch 188/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3710 - accuracy: 0.8225 - val_loss: 0.5107 - val_accuracy: 0.7259\n",
      "Epoch 189/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3772 - accuracy: 0.8151 - val_loss: 0.4395 - val_accuracy: 0.7969\n",
      "Epoch 190/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3740 - accuracy: 0.8231 - val_loss: 0.6293 - val_accuracy: 0.6751\n",
      "Epoch 191/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3694 - accuracy: 0.8239 - val_loss: 0.4987 - val_accuracy: 0.7354\n",
      "Epoch 192/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3682 - accuracy: 0.8237 - val_loss: 0.6115 - val_accuracy: 0.6803\n",
      "Epoch 193/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3676 - accuracy: 0.8250 - val_loss: 0.4858 - val_accuracy: 0.7464\n",
      "Epoch 194/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3669 - accuracy: 0.8238 - val_loss: 0.4540 - val_accuracy: 0.7702\n",
      "Epoch 195/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3661 - accuracy: 0.8241 - val_loss: 0.4609 - val_accuracy: 0.7764\n",
      "Epoch 196/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3688 - accuracy: 0.8226 - val_loss: 0.5577 - val_accuracy: 0.7194\n",
      "Epoch 197/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3653 - accuracy: 0.8263 - val_loss: 0.4932 - val_accuracy: 0.7383\n",
      "Epoch 198/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3610 - accuracy: 0.8261 - val_loss: 0.5407 - val_accuracy: 0.7318\n",
      "Epoch 199/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3613 - accuracy: 0.8287 - val_loss: 0.5179 - val_accuracy: 0.7389\n",
      "Epoch 200/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3573 - accuracy: 0.8315 - val_loss: 0.4848 - val_accuracy: 0.7562\n",
      "Epoch 201/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3578 - accuracy: 0.8279 - val_loss: 0.5085 - val_accuracy: 0.7640\n",
      "Epoch 202/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3536 - accuracy: 0.8323 - val_loss: 0.6429 - val_accuracy: 0.7129\n",
      "Epoch 203/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3512 - accuracy: 0.8319 - val_loss: 0.4757 - val_accuracy: 0.7581\n",
      "Epoch 204/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3567 - accuracy: 0.8290 - val_loss: 0.6022 - val_accuracy: 0.6976\n",
      "Epoch 205/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3394 - accuracy: 0.8414 - val_loss: 0.5127 - val_accuracy: 0.7409\n",
      "Epoch 206/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3445 - accuracy: 0.8375 - val_loss: 0.5627 - val_accuracy: 0.7438\n",
      "Epoch 207/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3500 - accuracy: 0.8345 - val_loss: 0.6292 - val_accuracy: 0.7018\n",
      "Epoch 208/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3464 - accuracy: 0.8372 - val_loss: 0.5181 - val_accuracy: 0.7373\n",
      "Epoch 209/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3506 - accuracy: 0.8349 - val_loss: 0.4812 - val_accuracy: 0.7513\n",
      "Epoch 210/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3409 - accuracy: 0.8390 - val_loss: 0.4788 - val_accuracy: 0.7578\n",
      "Epoch 211/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3424 - accuracy: 0.8377 - val_loss: 0.6291 - val_accuracy: 0.7282\n",
      "Epoch 212/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3443 - accuracy: 0.8371 - val_loss: 0.7344 - val_accuracy: 0.6562\n",
      "Epoch 213/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3414 - accuracy: 0.8413 - val_loss: 0.4783 - val_accuracy: 0.7725\n",
      "Epoch 214/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3476 - accuracy: 0.8371 - val_loss: 0.5130 - val_accuracy: 0.7601\n",
      "Epoch 215/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3429 - accuracy: 0.8383 - val_loss: 0.4778 - val_accuracy: 0.7643\n",
      "Epoch 216/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3380 - accuracy: 0.8416 - val_loss: 0.4728 - val_accuracy: 0.7614\n",
      "Epoch 217/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3439 - accuracy: 0.8386 - val_loss: 0.4913 - val_accuracy: 0.7471\n",
      "Epoch 218/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3407 - accuracy: 0.8385 - val_loss: 0.6036 - val_accuracy: 0.7142\n",
      "Epoch 219/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3440 - accuracy: 0.8369 - val_loss: 0.4391 - val_accuracy: 0.7917\n",
      "Epoch 220/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3258 - accuracy: 0.8448 - val_loss: 0.5852 - val_accuracy: 0.7295\n",
      "Epoch 221/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3322 - accuracy: 0.8455 - val_loss: 0.4976 - val_accuracy: 0.7334\n",
      "Epoch 222/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3315 - accuracy: 0.8455 - val_loss: 0.4877 - val_accuracy: 0.7695\n",
      "Epoch 223/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3367 - accuracy: 0.8444 - val_loss: 0.6298 - val_accuracy: 0.7103\n",
      "Epoch 224/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3275 - accuracy: 0.8487 - val_loss: 0.5447 - val_accuracy: 0.7471\n",
      "Epoch 225/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3276 - accuracy: 0.8468 - val_loss: 0.4837 - val_accuracy: 0.7770\n",
      "Epoch 226/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3273 - accuracy: 0.8502 - val_loss: 0.5841 - val_accuracy: 0.7253\n",
      "Epoch 227/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3368 - accuracy: 0.8435 - val_loss: 0.4663 - val_accuracy: 0.7559\n",
      "Epoch 228/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3273 - accuracy: 0.8497 - val_loss: 0.5145 - val_accuracy: 0.7614\n",
      "Epoch 229/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3206 - accuracy: 0.8515 - val_loss: 0.5696 - val_accuracy: 0.7344\n",
      "Epoch 230/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3243 - accuracy: 0.8504 - val_loss: 0.4940 - val_accuracy: 0.7630\n",
      "Epoch 231/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3231 - accuracy: 0.8509 - val_loss: 0.4976 - val_accuracy: 0.7633\n",
      "Epoch 232/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3261 - accuracy: 0.8482 - val_loss: 0.4694 - val_accuracy: 0.7617\n",
      "Epoch 233/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3247 - accuracy: 0.8453 - val_loss: 0.5281 - val_accuracy: 0.7419\n",
      "Epoch 234/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3247 - accuracy: 0.8494 - val_loss: 0.5003 - val_accuracy: 0.7653\n",
      "Epoch 235/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3169 - accuracy: 0.8539 - val_loss: 0.4977 - val_accuracy: 0.7588\n",
      "Epoch 236/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3138 - accuracy: 0.8541 - val_loss: 0.4722 - val_accuracy: 0.7770\n",
      "Epoch 237/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3033 - accuracy: 0.8611 - val_loss: 0.5089 - val_accuracy: 0.7682\n",
      "Epoch 238/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3066 - accuracy: 0.8573 - val_loss: 0.4876 - val_accuracy: 0.7699\n",
      "Epoch 239/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3083 - accuracy: 0.8589 - val_loss: 0.5391 - val_accuracy: 0.7311\n",
      "Epoch 240/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3169 - accuracy: 0.8538 - val_loss: 0.4626 - val_accuracy: 0.7816\n",
      "Epoch 241/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3071 - accuracy: 0.8570 - val_loss: 0.5578 - val_accuracy: 0.7471\n",
      "Epoch 242/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3051 - accuracy: 0.8569 - val_loss: 0.5192 - val_accuracy: 0.7402\n",
      "Epoch 243/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3137 - accuracy: 0.8546 - val_loss: 0.5980 - val_accuracy: 0.7155\n",
      "Epoch 244/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3027 - accuracy: 0.8631 - val_loss: 0.5005 - val_accuracy: 0.7633\n",
      "Epoch 245/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3062 - accuracy: 0.8573 - val_loss: 0.4876 - val_accuracy: 0.7646\n",
      "Epoch 246/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2991 - accuracy: 0.8622 - val_loss: 0.5414 - val_accuracy: 0.7415\n",
      "Epoch 247/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2936 - accuracy: 0.8666 - val_loss: 0.6071 - val_accuracy: 0.7324\n",
      "Epoch 248/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3018 - accuracy: 0.8643 - val_loss: 0.5539 - val_accuracy: 0.7406\n",
      "Epoch 249/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3059 - accuracy: 0.8581 - val_loss: 0.4892 - val_accuracy: 0.7702\n",
      "Epoch 250/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3135 - accuracy: 0.8545 - val_loss: 0.5933 - val_accuracy: 0.7103\n",
      "Epoch 251/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2894 - accuracy: 0.8682 - val_loss: 0.4654 - val_accuracy: 0.7793\n",
      "Epoch 252/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2949 - accuracy: 0.8672 - val_loss: 0.5605 - val_accuracy: 0.7454\n",
      "Epoch 253/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2913 - accuracy: 0.8685 - val_loss: 0.4781 - val_accuracy: 0.7747\n",
      "Epoch 254/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2984 - accuracy: 0.8633 - val_loss: 0.5221 - val_accuracy: 0.7526\n",
      "Epoch 255/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2962 - accuracy: 0.8677 - val_loss: 0.4953 - val_accuracy: 0.7728\n",
      "Epoch 256/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2882 - accuracy: 0.8704 - val_loss: 0.5037 - val_accuracy: 0.7669\n",
      "Epoch 257/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2797 - accuracy: 0.8749 - val_loss: 0.5422 - val_accuracy: 0.7598\n",
      "Epoch 258/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2774 - accuracy: 0.8759 - val_loss: 0.5517 - val_accuracy: 0.7461\n",
      "Epoch 259/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2946 - accuracy: 0.8665 - val_loss: 0.4972 - val_accuracy: 0.7660\n",
      "Epoch 260/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2864 - accuracy: 0.8680 - val_loss: 0.5303 - val_accuracy: 0.7686\n",
      "Epoch 261/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2890 - accuracy: 0.8680 - val_loss: 0.6340 - val_accuracy: 0.7373\n",
      "Epoch 262/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2802 - accuracy: 0.8734 - val_loss: 0.6087 - val_accuracy: 0.7464\n",
      "Epoch 263/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2900 - accuracy: 0.8694 - val_loss: 0.5945 - val_accuracy: 0.7288\n",
      "Epoch 264/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2773 - accuracy: 0.8762 - val_loss: 0.4991 - val_accuracy: 0.7679\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00264: early stopping\n",
      "      1/Unknown - 0s 109ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121/3121 [==============================] - 14s 5ms/step\n",
      "347/347 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|       | 9/10 [12:01:31<1:20:49, 4849.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6914 - accuracy: 0.5332 - val_loss: 0.6921 - val_accuracy: 0.4954\n",
      "Epoch 2/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6858 - accuracy: 0.5554 - val_loss: 0.6928 - val_accuracy: 0.5124\n",
      "Epoch 3/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6798 - accuracy: 0.5603 - val_loss: 0.6926 - val_accuracy: 0.5055\n",
      "Epoch 4/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6734 - accuracy: 0.5627 - val_loss: 0.6849 - val_accuracy: 0.5124\n",
      "Epoch 5/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6680 - accuracy: 0.5729 - val_loss: 0.6855 - val_accuracy: 0.5505\n",
      "Epoch 6/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6677 - accuracy: 0.5686 - val_loss: 0.6974 - val_accuracy: 0.5384\n",
      "Epoch 7/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6648 - accuracy: 0.5742 - val_loss: 0.6938 - val_accuracy: 0.5361\n",
      "Epoch 8/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6637 - accuracy: 0.5779 - val_loss: 0.6917 - val_accuracy: 0.5612\n",
      "Epoch 9/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6591 - accuracy: 0.5814 - val_loss: 0.6825 - val_accuracy: 0.5449\n",
      "Epoch 10/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6603 - accuracy: 0.5794 - val_loss: 0.6844 - val_accuracy: 0.5654\n",
      "Epoch 11/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6592 - accuracy: 0.5863 - val_loss: 0.6853 - val_accuracy: 0.5312\n",
      "Epoch 12/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6572 - accuracy: 0.5898 - val_loss: 0.6953 - val_accuracy: 0.5290\n",
      "Epoch 13/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6537 - accuracy: 0.5921 - val_loss: 0.6989 - val_accuracy: 0.5127\n",
      "Epoch 14/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6555 - accuracy: 0.5899 - val_loss: 0.7003 - val_accuracy: 0.5218\n",
      "Epoch 15/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6562 - accuracy: 0.5889 - val_loss: 0.7077 - val_accuracy: 0.5202\n",
      "Epoch 16/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6517 - accuracy: 0.5940 - val_loss: 0.6874 - val_accuracy: 0.5378\n",
      "Epoch 17/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6494 - accuracy: 0.5991 - val_loss: 0.6881 - val_accuracy: 0.5417\n",
      "Epoch 18/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6497 - accuracy: 0.6023 - val_loss: 0.6876 - val_accuracy: 0.5107\n",
      "Epoch 19/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6505 - accuracy: 0.5982 - val_loss: 0.6826 - val_accuracy: 0.5446\n",
      "Epoch 20/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6484 - accuracy: 0.5988 - val_loss: 0.6745 - val_accuracy: 0.5524\n",
      "Epoch 21/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6482 - accuracy: 0.6013 - val_loss: 0.6757 - val_accuracy: 0.5527\n",
      "Epoch 22/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6442 - accuracy: 0.6081 - val_loss: 0.6811 - val_accuracy: 0.5277\n",
      "Epoch 23/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6457 - accuracy: 0.6012 - val_loss: 0.6715 - val_accuracy: 0.5736\n",
      "Epoch 24/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6443 - accuracy: 0.6038 - val_loss: 0.6802 - val_accuracy: 0.5384\n",
      "Epoch 25/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6455 - accuracy: 0.6011 - val_loss: 0.6847 - val_accuracy: 0.5371\n",
      "Epoch 26/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6435 - accuracy: 0.6073 - val_loss: 0.7079 - val_accuracy: 0.5065\n",
      "Epoch 27/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6419 - accuracy: 0.6099 - val_loss: 0.6672 - val_accuracy: 0.5378\n",
      "Epoch 28/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6393 - accuracy: 0.6111 - val_loss: 0.7004 - val_accuracy: 0.5228\n",
      "Epoch 29/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6415 - accuracy: 0.6090 - val_loss: 0.6834 - val_accuracy: 0.5378\n",
      "Epoch 30/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6369 - accuracy: 0.6142 - val_loss: 0.6561 - val_accuracy: 0.5599\n",
      "Epoch 31/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6364 - accuracy: 0.6132 - val_loss: 0.6817 - val_accuracy: 0.5378\n",
      "Epoch 32/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6351 - accuracy: 0.6156 - val_loss: 0.6814 - val_accuracy: 0.5254\n",
      "Epoch 33/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6314 - accuracy: 0.6196 - val_loss: 0.7075 - val_accuracy: 0.4951\n",
      "Epoch 34/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6322 - accuracy: 0.6203 - val_loss: 0.6802 - val_accuracy: 0.5208\n",
      "Epoch 35/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6293 - accuracy: 0.6190 - val_loss: 0.6907 - val_accuracy: 0.5355\n",
      "Epoch 36/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6300 - accuracy: 0.6196 - val_loss: 0.6808 - val_accuracy: 0.5332\n",
      "Epoch 37/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6265 - accuracy: 0.6262 - val_loss: 0.6747 - val_accuracy: 0.5537\n",
      "Epoch 38/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6266 - accuracy: 0.6219 - val_loss: 0.6810 - val_accuracy: 0.5290\n",
      "Epoch 39/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6273 - accuracy: 0.6197 - val_loss: 0.6761 - val_accuracy: 0.5368\n",
      "Epoch 40/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6231 - accuracy: 0.6272 - val_loss: 0.6684 - val_accuracy: 0.5446\n",
      "Epoch 41/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6242 - accuracy: 0.6257 - val_loss: 0.6904 - val_accuracy: 0.5426\n",
      "Epoch 42/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6240 - accuracy: 0.6267 - val_loss: 0.6565 - val_accuracy: 0.5537\n",
      "Epoch 43/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6229 - accuracy: 0.6202 - val_loss: 0.6484 - val_accuracy: 0.5990\n",
      "Epoch 44/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6217 - accuracy: 0.6256 - val_loss: 0.6639 - val_accuracy: 0.5537\n",
      "Epoch 45/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6174 - accuracy: 0.6305 - val_loss: 0.6475 - val_accuracy: 0.5785\n",
      "Epoch 46/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6167 - accuracy: 0.6278 - val_loss: 0.6779 - val_accuracy: 0.5241\n",
      "Epoch 47/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6162 - accuracy: 0.6320 - val_loss: 0.6266 - val_accuracy: 0.6302\n",
      "Epoch 48/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6148 - accuracy: 0.6291 - val_loss: 0.6760 - val_accuracy: 0.5488\n",
      "Epoch 49/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6167 - accuracy: 0.6315 - val_loss: 0.6779 - val_accuracy: 0.5400\n",
      "Epoch 50/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6116 - accuracy: 0.6341 - val_loss: 0.6528 - val_accuracy: 0.5775\n",
      "Epoch 51/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6134 - accuracy: 0.6316 - val_loss: 0.6687 - val_accuracy: 0.5531\n",
      "Epoch 52/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6126 - accuracy: 0.6294 - val_loss: 0.6730 - val_accuracy: 0.5492\n",
      "Epoch 53/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6106 - accuracy: 0.6329 - val_loss: 0.6927 - val_accuracy: 0.5374\n",
      "Epoch 54/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6095 - accuracy: 0.6347 - val_loss: 0.6409 - val_accuracy: 0.5729\n",
      "Epoch 55/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6041 - accuracy: 0.6415 - val_loss: 0.6560 - val_accuracy: 0.5804\n",
      "Epoch 56/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.6069 - accuracy: 0.6387 - val_loss: 0.6367 - val_accuracy: 0.5993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6035 - accuracy: 0.6454 - val_loss: 0.6388 - val_accuracy: 0.6279\n",
      "Epoch 58/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.6003 - accuracy: 0.6454 - val_loss: 0.6524 - val_accuracy: 0.5654\n",
      "Epoch 59/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5963 - accuracy: 0.6479 - val_loss: 0.7139 - val_accuracy: 0.5277\n",
      "Epoch 60/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.6003 - accuracy: 0.6444 - val_loss: 0.6031 - val_accuracy: 0.6439\n",
      "Epoch 61/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5948 - accuracy: 0.6457 - val_loss: 0.6230 - val_accuracy: 0.6175\n",
      "Epoch 62/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5938 - accuracy: 0.6518 - val_loss: 0.6855 - val_accuracy: 0.5827- accura\n",
      "Epoch 63/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5883 - accuracy: 0.6546 - val_loss: 0.5907 - val_accuracy: 0.6657\n",
      "Epoch 64/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5906 - accuracy: 0.6535 - val_loss: 0.6641 - val_accuracy: 0.5599\n",
      "Epoch 65/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5902 - accuracy: 0.6574 - val_loss: 0.6167 - val_accuracy: 0.6152\n",
      "Epoch 66/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5874 - accuracy: 0.6584 - val_loss: 0.6189 - val_accuracy: 0.6693\n",
      "Epoch 67/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5882 - accuracy: 0.6580 - val_loss: 0.6167 - val_accuracy: 0.6423\n",
      "Epoch 68/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5831 - accuracy: 0.6612 - val_loss: 0.6098 - val_accuracy: 0.6286\n",
      "Epoch 69/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5798 - accuracy: 0.6641 - val_loss: 0.6031 - val_accuracy: 0.6250\n",
      "Epoch 70/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5741 - accuracy: 0.6674 - val_loss: 0.5990 - val_accuracy: 0.6608\n",
      "Epoch 71/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5850 - accuracy: 0.6567 - val_loss: 0.6106 - val_accuracy: 0.6253\n",
      "Epoch 72/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5727 - accuracy: 0.6692 - val_loss: 0.5800 - val_accuracy: 0.6598\n",
      "Epoch 73/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5764 - accuracy: 0.6661 - val_loss: 0.5769 - val_accuracy: 0.6755\n",
      "Epoch 74/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5697 - accuracy: 0.6707 - val_loss: 0.6025 - val_accuracy: 0.6201\n",
      "Epoch 75/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5667 - accuracy: 0.6748 - val_loss: 0.6149 - val_accuracy: 0.6390\n",
      "Epoch 76/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5685 - accuracy: 0.6729 - val_loss: 0.5943 - val_accuracy: 0.6234\n",
      "Epoch 77/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5707 - accuracy: 0.6724 - val_loss: 0.6040 - val_accuracy: 0.6768\n",
      "Epoch 78/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5668 - accuracy: 0.6748 - val_loss: 0.6063 - val_accuracy: 0.6276\n",
      "Epoch 79/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5654 - accuracy: 0.6754 - val_loss: 0.5793 - val_accuracy: 0.6670\n",
      "Epoch 80/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5612 - accuracy: 0.6792 - val_loss: 0.5853 - val_accuracy: 0.6582\n",
      "Epoch 81/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5633 - accuracy: 0.6739 - val_loss: 0.5944 - val_accuracy: 0.6546\n",
      "Epoch 82/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5543 - accuracy: 0.6815 - val_loss: 0.6260 - val_accuracy: 0.5892\n",
      "Epoch 83/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5606 - accuracy: 0.6833 - val_loss: 0.5971 - val_accuracy: 0.6520\n",
      "Epoch 84/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5540 - accuracy: 0.6861 - val_loss: 0.6114 - val_accuracy: 0.6348\n",
      "Epoch 85/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5565 - accuracy: 0.6813 - val_loss: 0.5920 - val_accuracy: 0.6647\n",
      "Epoch 86/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5503 - accuracy: 0.6890 - val_loss: 0.7682 - val_accuracy: 0.5420\n",
      "Epoch 87/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5505 - accuracy: 0.6884 - val_loss: 0.5840 - val_accuracy: 0.6546\n",
      "Epoch 88/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5510 - accuracy: 0.6889 - val_loss: 0.5718 - val_accuracy: 0.6888\n",
      "Epoch 89/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5462 - accuracy: 0.6882 - val_loss: 0.6102 - val_accuracy: 0.6156\n",
      "Epoch 90/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5501 - accuracy: 0.6896 - val_loss: 0.5879 - val_accuracy: 0.6885\n",
      "Epoch 91/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5518 - accuracy: 0.6894 - val_loss: 0.5712 - val_accuracy: 0.6882\n",
      "Epoch 92/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5484 - accuracy: 0.6877 - val_loss: 0.6051 - val_accuracy: 0.6475\n",
      "Epoch 93/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5500 - accuracy: 0.6861 - val_loss: 0.5932 - val_accuracy: 0.6318\n",
      "Epoch 94/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5411 - accuracy: 0.6967 - val_loss: 0.6493 - val_accuracy: 0.6178\n",
      "Epoch 95/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5428 - accuracy: 0.6980 - val_loss: 0.5857 - val_accuracy: 0.6777\n",
      "Epoch 96/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5394 - accuracy: 0.6987 - val_loss: 0.5777 - val_accuracy: 0.6667\n",
      "Epoch 97/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5385 - accuracy: 0.6976 - val_loss: 0.5626 - val_accuracy: 0.6930\n",
      "Epoch 98/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5383 - accuracy: 0.7016 - val_loss: 0.5960 - val_accuracy: 0.6546\n",
      "Epoch 99/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5355 - accuracy: 0.7014 - val_loss: 0.5615 - val_accuracy: 0.6934\n",
      "Epoch 100/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5304 - accuracy: 0.7029 - val_loss: 0.5403 - val_accuracy: 0.7031\n",
      "Epoch 101/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5302 - accuracy: 0.7058 - val_loss: 0.5914 - val_accuracy: 0.6523\n",
      "Epoch 102/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5312 - accuracy: 0.7069 - val_loss: 0.6193 - val_accuracy: 0.6465\n",
      "Epoch 103/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5284 - accuracy: 0.7079 - val_loss: 0.5465 - val_accuracy: 0.6898\n",
      "Epoch 104/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5254 - accuracy: 0.7089 - val_loss: 0.5686 - val_accuracy: 0.6882\n",
      "Epoch 105/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5271 - accuracy: 0.7051 - val_loss: 0.5618 - val_accuracy: 0.6715\n",
      "Epoch 106/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5240 - accuracy: 0.7111 - val_loss: 0.5712 - val_accuracy: 0.6774\n",
      "Epoch 107/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5226 - accuracy: 0.7142 - val_loss: 0.5587 - val_accuracy: 0.6719\n",
      "Epoch 108/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5185 - accuracy: 0.7126 - val_loss: 0.5611 - val_accuracy: 0.6872\n",
      "Epoch 109/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5200 - accuracy: 0.7132 - val_loss: 0.5419 - val_accuracy: 0.6963\n",
      "Epoch 110/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.5213 - accuracy: 0.7126 - val_loss: 0.5516 - val_accuracy: 0.6846\n",
      "Epoch 111/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5219 - accuracy: 0.7144 - val_loss: 0.5344 - val_accuracy: 0.7031\n",
      "Epoch 112/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5121 - accuracy: 0.7206 - val_loss: 0.6450 - val_accuracy: 0.6406\n",
      "Epoch 113/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5166 - accuracy: 0.7165 - val_loss: 0.5765 - val_accuracy: 0.6898\n",
      "Epoch 114/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5178 - accuracy: 0.7170 - val_loss: 0.5720 - val_accuracy: 0.6878\n",
      "Epoch 115/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5106 - accuracy: 0.7209 - val_loss: 0.6213 - val_accuracy: 0.6211\n",
      "Epoch 116/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5131 - accuracy: 0.7205 - val_loss: 0.5971 - val_accuracy: 0.6569\n",
      "Epoch 117/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5094 - accuracy: 0.7184 - val_loss: 0.5580 - val_accuracy: 0.6768\n",
      "Epoch 118/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.5075 - accuracy: 0.7245 - val_loss: 0.5514 - val_accuracy: 0.6914\n",
      "Epoch 119/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5036 - accuracy: 0.7250 - val_loss: 0.5689 - val_accuracy: 0.6901\n",
      "Epoch 120/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5066 - accuracy: 0.7229 - val_loss: 0.5870 - val_accuracy: 0.6507\n",
      "Epoch 121/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5059 - accuracy: 0.7246 - val_loss: 0.5544 - val_accuracy: 0.6673\n",
      "Epoch 122/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5016 - accuracy: 0.7272 - val_loss: 0.6036 - val_accuracy: 0.6390\n",
      "Epoch 123/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5059 - accuracy: 0.7224 - val_loss: 0.5283 - val_accuracy: 0.6921\n",
      "Epoch 124/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.5015 - accuracy: 0.7259 - val_loss: 0.5429 - val_accuracy: 0.7051\n",
      "Epoch 125/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4975 - accuracy: 0.7305 - val_loss: 0.5867 - val_accuracy: 0.6465\n",
      "Epoch 126/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4927 - accuracy: 0.7337 - val_loss: 0.5545 - val_accuracy: 0.7090\n",
      "Epoch 127/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4986 - accuracy: 0.7316 - val_loss: 0.5545 - val_accuracy: 0.6930\n",
      "Epoch 128/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4919 - accuracy: 0.7354 - val_loss: 0.5567 - val_accuracy: 0.6885\n",
      "Epoch 129/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4900 - accuracy: 0.7412 - val_loss: 0.5865 - val_accuracy: 0.6546\n",
      "Epoch 130/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4912 - accuracy: 0.7363 - val_loss: 0.5216 - val_accuracy: 0.7197\n",
      "Epoch 131/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4884 - accuracy: 0.7407 - val_loss: 0.5643 - val_accuracy: 0.6846\n",
      "Epoch 132/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4839 - accuracy: 0.7417 - val_loss: 0.5415 - val_accuracy: 0.6940\n",
      "Epoch 133/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4883 - accuracy: 0.7373 - val_loss: 0.5595 - val_accuracy: 0.6930\n",
      "Epoch 134/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4881 - accuracy: 0.7367 - val_loss: 0.5998 - val_accuracy: 0.6637\n",
      "Epoch 135/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4838 - accuracy: 0.7432 - val_loss: 0.5648 - val_accuracy: 0.7002\n",
      "Epoch 136/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4834 - accuracy: 0.7417 - val_loss: 0.5280 - val_accuracy: 0.7116\n",
      "Epoch 137/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4771 - accuracy: 0.7440 - val_loss: 0.5238 - val_accuracy: 0.7233\n",
      "Epoch 138/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4730 - accuracy: 0.7504 - val_loss: 0.5707 - val_accuracy: 0.6826\n",
      "Epoch 139/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4801 - accuracy: 0.7412 - val_loss: 0.5564 - val_accuracy: 0.7057\n",
      "Epoch 140/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4739 - accuracy: 0.7531 - val_loss: 0.5733 - val_accuracy: 0.7044\n",
      "Epoch 141/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4725 - accuracy: 0.7489 - val_loss: 0.5440 - val_accuracy: 0.7135\n",
      "Epoch 142/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4732 - accuracy: 0.7479 - val_loss: 0.5799 - val_accuracy: 0.6702\n",
      "Epoch 143/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4752 - accuracy: 0.7476 - val_loss: 0.6223 - val_accuracy: 0.6458\n",
      "Epoch 144/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4758 - accuracy: 0.7493 - val_loss: 0.5587 - val_accuracy: 0.7015\n",
      "Epoch 145/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4679 - accuracy: 0.7536 - val_loss: 0.5262 - val_accuracy: 0.7249\n",
      "Epoch 146/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4668 - accuracy: 0.7553 - val_loss: 0.5461 - val_accuracy: 0.7015\n",
      "Epoch 147/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4716 - accuracy: 0.7504 - val_loss: 0.5291 - val_accuracy: 0.7083\n",
      "Epoch 148/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4655 - accuracy: 0.7564 - val_loss: 0.5904 - val_accuracy: 0.6618\n",
      "Epoch 149/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4704 - accuracy: 0.7507 - val_loss: 0.5896 - val_accuracy: 0.6331\n",
      "Epoch 150/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4698 - accuracy: 0.7510 - val_loss: 0.6373 - val_accuracy: 0.6383\n",
      "Epoch 151/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4623 - accuracy: 0.7552 - val_loss: 0.5618 - val_accuracy: 0.6982\n",
      "Epoch 152/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4597 - accuracy: 0.7582 - val_loss: 0.7034 - val_accuracy: 0.6260\n",
      "Epoch 153/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4553 - accuracy: 0.7628 - val_loss: 0.7361 - val_accuracy: 0.6055\n",
      "Epoch 154/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4602 - accuracy: 0.7583 - val_loss: 0.5687 - val_accuracy: 0.6813\n",
      "Epoch 155/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4571 - accuracy: 0.7637 - val_loss: 0.6057 - val_accuracy: 0.6878\n",
      "Epoch 156/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4476 - accuracy: 0.7702 - val_loss: 0.5607 - val_accuracy: 0.7145\n",
      "Epoch 157/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4536 - accuracy: 0.7644 - val_loss: 0.6183 - val_accuracy: 0.6758\n",
      "Epoch 158/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4475 - accuracy: 0.7690 - val_loss: 0.6884 - val_accuracy: 0.6370\n",
      "Epoch 159/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4569 - accuracy: 0.7612 - val_loss: 0.6042 - val_accuracy: 0.6585\n",
      "Epoch 160/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4539 - accuracy: 0.7642 - val_loss: 0.5868 - val_accuracy: 0.6846\n",
      "Epoch 161/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4490 - accuracy: 0.7642 - val_loss: 0.6121 - val_accuracy: 0.6820\n",
      "Epoch 162/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4418 - accuracy: 0.7709 - val_loss: 0.5585 - val_accuracy: 0.7184\n",
      "Epoch 163/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4377 - accuracy: 0.7751 - val_loss: 0.5937 - val_accuracy: 0.6829\n",
      "Epoch 164/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4437 - accuracy: 0.7706 - val_loss: 0.5109 - val_accuracy: 0.7406\n",
      "Epoch 165/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4425 - accuracy: 0.7708 - val_loss: 0.5731 - val_accuracy: 0.7025\n",
      "Epoch 166/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4395 - accuracy: 0.7753 - val_loss: 0.5303 - val_accuracy: 0.7412\n",
      "Epoch 167/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4400 - accuracy: 0.7747 - val_loss: 0.5528 - val_accuracy: 0.7142\n",
      "Epoch 168/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4349 - accuracy: 0.7738 - val_loss: 0.5444 - val_accuracy: 0.7155\n",
      "Epoch 169/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4408 - accuracy: 0.7731 - val_loss: 0.6350 - val_accuracy: 0.6670\n",
      "Epoch 170/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4349 - accuracy: 0.7770 - val_loss: 0.5458 - val_accuracy: 0.7266\n",
      "Epoch 171/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4350 - accuracy: 0.7766 - val_loss: 0.6614 - val_accuracy: 0.6491\n",
      "Epoch 172/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4283 - accuracy: 0.7789 - val_loss: 0.5392 - val_accuracy: 0.7272\n",
      "Epoch 173/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4302 - accuracy: 0.7826 - val_loss: 0.5438 - val_accuracy: 0.7207\n",
      "Epoch 174/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4254 - accuracy: 0.7826 - val_loss: 0.5585 - val_accuracy: 0.6999\n",
      "Epoch 175/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.4369 - accuracy: 0.7763 - val_loss: 0.5405 - val_accuracy: 0.7598\n",
      "Epoch 176/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4286 - accuracy: 0.7812 - val_loss: 0.6233 - val_accuracy: 0.6709\n",
      "Epoch 177/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4205 - accuracy: 0.7892 - val_loss: 0.5265 - val_accuracy: 0.7386\n",
      "Epoch 178/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.6245 - val_accuracy: 0.6784\n",
      "Epoch 179/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4195 - accuracy: 0.7869 - val_loss: 0.5810 - val_accuracy: 0.7233\n",
      "Epoch 180/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4249 - accuracy: 0.7859 - val_loss: 0.5945 - val_accuracy: 0.7122\n",
      "Epoch 181/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4198 - accuracy: 0.7859 - val_loss: 0.6427 - val_accuracy: 0.6654\n",
      "Epoch 182/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4125 - accuracy: 0.7908 - val_loss: 0.5945 - val_accuracy: 0.7217\n",
      "Epoch 183/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4207 - accuracy: 0.7868 - val_loss: 0.5377 - val_accuracy: 0.7318\n",
      "Epoch 184/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4195 - accuracy: 0.7876 - val_loss: 0.5511 - val_accuracy: 0.7275\n",
      "Epoch 185/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4152 - accuracy: 0.7878 - val_loss: 0.5768 - val_accuracy: 0.7087\n",
      "Epoch 186/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4117 - accuracy: 0.7932 - val_loss: 0.5695 - val_accuracy: 0.7171\n",
      "Epoch 187/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4103 - accuracy: 0.7910 - val_loss: 0.6593 - val_accuracy: 0.6969\n",
      "Epoch 188/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4093 - accuracy: 0.7917 - val_loss: 0.5868 - val_accuracy: 0.7132\n",
      "Epoch 189/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4277 - accuracy: 0.7833 - val_loss: 0.5644 - val_accuracy: 0.7188\n",
      "Epoch 190/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4161 - accuracy: 0.7916 - val_loss: 0.6165 - val_accuracy: 0.6911\n",
      "Epoch 191/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4150 - accuracy: 0.7886 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 192/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4234 - accuracy: 0.7866 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
      "Epoch 193/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4159 - accuracy: 0.7899 - val_loss: 0.5690 - val_accuracy: 0.7243\n",
      "Epoch 194/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4122 - accuracy: 0.7898 - val_loss: 0.5960 - val_accuracy: 0.7148\n",
      "Epoch 195/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4039 - accuracy: 0.7954 - val_loss: 0.5520 - val_accuracy: 0.7318\n",
      "Epoch 196/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4046 - accuracy: 0.7963 - val_loss: 0.6074 - val_accuracy: 0.7152\n",
      "Epoch 197/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4013 - accuracy: 0.7990 - val_loss: 0.5829 - val_accuracy: 0.7367\n",
      "Epoch 198/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.4041 - accuracy: 0.7953 - val_loss: 0.6378 - val_accuracy: 0.6829\n",
      "Epoch 199/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3991 - accuracy: 0.8033 - val_loss: 0.7185 - val_accuracy: 0.6387\n",
      "Epoch 200/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3986 - accuracy: 0.8035 - val_loss: 0.6626 - val_accuracy: 0.6774\n",
      "Epoch 201/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3972 - accuracy: 0.8010 - val_loss: 0.6416 - val_accuracy: 0.6849\n",
      "Epoch 202/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3936 - accuracy: 0.8021 - val_loss: 0.5955 - val_accuracy: 0.7334\n",
      "Epoch 203/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3907 - accuracy: 0.8057 - val_loss: 0.6685 - val_accuracy: 0.6647\n",
      "Epoch 204/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.4031 - accuracy: 0.7985 - val_loss: 0.6880 - val_accuracy: 0.6794\n",
      "Epoch 205/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3887 - accuracy: 0.8078 - val_loss: 0.6090 - val_accuracy: 0.7021\n",
      "Epoch 206/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3927 - accuracy: 0.8027 - val_loss: 0.6362 - val_accuracy: 0.7129\n",
      "Epoch 207/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3876 - accuracy: 0.8063 - val_loss: 0.6303 - val_accuracy: 0.7008\n",
      "Epoch 208/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3851 - accuracy: 0.8091 - val_loss: 0.6150 - val_accuracy: 0.7188\n",
      "Epoch 209/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3907 - accuracy: 0.8068 - val_loss: 0.6149 - val_accuracy: 0.7370\n",
      "Epoch 210/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3826 - accuracy: 0.8095 - val_loss: 0.6744 - val_accuracy: 0.6836\n",
      "Epoch 211/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3888 - accuracy: 0.8089 - val_loss: 0.6058 - val_accuracy: 0.7256\n",
      "Epoch 212/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3919 - accuracy: 0.8054 - val_loss: 0.6790 - val_accuracy: 0.6823\n",
      "Epoch 213/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3808 - accuracy: 0.8099 - val_loss: 0.6369 - val_accuracy: 0.6956\n",
      "Epoch 214/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3800 - accuracy: 0.8116 - val_loss: 0.7422 - val_accuracy: 0.6800\n",
      "Epoch 215/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3807 - accuracy: 0.8132 - val_loss: 0.5895 - val_accuracy: 0.7354\n",
      "Epoch 216/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3815 - accuracy: 0.8114 - val_loss: 0.6960 - val_accuracy: 0.6943\n",
      "Epoch 217/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3803 - accuracy: 0.8113 - val_loss: 0.6781 - val_accuracy: 0.6820\n",
      "Epoch 218/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3759 - accuracy: 0.8114 - val_loss: 0.7783 - val_accuracy: 0.6540\n",
      "Epoch 219/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3731 - accuracy: 0.8149 - val_loss: 0.6888 - val_accuracy: 0.7031\n",
      "Epoch 220/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3767 - accuracy: 0.8137 - val_loss: 0.7390 - val_accuracy: 0.6950\n",
      "Epoch 221/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3767 - accuracy: 0.8156 - val_loss: 0.6361 - val_accuracy: 0.7262\n",
      "Epoch 222/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3695 - accuracy: 0.8163 - val_loss: 0.6640 - val_accuracy: 0.6702\n",
      "Epoch 223/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3629 - accuracy: 0.8203 - val_loss: 0.6095 - val_accuracy: 0.7184\n",
      "Epoch 224/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3655 - accuracy: 0.8202 - val_loss: 0.5959 - val_accuracy: 0.7370\n",
      "Epoch 225/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3707 - accuracy: 0.8201 - val_loss: 0.5631 - val_accuracy: 0.7686\n",
      "Epoch 226/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3625 - accuracy: 0.8229 - val_loss: 0.5577 - val_accuracy: 0.7520\n",
      "Epoch 227/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3633 - accuracy: 0.8217 - val_loss: 0.5797 - val_accuracy: 0.7448 - los - ETA: 1s - loss: 0.3641  - ETA: 0s -\n",
      "Epoch 228/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3637 - accuracy: 0.8201 - val_loss: 0.7005 - val_accuracy: 0.6888\n",
      "Epoch 229/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3628 - accuracy: 0.8242 - val_loss: 0.6384 - val_accuracy: 0.7145\n",
      "Epoch 230/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3616 - accuracy: 0.8208 - val_loss: 0.6799 - val_accuracy: 0.7285\n",
      "Epoch 231/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3648 - accuracy: 0.8208 - val_loss: 0.6658 - val_accuracy: 0.7253\n",
      "Epoch 232/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3576 - accuracy: 0.8260 - val_loss: 0.6716 - val_accuracy: 0.7171\n",
      "Epoch 233/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3589 - accuracy: 0.8235 - val_loss: 0.5765 - val_accuracy: 0.7500\n",
      "Epoch 234/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3530 - accuracy: 0.8265 - val_loss: 0.6408 - val_accuracy: 0.7279\n",
      "Epoch 235/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3504 - accuracy: 0.8286 - val_loss: 0.7028 - val_accuracy: 0.7002\n",
      "Epoch 236/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3583 - accuracy: 0.8231 - val_loss: 0.5552 - val_accuracy: 0.7695\n",
      "Epoch 237/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3572 - accuracy: 0.8256 - val_loss: 0.6462 - val_accuracy: 0.6908\n",
      "Epoch 238/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3485 - accuracy: 0.8301 - val_loss: 0.5822 - val_accuracy: 0.7256\n",
      "Epoch 239/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3495 - accuracy: 0.8292 - val_loss: 0.5880 - val_accuracy: 0.7282\n",
      "Epoch 240/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3441 - accuracy: 0.8331 - val_loss: 0.6605 - val_accuracy: 0.7318\n",
      "Epoch 241/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3462 - accuracy: 0.8315 - val_loss: 0.6598 - val_accuracy: 0.6995\n",
      "Epoch 242/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3405 - accuracy: 0.8335 - val_loss: 0.5459 - val_accuracy: 0.7757\n",
      "Epoch 243/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3459 - accuracy: 0.8319 - val_loss: 0.7233 - val_accuracy: 0.6689\n",
      "Epoch 244/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3433 - accuracy: 0.8317 - val_loss: 0.7466 - val_accuracy: 0.6628\n",
      "Epoch 245/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3493 - accuracy: 0.8343 - val_loss: 0.6020 - val_accuracy: 0.7454\n",
      "Epoch 246/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3390 - accuracy: 0.8372 - val_loss: 0.6361 - val_accuracy: 0.7272\n",
      "Epoch 247/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3386 - accuracy: 0.8346 - val_loss: 0.7009 - val_accuracy: 0.6947\n",
      "Epoch 248/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3420 - accuracy: 0.8337 - val_loss: 0.6821 - val_accuracy: 0.7393\n",
      "Epoch 249/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3390 - accuracy: 0.8331 - val_loss: 0.6220 - val_accuracy: 0.7594\n",
      "Epoch 250/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3426 - accuracy: 0.8358 - val_loss: 0.6187 - val_accuracy: 0.7386\n",
      "Epoch 251/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3403 - accuracy: 0.8306 - val_loss: 0.5989 - val_accuracy: 0.7354\n",
      "Epoch 252/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3478 - accuracy: 0.8303 - val_loss: 0.5746 - val_accuracy: 0.7565\n",
      "Epoch 253/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3372 - accuracy: 0.8368 - val_loss: 0.6035 - val_accuracy: 0.7487\n",
      "Epoch 254/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3344 - accuracy: 0.8391 - val_loss: 0.6392 - val_accuracy: 0.7331\n",
      "Epoch 255/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3381 - accuracy: 0.8364 - val_loss: 0.6011 - val_accuracy: 0.7451\n",
      "Epoch 256/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3255 - accuracy: 0.8433 - val_loss: 0.6155 - val_accuracy: 0.7490\n",
      "Epoch 257/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3336 - accuracy: 0.8386 - val_loss: 0.6877 - val_accuracy: 0.6973\n",
      "Epoch 258/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3298 - accuracy: 0.8420 - val_loss: 0.6540 - val_accuracy: 0.7139\n",
      "Epoch 259/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3306 - accuracy: 0.8396 - val_loss: 0.6502 - val_accuracy: 0.7243\n",
      "Epoch 260/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3249 - accuracy: 0.8428 - val_loss: 0.6654 - val_accuracy: 0.7152\n",
      "Epoch 261/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3254 - accuracy: 0.8444 - val_loss: 0.6451 - val_accuracy: 0.7487\n",
      "Epoch 262/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3265 - accuracy: 0.8435 - val_loss: 0.6119 - val_accuracy: 0.7318\n",
      "Epoch 263/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3311 - accuracy: 0.8409 - val_loss: 0.6478 - val_accuracy: 0.7100\n",
      "Epoch 264/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3175 - accuracy: 0.8491 - val_loss: 0.7423 - val_accuracy: 0.6852\n",
      "Epoch 265/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3177 - accuracy: 0.8460 - val_loss: 0.7883 - val_accuracy: 0.6628\n",
      "Epoch 266/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3242 - accuracy: 0.8447 - val_loss: 0.6023 - val_accuracy: 0.7516\n",
      "Epoch 267/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3257 - accuracy: 0.8465 - val_loss: 0.7598 - val_accuracy: 0.6947\n",
      "Epoch 268/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3210 - accuracy: 0.8482 - val_loss: 0.6167 - val_accuracy: 0.7340\n",
      "Epoch 269/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3227 - accuracy: 0.8456 - val_loss: 0.6875 - val_accuracy: 0.7220\n",
      "Epoch 270/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3208 - accuracy: 0.8463 - val_loss: 0.6833 - val_accuracy: 0.7578\n",
      "Epoch 271/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3173 - accuracy: 0.8477 - val_loss: 0.5936 - val_accuracy: 0.7666\n",
      "Epoch 272/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3129 - accuracy: 0.8492 - val_loss: 0.6468 - val_accuracy: 0.7461\n",
      "Epoch 273/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3187 - accuracy: 0.8479 - val_loss: 0.5873 - val_accuracy: 0.7627\n",
      "Epoch 274/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3117 - accuracy: 0.8502 - val_loss: 0.6492 - val_accuracy: 0.7412\n",
      "Epoch 275/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3131 - accuracy: 0.8518 - val_loss: 0.7629 - val_accuracy: 0.7256\n",
      "Epoch 276/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3194 - accuracy: 0.8479 - val_loss: 0.5939 - val_accuracy: 0.7399\n",
      "Epoch 277/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3116 - accuracy: 0.8500 - val_loss: 0.9113 - val_accuracy: 0.6413\n",
      "Epoch 278/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3144 - accuracy: 0.8484 - val_loss: 0.6932 - val_accuracy: 0.7227\n",
      "Epoch 279/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3099 - accuracy: 0.8524 - val_loss: 0.6478 - val_accuracy: 0.7236\n",
      "Epoch 280/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3053 - accuracy: 0.8551 - val_loss: 0.6395 - val_accuracy: 0.7640\n",
      "Epoch 281/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3103 - accuracy: 0.8506 - val_loss: 0.7320 - val_accuracy: 0.7025\n",
      "Epoch 282/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.3206 - accuracy: 0.8484 - val_loss: 0.6995 - val_accuracy: 0.7077\n",
      "Epoch 283/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3054 - accuracy: 0.8532 - val_loss: 0.6983 - val_accuracy: 0.7155\n",
      "Epoch 284/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3087 - accuracy: 0.8510 - val_loss: 0.6923 - val_accuracy: 0.7542\n",
      "Epoch 285/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3024 - accuracy: 0.8548 - val_loss: 0.6884 - val_accuracy: 0.7347\n",
      "Epoch 286/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3140 - accuracy: 0.8516 - val_loss: 0.6081 - val_accuracy: 0.7734\n",
      "Epoch 287/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3048 - accuracy: 0.8581 - val_loss: 0.7509 - val_accuracy: 0.7100\n",
      "Epoch 288/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3030 - accuracy: 0.8574 - val_loss: 0.6967 - val_accuracy: 0.7318\n",
      "Epoch 289/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3059 - accuracy: 0.8538 - val_loss: 0.6371 - val_accuracy: 0.7334\n",
      "Epoch 290/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3046 - accuracy: 0.8553 - val_loss: 0.7974 - val_accuracy: 0.7038\n",
      "Epoch 291/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2983 - accuracy: 0.8592 - val_loss: 0.7421 - val_accuracy: 0.7334\n",
      "Epoch 292/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3060 - accuracy: 0.8554 - val_loss: 0.7291 - val_accuracy: 0.7337\n",
      "Epoch 293/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2976 - accuracy: 0.8600 - val_loss: 0.6535 - val_accuracy: 0.7415\n",
      "Epoch 294/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2951 - accuracy: 0.8590 - val_loss: 0.8530 - val_accuracy: 0.7008\n",
      "Epoch 295/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.3051 - accuracy: 0.8543 - val_loss: 0.6820 - val_accuracy: 0.7445\n",
      "Epoch 296/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.3020 - accuracy: 0.8580 - val_loss: 0.7296 - val_accuracy: 0.7122\n",
      "Epoch 297/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2954 - accuracy: 0.8629 - val_loss: 0.8121 - val_accuracy: 0.6904\n",
      "Epoch 298/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2931 - accuracy: 0.8630 - val_loss: 0.7389 - val_accuracy: 0.7412\n",
      "Epoch 299/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2919 - accuracy: 0.8633 - val_loss: 0.6874 - val_accuracy: 0.7480\n",
      "Epoch 300/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2987 - accuracy: 0.8600 - val_loss: 0.7052 - val_accuracy: 0.7412\n",
      "Epoch 301/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2933 - accuracy: 0.8638 - val_loss: 0.7945 - val_accuracy: 0.7119\n",
      "Epoch 302/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2942 - accuracy: 0.8608 - val_loss: 0.7066 - val_accuracy: 0.7409\n",
      "Epoch 303/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2943 - accuracy: 0.8623 - val_loss: 0.6555 - val_accuracy: 0.7490\n",
      "Epoch 304/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2918 - accuracy: 0.8621 - val_loss: 0.7508 - val_accuracy: 0.7181\n",
      "Epoch 305/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2937 - accuracy: 0.8612 - val_loss: 0.6835 - val_accuracy: 0.74540s\n",
      "Epoch 306/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2919 - accuracy: 0.8652 - val_loss: 0.7258 - val_accuracy: 0.7240\n",
      "Epoch 307/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2950 - accuracy: 0.8608 - val_loss: 0.7502 - val_accuracy: 0.7298\n",
      "Epoch 308/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2931 - accuracy: 0.8633 - val_loss: 0.7448 - val_accuracy: 0.7217\n",
      "Epoch 309/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2886 - accuracy: 0.8642 - val_loss: 0.7048 - val_accuracy: 0.7383\n",
      "Epoch 310/1200\n",
      "438/438 [==============================] - 15s 34ms/step - loss: 0.2885 - accuracy: 0.8638 - val_loss: 0.6474 - val_accuracy: 0.7520\n",
      "Epoch 311/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2750 - accuracy: 0.8705 - val_loss: 0.7338 - val_accuracy: 0.7240\n",
      "Epoch 312/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2799 - accuracy: 0.8707 - val_loss: 0.6232 - val_accuracy: 0.7620\n",
      "Epoch 313/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2848 - accuracy: 0.8662 - val_loss: 0.7485 - val_accuracy: 0.7096\n",
      "Epoch 314/1200\n",
      "438/438 [==============================] - 14s 33ms/step - loss: 0.2828 - accuracy: 0.8682 - val_loss: 0.7783 - val_accuracy: 0.6855\n",
      "Epoch 315/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2816 - accuracy: 0.8694 - val_loss: 0.7604 - val_accuracy: 0.7223\n",
      "Epoch 316/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2799 - accuracy: 0.8698 - val_loss: 0.8273 - val_accuracy: 0.7025\n",
      "Epoch 317/1200\n",
      "438/438 [==============================] - 15s 33ms/step - loss: 0.2835 - accuracy: 0.8674 - val_loss: 1.0927 - val_accuracy: 0.6917\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00317: early stopping\n",
      "      1/Unknown - 0s 109ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121/3121 [==============================] - 14s 5ms/step\n",
      "347/347 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [13:19:03<00:00, 4794.32s/it]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "dt = 0.05\n",
    "# dfrigor = pd.read_csv(\"E:\\\\NN\\\\results_LFP_retrain_crossVal.csv\")\n",
    "dfrigor = pd.DataFrame(columns=['itr'])\n",
    "modelName = 'retesting_v5n_allSplits_30'\n",
    "batchSize = 64\n",
    "sampleSize = batchSize//2\n",
    "classes=['Healthy','Acute']\n",
    "\n",
    "os.mkdir('E:\\\\NN\\\\confusionMatrices\\\\retestingLFPv5n_crossVal_5')\n",
    "folder = 'confusionMatrices\\\\retestingLFPv5n_crossVal_5\\\\' \n",
    "# comb_List = []\n",
    "# comb = combinations(miceList, 2)\n",
    "# for i in comb:\n",
    "#     comb_List.append(i)\n",
    "\n",
    "fpr = []\n",
    "tpr = []\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,\n",
    "    patience=75,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "# df = pd.read_csv('availableData2.csv')  \n",
    "# try 30s with 20s overlab\n",
    "dtL = 0.0032768\n",
    "segN = int(np.ceil(5/dtL))\n",
    "overlap = int(np.ceil(1/dtL))\n",
    "\n",
    "# df = prepData(segN,overlap,df)\n",
    "df = df.sort_values('start')\n",
    "\n",
    "for l in tqdm(range(0,10)): # 10-fold cross validation\n",
    "    results = {'Test':{},'Train':{},'Val':{}}\n",
    "    \n",
    "    trainData = df.copy()\n",
    "    valData = trainData.iloc[(len(trainData)//10)*l:(len(trainData)//10)*(l+1)]\n",
    "    trainData = trainData.drop(valData.index)\n",
    "\n",
    "    stepTrain=len(trainData)//batchSize\n",
    "    stepValidate=len(valData)//batchSize\n",
    "\n",
    "#     model =  get_model(segN)\n",
    "    model = get_model(segN)# tf.keras.models.load_model('E:\\\\rawLFP_v5n_tunning_binary')\n",
    "    model.compile(optimizer='sgd',\n",
    "          loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "          metrics=['accuracy'])\n",
    "    # model.load_weights('E:\\\\'+modelName+'_bestWeights.h5')\n",
    "\n",
    "    history = model.fit(loadTrain(trainData,sampleSize),\n",
    "                steps_per_epoch=stepTrain,\n",
    "                validation_data=loadTrain(valData,sampleSize),\n",
    "                validation_steps=stepValidate,\n",
    "                epochs=1200,callbacks=[early_stopping])#,\n",
    "\n",
    "\n",
    "    plotHistory(history,folder+modelName,str(l),'bla')\n",
    "    #  test and save scores\n",
    "\n",
    "    y = []\n",
    "    for ind,(dataP,label) in enumerate(loadTest(trainData)):\n",
    "        y = y+list(np.argmax(label,axis=1))\n",
    "\n",
    "    pred = model.predict_generator(loadTest(trainData),verbose=1)\n",
    "    pred = np.argmax(pred, axis = 1)\n",
    "\n",
    "    plotConfusionMatrix(y,pred,folder+str(l)+modelName, 'train')\n",
    "    y = np.array(y)\n",
    "    results['Train']['Acc'] = (np.sum(y==pred)/len(y))\n",
    "    results['Train']['Sen'] = (np.sum(y*pred)/sum(y))\n",
    "    results['Train']['Spe'] = np.sum(1*(y == pred)*(y==0))/sum(y==0)\n",
    "\n",
    "    y = []\n",
    "    for ind,(dataP,label) in enumerate(loadTest(valData)):\n",
    "        y = y+list(np.argmax(label,axis=1))\n",
    "\n",
    "    pred = model.predict_generator(loadTest(valData),verbose=1)\n",
    "    fpr_t , tpr_t , thresholds = roc_curve ( y , pred[:,1])\n",
    "    fpr.append(fpr_t)\n",
    "    tpr.append(tpr_t)\n",
    "    pred = np.argmax(pred, axis = 1)\n",
    "\n",
    "    plotConfusionMatrix(y,pred,folder+str(l)+modelName, 'val')\n",
    "    y = np.array(y)\n",
    "    results['Val']['Acc'] = (np.sum(y==pred)/len(y))\n",
    "    results['Val']['Sen'] = (np.sum(y*pred)/sum(y))\n",
    "    results['Val']['Spe'] = np.sum(1*(y == pred)*(y==0))/sum(y==0)\n",
    "\n",
    "    del model\n",
    "\n",
    "\n",
    "    for spl in ['Test','Train','Val']:\n",
    "        dfrow = pd.DataFrame(results[spl],index=[0])\n",
    "        dfrow['split'] = spl\n",
    "        dfrow['itr'] = l\n",
    "#         dfrow['i'] = str(i)\n",
    "        dfrigor = pd.concat([dfrigor,dfrow])\n",
    "\n",
    "plotROC(fpr,tpr,\"section3_AUC_LFP_retrain_crossVal_5\")\n",
    "\n",
    "dfrigor.to_csv(\"E:\\\\NN\\\\results_LFP_retrain_crossVal_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc80be1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itr</th>\n",
       "      <th>split</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Sen</th>\n",
       "      <th>Spe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Val</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.701196</td>\n",
       "      <td>0.722879</td>\n",
       "      <td>0.627886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Val</td>\n",
       "      <td>0.649635</td>\n",
       "      <td>0.673709</td>\n",
       "      <td>0.565574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.817353</td>\n",
       "      <td>0.858793</td>\n",
       "      <td>0.676759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Val</td>\n",
       "      <td>0.687956</td>\n",
       "      <td>0.763593</td>\n",
       "      <td>0.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.755727</td>\n",
       "      <td>0.768908</td>\n",
       "      <td>0.711111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Val</td>\n",
       "      <td>0.682482</td>\n",
       "      <td>0.708235</td>\n",
       "      <td>0.593496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.675654</td>\n",
       "      <td>0.731951</td>\n",
       "      <td>0.484875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Val</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.775943</td>\n",
       "      <td>0.540323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.931076</td>\n",
       "      <td>0.953769</td>\n",
       "      <td>0.854352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Val</td>\n",
       "      <td>0.673358</td>\n",
       "      <td>0.758216</td>\n",
       "      <td>0.377049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.710724</td>\n",
       "      <td>0.718144</td>\n",
       "      <td>0.685433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Val</td>\n",
       "      <td>0.713504</td>\n",
       "      <td>0.751790</td>\n",
       "      <td>0.589147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.732009</td>\n",
       "      <td>0.744815</td>\n",
       "      <td>0.688612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Val</td>\n",
       "      <td>0.706204</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.604839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.686195</td>\n",
       "      <td>0.729325</td>\n",
       "      <td>0.540036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Val</td>\n",
       "      <td>0.667883</td>\n",
       "      <td>0.700472</td>\n",
       "      <td>0.556452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>Test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.760997</td>\n",
       "      <td>0.816894</td>\n",
       "      <td>0.570919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>Val</td>\n",
       "      <td>0.726277</td>\n",
       "      <td>0.831354</td>\n",
       "      <td>0.377953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  itr  split       Acc       Sen       Spe\n",
       "0   1   Test       NaN       NaN       NaN\n",
       "0   1  Train       NaN       NaN       NaN\n",
       "0   1    Val       NaN       NaN       NaN\n",
       "0   1   Test       NaN       NaN       NaN\n",
       "0   1  Train  0.701196  0.722879  0.627886\n",
       "0   1    Val  0.649635  0.673709  0.565574\n",
       "0   2   Test       NaN       NaN       NaN\n",
       "0   2  Train  0.817353  0.858793  0.676759\n",
       "0   2    Val  0.687956  0.763593  0.432000\n",
       "0   3   Test       NaN       NaN       NaN\n",
       "0   3  Train  0.755727  0.768908  0.711111\n",
       "0   3    Val  0.682482  0.708235  0.593496\n",
       "0   4   Test       NaN       NaN       NaN\n",
       "0   4  Train  0.675654  0.731951  0.484875\n",
       "0   4    Val  0.722628  0.775943  0.540323\n",
       "0   5   Test       NaN       NaN       NaN\n",
       "0   5  Train  0.931076  0.953769  0.854352\n",
       "0   5    Val  0.673358  0.758216  0.377049\n",
       "0   6   Test       NaN       NaN       NaN\n",
       "0   6  Train  0.710724  0.718144  0.685433\n",
       "0   6    Val  0.713504  0.751790  0.589147\n",
       "0   7   Test       NaN       NaN       NaN\n",
       "0   7  Train  0.732009  0.744815  0.688612\n",
       "0   7    Val  0.706204  0.735849  0.604839\n",
       "0   8   Test       NaN       NaN       NaN\n",
       "0   8  Train  0.686195  0.729325  0.540036\n",
       "0   8    Val  0.667883  0.700472  0.556452\n",
       "0   9   Test       NaN       NaN       NaN\n",
       "0   9  Train  0.760997  0.816894  0.570919\n",
       "0   9    Val  0.726277  0.831354  0.377953"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d93a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "206e8774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 64, 64)\n",
      "(2,)\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[9].kernel.shape)\n",
    "print(model.layers[7].pool_size)\n",
    "print(model.layers[8].rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4358970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(segN):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(16, 53, input_shape=(segN,2), activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Conv1D(4, 11, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(0.0))\n",
    "\n",
    "    model.add(Conv1D(64, 31, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(0.40))\n",
    "\n",
    "    model.add(Conv1D(64, 27, activation='relu',padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(0.0))\n",
    "\n",
    "    model.add(Conv1D(16, 25, activation='relu',padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Conv1D(64, (3), activation='relu',padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "\n",
    "    # model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))#,kernel_initializer=initializer))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))#,kernel_initializer=initializer))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "# layer = Conv1D(model.layers[0].kernel.shape[2], (model.layers[0].kernel.shape[0]), input_shape=(3,2), activation='relu')\n",
    "# model\n",
    "# model.layers[0] = Conv1D(model.layers[0].kernel.shape[2], (model.layers[0].kernel.shape[0]), input_shape=(3,2), activation='relu')\n",
    "\n",
    "# print(model.layers[0].input.shape)#\n",
    "# print(model.summary())#,modelOld.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3304ea8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31205 2 31207\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('availableData2.csv')  \n",
    "trainData2 = prepData(segN,overlap,df)\n",
    "print(len(trainData),len(badDp),len(trainData2))\n",
    "# trainData.drop(trainData.index[badDp],0,inplace=True)\n",
    "# print(len(trainData),len(badDp))\n",
    "# trainData.index\n",
    "df = trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9fbdc142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\Miniconda3\\envs\\LSTM\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "source": [
    "# f = h5py.File('E:\\\\rawLFPData2.hdf5','r')\n",
    "# df = pd.read_csv('availableData2.csv')  \n",
    "# # try 30s with 20s overlab\n",
    "# dtL = 0.0032768\n",
    "# segN = int(np.ceil(5/dtL))\n",
    "# overlap = int(np.ceil(1/dtL))\n",
    "\n",
    "# trainData = prepData(segN,overlap,df)\n",
    "# trainData = trainData.sort_values('start')\n",
    "\n",
    "# print(segN)\n",
    "# badDp = []\n",
    "# dataPoint = trainData.apply(lambda row: f[row.Session][:,row.start:row.end].T, axis=1).values               \n",
    "# for ind,l in enumerate(dataPoint):\n",
    "#     if l.shape != (segN,2):\n",
    "#         badDp.append(ind)\n",
    "# f.close()\n",
    "# badDp\n",
    "\n",
    "trainData.drop(trainData.index[badDp],0,inplace=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b6a4687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Acc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Sen</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Spe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.857550</td>\n",
       "      <td>0.036073</td>\n",
       "      <td>0.842017</td>\n",
       "      <td>0.042894</td>\n",
       "      <td>0.910237</td>\n",
       "      <td>0.055279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Val</th>\n",
       "      <td>0.779519</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>0.784464</td>\n",
       "      <td>0.037293</td>\n",
       "      <td>0.762783</td>\n",
       "      <td>0.053985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Acc                 Sen                 Spe          \n",
       "           mean       std      mean       std      mean       std\n",
       "split                                                            \n",
       "Train  0.857550  0.036073  0.842017  0.042894  0.910237  0.055279\n",
       "Val    0.779519  0.023166  0.784464  0.037293  0.762783  0.053985"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfrigor = pd.read_csv(\"E:\\\\NN\\\\results_LFP_retrain_crossVal_5.csv\")\n",
    "dfrigor = dfrigor[dfrigor.split!='Test']\n",
    "dfrigor[['split','Acc','Sen','Spe']].groupby('split').describe().loc[:,(slice(None),['mean','std'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bb26a8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 452.75x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"E:\\\\NN\\\\results_LFP_retrain_crossVal_5.csv\")\n",
    "# df['input'] = '5 seconds'\n",
    "# df2 =  pd.read_csv(\"E:\\\\NN\\\\results_LFP_retrain_crossVal.csv\")\n",
    "# df2['input'] = '15 seconds'\n",
    "# df3 =  pd.read_csv(\"E:\\\\NN\\\\results_LFP_retrain_crossVal_30.csv\")\n",
    "# df3['input'] = '30 seconds'\n",
    "# df = pd.concat([df,df2,df3])\n",
    "df = df[df.split=='Val']\n",
    "df_melt = pd.melt(df,id_vars=['itr','input'],value_vars=['Acc','Spe','Sen'],\n",
    "                  var_name='metric', value_name='value')\n",
    "sns.catplot(data = df_melt,x='metric',hue='input',y='value',kind='box',palette=a1[0:16:7])#, hue_order=['5','15','30'], showfliers=False)\n",
    "plt.savefig(\"E:\\\\NN\\\\LFPperformance.svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0db1ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = sns.color_palette(\"crest\",16)\n",
    "# a1[0:6:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e7395066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 1474, 16)          1712      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 737, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 737, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 727, 4)            708       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 363, 4)            0         \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 363, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 333, 64)           8000      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 166, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 166, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 166, 64)           110656    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 83, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 83, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 83, 16)            25616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 41, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 41, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 41, 64)            3136      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                12810     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 162,660\n",
      "Trainable params: 162,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_model(segN)\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
