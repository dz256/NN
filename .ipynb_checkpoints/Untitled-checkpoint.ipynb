{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for start training neural nets on my LFP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since noteboke doesn't work in jupiterlabs    %matplotlib notebook \n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "import scipy.stats as stats\n",
    "import scipy.signal as signal\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "import ipywidgets\n",
    "#import PIL\n",
    "#import itertools\n",
    "import os\n",
    "from numpy.lib.format import open_memmap\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import net layers structure and optimizers from Keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Concatenate\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Lambda\n",
    "import keras.optimizers as optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder_list = ['/home/dana_z/HD1/lfp2ca_notNormalize/MSN','/home/dana_z/HD1/lfp2ca_notNormalize/CRE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8430_BaselineS', '8803_day19L']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_filename_list[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Files:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8430_BaselineS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Files:  50%|█████     | 1/2 [00:04<00:04,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12206, 87, 64)\n",
      "8803_day19L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files: 100%|██████████| 2/2 [00:11<00:00,  5.89s/it]\n",
      "Files:  50%|█████     | 1/2 [00:00<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12206, 87, 104)\n",
      "4539_day10\n",
      "(12206, 87, 2)\n",
      "1236_BaselineS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files: 100%|██████████| 2/2 [00:00<00:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12206, 87, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def periodCalc(sess):\n",
    "    \n",
    "    if sess[5] == 'B':\n",
    "            day = 0\n",
    "        else:\n",
    "            day = int(re.findall(r'\\d+',sess[5:])[0])\n",
    "    \n",
    "    if day== 0:\n",
    "        return 'Healthy'\n",
    "    elif day<5:\n",
    "        return 'Day 1-4'\n",
    "    elif day<13:\n",
    "        return 'Day 5-12'\n",
    "    elif day<21:\n",
    "        return 'Day 13-20'\n",
    "    else:\n",
    "        return 'One Month'\n",
    "\n",
    "\n",
    "for dataset_folder in dataset_folder_list:\n",
    "    dataset_folder = os.path.normpath(dataset_folder)\n",
    "\n",
    "    # Get image file names from folder\n",
    "    image_filename_list = next(os.walk(dataset_folder))[2]\n",
    "    for current_image_filename in tqdm(image_filename_list[1:3], desc='Files'): #remove the [1] after debugging\n",
    "        print(current_image_filename,periodCalc(current_image_filename))\n",
    "        filePeriod = periodCalc(current_image_filename)\n",
    "        current_image_path = os.path.join(dataset_folder, current_image_filename)\n",
    "        # load data\n",
    "        tempD = pickle.load(open(current_image_path,'rb'))\n",
    "        tempD[tempD==9999] = np.nan\n",
    "        tempD[tempD==-9999] = np.nan\n",
    "        print(tempD.shape)\n",
    "#         self.image_file_list.append(current_image_path)\n",
    "        # calc how many cells\n",
    "        if image_stack.series[0].ndim==3:\n",
    "            image_width, image_heigh ,numCells  = image_stack.series[0].shape\n",
    "        elif image_stack.series[0].ndim==2:\n",
    "            numCells = 1\n",
    "            image_width, image_heigh  = image_stack.series[0].shape\n",
    "        else:\n",
    "            print(\"Skip {}\".format(current_image_filename))\n",
    "            break\n",
    "        for cell in range(0,numCells):\n",
    "            data_info = {\n",
    "                            \"id\": current_image_filename+\"_\"+str(cell),\n",
    "                            \"path\": current_image_path,\n",
    "                            \"idx\": cell,\n",
    "                            \"period\": filePeriod\n",
    "                        }\n",
    "            self.data_info.append(data_info)\n",
    "            \n",
    "            freq_idx_max = trace_cfs.shape[0] \n",
    "        freq_idx_min = 0\n",
    "        print(\"Frequency range: {:1.2f}-{:1.2f} Hz (max idx: {:1.2f} ).\".format(trace_cfs_freq[freq_idx_max-1],trace_cfs_freq[freq_idx_min],freq_idx_max))\n",
    "        try:                   \n",
    "            if len(self.frequency_idx)==2:\n",
    "                freq_idx_min = np.amax([freq_idx_min,self.frequency_idx[0]])\n",
    "                freq_idx_max = np.amin([freq_idx_max,self.frequency_idx[1]+1])\n",
    "            elif len(self.frequency_idx)==1:\n",
    "                freq_idx_min = np.amax([freq_idx_min,freq_idx_max-self.frequency_idx[0]])\n",
    "        except:\n",
    "            pass\n",
    "        self.frequency_idx = [freq_idx_min,freq_idx_max]\n",
    "        self.frequency_idx_length = self.frequency_idx[1]-self.frequency_idx[0]\n",
    "        print(\"Selected frequency range: {:1.2f}-{:1.2f} Hz ({:1.2f} data points).\".format(trace_cfs_freq[self.frequency_idx[1]-1],trace_cfs_freq[self.frequency_idx[0]],self.frequency_idx_length))\n",
    "        print(\"Total {} samples.\".format(len(self.data_info)))\n",
    "\n",
    "        # calculate sample with events\n",
    "\n",
    "        event_data_id_list = []\n",
    "        non_event_data_id_list = []\n",
    "        for data_id in tqdm(range(len(self.data_info)),desc=\"Calculating sample with events\"):\n",
    "            if self.data_info[data_id]['event']==1:\n",
    "                event_data_id_list.append(data_id)\n",
    "            elif self.data_info[data_id]['event']==0:\n",
    "                non_event_data_id_list.append(data_id)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        print(\"Sample with event: {} ({}%)\".format(len(event_data_id_list),100*len(event_data_id_list)/len(self.data_info)))\n",
    "        print(\"Sample without event: {} ({}%)\".format(len(non_event_data_id_list),100*len(non_event_data_id_list)/len(self.data_info)))\n",
    "\n",
    "        self.event_data_id_list = event_data_id_list\n",
    "        self.non_event_data_id_list = non_event_data_id_list\n",
    "\n",
    "        total_id_count = np.ceil(np.amax((len(self.non_event_data_id_list)/(1-self.event_ratio),len(self.event_data_id_list)/self.event_ratio)))\n",
    "        event_data_id_list = np.repeat(self.event_data_id_list,int(np.ceil((self.event_ratio*total_id_count)/len(self.event_data_id_list))))\n",
    "        non_event_data_id_list = np.repeat(self.non_event_data_id_list,int(np.ceil(((1-self.event_ratio)*total_id_count)/len(self.non_event_data_id_list))))\n",
    "        np.random.shuffle(event_data_id_list)\n",
    "        np.random.shuffle(non_event_data_id_list)\n",
    "        event_data_id_list = event_data_id_list[:int(self.event_ratio*total_id_count)]\n",
    "        non_event_data_id_list = non_event_data_id_list[:int((1-self.event_ratio)*total_id_count)]\n",
    "\n",
    "        print(\"Adjusted sample with event: {} ({}%)\".format(len(event_data_id_list),100*len(event_data_id_list)/(len(event_data_id_list)+len(non_event_data_id_list))))\n",
    "        print(\"Adjusted sample without event: {} ({}%)\".format(len(non_event_data_id_list),100*len(non_event_data_id_list)/(len(event_data_id_list)+len(non_event_data_id_list))))\n",
    "\n",
    "        self.on_epoch_end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
