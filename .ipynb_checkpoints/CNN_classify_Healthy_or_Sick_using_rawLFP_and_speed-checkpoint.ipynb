{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "929a0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since noteboke doesn't work in jupiterlabs    %matplotlib notebook \n",
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2904af6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "# os.environ['PATH'] += os.pathsep + 'D:\\\\6OHDA\\\\'\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "from IO import *\n",
    "from utils import *\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Concatenate\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D,Conv2D, Conv1D,MaxPooling1D\n",
    "# from tensorflow.keras.layers.core import Lambda\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "# import png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "651e941a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6383503252124536469\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10091102208\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6018894237779460099\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10091102208\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6436897108621986155\n",
      "physical_device_desc: \"device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dabf073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Files = ['FinalData_6OHDA.h5','FinalData_6OHDA_H.h5']\n",
    "#miceList.remove('1253')\n",
    "#miceList.remove('1231')\n",
    "def periodCalc(day):\n",
    "    if day== 0:\n",
    "        return 'Healthy'\n",
    "    elif day<13:\n",
    "        return 'Acute' #day 1-13\n",
    "    else:\n",
    "        return 'Chronic' #day 14-35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4874a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "I deleted session: 1208_day12\n",
      "I deleted session: 2976_day4\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    }
   ],
   "source": [
    "data_train = getData(Files[0],['lfp','speed'],period ='Pre', mice=mTrain)\n",
    "data_validate = getData(Files[0],['lfp','speed'],period ='Pre', mice=mValidate)\n",
    "data_test = getData(Files[0],['lfp','speed'],period ='Pre', mice=mTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f5a8141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "I deleted session: 1208_day12\n",
      "cleaning up speed data\n",
      "found  17.0  outlier points\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "found  1.0  outlier points\n",
      "found  888231.0  outlier points\n",
      "found  481139.0  outlier points\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "I deleted session: 2976_day4\n",
      "cleaning up speed data\n",
      "found  1.0  outlier points\n",
      "found  3.0  outlier points\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "found  50.0  outlier points\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "found  29.0  outlier points\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('E:\\\\rawLFPData.hdf5','a')\n",
    "df = pd.DataFrame(columns= [\"Mouse\",\"Session\",\"Period\",\"length\"])\n",
    "dtL = 0.00032768\n",
    "for m in getMiceList(Files[0]):\n",
    "    data =  getData(Files[0],['lfp','speed'],period ='Pre', mice=m)\n",
    "    for sess in data.keys():\n",
    "        lfp = data[sess]['lfp']['lfp']\n",
    "        speed = data[sess]['speed']['speed']\n",
    "\n",
    "        if sess[5] == 'B':\n",
    "            day = 0\n",
    "        else:\n",
    "            day = int(re.findall(r'\\d+',sess[5:])[0])\n",
    "        \n",
    "       \n",
    "        # get data\n",
    "        caT = np.arange(max(speed.shape))*0.05\n",
    "        speedF = sci.interpolate.interp1d(caT, speed,kind='linear')\n",
    "        lfpOutliers = removeLFPOutliers(lfp, sess)\n",
    "        \n",
    "        lfpT = np.arange(max(lfp.shape))*dtL\n",
    "        \n",
    "        \n",
    "        if max(caT)< max(lfpT):\n",
    "            endInd = np.argmin(np.abs(max(caT)-lfpT))\n",
    "            while lfpT[endInd]>max(caT):\n",
    "                endInd = endInd-1\n",
    "\n",
    "        speedNew = speedF(lfpT[:endInd]).T\n",
    "        lfpOutliers = lfpOutliers[:endInd,0]\n",
    "        lfp = lfp[:endInd]\n",
    "        lfp = lfp[(lfpOutliers[:]==0),0] \n",
    "        speedNew = speedNew[(lfpOutliers[:]==0),0]\n",
    "        \n",
    "        lfp = sci.signal.decimate(lfp,10,axis=0)\n",
    "        speedNew = sci.signal.decimate(speedNew,10,axis=0)\n",
    "        \n",
    "        a = np.vstack((lfp,speedNew))\n",
    "        try:\n",
    "            f.create_dataset(sess, data=a)\n",
    "        except:\n",
    "            del f[sess]\n",
    "            f.create_dataset(sess, data=a)\n",
    "        df = df.append({\"Mouse\":m,\"Session\":sess,'Period':periodCalc(day),\"length\":np.max(a.shape)},ignore_index=True)\n",
    "        \n",
    "df.to_csv('availableData.csv')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "33d3aed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018569921716620478 0.9609278601300294\n"
     ]
    }
   ],
   "source": [
    "# lfp = data[sess]['lfp']['lfp']\n",
    "# lfp = (lfp-np.min(lfp))/(np.max(lfp)-np.min(lfp))\n",
    "# lfp = lfp[:endInd]\n",
    "# lfp = lfp[(lfpOutliers[:]==0),0] \n",
    "print(np.min(lfp),np.max(lfp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "58efd6c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████▏                                                                             | 1/16 [00:06<01:36,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "I deleted session: 1208_day12\n",
      "cleaning up speed data\n",
      "found  17.0  outlier points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████▍                                                                        | 2/16 [00:12<01:26,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▌                                                                   | 3/16 [00:18<01:20,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 4/16 [00:20<00:53,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "found  1.0  outlier points\n",
      "found  888231.0  outlier points\n",
      "found  481139.0  outlier points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▉                                                         | 5/16 [00:26<00:55,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████▏                                                   | 6/16 [00:28<00:39,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████▎                                              | 7/16 [00:34<00:42,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "I deleted session: 2976_day4\n",
      "cleaning up speed data\n",
      "found  1.0  outlier points\n",
      "found  3.0  outlier points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 8/16 [00:40<00:41,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████████▋                                    | 9/16 [00:47<00:39,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "found  50.0  outlier points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|███████████████████████████████████████████████████▎                              | 10/16 [00:53<00:34,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "found  29.0  outlier points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████████▍                         | 11/16 [01:01<00:32,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [01:08<00:26,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|██████████████████████████████████████████████████████████████████▋               | 13/16 [01:16<00:21,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|███████████████████████████████████████████████████████████████████████▊          | 14/16 [01:22<00:13,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|████████████████████████████████████████████████████████████████████████████▉     | 15/16 [01:29<00:06,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up lfp data\n",
      "cleaning up speed data\n",
      "cleaning up lfp data\n",
      "cleaning up speed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [01:35<00:00,  5.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# add normalized speed\n",
    "f = h5py.File('E:\\\\rawLFPData2.hdf5','a')\n",
    "df = pd.DataFrame(columns= [\"Mouse\",\"Session\",\"Period\",\"length\"])\n",
    "dtL = 0.00032768\n",
    "for m in tqdm(getMiceList(Files[0])):\n",
    "    data =  getData(Files[0],['lfp','speed'],period ='Pre', mice=m, day = lambda x: x== 0)\n",
    "    maxSpeed = []\n",
    "    for sess in data:\n",
    "        speed = smooth(data[sess]['speed']['speed'],20)\n",
    "        maxSpeed.append(np.max(speed))\n",
    "    maxSpeed = np.mean(maxSpeed)\n",
    "    data =  getData(Files[0],['lfp','speed'],period ='Pre', mice=m)\n",
    "    for sess in data.keys():\n",
    "        lfp = data[sess]['lfp']['lfp']\n",
    "        speed = data[sess]['speed']['speed']\n",
    "        speed = speed/maxSpeed\n",
    "\n",
    "        if sess[5] == 'B':\n",
    "            day = 0\n",
    "        else:\n",
    "            day = int(re.findall(r'\\d+',sess[5:])[0])\n",
    "        \n",
    "       \n",
    "        # get data\n",
    "        caT = np.arange(max(speed.shape))*0.05\n",
    "        speedF = sci.interpolate.interp1d(caT, speed,kind='linear')\n",
    "        lfpOutliers = removeLFPOutliers(lfp, sess)\n",
    "        \n",
    "        lfpT = np.arange(max(lfp.shape))*dtL\n",
    "        \n",
    "        \n",
    "        if max(caT)< max(lfpT):\n",
    "            endInd = np.argmin(np.abs(max(caT)-lfpT))\n",
    "            while lfpT[endInd]>max(caT):\n",
    "                endInd = endInd-1\n",
    "\n",
    "        speedNew = speedF(lfpT[:endInd]).T\n",
    "        lfpOutliers = lfpOutliers[:endInd,0]\n",
    "        lfp = lfp[:endInd]\n",
    "        lfp = lfp[(lfpOutliers[:]==0),0] \n",
    "        lfp = (lfp-np.min(lfp))/(np.max(lfp)-np.min(lfp))\n",
    "        speedNew = speedNew[(lfpOutliers[:]==0),0]\n",
    "        \n",
    "        lfp = sci.signal.decimate(lfp,10,axis=0)\n",
    "        speedNew = sci.signal.decimate(speedNew,10,axis=0)\n",
    "        \n",
    "        a = np.vstack((lfp,speedNew))\n",
    "        try:\n",
    "            f.create_dataset(sess, data=a)\n",
    "        except:\n",
    "            del f[sess]\n",
    "            f.create_dataset(sess, data=a)\n",
    "        df = df.append({\"Mouse\":m,\"Session\":sess,'Period':periodCalc(day),\"length\":np.max(a.shape)},ignore_index=True)\n",
    "        \n",
    "df.to_csv('availableData2.csv')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "2e69ab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1231, 1253, 7584, 4539, 1208, 8430, 2980, 7909, 1236, 1793, 8815, 2976, 761, 8803] [1222, 2981]\n"
     ]
    }
   ],
   "source": [
    "miceList = getMiceList(Files[0])\n",
    "miceList.remove('1253')\n",
    "miceList.remove('1231')\n",
    "mOrder = np.random.permutation(len(miceList))\n",
    "\n",
    "mTrain = [1231, 1253]\n",
    "mTest =[int(miceList[i]) for i in mOrder[:2]]\n",
    "mTrain = mTrain+ [int(miceList[i]) for i in mOrder[2:]]\n",
    "\n",
    "print(mTrain,mTest)\n",
    "# print(miceList[mOrder[:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "018fd8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepData(segN,overlap,df):\n",
    "    df2 = df\n",
    "    df2['start'] = pd.Series([[]] * len(df2), index=df2.index)\n",
    "    df2['end'] = pd.Series([[]] * len(df2), index=df2.index)\n",
    "    for l in df.length.unique():\n",
    "        a = np.asarray([[i,i + segN] for i in range(0, l-(segN-overlap),int(segN-overlap))])\n",
    "        df2.loc[df2.length==l,'start'] = pd.Series([a[:,0]] * len(df2), index=df2.index)\n",
    "        df2.loc[df2.length==l,'end'] =  pd.Series([a[:,1]] * len(df2), index=df2.index)\n",
    "    lst_col = 'start'\n",
    "\n",
    "    lst_col = 'start'\n",
    "    lst_col2 = 'end'\n",
    "    df3 = pd.DataFrame({\n",
    "        col:np.repeat(df2[col].values, df2['start'].str.len())\n",
    "        for col in df2.columns.difference(['start','end'])\n",
    "    }).assign(**{'start':np.concatenate(df2['start'].values)}).assign(**{'end':np.concatenate(df2['end'].values)})[df2.columns.tolist()]\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "20d00105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('availableData2.csv')  \n",
    "# try 30s with 20s overlab\n",
    "dtL = 0.0032768\n",
    "segN = int(np.ceil(15/dtL))\n",
    "overlap = int(np.ceil(3/dtL))\n",
    "dataSamples = prepData(segN,overlap,df)\n",
    "\n",
    "df = prepData(segN,overlap,df)\n",
    "testData = df[df.Mouse.isin(mTest)]\n",
    "trainData = df[df.Mouse.isin(mTrain)]\n",
    "validate = trainData.sample(frac=.1)\n",
    "trainData = trainData.drop(validate.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "66cd1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataVersion = 'v1_n'\n",
    "#save data partition: \n",
    "trainData.to_csv('dataPartition_'+dataVersion+'_train.csv')\n",
    "validate.to_csv('dataPartition_'+dataVersion+'_val.csv')\n",
    "testData.to_csv('dataPartition_'+dataVersion+'_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "798ce3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrain(data,sampleSize):\n",
    "    f = h5py.File('E:\\\\rawLFPData2.hdf5','r')\n",
    "    # sampleSize = batchSize/3\n",
    "    while True: \n",
    "        batch = data.groupby('Period').apply(lambda x: x.sample(sampleSize))\n",
    "        batch = batch.sample(frac=1)\n",
    "        labels = batch.Period.apply(lambda x: [1,0,0] if x=='Healthy' else  ([0,1,0] if x=='Acute' else [0,0,1]) )\n",
    "        labels = np.stack(labels.values)\n",
    "        dataPoint = batch.apply(lambda row: f[row.Session][:,row.start:row.end].T, axis=1).values\n",
    "        try:\n",
    "            dataPoint = np.stack(dataPoint)\n",
    "        except:\n",
    "            continue\n",
    "        yield (dataPoint,labels)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "362f8df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                 0\n",
       "Mouse                    761\n",
       "Session       0761_BaselineA\n",
       "Period               Healthy\n",
       "length                181549\n",
       "start                  15260\n",
       "end                    24416\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "03fdbdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTest(data):\n",
    "    f = h5py.File('E:\\\\rawLFPData2.hdf5','r')\n",
    "    # sampleSize = batchSize/3 \n",
    "    for i, g in data.groupby(np.arange(len(data)) // 9):\n",
    "        batch = g\n",
    "        labels = batch.Period.apply(lambda x: [1,0,0] if x=='Healthy' else  ([0,1,0] if x=='Acute' else [0,0,1]) )\n",
    "        labels = np.stack(labels.values)\n",
    "        dataPoint = batch.apply(lambda row: f[row.Session][:,row.start:row.end].T, axis=1).values\n",
    "        try:\n",
    "            dataPoint = np.stack(dataPoint)\n",
    "        except:\n",
    "            continue\n",
    "        yield (dataPoint,labels)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "b27ff0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.86416717e-04 1.82222573e+01]\n",
      "[1.96826389e-04 1.42866774e+01]\n"
     ]
    }
   ],
   "source": [
    "for ind,(dataP,label) in enumerate(loadTest(testData)):\n",
    "    print(np.max(dataP[3,:,:],axis=0))\n",
    "    if ind == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4e809611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 3) (9, 9156, 2)\n",
      "(9, 3) (9, 9156, 2)\n",
      "(9, 3) (9, 9156, 2)\n",
      "(9, 3) (9, 9156, 2)\n"
     ]
    }
   ],
   "source": [
    "for ind,(dataP,label) in enumerate(loadTrain(trainData,3)):\n",
    "    print(label.shape,dataP.shape)\n",
    "    if ind == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "2de8fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b6926156",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSize = 20\n",
    "batchSize = sampleSize*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "e96c0632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for v4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(8, (3), input_shape=(segN,2), activation='relu'))\n",
    "model.add(Conv1D(8, (3), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Conv1D(16, (5), activation='relu'))\n",
    "model.add(Conv1D(16, (5), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Conv1D(16, (9), activation='relu'))\n",
    "model.add(Conv1D(16, (9), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "model.add(Conv1D(32, (21), activation='relu'))\n",
    "model.add(Conv1D(32, (21), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "model.add(Conv1D(32, (31), activation='relu'))\n",
    "model.add(Conv1D(32, (31), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "model.add(Conv1D(64, (41), activation='relu'))\n",
    "model.add(Conv1D(64, (41), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "\n",
    "# model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))#,kernel_initializer=initializer))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))#,kernel_initializer=initializer))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "8fb8411a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_112 (Conv1D)          (None, 4538, 8)           664       \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 4498, 8)           2632      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 2249, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 2249, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 2219, 16)          3984      \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 2189, 16)          7952      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 1094, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 1094, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 1074, 16)          5392      \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1054, 16)          5392      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 527, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 527, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 519, 32)           4640      \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 511, 32)           9248      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 255, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 255, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 251, 32)           5152      \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 247, 32)           5152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 123, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 123, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 121, 64)           6208      \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 119, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 59, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 59, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 3776)              0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                37770     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 106,571\n",
      "Trainable params: 106,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "6b89f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperModel as hp\n",
    "from keras_tuner.tuners import RandomSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "d4551229",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,\n",
    "    patience=350,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "50b307a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "134/134 [==============================] - 6s 36ms/step - loss: 0.1465 - accuracy: 0.9469 - val_loss: 2.1077 - val_accuracy: 0.5798\n",
      "Epoch 2/1200\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.1480 - accuracy: 0.9444"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-504-a181660e1468>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mstepValidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m history = model.fit(loadTrain(trainData,sampleSize),\n\u001b[0m\u001b[0;32m     11\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstepTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloadTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msampleSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1212\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1214\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1215\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelName = 'rawLFP_v5n'\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "stepTrain=len(trainData)//batchSize\n",
    "stepValidate=len(validate)//batchSize\n",
    "\n",
    "history = model.fit(loadTrain(trainData,sampleSize),\n",
    "                    steps_per_epoch=stepTrain,\n",
    "                    validation_data=loadTrain(validate,sampleSize),\n",
    "                    validation_steps=stepValidate,\n",
    "                    epochs=1200,callbacks=[early_stopping])#,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "20602c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = hp.Int('numFilters_1', min_value=4, max_value=64, step=4),\n",
    "                     kernel_size= hp.Int('kernalSize_1', min_value=3, max_value=89, step=2), \n",
    "                     input_shape=(segN,2), activation='relu'))\n",
    "#     model.add(Conv1D(filters = hp.Int('numFilters_2', min_value=4, max_value=64, step=4),\n",
    "#                      kernel_size= hp.Int('kernalSize_2', min_value=3, max_value=89, step=2),\n",
    "#                      activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(rate=hp.Float(\n",
    "                'dropout_1',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.20,\n",
    "                step=0.05,)))\n",
    "\n",
    "#     model.add(Conv1D(16, (5), activation='relu'))\n",
    "    model.add(Conv1D(filters = hp.Int('numFilters_2', min_value=4, max_value=64, step=4),\n",
    "                     kernel_size= hp.Int('kernalSize_2', min_value=3, max_value=89, step=2), activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(rate=hp.Float(\n",
    "                'dropout_2',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.20,\n",
    "                step=0.05,)))\n",
    "\n",
    "#     model.add(Conv1D(16, (9), activation='relu'))\n",
    "    model.add(Conv1D(filters = hp.Int('numFilters_3', min_value=8, max_value=64, step=4),\n",
    "                     kernel_size= hp.Int('kernalSize_3', min_value=3, max_value=89, step=2), activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(rate=hp.Float(\n",
    "                'dropout_3',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.20,\n",
    "                step=0.05,)))\n",
    "\n",
    "#     model.add(Conv1D(32, (21), activation='relu'))\n",
    "    model.add(Conv1D(filters = hp.Int('numFilters_4', min_value=16, max_value=64, step=4),\n",
    "                     kernel_size= hp.Int('kernalSize_4', min_value=3, max_value=89, step=2), activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(rate=hp.Float(\n",
    "                'dropout_4',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.20,\n",
    "                step=0.05,)))\n",
    "\n",
    "#     model.add(Conv1D(32, (31), activation='relu'))\n",
    "    model.add(Conv1D(filters = hp.Int('numFilters_5', min_value=16, max_value=64, step=4),\n",
    "                     kernel_size= hp.Int('kernalSize_5', min_value=3, max_value=89, step=2), activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(rate=hp.Float(\n",
    "                'dropout_5',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.20,\n",
    "                step=0.05,)))\n",
    "\n",
    "#     model.add(Conv1D(64, (41), activation='relu'))\n",
    "    model.add(Conv1D(filters = hp.Int('numFilters_6', min_value=16, max_value=64, step=4),\n",
    "                     kernel_size= hp.Int('kernalSize_6', min_value=3, max_value=89, step=2), activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(rate=hp.Float(\n",
    "                'dropout_6',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.20,\n",
    "                step=0.05,)))\n",
    "\n",
    "\n",
    "    # model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))#,kernel_initializer=initializer))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hp.Int(\n",
    "                    'units',\n",
    "                    min_value=5,\n",
    "                    max_value=30,\n",
    "                    step=5,\n",
    "                    default=10), activation='relu'))#,kernel_initializer=initializer))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "9f25f634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [10h 46m 29s]\n",
      "val_accuracy: 0.5543367351804461\n",
      "\n",
      "Best val_accuracy So Far: 0.7854591820921216\n",
      "Total elapsed time: 06h 57m 07s\n",
      "\n",
      "Search: Running Trial #4\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "filters           |12                |12                \n",
      "numFilters_1      |60                |60                \n",
      "kernalSize_1      |3                 |3                 \n",
      "dropout_1         |0                 |0                 \n",
      "numFilters_2      |64                |64                \n",
      "kernalSize_2      |41                |83                \n",
      "dropout_2         |0                 |0.15              \n",
      "numFilters_3      |40                |36                \n",
      "kernalSize_3      |57                |5                 \n",
      "dropout_3         |0.5               |0.5               \n",
      "numFilters_4      |24                |24                \n",
      "kernalSize_4      |3                 |17                \n",
      "dropout_4         |0                 |0.15              \n",
      "numFilters_5      |16                |16                \n",
      "kernalSize_5      |89                |89                \n",
      "dropout_5         |0.45              |0.4               \n",
      "numFilters_6      |32                |16                \n",
      "kernalSize_6      |3                 |3                 \n",
      "dropout_6         |0.4               |0.5               \n",
      "units             |30                |30                \n",
      "\n",
      "Epoch 1/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0985 - accuracy: 0.3509 - val_loss: 1.0981 - val_accuracy: 0.3560\n",
      "Epoch 2/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0972 - accuracy: 0.3697 - val_loss: 1.0970 - val_accuracy: 0.3310\n",
      "Epoch 3/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0971 - accuracy: 0.3729 - val_loss: 1.0963 - val_accuracy: 0.3500\n",
      "Epoch 4/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0948 - accuracy: 0.3751 - val_loss: 1.0954 - val_accuracy: 0.3548\n",
      "Epoch 5/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0942 - accuracy: 0.3871 - val_loss: 1.0954 - val_accuracy: 0.3298\n",
      "Epoch 6/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0928 - accuracy: 0.3866 - val_loss: 1.0948 - val_accuracy: 0.3333\n",
      "Epoch 7/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0936 - accuracy: 0.3774 - val_loss: 1.0919 - val_accuracy: 0.3548\n",
      "Epoch 8/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0925 - accuracy: 0.3835 - val_loss: 1.0955 - val_accuracy: 0.3357\n",
      "Epoch 9/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0927 - accuracy: 0.3772 - val_loss: 1.0909 - val_accuracy: 0.3298\n",
      "Epoch 10/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0897 - accuracy: 0.3882 - val_loss: 1.0877 - val_accuracy: 0.3524\n",
      "Epoch 11/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0903 - accuracy: 0.3821 - val_loss: 1.0929 - val_accuracy: 0.3321\n",
      "Epoch 12/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0871 - accuracy: 0.3863 - val_loss: 1.0889 - val_accuracy: 0.3464\n",
      "Epoch 13/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0871 - accuracy: 0.3825 - val_loss: 1.0861 - val_accuracy: 0.3679\n",
      "Epoch 14/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0878 - accuracy: 0.3807 - val_loss: 1.0966 - val_accuracy: 0.3369\n",
      "Epoch 15/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0847 - accuracy: 0.3928 - val_loss: 1.0772 - val_accuracy: 0.3881\n",
      "Epoch 16/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0798 - accuracy: 0.3914 - val_loss: 1.0812 - val_accuracy: 0.3810\n",
      "Epoch 17/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0796 - accuracy: 0.3925 - val_loss: 1.0699 - val_accuracy: 0.4143\n",
      "Epoch 18/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0781 - accuracy: 0.3910 - val_loss: 1.0859 - val_accuracy: 0.3893\n",
      "Epoch 19/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0759 - accuracy: 0.4000 - val_loss: 1.0720 - val_accuracy: 0.4048\n",
      "Epoch 20/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0789 - accuracy: 0.3937 - val_loss: 1.0900 - val_accuracy: 0.3631\n",
      "Epoch 21/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0704 - accuracy: 0.4068 - val_loss: 1.0779 - val_accuracy: 0.3881\n",
      "Epoch 22/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0713 - accuracy: 0.3998 - val_loss: 1.0737 - val_accuracy: 0.3952\n",
      "Epoch 23/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0692 - accuracy: 0.4009 - val_loss: 1.0758 - val_accuracy: 0.3929\n",
      "Epoch 24/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0640 - accuracy: 0.4108 - val_loss: 1.0589 - val_accuracy: 0.4155\n",
      "Epoch 25/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0631 - accuracy: 0.4032 - val_loss: 1.0656 - val_accuracy: 0.3857\n",
      "Epoch 26/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0607 - accuracy: 0.4104 - val_loss: 1.1326 - val_accuracy: 0.3500\n",
      "Epoch 27/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0611 - accuracy: 0.4046 - val_loss: 1.0910 - val_accuracy: 0.3810\n",
      "Epoch 28/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0589 - accuracy: 0.4039 - val_loss: 1.0765 - val_accuracy: 0.3714\n",
      "Epoch 29/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0539 - accuracy: 0.4236 - val_loss: 1.0637 - val_accuracy: 0.4167\n",
      "Epoch 30/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0507 - accuracy: 0.4148 - val_loss: 1.0634 - val_accuracy: 0.4214\n",
      "Epoch 31/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0551 - accuracy: 0.4163 - val_loss: 1.0492 - val_accuracy: 0.4083\n",
      "Epoch 32/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0482 - accuracy: 0.4159 - val_loss: 1.0609 - val_accuracy: 0.4119\n",
      "Epoch 33/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0463 - accuracy: 0.4200 - val_loss: 1.0485 - val_accuracy: 0.3869\n",
      "Epoch 34/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0510 - accuracy: 0.4187 - val_loss: 1.0618 - val_accuracy: 0.4214\n",
      "Epoch 35/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0439 - accuracy: 0.4139 - val_loss: 1.0837 - val_accuracy: 0.3726\n",
      "Epoch 36/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0380 - accuracy: 0.4303 - val_loss: 1.0642 - val_accuracy: 0.4095\n",
      "Epoch 37/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0408 - accuracy: 0.4249 - val_loss: 1.0562 - val_accuracy: 0.3988\n",
      "Epoch 38/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0357 - accuracy: 0.4294 - val_loss: 1.0787 - val_accuracy: 0.3774\n",
      "Epoch 39/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0385 - accuracy: 0.4256 - val_loss: 1.0534 - val_accuracy: 0.4202\n",
      "Epoch 40/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0326 - accuracy: 0.4275 - val_loss: 1.1196 - val_accuracy: 0.3726\n",
      "Epoch 41/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0391 - accuracy: 0.4284 - val_loss: 1.0600 - val_accuracy: 0.4012\n",
      "Epoch 42/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0427 - accuracy: 0.4352 - val_loss: 1.0492 - val_accuracy: 0.4429\n",
      "Epoch 43/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0380 - accuracy: 0.4318 - val_loss: 1.0049 - val_accuracy: 0.4738\n",
      "Epoch 44/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0361 - accuracy: 0.4241 - val_loss: 1.0453 - val_accuracy: 0.4333\n",
      "Epoch 45/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0271 - accuracy: 0.4352 - val_loss: 1.0835 - val_accuracy: 0.4298\n",
      "Epoch 46/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0305 - accuracy: 0.4354 - val_loss: 1.0523 - val_accuracy: 0.4036\n",
      "Epoch 47/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0245 - accuracy: 0.4423 - val_loss: 1.0899 - val_accuracy: 0.3940\n",
      "Epoch 48/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0224 - accuracy: 0.4412 - val_loss: 1.1416 - val_accuracy: 0.4274\n",
      "Epoch 49/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0279 - accuracy: 0.4318 - val_loss: 1.0385 - val_accuracy: 0.4274\n",
      "Epoch 50/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0263 - accuracy: 0.4405 - val_loss: 1.0572 - val_accuracy: 0.4155\n",
      "Epoch 51/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0193 - accuracy: 0.4425 - val_loss: 1.0290 - val_accuracy: 0.4512\n",
      "Epoch 52/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0214 - accuracy: 0.4399 - val_loss: 1.0228 - val_accuracy: 0.4679\n",
      "Epoch 53/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0219 - accuracy: 0.4410 - val_loss: 1.0139 - val_accuracy: 0.4583\n",
      "Epoch 54/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0171 - accuracy: 0.4463 - val_loss: 1.0041 - val_accuracy: 0.4500\n",
      "Epoch 55/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0184 - accuracy: 0.4414 - val_loss: 1.0987 - val_accuracy: 0.4036\n",
      "Epoch 56/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0103 - accuracy: 0.4456 - val_loss: 0.9778 - val_accuracy: 0.4869\n",
      "Epoch 57/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0105 - accuracy: 0.4525 - val_loss: 1.0400 - val_accuracy: 0.4452\n",
      "Epoch 58/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0180 - accuracy: 0.4369 - val_loss: 1.0377 - val_accuracy: 0.4524\n",
      "Epoch 59/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0089 - accuracy: 0.4522 - val_loss: 1.0239 - val_accuracy: 0.4381\n",
      "Epoch 60/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0022 - accuracy: 0.4480 - val_loss: 1.0805 - val_accuracy: 0.4190\n",
      "Epoch 61/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0087 - accuracy: 0.4398 - val_loss: 1.0870 - val_accuracy: 0.3762\n",
      "Epoch 62/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9991 - accuracy: 0.4468 - val_loss: 0.9983 - val_accuracy: 0.4726\n",
      "Epoch 63/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0084 - accuracy: 0.4393 - val_loss: 0.9878 - val_accuracy: 0.4488\n",
      "Epoch 64/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0109 - accuracy: 0.4445 - val_loss: 1.0662 - val_accuracy: 0.4155\n",
      "Epoch 65/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0070 - accuracy: 0.4531 - val_loss: 1.0230 - val_accuracy: 0.4298\n",
      "Epoch 66/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0015 - accuracy: 0.4545 - val_loss: 1.0042 - val_accuracy: 0.4512\n",
      "Epoch 67/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9967 - accuracy: 0.4598 - val_loss: 1.0648 - val_accuracy: 0.4357\n",
      "Epoch 68/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9990 - accuracy: 0.4516 - val_loss: 1.0797 - val_accuracy: 0.4321\n",
      "Epoch 69/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9984 - accuracy: 0.4573 - val_loss: 1.0499 - val_accuracy: 0.4048\n",
      "Epoch 70/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9935 - accuracy: 0.4710 - val_loss: 1.0615 - val_accuracy: 0.4286\n",
      "Epoch 71/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9828 - accuracy: 0.4738 - val_loss: 1.0077 - val_accuracy: 0.4548\n",
      "Epoch 72/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9915 - accuracy: 0.4660 - val_loss: 0.9986 - val_accuracy: 0.4607\n",
      "Epoch 73/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9836 - accuracy: 0.4708 - val_loss: 1.0443 - val_accuracy: 0.4369\n",
      "Epoch 74/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9833 - accuracy: 0.4735 - val_loss: 1.0206 - val_accuracy: 0.4345\n",
      "Epoch 75/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9965 - accuracy: 0.4700 - val_loss: 1.0134 - val_accuracy: 0.4357\n",
      "Epoch 76/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9834 - accuracy: 0.4913 - val_loss: 0.9956 - val_accuracy: 0.4940\n",
      "Epoch 77/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9868 - accuracy: 0.4954 - val_loss: 1.0068 - val_accuracy: 0.4690\n",
      "Epoch 78/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9741 - accuracy: 0.5029 - val_loss: 1.0191 - val_accuracy: 0.4726\n",
      "Epoch 79/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9733 - accuracy: 0.5159 - val_loss: 1.0308 - val_accuracy: 0.4714\n",
      "Epoch 80/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9718 - accuracy: 0.5119 - val_loss: 1.2268 - val_accuracy: 0.4417\n",
      "Epoch 81/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9602 - accuracy: 0.5276 - val_loss: 0.9848 - val_accuracy: 0.5179\n",
      "Epoch 82/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9661 - accuracy: 0.5205 - val_loss: 1.0487 - val_accuracy: 0.4381\n",
      "Epoch 83/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9475 - accuracy: 0.5382 - val_loss: 0.9921 - val_accuracy: 0.4738\n",
      "Epoch 84/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9505 - accuracy: 0.5320 - val_loss: 1.0506 - val_accuracy: 0.4750\n",
      "Epoch 85/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9323 - accuracy: 0.5478 - val_loss: 1.0455 - val_accuracy: 0.4595\n",
      "Epoch 86/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9469 - accuracy: 0.5351 - val_loss: 0.9700 - val_accuracy: 0.5036\n",
      "Epoch 87/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9385 - accuracy: 0.5471 - val_loss: 1.0605 - val_accuracy: 0.4738\n",
      "Epoch 88/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9347 - accuracy: 0.5501 - val_loss: 1.0382 - val_accuracy: 0.4726\n",
      "Epoch 89/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9348 - accuracy: 0.5424 - val_loss: 0.9891 - val_accuracy: 0.5119\n",
      "Epoch 90/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9281 - accuracy: 0.5498 - val_loss: 1.0461 - val_accuracy: 0.4321\n",
      "Epoch 91/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9319 - accuracy: 0.5504 - val_loss: 0.9714 - val_accuracy: 0.5214\n",
      "Epoch 92/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9300 - accuracy: 0.5509 - val_loss: 0.9738 - val_accuracy: 0.5107\n",
      "Epoch 93/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9307 - accuracy: 0.5526 - val_loss: 0.9814 - val_accuracy: 0.5095\n",
      "Epoch 94/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9160 - accuracy: 0.5498 - val_loss: 1.0008 - val_accuracy: 0.5024\n",
      "Epoch 95/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9071 - accuracy: 0.5663 - val_loss: 1.0025 - val_accuracy: 0.5071\n",
      "Epoch 96/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9087 - accuracy: 0.5704 - val_loss: 0.9937 - val_accuracy: 0.5000\n",
      "Epoch 97/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9131 - accuracy: 0.5595 - val_loss: 1.0832 - val_accuracy: 0.4690\n",
      "Epoch 98/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9092 - accuracy: 0.5665 - val_loss: 0.9391 - val_accuracy: 0.5417\n",
      "Epoch 99/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9066 - accuracy: 0.5685 - val_loss: 0.9872 - val_accuracy: 0.5369\n",
      "Epoch 100/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9019 - accuracy: 0.5611 - val_loss: 0.9349 - val_accuracy: 0.5405\n",
      "Epoch 101/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8951 - accuracy: 0.5668 - val_loss: 1.0184 - val_accuracy: 0.4798\n",
      "Epoch 102/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9024 - accuracy: 0.5601 - val_loss: 1.0169 - val_accuracy: 0.4738\n",
      "Epoch 103/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8997 - accuracy: 0.5665 - val_loss: 0.9941 - val_accuracy: 0.5226\n",
      "Epoch 104/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8874 - accuracy: 0.5777 - val_loss: 0.9612 - val_accuracy: 0.5119\n",
      "Epoch 105/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8853 - accuracy: 0.5731 - val_loss: 1.0300 - val_accuracy: 0.4607\n",
      "Epoch 106/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8830 - accuracy: 0.5825 - val_loss: 0.9422 - val_accuracy: 0.5155\n",
      "Epoch 107/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8912 - accuracy: 0.5767 - val_loss: 0.9179 - val_accuracy: 0.5226\n",
      "Epoch 108/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8863 - accuracy: 0.5806 - val_loss: 1.0110 - val_accuracy: 0.4726\n",
      "Epoch 109/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8726 - accuracy: 0.5913 - val_loss: 1.0346 - val_accuracy: 0.4393\n",
      "Epoch 110/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8813 - accuracy: 0.5851 - val_loss: 0.9495 - val_accuracy: 0.5536\n",
      "Epoch 111/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8695 - accuracy: 0.5782 - val_loss: 0.9816 - val_accuracy: 0.5310\n",
      "Epoch 112/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8738 - accuracy: 0.5866 - val_loss: 0.9407 - val_accuracy: 0.5357\n",
      "Epoch 113/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8788 - accuracy: 0.5784 - val_loss: 0.9631 - val_accuracy: 0.5464\n",
      "Epoch 114/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8772 - accuracy: 0.5827 - val_loss: 0.9822 - val_accuracy: 0.5131\n",
      "Epoch 115/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8605 - accuracy: 0.5903 - val_loss: 1.0593 - val_accuracy: 0.4679\n",
      "Epoch 116/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8702 - accuracy: 0.5808 - val_loss: 0.9572 - val_accuracy: 0.5524\n",
      "Epoch 117/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8527 - accuracy: 0.5927 - val_loss: 0.9138 - val_accuracy: 0.5321\n",
      "Epoch 118/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8538 - accuracy: 0.5948 - val_loss: 0.9770 - val_accuracy: 0.4905\n",
      "Epoch 119/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8661 - accuracy: 0.5897 - val_loss: 0.9623 - val_accuracy: 0.5071\n",
      "Epoch 120/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8572 - accuracy: 0.5897 - val_loss: 0.9412 - val_accuracy: 0.5595\n",
      "Epoch 121/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8487 - accuracy: 0.5961 - val_loss: 0.9905 - val_accuracy: 0.4536\n",
      "Epoch 122/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8518 - accuracy: 0.5971 - val_loss: 0.9771 - val_accuracy: 0.5095\n",
      "Epoch 123/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8404 - accuracy: 0.6090 - val_loss: 0.9128 - val_accuracy: 0.5929\n",
      "Epoch 124/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8583 - accuracy: 0.5919 - val_loss: 0.9860 - val_accuracy: 0.4714\n",
      "Epoch 125/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8483 - accuracy: 0.5963 - val_loss: 0.9611 - val_accuracy: 0.5131\n",
      "Epoch 126/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8381 - accuracy: 0.6101 - val_loss: 1.0444 - val_accuracy: 0.4905\n",
      "Epoch 127/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8389 - accuracy: 0.6039 - val_loss: 0.9835 - val_accuracy: 0.5012\n",
      "Epoch 128/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8360 - accuracy: 0.6111 - val_loss: 1.0145 - val_accuracy: 0.4845\n",
      "Epoch 129/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8450 - accuracy: 0.6020 - val_loss: 0.9853 - val_accuracy: 0.4810\n",
      "Epoch 130/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8278 - accuracy: 0.6077 - val_loss: 0.9938 - val_accuracy: 0.5131\n",
      "Epoch 131/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8382 - accuracy: 0.6078 - val_loss: 0.9981 - val_accuracy: 0.5000\n",
      "Epoch 132/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8214 - accuracy: 0.6143 - val_loss: 1.0286 - val_accuracy: 0.4667\n",
      "Epoch 133/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8268 - accuracy: 0.6126 - val_loss: 0.9755 - val_accuracy: 0.5238\n",
      "Epoch 134/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8266 - accuracy: 0.6138 - val_loss: 0.9913 - val_accuracy: 0.5095\n",
      "Epoch 135/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8155 - accuracy: 0.6193 - val_loss: 0.9479 - val_accuracy: 0.5155\n",
      "Epoch 136/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8279 - accuracy: 0.6092 - val_loss: 1.0054 - val_accuracy: 0.4714\n",
      "Epoch 137/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8122 - accuracy: 0.6229 - val_loss: 1.0389 - val_accuracy: 0.4726\n",
      "Epoch 138/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8238 - accuracy: 0.6131 - val_loss: 0.9961 - val_accuracy: 0.5369\n",
      "Epoch 139/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8261 - accuracy: 0.6080 - val_loss: 0.9793 - val_accuracy: 0.4798\n",
      "Epoch 140/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8119 - accuracy: 0.6241 - val_loss: 0.9300 - val_accuracy: 0.5500\n",
      "Epoch 141/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8133 - accuracy: 0.6189 - val_loss: 0.9560 - val_accuracy: 0.5226\n",
      "Epoch 142/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8098 - accuracy: 0.6256 - val_loss: 1.0197 - val_accuracy: 0.4512\n",
      "Epoch 143/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8174 - accuracy: 0.6163 - val_loss: 0.9574 - val_accuracy: 0.5310\n",
      "Epoch 144/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7994 - accuracy: 0.6266 - val_loss: 1.0244 - val_accuracy: 0.4714\n",
      "Epoch 145/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7878 - accuracy: 0.6369 - val_loss: 0.9716 - val_accuracy: 0.5190\n",
      "Epoch 146/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7994 - accuracy: 0.6271 - val_loss: 0.9291 - val_accuracy: 0.5429\n",
      "Epoch 147/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7894 - accuracy: 0.6358 - val_loss: 1.1083 - val_accuracy: 0.5012\n",
      "Epoch 148/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7817 - accuracy: 0.6381 - val_loss: 0.9098 - val_accuracy: 0.5440\n",
      "Epoch 149/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7877 - accuracy: 0.6383 - val_loss: 1.0468 - val_accuracy: 0.4488\n",
      "Epoch 150/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7976 - accuracy: 0.6267 - val_loss: 0.9761 - val_accuracy: 0.5488\n",
      "Epoch 151/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7799 - accuracy: 0.6403 - val_loss: 1.0286 - val_accuracy: 0.4810\n",
      "Epoch 152/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7813 - accuracy: 0.6432 - val_loss: 0.9753 - val_accuracy: 0.5607\n",
      "Epoch 153/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7928 - accuracy: 0.6308 - val_loss: 0.9503 - val_accuracy: 0.5226\n",
      "Epoch 154/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7800 - accuracy: 0.6475 - val_loss: 0.9196 - val_accuracy: 0.5607\n",
      "Epoch 155/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7665 - accuracy: 0.6479 - val_loss: 0.9496 - val_accuracy: 0.5202\n",
      "Epoch 156/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7846 - accuracy: 0.6378 - val_loss: 0.9715 - val_accuracy: 0.5714\n",
      "Epoch 157/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8031 - accuracy: 0.6234 - val_loss: 0.9736 - val_accuracy: 0.5274\n",
      "Epoch 158/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7727 - accuracy: 0.6322 - val_loss: 0.9946 - val_accuracy: 0.5238\n",
      "Epoch 159/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7923 - accuracy: 0.6238 - val_loss: 0.9789 - val_accuracy: 0.5369\n",
      "Epoch 160/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7644 - accuracy: 0.6414 - val_loss: 0.8688 - val_accuracy: 0.6095\n",
      "Epoch 161/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7662 - accuracy: 0.6418 - val_loss: 0.9240 - val_accuracy: 0.5845\n",
      "Epoch 162/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7793 - accuracy: 0.6311 - val_loss: 0.9942 - val_accuracy: 0.5143\n",
      "Epoch 163/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7758 - accuracy: 0.6389 - val_loss: 0.9543 - val_accuracy: 0.5571\n",
      "Epoch 164/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7573 - accuracy: 0.6494 - val_loss: 0.9540 - val_accuracy: 0.5417\n",
      "Epoch 165/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7738 - accuracy: 0.6396 - val_loss: 1.3741 - val_accuracy: 0.4143\n",
      "Epoch 166/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7546 - accuracy: 0.6461 - val_loss: 0.8658 - val_accuracy: 0.6071\n",
      "Epoch 167/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7474 - accuracy: 0.6536 - val_loss: 0.8122 - val_accuracy: 0.6131\n",
      "Epoch 168/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7467 - accuracy: 0.6563 - val_loss: 0.8389 - val_accuracy: 0.6298\n",
      "Epoch 169/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7536 - accuracy: 0.6546 - val_loss: 0.8867 - val_accuracy: 0.5560\n",
      "Epoch 170/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7610 - accuracy: 0.6521 - val_loss: 0.8935 - val_accuracy: 0.5714\n",
      "Epoch 171/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7676 - accuracy: 0.6465 - val_loss: 1.1945 - val_accuracy: 0.4976\n",
      "Epoch 172/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7618 - accuracy: 0.6443 - val_loss: 0.9737 - val_accuracy: 0.5571\n",
      "Epoch 173/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7561 - accuracy: 0.6500 - val_loss: 0.9740 - val_accuracy: 0.5119\n",
      "Epoch 174/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7527 - accuracy: 0.6553 - val_loss: 1.0101 - val_accuracy: 0.4833\n",
      "Epoch 175/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7483 - accuracy: 0.6568 - val_loss: 0.8555 - val_accuracy: 0.5869\n",
      "Epoch 176/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7302 - accuracy: 0.6715 - val_loss: 0.8818 - val_accuracy: 0.5595\n",
      "Epoch 177/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7311 - accuracy: 0.6664 - val_loss: 1.0170 - val_accuracy: 0.5571\n",
      "Epoch 178/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7368 - accuracy: 0.6604 - val_loss: 0.8661 - val_accuracy: 0.5810\n",
      "Epoch 179/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7258 - accuracy: 0.6743 - val_loss: 0.9184 - val_accuracy: 0.5548\n",
      "Epoch 180/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7228 - accuracy: 0.6639 - val_loss: 0.9485 - val_accuracy: 0.5357\n",
      "Epoch 181/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7150 - accuracy: 0.6708 - val_loss: 0.9436 - val_accuracy: 0.5262\n",
      "Epoch 182/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7289 - accuracy: 0.6619 - val_loss: 0.9310 - val_accuracy: 0.5536\n",
      "Epoch 183/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7339 - accuracy: 0.6679 - val_loss: 0.9325 - val_accuracy: 0.5631\n",
      "Epoch 184/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7107 - accuracy: 0.6799 - val_loss: 0.9393 - val_accuracy: 0.5274\n",
      "Epoch 185/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7071 - accuracy: 0.6779 - val_loss: 0.8475 - val_accuracy: 0.5643\n",
      "Epoch 186/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7136 - accuracy: 0.6775 - val_loss: 0.8506 - val_accuracy: 0.5881\n",
      "Epoch 187/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7036 - accuracy: 0.6840 - val_loss: 0.9071 - val_accuracy: 0.5893\n",
      "Epoch 188/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7123 - accuracy: 0.6765 - val_loss: 1.0410 - val_accuracy: 0.5476\n",
      "Epoch 189/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7377 - accuracy: 0.6611 - val_loss: 1.0596 - val_accuracy: 0.5250\n",
      "Epoch 190/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6793 - accuracy: 0.6902 - val_loss: 0.8542 - val_accuracy: 0.5976\n",
      "Epoch 191/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7056 - accuracy: 0.6792 - val_loss: 0.9861 - val_accuracy: 0.5702\n",
      "Epoch 192/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7089 - accuracy: 0.6741 - val_loss: 0.9863 - val_accuracy: 0.5131\n",
      "Epoch 193/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6888 - accuracy: 0.6904 - val_loss: 0.8645 - val_accuracy: 0.5988\n",
      "Epoch 194/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7111 - accuracy: 0.6762 - val_loss: 0.9065 - val_accuracy: 0.5798\n",
      "Epoch 195/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6810 - accuracy: 0.6930 - val_loss: 0.7770 - val_accuracy: 0.6429\n",
      "Epoch 196/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6854 - accuracy: 0.6939 - val_loss: 0.9550 - val_accuracy: 0.5738\n",
      "Epoch 197/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6953 - accuracy: 0.6923 - val_loss: 0.8738 - val_accuracy: 0.5774\n",
      "Epoch 198/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6949 - accuracy: 0.6893 - val_loss: 0.9000 - val_accuracy: 0.5798\n",
      "Epoch 199/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6699 - accuracy: 0.7012 - val_loss: 0.8073 - val_accuracy: 0.6238\n",
      "Epoch 200/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6919 - accuracy: 0.6907 - val_loss: 1.0940 - val_accuracy: 0.5417\n",
      "Epoch 201/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6721 - accuracy: 0.6948 - val_loss: 1.0421 - val_accuracy: 0.5024\n",
      "Epoch 202/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6753 - accuracy: 0.6965 - val_loss: 0.9051 - val_accuracy: 0.6060\n",
      "Epoch 203/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6887 - accuracy: 0.6881 - val_loss: 0.8369 - val_accuracy: 0.6167\n",
      "Epoch 204/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6854 - accuracy: 0.6902 - val_loss: 1.0131 - val_accuracy: 0.6119\n",
      "Epoch 205/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6932 - accuracy: 0.6884 - val_loss: 0.8270 - val_accuracy: 0.6095\n",
      "Epoch 206/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6659 - accuracy: 0.7005 - val_loss: 0.8614 - val_accuracy: 0.6238\n",
      "Epoch 207/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6661 - accuracy: 0.7051 - val_loss: 0.8299 - val_accuracy: 0.6131\n",
      "Epoch 208/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6531 - accuracy: 0.7081 - val_loss: 0.8473 - val_accuracy: 0.5810\n",
      "Epoch 209/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6879 - accuracy: 0.6912 - val_loss: 0.9546 - val_accuracy: 0.5417\n",
      "Epoch 210/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6505 - accuracy: 0.7068 - val_loss: 0.9000 - val_accuracy: 0.6012\n",
      "Epoch 211/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6726 - accuracy: 0.7027 - val_loss: 0.8225 - val_accuracy: 0.6417\n",
      "Epoch 212/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6902 - accuracy: 0.6872 - val_loss: 0.8376 - val_accuracy: 0.6012\n",
      "Epoch 213/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6512 - accuracy: 0.7150 - val_loss: 0.9753 - val_accuracy: 0.5821\n",
      "Epoch 214/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6700 - accuracy: 0.7056 - val_loss: 0.8110 - val_accuracy: 0.6369\n",
      "Epoch 215/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6230 - accuracy: 0.7310 - val_loss: 0.8519 - val_accuracy: 0.6214\n",
      "Epoch 216/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6982 - accuracy: 0.6869 - val_loss: 0.8844 - val_accuracy: 0.6083\n",
      "Epoch 217/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6571 - accuracy: 0.7061 - val_loss: 0.8101 - val_accuracy: 0.5917\n",
      "Epoch 218/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6559 - accuracy: 0.7098 - val_loss: 1.1906 - val_accuracy: 0.5464\n",
      "Epoch 219/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6341 - accuracy: 0.7246 - val_loss: 0.8249 - val_accuracy: 0.6190\n",
      "Epoch 220/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6635 - accuracy: 0.7072 - val_loss: 0.9446 - val_accuracy: 0.5786\n",
      "Epoch 221/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6301 - accuracy: 0.7231 - val_loss: 0.9555 - val_accuracy: 0.5917\n",
      "Epoch 222/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6309 - accuracy: 0.7236 - val_loss: 0.8627 - val_accuracy: 0.6381\n",
      "Epoch 223/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6408 - accuracy: 0.7177 - val_loss: 0.9070 - val_accuracy: 0.6119\n",
      "Epoch 224/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6396 - accuracy: 0.7195 - val_loss: 0.9231 - val_accuracy: 0.5929\n",
      "Epoch 225/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6310 - accuracy: 0.7236 - val_loss: 0.7886 - val_accuracy: 0.6321\n",
      "Epoch 226/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6298 - accuracy: 0.7198 - val_loss: 0.9721 - val_accuracy: 0.5536\n",
      "Epoch 227/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6282 - accuracy: 0.7249 - val_loss: 0.8185 - val_accuracy: 0.6464\n",
      "Epoch 228/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6032 - accuracy: 0.7340 - val_loss: 0.8698 - val_accuracy: 0.5667\n",
      "Epoch 229/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6336 - accuracy: 0.7229 - val_loss: 0.8151 - val_accuracy: 0.6298\n",
      "Epoch 230/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6187 - accuracy: 0.7310 - val_loss: 0.7582 - val_accuracy: 0.6548\n",
      "Epoch 231/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6250 - accuracy: 0.7260 - val_loss: 0.9255 - val_accuracy: 0.5917\n",
      "Epoch 232/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6099 - accuracy: 0.7270 - val_loss: 0.9715 - val_accuracy: 0.5964\n",
      "Epoch 233/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6132 - accuracy: 0.7374 - val_loss: 1.0544 - val_accuracy: 0.5250\n",
      "Epoch 234/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6166 - accuracy: 0.7307 - val_loss: 0.8698 - val_accuracy: 0.6095\n",
      "Epoch 235/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6239 - accuracy: 0.7299 - val_loss: 0.8321 - val_accuracy: 0.6417\n",
      "Epoch 236/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6033 - accuracy: 0.7392 - val_loss: 0.8443 - val_accuracy: 0.6190\n",
      "Epoch 237/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5962 - accuracy: 0.7415 - val_loss: 0.9558 - val_accuracy: 0.5976\n",
      "Epoch 238/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6105 - accuracy: 0.7316 - val_loss: 0.9047 - val_accuracy: 0.5929\n",
      "Epoch 239/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5985 - accuracy: 0.7384 - val_loss: 0.8867 - val_accuracy: 0.6095\n",
      "Epoch 240/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6027 - accuracy: 0.7394 - val_loss: 0.8579 - val_accuracy: 0.6214\n",
      "Epoch 241/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6394 - accuracy: 0.7208 - val_loss: 0.9572 - val_accuracy: 0.6131\n",
      "Epoch 242/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5837 - accuracy: 0.7478 - val_loss: 0.8427 - val_accuracy: 0.6083\n",
      "Epoch 243/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5765 - accuracy: 0.7535 - val_loss: 0.8606 - val_accuracy: 0.6202\n",
      "Epoch 244/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5963 - accuracy: 0.7425 - val_loss: 0.9158 - val_accuracy: 0.6202\n",
      "Epoch 245/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6011 - accuracy: 0.7419 - val_loss: 0.9400 - val_accuracy: 0.5964\n",
      "Epoch 246/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5983 - accuracy: 0.7361 - val_loss: 0.9389 - val_accuracy: 0.6071\n",
      "Epoch 247/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5967 - accuracy: 0.7369 - val_loss: 0.9033 - val_accuracy: 0.6512\n",
      "Epoch 248/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6156 - accuracy: 0.7287 - val_loss: 0.8372 - val_accuracy: 0.6393\n",
      "Epoch 249/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6122 - accuracy: 0.7336 - val_loss: 0.8384 - val_accuracy: 0.6226\n",
      "Epoch 250/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5925 - accuracy: 0.7420 - val_loss: 0.9713 - val_accuracy: 0.5833\n",
      "Epoch 251/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5908 - accuracy: 0.7499 - val_loss: 0.7996 - val_accuracy: 0.6190\n",
      "Epoch 252/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5997 - accuracy: 0.7367 - val_loss: 0.8185 - val_accuracy: 0.6583\n",
      "Epoch 253/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5763 - accuracy: 0.7493 - val_loss: 0.7772 - val_accuracy: 0.6679\n",
      "Epoch 254/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5892 - accuracy: 0.7440 - val_loss: 0.8772 - val_accuracy: 0.6155\n",
      "Epoch 255/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5814 - accuracy: 0.7521 - val_loss: 0.9518 - val_accuracy: 0.6226\n",
      "Epoch 256/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5954 - accuracy: 0.7509 - val_loss: 0.8583 - val_accuracy: 0.6262\n",
      "Epoch 257/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5477 - accuracy: 0.7655 - val_loss: 0.9329 - val_accuracy: 0.6095\n",
      "Epoch 258/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5864 - accuracy: 0.7439 - val_loss: 0.7973 - val_accuracy: 0.6750\n",
      "Epoch 259/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6034 - accuracy: 0.7325 - val_loss: 0.8266 - val_accuracy: 0.6548\n",
      "Epoch 260/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5875 - accuracy: 0.7373 - val_loss: 0.8050 - val_accuracy: 0.6476\n",
      "Epoch 261/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5943 - accuracy: 0.7313 - val_loss: 0.8212 - val_accuracy: 0.6405\n",
      "Epoch 262/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5919 - accuracy: 0.7393 - val_loss: 0.7491 - val_accuracy: 0.6810\n",
      "Epoch 263/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6053 - accuracy: 0.7306 - val_loss: 0.8236 - val_accuracy: 0.6643\n",
      "Epoch 264/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5582 - accuracy: 0.7558 - val_loss: 0.8406 - val_accuracy: 0.6262\n",
      "Epoch 265/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5619 - accuracy: 0.7628 - val_loss: 0.9412 - val_accuracy: 0.6095\n",
      "Epoch 266/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5499 - accuracy: 0.7653 - val_loss: 0.9773 - val_accuracy: 0.5667\n",
      "Epoch 267/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5426 - accuracy: 0.7719 - val_loss: 0.9381 - val_accuracy: 0.6536\n",
      "Epoch 268/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5525 - accuracy: 0.7643 - val_loss: 0.8855 - val_accuracy: 0.5869\n",
      "Epoch 269/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5421 - accuracy: 0.7648 - val_loss: 0.9168 - val_accuracy: 0.6440\n",
      "Epoch 270/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5473 - accuracy: 0.7621 - val_loss: 0.8503 - val_accuracy: 0.6440\n",
      "Epoch 271/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5474 - accuracy: 0.7632 - val_loss: 0.8205 - val_accuracy: 0.6214\n",
      "Epoch 272/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5262 - accuracy: 0.7827 - val_loss: 1.0483 - val_accuracy: 0.5964\n",
      "Epoch 273/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5403 - accuracy: 0.7685 - val_loss: 0.9481 - val_accuracy: 0.5964\n",
      "Epoch 274/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5601 - accuracy: 0.7619 - val_loss: 0.9453 - val_accuracy: 0.5964\n",
      "Epoch 275/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5247 - accuracy: 0.7716 - val_loss: 0.7817 - val_accuracy: 0.6452\n",
      "Epoch 276/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5285 - accuracy: 0.7786 - val_loss: 0.8955 - val_accuracy: 0.6214\n",
      "Epoch 277/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5885 - accuracy: 0.7520 - val_loss: 1.1185 - val_accuracy: 0.5810\n",
      "Epoch 278/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5538 - accuracy: 0.7642 - val_loss: 0.8255 - val_accuracy: 0.6500\n",
      "Epoch 279/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5371 - accuracy: 0.7706 - val_loss: 0.7667 - val_accuracy: 0.6798\n",
      "Epoch 280/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5095 - accuracy: 0.7861 - val_loss: 0.8671 - val_accuracy: 0.6571\n",
      "Epoch 281/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5498 - accuracy: 0.7655 - val_loss: 0.9445 - val_accuracy: 0.6214\n",
      "Epoch 282/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5522 - accuracy: 0.7628 - val_loss: 0.8244 - val_accuracy: 0.6226\n",
      "Epoch 283/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5774 - accuracy: 0.7486 - val_loss: 1.0089 - val_accuracy: 0.5964\n",
      "Epoch 284/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5764 - accuracy: 0.7514 - val_loss: 0.8703 - val_accuracy: 0.6393\n",
      "Epoch 285/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5415 - accuracy: 0.7632 - val_loss: 0.9295 - val_accuracy: 0.6833\n",
      "Epoch 286/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5338 - accuracy: 0.7709 - val_loss: 0.9405 - val_accuracy: 0.6429\n",
      "Epoch 287/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5715 - accuracy: 0.7592 - val_loss: 0.8331 - val_accuracy: 0.6298\n",
      "Epoch 288/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5289 - accuracy: 0.7724 - val_loss: 0.7954 - val_accuracy: 0.6405\n",
      "Epoch 289/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5251 - accuracy: 0.7725 - val_loss: 0.8777 - val_accuracy: 0.6310\n",
      "Epoch 290/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5509 - accuracy: 0.7670 - val_loss: 0.9487 - val_accuracy: 0.5976\n",
      "Epoch 291/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5092 - accuracy: 0.7857 - val_loss: 0.8648 - val_accuracy: 0.6262\n",
      "Epoch 292/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5179 - accuracy: 0.7815 - val_loss: 0.7537 - val_accuracy: 0.6702\n",
      "Epoch 293/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5169 - accuracy: 0.7821 - val_loss: 0.8159 - val_accuracy: 0.6679\n",
      "Epoch 294/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5128 - accuracy: 0.7810 - val_loss: 0.8232 - val_accuracy: 0.6464\n",
      "Epoch 295/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5431 - accuracy: 0.7792 - val_loss: 0.7255 - val_accuracy: 0.6762\n",
      "Epoch 296/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5058 - accuracy: 0.7806 - val_loss: 0.8748 - val_accuracy: 0.6488\n",
      "Epoch 297/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4973 - accuracy: 0.7889 - val_loss: 0.7377 - val_accuracy: 0.6881\n",
      "Epoch 298/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5530 - accuracy: 0.7704 - val_loss: 0.8425 - val_accuracy: 0.6524\n",
      "Epoch 299/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5003 - accuracy: 0.7943 - val_loss: 0.9753 - val_accuracy: 0.6238\n",
      "Epoch 300/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4797 - accuracy: 0.8006 - val_loss: 0.9227 - val_accuracy: 0.6417\n",
      "Epoch 301/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5107 - accuracy: 0.7867 - val_loss: 0.7363 - val_accuracy: 0.7262\n",
      "Epoch 302/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5038 - accuracy: 0.7862 - val_loss: 0.9128 - val_accuracy: 0.6595\n",
      "Epoch 303/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4950 - accuracy: 0.7915 - val_loss: 0.7995 - val_accuracy: 0.6774\n",
      "Epoch 304/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5591 - accuracy: 0.7566 - val_loss: 1.0427 - val_accuracy: 0.5488\n",
      "Epoch 305/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6130 - accuracy: 0.7173 - val_loss: 0.9690 - val_accuracy: 0.5881\n",
      "Epoch 306/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5671 - accuracy: 0.7337 - val_loss: 0.8859 - val_accuracy: 0.6440\n",
      "Epoch 307/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5544 - accuracy: 0.7496 - val_loss: 1.0336 - val_accuracy: 0.5929\n",
      "Epoch 308/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5549 - accuracy: 0.7595 - val_loss: 0.9710 - val_accuracy: 0.5560\n",
      "Epoch 309/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5536 - accuracy: 0.7654 - val_loss: 0.6947 - val_accuracy: 0.7012\n",
      "Epoch 310/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4946 - accuracy: 0.7909 - val_loss: 0.9398 - val_accuracy: 0.6381\n",
      "Epoch 311/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4820 - accuracy: 0.7980 - val_loss: 0.8040 - val_accuracy: 0.6631\n",
      "Epoch 312/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4738 - accuracy: 0.8009 - val_loss: 0.8535 - val_accuracy: 0.6810\n",
      "Epoch 313/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4823 - accuracy: 0.7905 - val_loss: 0.8847 - val_accuracy: 0.6333\n",
      "Epoch 314/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4907 - accuracy: 0.7956 - val_loss: 0.8516 - val_accuracy: 0.6917\n",
      "Epoch 315/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4788 - accuracy: 0.7996 - val_loss: 0.8614 - val_accuracy: 0.6405\n",
      "Epoch 316/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4692 - accuracy: 0.8030 - val_loss: 0.7062 - val_accuracy: 0.6964\n",
      "Epoch 317/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4732 - accuracy: 0.8014 - val_loss: 0.7740 - val_accuracy: 0.6881\n",
      "Epoch 318/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4590 - accuracy: 0.8118 - val_loss: 0.9752 - val_accuracy: 0.6131\n",
      "Epoch 319/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4657 - accuracy: 0.8124 - val_loss: 0.8566 - val_accuracy: 0.6929\n",
      "Epoch 320/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4587 - accuracy: 0.8093 - val_loss: 1.0024 - val_accuracy: 0.6381\n",
      "Epoch 321/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4630 - accuracy: 0.8080 - val_loss: 0.8979 - val_accuracy: 0.6262\n",
      "Epoch 322/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4610 - accuracy: 0.8100 - val_loss: 0.9085 - val_accuracy: 0.6476\n",
      "Epoch 323/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4438 - accuracy: 0.8160 - val_loss: 0.7687 - val_accuracy: 0.6774\n",
      "Epoch 324/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4893 - accuracy: 0.7984 - val_loss: 0.8863 - val_accuracy: 0.6560\n",
      "Epoch 325/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4674 - accuracy: 0.8107 - val_loss: 0.8511 - val_accuracy: 0.6845\n",
      "Epoch 326/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4604 - accuracy: 0.8097 - val_loss: 0.8779 - val_accuracy: 0.6250\n",
      "Epoch 327/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4545 - accuracy: 0.8113 - val_loss: 0.6879 - val_accuracy: 0.6702\n",
      "Epoch 328/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4630 - accuracy: 0.8091 - val_loss: 0.8927 - val_accuracy: 0.6512\n",
      "Epoch 329/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4543 - accuracy: 0.8162 - val_loss: 0.8907 - val_accuracy: 0.6321\n",
      "Epoch 330/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4731 - accuracy: 0.8021 - val_loss: 1.0636 - val_accuracy: 0.5786\n",
      "Epoch 331/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4984 - accuracy: 0.7853 - val_loss: 0.8511 - val_accuracy: 0.6417\n",
      "Epoch 332/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4681 - accuracy: 0.7944 - val_loss: 0.8612 - val_accuracy: 0.6619\n",
      "Epoch 333/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4927 - accuracy: 0.7878 - val_loss: 0.7813 - val_accuracy: 0.6702\n",
      "Epoch 334/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5219 - accuracy: 0.7762 - val_loss: 0.8324 - val_accuracy: 0.6381\n",
      "Epoch 335/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4720 - accuracy: 0.7985 - val_loss: 0.8980 - val_accuracy: 0.6845\n",
      "Epoch 336/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4724 - accuracy: 0.7928 - val_loss: 0.7078 - val_accuracy: 0.6821\n",
      "Epoch 337/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4534 - accuracy: 0.8020 - val_loss: 0.7344 - val_accuracy: 0.6857\n",
      "Epoch 338/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4680 - accuracy: 0.7954 - val_loss: 0.7544 - val_accuracy: 0.7143\n",
      "Epoch 339/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4480 - accuracy: 0.8102 - val_loss: 0.7884 - val_accuracy: 0.6690\n",
      "Epoch 340/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4678 - accuracy: 0.7969 - val_loss: 0.9131 - val_accuracy: 0.6548\n",
      "Epoch 341/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4590 - accuracy: 0.8016 - val_loss: 0.8246 - val_accuracy: 0.6643\n",
      "Epoch 342/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4749 - accuracy: 0.7934 - val_loss: 0.8241 - val_accuracy: 0.6810\n",
      "Epoch 343/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4573 - accuracy: 0.8032 - val_loss: 1.0422 - val_accuracy: 0.6512\n",
      "Epoch 344/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4468 - accuracy: 0.8060 - val_loss: 0.8518 - val_accuracy: 0.6738\n",
      "Epoch 345/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4419 - accuracy: 0.8123 - val_loss: 0.8028 - val_accuracy: 0.6833\n",
      "Epoch 346/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4436 - accuracy: 0.8103 - val_loss: 0.9478 - val_accuracy: 0.6440\n",
      "Epoch 347/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4493 - accuracy: 0.8077 - val_loss: 0.8482 - val_accuracy: 0.6881\n",
      "Epoch 348/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4750 - accuracy: 0.7993 - val_loss: 0.8675 - val_accuracy: 0.6690\n",
      "Epoch 349/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4415 - accuracy: 0.8121 - val_loss: 0.8283 - val_accuracy: 0.6786\n",
      "Epoch 350/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4683 - accuracy: 0.7970 - val_loss: 0.8733 - val_accuracy: 0.6476\n",
      "Epoch 351/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4331 - accuracy: 0.8157 - val_loss: 0.7456 - val_accuracy: 0.6988\n",
      "Epoch 352/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4257 - accuracy: 0.8228 - val_loss: 0.8192 - val_accuracy: 0.6560\n",
      "Epoch 353/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4444 - accuracy: 0.8097 - val_loss: 0.9246 - val_accuracy: 0.6452\n",
      "Epoch 354/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4539 - accuracy: 0.8037 - val_loss: 1.0270 - val_accuracy: 0.6250\n",
      "Epoch 355/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4519 - accuracy: 0.8044 - val_loss: 0.8185 - val_accuracy: 0.6810\n",
      "Epoch 356/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4550 - accuracy: 0.8118 - val_loss: 0.7697 - val_accuracy: 0.6786\n",
      "Epoch 357/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4448 - accuracy: 0.8118 - val_loss: 0.8835 - val_accuracy: 0.6464\n",
      "Epoch 358/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4399 - accuracy: 0.8144 - val_loss: 0.8845 - val_accuracy: 0.6619\n",
      "Epoch 359/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4291 - accuracy: 0.8128 - val_loss: 0.7885 - val_accuracy: 0.6583\n",
      "Epoch 360/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4295 - accuracy: 0.8180 - val_loss: 0.8350 - val_accuracy: 0.6810\n",
      "Epoch 361/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4317 - accuracy: 0.8128 - val_loss: 0.8346 - val_accuracy: 0.6774\n",
      "Epoch 362/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4229 - accuracy: 0.8219 - val_loss: 0.7573 - val_accuracy: 0.7012\n",
      "Epoch 363/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4105 - accuracy: 0.8287 - val_loss: 0.8537 - val_accuracy: 0.6762\n",
      "Epoch 364/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4088 - accuracy: 0.8276 - val_loss: 0.7229 - val_accuracy: 0.7262\n",
      "Epoch 365/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4342 - accuracy: 0.8201 - val_loss: 0.9360 - val_accuracy: 0.6429\n",
      "Epoch 366/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4504 - accuracy: 0.8104 - val_loss: 1.1537 - val_accuracy: 0.5548\n",
      "Epoch 367/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4316 - accuracy: 0.8193 - val_loss: 1.0549 - val_accuracy: 0.5893\n",
      "Epoch 368/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4215 - accuracy: 0.8234 - val_loss: 0.7916 - val_accuracy: 0.6940\n",
      "Epoch 369/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4005 - accuracy: 0.8323 - val_loss: 0.7595 - val_accuracy: 0.7024\n",
      "Epoch 370/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4122 - accuracy: 0.8277 - val_loss: 0.8631 - val_accuracy: 0.6940\n",
      "Epoch 371/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3914 - accuracy: 0.8320 - val_loss: 0.8173 - val_accuracy: 0.6821\n",
      "Epoch 372/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4236 - accuracy: 0.8213 - val_loss: 0.9528 - val_accuracy: 0.6583\n",
      "Epoch 373/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4067 - accuracy: 0.8341 - val_loss: 0.7927 - val_accuracy: 0.7167\n",
      "Epoch 374/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4131 - accuracy: 0.8266 - val_loss: 0.8791 - val_accuracy: 0.6512\n",
      "Epoch 375/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4132 - accuracy: 0.8311 - val_loss: 0.8542 - val_accuracy: 0.6714\n",
      "Epoch 376/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4137 - accuracy: 0.8249 - val_loss: 0.7432 - val_accuracy: 0.6893\n",
      "Epoch 377/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3976 - accuracy: 0.8354 - val_loss: 0.8443 - val_accuracy: 0.6833\n",
      "Epoch 378/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4187 - accuracy: 0.8246 - val_loss: 0.7921 - val_accuracy: 0.7119\n",
      "Epoch 379/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4138 - accuracy: 0.8266 - val_loss: 0.7626 - val_accuracy: 0.7202\n",
      "Epoch 380/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3946 - accuracy: 0.8340 - val_loss: 0.8415 - val_accuracy: 0.6643\n",
      "Epoch 381/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4024 - accuracy: 0.8328 - val_loss: 0.9929 - val_accuracy: 0.6274\n",
      "Epoch 382/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4307 - accuracy: 0.8195 - val_loss: 1.1872 - val_accuracy: 0.5679\n",
      "Epoch 383/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3868 - accuracy: 0.8408 - val_loss: 0.8700 - val_accuracy: 0.6738\n",
      "Epoch 384/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3749 - accuracy: 0.8400 - val_loss: 0.7232 - val_accuracy: 0.7274\n",
      "Epoch 385/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4546 - accuracy: 0.8072 - val_loss: 0.7111 - val_accuracy: 0.7298\n",
      "Epoch 386/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4123 - accuracy: 0.8276 - val_loss: 0.9767 - val_accuracy: 0.6250\n",
      "Epoch 387/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4448 - accuracy: 0.8133 - val_loss: 0.7560 - val_accuracy: 0.7107\n",
      "Epoch 388/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3832 - accuracy: 0.8439 - val_loss: 0.8254 - val_accuracy: 0.7393\n",
      "Epoch 389/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3944 - accuracy: 0.8347 - val_loss: 0.7405 - val_accuracy: 0.7071\n",
      "Epoch 390/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3818 - accuracy: 0.8364 - val_loss: 1.1360 - val_accuracy: 0.6036\n",
      "Epoch 391/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3755 - accuracy: 0.8463 - val_loss: 0.8211 - val_accuracy: 0.7012\n",
      "Epoch 392/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3912 - accuracy: 0.8400 - val_loss: 0.7747 - val_accuracy: 0.6976\n",
      "Epoch 393/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4278 - accuracy: 0.8198 - val_loss: 0.8997 - val_accuracy: 0.6583\n",
      "Epoch 394/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3975 - accuracy: 0.8259 - val_loss: 0.8900 - val_accuracy: 0.6905\n",
      "Epoch 395/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3967 - accuracy: 0.8343 - val_loss: 0.7207 - val_accuracy: 0.6976\n",
      "Epoch 396/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4175 - accuracy: 0.8254 - val_loss: 0.8182 - val_accuracy: 0.6607\n",
      "Epoch 397/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3716 - accuracy: 0.8413 - val_loss: 0.9720 - val_accuracy: 0.6631\n",
      "Epoch 398/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3837 - accuracy: 0.8397 - val_loss: 0.6959 - val_accuracy: 0.7238\n",
      "Epoch 399/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3621 - accuracy: 0.8444 - val_loss: 0.7765 - val_accuracy: 0.7274\n",
      "Epoch 400/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3832 - accuracy: 0.8361 - val_loss: 0.7983 - val_accuracy: 0.6964\n",
      "Epoch 401/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3686 - accuracy: 0.8453 - val_loss: 0.7740 - val_accuracy: 0.7048\n",
      "Epoch 402/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3833 - accuracy: 0.8358 - val_loss: 0.9051 - val_accuracy: 0.6702\n",
      "Epoch 403/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3838 - accuracy: 0.8408 - val_loss: 0.8640 - val_accuracy: 0.6571\n",
      "Epoch 404/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3675 - accuracy: 0.8437 - val_loss: 0.7963 - val_accuracy: 0.6976\n",
      "Epoch 405/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3700 - accuracy: 0.8398 - val_loss: 0.7528 - val_accuracy: 0.7190\n",
      "Epoch 406/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3791 - accuracy: 0.8415 - val_loss: 0.9337 - val_accuracy: 0.6893\n",
      "Epoch 407/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3673 - accuracy: 0.8433 - val_loss: 0.7415 - val_accuracy: 0.7095\n",
      "Epoch 408/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3558 - accuracy: 0.8540 - val_loss: 0.7551 - val_accuracy: 0.7250\n",
      "Epoch 409/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4215 - accuracy: 0.8228 - val_loss: 1.0637 - val_accuracy: 0.5929\n",
      "Epoch 410/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3968 - accuracy: 0.8276 - val_loss: 0.7771 - val_accuracy: 0.6940\n",
      "Epoch 411/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4007 - accuracy: 0.8289 - val_loss: 0.7788 - val_accuracy: 0.7060\n",
      "Epoch 412/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3927 - accuracy: 0.8372 - val_loss: 0.7190 - val_accuracy: 0.7333\n",
      "Epoch 413/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3823 - accuracy: 0.8463 - val_loss: 0.9040 - val_accuracy: 0.6405\n",
      "Epoch 414/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3657 - accuracy: 0.8514 - val_loss: 0.9257 - val_accuracy: 0.7095\n",
      "Epoch 415/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4091 - accuracy: 0.8236 - val_loss: 0.7774 - val_accuracy: 0.7107\n",
      "Epoch 416/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3842 - accuracy: 0.8394 - val_loss: 0.9661 - val_accuracy: 0.6940\n",
      "Epoch 417/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3509 - accuracy: 0.8481 - val_loss: 0.8414 - val_accuracy: 0.7405\n",
      "Epoch 418/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3780 - accuracy: 0.8427 - val_loss: 0.8552 - val_accuracy: 0.7095\n",
      "Epoch 419/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3555 - accuracy: 0.8478 - val_loss: 0.7400 - val_accuracy: 0.7214\n",
      "Epoch 420/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3529 - accuracy: 0.8555 - val_loss: 0.7283 - val_accuracy: 0.7393\n",
      "Epoch 421/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3406 - accuracy: 0.8614 - val_loss: 0.8369 - val_accuracy: 0.7262\n",
      "Epoch 422/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3795 - accuracy: 0.8397 - val_loss: 0.7862 - val_accuracy: 0.7274\n",
      "Epoch 423/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3318 - accuracy: 0.8586 - val_loss: 0.9498 - val_accuracy: 0.6690\n",
      "Epoch 424/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3412 - accuracy: 0.8556 - val_loss: 0.8311 - val_accuracy: 0.7238\n",
      "Epoch 425/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3462 - accuracy: 0.8500 - val_loss: 0.6641 - val_accuracy: 0.7381\n",
      "Epoch 426/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3428 - accuracy: 0.8540 - val_loss: 0.8520 - val_accuracy: 0.7405\n",
      "Epoch 427/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3686 - accuracy: 0.8479 - val_loss: 0.7947 - val_accuracy: 0.7060\n",
      "Epoch 428/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3636 - accuracy: 0.8541 - val_loss: 1.0402 - val_accuracy: 0.6190\n",
      "Epoch 429/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3719 - accuracy: 0.8501 - val_loss: 0.7508 - val_accuracy: 0.7286\n",
      "Epoch 430/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3535 - accuracy: 0.8551 - val_loss: 0.7963 - val_accuracy: 0.6976\n",
      "Epoch 431/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3264 - accuracy: 0.8618 - val_loss: 0.7874 - val_accuracy: 0.7345\n",
      "Epoch 432/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3368 - accuracy: 0.8621 - val_loss: 0.8198 - val_accuracy: 0.7095\n",
      "Epoch 433/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3810 - accuracy: 0.8427 - val_loss: 0.8910 - val_accuracy: 0.6786\n",
      "Epoch 434/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3366 - accuracy: 0.8576 - val_loss: 0.7652 - val_accuracy: 0.7179\n",
      "Epoch 435/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3415 - accuracy: 0.8557 - val_loss: 0.7475 - val_accuracy: 0.7286\n",
      "Epoch 436/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3338 - accuracy: 0.8586 - val_loss: 0.7385 - val_accuracy: 0.7238\n",
      "Epoch 437/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3460 - accuracy: 0.8561 - val_loss: 0.8073 - val_accuracy: 0.7024\n",
      "Epoch 438/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3389 - accuracy: 0.8612 - val_loss: 0.6801 - val_accuracy: 0.7512\n",
      "Epoch 439/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3264 - accuracy: 0.8632 - val_loss: 0.7438 - val_accuracy: 0.7250\n",
      "Epoch 440/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3451 - accuracy: 0.8565 - val_loss: 0.8573 - val_accuracy: 0.7036\n",
      "Epoch 441/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3336 - accuracy: 0.8563 - val_loss: 0.7815 - val_accuracy: 0.7333\n",
      "Epoch 442/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3409 - accuracy: 0.8576 - val_loss: 0.7187 - val_accuracy: 0.7512\n",
      "Epoch 443/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3341 - accuracy: 0.8568 - val_loss: 0.7641 - val_accuracy: 0.7167\n",
      "Epoch 444/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3387 - accuracy: 0.8563 - val_loss: 0.7271 - val_accuracy: 0.7226\n",
      "Epoch 445/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3219 - accuracy: 0.8650 - val_loss: 0.7948 - val_accuracy: 0.7298\n",
      "Epoch 446/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3260 - accuracy: 0.8672 - val_loss: 0.8109 - val_accuracy: 0.7060\n",
      "Epoch 447/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3429 - accuracy: 0.8530 - val_loss: 0.7481 - val_accuracy: 0.7262\n",
      "Epoch 448/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3314 - accuracy: 0.8596 - val_loss: 0.8498 - val_accuracy: 0.7119\n",
      "Epoch 449/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3123 - accuracy: 0.8660 - val_loss: 1.0136 - val_accuracy: 0.6881\n",
      "Epoch 450/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3524 - accuracy: 0.8583 - val_loss: 0.8387 - val_accuracy: 0.7083\n",
      "Epoch 451/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3244 - accuracy: 0.8636 - val_loss: 0.7860 - val_accuracy: 0.7524\n",
      "Epoch 452/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3436 - accuracy: 0.8573 - val_loss: 0.9397 - val_accuracy: 0.7274\n",
      "Epoch 453/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3258 - accuracy: 0.8646 - val_loss: 0.8080 - val_accuracy: 0.7440\n",
      "Epoch 454/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3406 - accuracy: 0.8588 - val_loss: 0.8661 - val_accuracy: 0.6952\n",
      "Epoch 455/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3340 - accuracy: 0.8614 - val_loss: 0.9136 - val_accuracy: 0.6905\n",
      "Epoch 456/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3317 - accuracy: 0.8649 - val_loss: 0.7355 - val_accuracy: 0.7690\n",
      "Epoch 457/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3315 - accuracy: 0.8692 - val_loss: 0.9412 - val_accuracy: 0.6857\n",
      "Epoch 458/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3302 - accuracy: 0.8544 - val_loss: 0.8607 - val_accuracy: 0.7048\n",
      "Epoch 459/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3146 - accuracy: 0.8719 - val_loss: 0.7866 - val_accuracy: 0.7560\n",
      "Epoch 460/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3281 - accuracy: 0.8649 - val_loss: 0.9861 - val_accuracy: 0.6893\n",
      "Epoch 461/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3283 - accuracy: 0.8637 - val_loss: 0.8210 - val_accuracy: 0.7369\n",
      "Epoch 462/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3165 - accuracy: 0.8659 - val_loss: 0.9843 - val_accuracy: 0.6833\n",
      "Epoch 463/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3195 - accuracy: 0.8667 - val_loss: 0.7294 - val_accuracy: 0.7488\n",
      "Epoch 464/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3466 - accuracy: 0.8593 - val_loss: 0.8872 - val_accuracy: 0.7143\n",
      "Epoch 465/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3131 - accuracy: 0.8725 - val_loss: 0.8199 - val_accuracy: 0.7202\n",
      "Epoch 466/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3138 - accuracy: 0.8687 - val_loss: 0.8137 - val_accuracy: 0.7262\n",
      "Epoch 467/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3153 - accuracy: 0.8709 - val_loss: 0.7987 - val_accuracy: 0.7214\n",
      "Epoch 468/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3132 - accuracy: 0.8757 - val_loss: 0.8861 - val_accuracy: 0.7298\n",
      "Epoch 469/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3072 - accuracy: 0.8734 - val_loss: 0.9170 - val_accuracy: 0.7143\n",
      "Epoch 470/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3126 - accuracy: 0.8713 - val_loss: 0.7812 - val_accuracy: 0.7452\n",
      "Epoch 471/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3651 - accuracy: 0.8522 - val_loss: 1.0332 - val_accuracy: 0.6464\n",
      "Epoch 472/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3103 - accuracy: 0.8719 - val_loss: 0.7902 - val_accuracy: 0.7238\n",
      "Epoch 473/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3158 - accuracy: 0.8663 - val_loss: 0.8835 - val_accuracy: 0.7036\n",
      "Epoch 474/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3023 - accuracy: 0.8706 - val_loss: 0.8063 - val_accuracy: 0.7512\n",
      "Epoch 475/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3264 - accuracy: 0.8694 - val_loss: 0.8947 - val_accuracy: 0.7036\n",
      "Epoch 476/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3007 - accuracy: 0.8756 - val_loss: 0.7175 - val_accuracy: 0.7512\n",
      "Epoch 477/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3540 - accuracy: 0.8510 - val_loss: 1.0492 - val_accuracy: 0.6786\n",
      "Epoch 478/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3600 - accuracy: 0.8451 - val_loss: 0.6369 - val_accuracy: 0.7655\n",
      "Epoch 479/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3168 - accuracy: 0.8675 - val_loss: 0.8699 - val_accuracy: 0.7262\n",
      "Epoch 480/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3026 - accuracy: 0.8767 - val_loss: 0.7932 - val_accuracy: 0.7381\n",
      "Epoch 481/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3075 - accuracy: 0.8716 - val_loss: 0.7555 - val_accuracy: 0.7381\n",
      "Epoch 482/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3061 - accuracy: 0.8699 - val_loss: 0.6985 - val_accuracy: 0.7476\n",
      "Epoch 483/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3222 - accuracy: 0.8607 - val_loss: 0.7157 - val_accuracy: 0.7417\n",
      "Epoch 484/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3010 - accuracy: 0.8777 - val_loss: 0.7309 - val_accuracy: 0.7107\n",
      "Epoch 485/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3205 - accuracy: 0.8621 - val_loss: 0.7623 - val_accuracy: 0.7464\n",
      "Epoch 486/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3162 - accuracy: 0.8622 - val_loss: 0.7655 - val_accuracy: 0.7262\n",
      "Epoch 487/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3310 - accuracy: 0.8709 - val_loss: 0.8312 - val_accuracy: 0.7071\n",
      "Epoch 488/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2629 - accuracy: 0.8904 - val_loss: 0.7364 - val_accuracy: 0.7357\n",
      "Epoch 489/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2957 - accuracy: 0.8776 - val_loss: 0.8206 - val_accuracy: 0.7786\n",
      "Epoch 490/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3096 - accuracy: 0.8667 - val_loss: 0.7288 - val_accuracy: 0.7440\n",
      "Epoch 491/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2874 - accuracy: 0.8769 - val_loss: 0.7474 - val_accuracy: 0.7310\n",
      "Epoch 492/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3002 - accuracy: 0.8714 - val_loss: 0.7241 - val_accuracy: 0.7667\n",
      "Epoch 493/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3036 - accuracy: 0.8746 - val_loss: 0.6170 - val_accuracy: 0.7726\n",
      "Epoch 494/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2692 - accuracy: 0.8905 - val_loss: 0.8817 - val_accuracy: 0.7476\n",
      "Epoch 495/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3022 - accuracy: 0.8764 - val_loss: 0.8372 - val_accuracy: 0.7036\n",
      "Epoch 496/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2656 - accuracy: 0.8932 - val_loss: 0.7949 - val_accuracy: 0.7440\n",
      "Epoch 497/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2949 - accuracy: 0.8654 - val_loss: 1.0935 - val_accuracy: 0.6405\n",
      "Epoch 498/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3247 - accuracy: 0.8621 - val_loss: 0.7232 - val_accuracy: 0.7321\n",
      "Epoch 499/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2860 - accuracy: 0.8812 - val_loss: 0.7832 - val_accuracy: 0.7369\n",
      "Epoch 500/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2625 - accuracy: 0.8882 - val_loss: 0.7347 - val_accuracy: 0.7464\n",
      "Epoch 501/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2834 - accuracy: 0.8807 - val_loss: 0.7784 - val_accuracy: 0.7119\n",
      "Epoch 502/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2881 - accuracy: 0.8770 - val_loss: 0.7882 - val_accuracy: 0.7452\n",
      "Epoch 503/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2866 - accuracy: 0.8818 - val_loss: 0.8097 - val_accuracy: 0.7310\n",
      "Epoch 504/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2766 - accuracy: 0.8867 - val_loss: 0.8279 - val_accuracy: 0.7250\n",
      "Epoch 505/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2504 - accuracy: 0.8933 - val_loss: 0.8960 - val_accuracy: 0.7012\n",
      "Epoch 506/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2819 - accuracy: 0.8857 - val_loss: 0.9323 - val_accuracy: 0.7119\n",
      "Epoch 507/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2870 - accuracy: 0.8777 - val_loss: 0.7248 - val_accuracy: 0.7869\n",
      "Epoch 508/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3281 - accuracy: 0.8723 - val_loss: 0.6223 - val_accuracy: 0.7667\n",
      "Epoch 509/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3220 - accuracy: 0.8664 - val_loss: 0.7875 - val_accuracy: 0.6952\n",
      "Epoch 510/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3074 - accuracy: 0.8710 - val_loss: 0.6799 - val_accuracy: 0.7679\n",
      "Epoch 511/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2837 - accuracy: 0.8813 - val_loss: 0.7664 - val_accuracy: 0.7214\n",
      "Epoch 512/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2736 - accuracy: 0.8817 - val_loss: 0.8075 - val_accuracy: 0.7333\n",
      "Epoch 513/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2667 - accuracy: 0.8899 - val_loss: 0.7299 - val_accuracy: 0.7667\n",
      "Epoch 514/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2908 - accuracy: 0.8762 - val_loss: 0.6945 - val_accuracy: 0.7560\n",
      "Epoch 515/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2698 - accuracy: 0.8904 - val_loss: 0.8845 - val_accuracy: 0.7214\n",
      "Epoch 516/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2622 - accuracy: 0.8914 - val_loss: 0.8198 - val_accuracy: 0.7357\n",
      "Epoch 517/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2783 - accuracy: 0.8882 - val_loss: 0.8994 - val_accuracy: 0.6881\n",
      "Epoch 518/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2530 - accuracy: 0.8903 - val_loss: 0.8388 - val_accuracy: 0.7321\n",
      "Epoch 519/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2634 - accuracy: 0.8939 - val_loss: 0.7726 - val_accuracy: 0.7571\n",
      "Epoch 520/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2516 - accuracy: 0.8935 - val_loss: 0.8405 - val_accuracy: 0.7429\n",
      "Epoch 521/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2582 - accuracy: 0.8961 - val_loss: 0.7062 - val_accuracy: 0.7238\n",
      "Epoch 522/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2512 - accuracy: 0.9012 - val_loss: 0.7106 - val_accuracy: 0.7452\n",
      "Epoch 523/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2916 - accuracy: 0.8791 - val_loss: 0.6383 - val_accuracy: 0.7833\n",
      "Epoch 524/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2580 - accuracy: 0.8894 - val_loss: 0.7689 - val_accuracy: 0.7405\n",
      "Epoch 525/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2650 - accuracy: 0.8876 - val_loss: 0.8586 - val_accuracy: 0.7298\n",
      "Epoch 526/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2423 - accuracy: 0.8993 - val_loss: 0.8247 - val_accuracy: 0.7167\n",
      "Epoch 527/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2793 - accuracy: 0.8859 - val_loss: 0.8209 - val_accuracy: 0.7536\n",
      "Epoch 528/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2534 - accuracy: 0.8928 - val_loss: 0.8308 - val_accuracy: 0.6929\n",
      "Epoch 529/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2725 - accuracy: 0.8862 - val_loss: 0.6704 - val_accuracy: 0.7631\n",
      "Epoch 530/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2794 - accuracy: 0.8879 - val_loss: 0.7775 - val_accuracy: 0.7524\n",
      "Epoch 531/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2616 - accuracy: 0.8904 - val_loss: 0.8104 - val_accuracy: 0.6976\n",
      "Epoch 532/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2791 - accuracy: 0.8833 - val_loss: 0.7704 - val_accuracy: 0.7345\n",
      "Epoch 533/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2564 - accuracy: 0.8961 - val_loss: 0.7647 - val_accuracy: 0.7619\n",
      "Epoch 534/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3045 - accuracy: 0.8705 - val_loss: 0.6796 - val_accuracy: 0.7786\n",
      "Epoch 535/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2558 - accuracy: 0.8903 - val_loss: 0.9535 - val_accuracy: 0.7012\n",
      "Epoch 536/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2412 - accuracy: 0.9051 - val_loss: 0.7283 - val_accuracy: 0.7524\n",
      "Epoch 537/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2680 - accuracy: 0.8899 - val_loss: 0.6626 - val_accuracy: 0.7940\n",
      "Epoch 538/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2239 - accuracy: 0.9077 - val_loss: 0.6968 - val_accuracy: 0.7524\n",
      "Epoch 539/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3154 - accuracy: 0.8775 - val_loss: 0.7938 - val_accuracy: 0.7250\n",
      "Epoch 540/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2449 - accuracy: 0.9007 - val_loss: 0.6879 - val_accuracy: 0.7583\n",
      "Epoch 541/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2662 - accuracy: 0.8914 - val_loss: 0.8080 - val_accuracy: 0.7310\n",
      "Epoch 542/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2375 - accuracy: 0.9020 - val_loss: 0.7502 - val_accuracy: 0.7381\n",
      "Epoch 543/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2578 - accuracy: 0.8912 - val_loss: 0.7131 - val_accuracy: 0.7440\n",
      "Epoch 544/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2383 - accuracy: 0.9026 - val_loss: 0.8393 - val_accuracy: 0.7321\n",
      "Epoch 545/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2586 - accuracy: 0.8920 - val_loss: 0.7101 - val_accuracy: 0.7571\n",
      "Epoch 546/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2502 - accuracy: 0.8959 - val_loss: 0.7611 - val_accuracy: 0.7560\n",
      "Epoch 547/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2572 - accuracy: 0.8927 - val_loss: 0.7002 - val_accuracy: 0.7643\n",
      "Epoch 548/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2425 - accuracy: 0.8918 - val_loss: 0.7961 - val_accuracy: 0.7190\n",
      "Epoch 549/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2502 - accuracy: 0.8937 - val_loss: 0.8598 - val_accuracy: 0.7500\n",
      "Epoch 550/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2690 - accuracy: 0.8896 - val_loss: 0.7121 - val_accuracy: 0.7726\n",
      "Epoch 551/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3808 - accuracy: 0.8306 - val_loss: 1.2560 - val_accuracy: 0.6940\n",
      "Epoch 552/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3433 - accuracy: 0.8363 - val_loss: 1.0795 - val_accuracy: 0.6821\n",
      "Epoch 553/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3449 - accuracy: 0.8389 - val_loss: 0.9321 - val_accuracy: 0.7369\n",
      "Epoch 554/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3279 - accuracy: 0.8485 - val_loss: 0.9186 - val_accuracy: 0.7179\n",
      "Epoch 555/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3397 - accuracy: 0.8420 - val_loss: 0.9827 - val_accuracy: 0.6464\n",
      "Epoch 556/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3197 - accuracy: 0.8463 - val_loss: 1.0767 - val_accuracy: 0.6893\n",
      "Epoch 557/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3278 - accuracy: 0.8484 - val_loss: 0.9607 - val_accuracy: 0.7071\n",
      "Epoch 558/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2932 - accuracy: 0.8639 - val_loss: 0.8991 - val_accuracy: 0.7119\n",
      "Epoch 559/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3247 - accuracy: 0.8562 - val_loss: 0.9063 - val_accuracy: 0.7107\n",
      "Epoch 560/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3143 - accuracy: 0.8572 - val_loss: 1.0151 - val_accuracy: 0.6905\n",
      "Epoch 561/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3206 - accuracy: 0.8547 - val_loss: 0.9680 - val_accuracy: 0.7000\n",
      "Epoch 562/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3170 - accuracy: 0.8600 - val_loss: 0.8359 - val_accuracy: 0.7214\n",
      "Epoch 563/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3149 - accuracy: 0.8688 - val_loss: 0.8959 - val_accuracy: 0.7214\n",
      "Epoch 564/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3313 - accuracy: 0.8592 - val_loss: 0.8418 - val_accuracy: 0.7119\n",
      "Epoch 565/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2770 - accuracy: 0.8786 - val_loss: 0.7015 - val_accuracy: 0.7310\n",
      "Epoch 566/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2842 - accuracy: 0.8776 - val_loss: 1.1936 - val_accuracy: 0.6607\n",
      "Epoch 567/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3046 - accuracy: 0.8738 - val_loss: 0.8302 - val_accuracy: 0.6964\n",
      "Epoch 568/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3086 - accuracy: 0.8687 - val_loss: 0.9229 - val_accuracy: 0.6833\n",
      "Epoch 569/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2853 - accuracy: 0.8826 - val_loss: 0.8664 - val_accuracy: 0.6976\n",
      "Epoch 570/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2842 - accuracy: 0.8803 - val_loss: 1.1033 - val_accuracy: 0.6488\n",
      "Epoch 571/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3180 - accuracy: 0.8708 - val_loss: 0.7043 - val_accuracy: 0.7548\n",
      "Epoch 572/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2701 - accuracy: 0.8842 - val_loss: 0.7597 - val_accuracy: 0.7202\n",
      "Epoch 573/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2610 - accuracy: 0.8863 - val_loss: 1.0775 - val_accuracy: 0.6762\n",
      "Epoch 574/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2752 - accuracy: 0.8856 - val_loss: 0.9648 - val_accuracy: 0.6952\n",
      "Epoch 575/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2638 - accuracy: 0.8887 - val_loss: 0.8332 - val_accuracy: 0.7060\n",
      "Epoch 576/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2802 - accuracy: 0.8859 - val_loss: 0.7463 - val_accuracy: 0.7202\n",
      "Epoch 577/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2632 - accuracy: 0.8889 - val_loss: 0.7291 - val_accuracy: 0.7250\n",
      "Epoch 578/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2511 - accuracy: 0.8959 - val_loss: 0.6687 - val_accuracy: 0.7452\n",
      "Epoch 579/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2527 - accuracy: 0.8939 - val_loss: 0.6477 - val_accuracy: 0.7679\n",
      "Epoch 580/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2534 - accuracy: 0.8903 - val_loss: 0.7494 - val_accuracy: 0.7393\n",
      "Epoch 581/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2594 - accuracy: 0.8923 - val_loss: 0.7954 - val_accuracy: 0.7143\n",
      "Epoch 582/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2509 - accuracy: 0.8979 - val_loss: 0.7534 - val_accuracy: 0.7393\n",
      "Epoch 583/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2553 - accuracy: 0.8881 - val_loss: 0.6902 - val_accuracy: 0.7179\n",
      "Epoch 584/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2804 - accuracy: 0.8868 - val_loss: 0.7829 - val_accuracy: 0.7381\n",
      "Epoch 585/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2347 - accuracy: 0.9029 - val_loss: 0.8454 - val_accuracy: 0.7405\n",
      "Epoch 586/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2753 - accuracy: 0.8896 - val_loss: 0.6688 - val_accuracy: 0.7583\n",
      "Epoch 587/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2341 - accuracy: 0.9007 - val_loss: 0.7515 - val_accuracy: 0.7488\n",
      "Epoch 588/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2611 - accuracy: 0.8979 - val_loss: 0.7234 - val_accuracy: 0.7440\n",
      "Epoch 589/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2397 - accuracy: 0.9011 - val_loss: 0.7672 - val_accuracy: 0.7357\n",
      "Epoch 590/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2041 - accuracy: 0.9133 - val_loss: 0.7024 - val_accuracy: 0.7429\n",
      "Epoch 591/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2493 - accuracy: 0.8964 - val_loss: 0.7653 - val_accuracy: 0.7548\n",
      "Epoch 592/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2338 - accuracy: 0.9090 - val_loss: 0.7497 - val_accuracy: 0.7536\n",
      "Epoch 593/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2306 - accuracy: 0.9025 - val_loss: 0.8216 - val_accuracy: 0.7131\n",
      "Epoch 594/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2902 - accuracy: 0.8881 - val_loss: 0.6547 - val_accuracy: 0.7595\n",
      "Epoch 595/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2114 - accuracy: 0.9113 - val_loss: 0.6452 - val_accuracy: 0.7774\n",
      "Epoch 596/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2049 - accuracy: 0.9107 - val_loss: 0.6692 - val_accuracy: 0.7702\n",
      "Epoch 597/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2293 - accuracy: 0.9039 - val_loss: 0.7136 - val_accuracy: 0.7667\n",
      "Epoch 598/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2294 - accuracy: 0.9097 - val_loss: 0.6664 - val_accuracy: 0.7464\n",
      "Epoch 599/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.1949 - accuracy: 0.9160 - val_loss: 0.7964 - val_accuracy: 0.7369\n",
      "Epoch 600/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2146 - accuracy: 0.9090 - val_loss: 0.7236 - val_accuracy: 0.7583\n",
      "Epoch 1/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0987 - accuracy: 0.3412 - val_loss: 1.0982 - val_accuracy: 0.3369\n",
      "Epoch 2/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0983 - accuracy: 0.3504 - val_loss: 1.0984 - val_accuracy: 0.3333\n",
      "Epoch 3/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0973 - accuracy: 0.3685 - val_loss: 1.0975 - val_accuracy: 0.3286\n",
      "Epoch 4/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0961 - accuracy: 0.3856 - val_loss: 1.0966 - val_accuracy: 0.3405\n",
      "Epoch 5/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0944 - accuracy: 0.3836 - val_loss: 1.0970 - val_accuracy: 0.3333\n",
      "Epoch 6/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0931 - accuracy: 0.3833 - val_loss: 1.0932 - val_accuracy: 0.3548\n",
      "Epoch 7/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0931 - accuracy: 0.3774 - val_loss: 1.0938 - val_accuracy: 0.3560\n",
      "Epoch 8/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0902 - accuracy: 0.3873 - val_loss: 1.0912 - val_accuracy: 0.3690\n",
      "Epoch 9/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0929 - accuracy: 0.3716 - val_loss: 1.0931 - val_accuracy: 0.3381\n",
      "Epoch 10/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0889 - accuracy: 0.3872 - val_loss: 1.0909 - val_accuracy: 0.3417\n",
      "Epoch 11/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0904 - accuracy: 0.3797 - val_loss: 1.0953 - val_accuracy: 0.3333\n",
      "Epoch 12/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0878 - accuracy: 0.3945 - val_loss: 1.0876 - val_accuracy: 0.3845\n",
      "Epoch 13/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0906 - accuracy: 0.3775 - val_loss: 1.0907 - val_accuracy: 0.3393\n",
      "Epoch 14/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0863 - accuracy: 0.3888 - val_loss: 1.0845 - val_accuracy: 0.3798\n",
      "Epoch 15/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0881 - accuracy: 0.3851 - val_loss: 1.0912 - val_accuracy: 0.3393\n",
      "Epoch 16/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0851 - accuracy: 0.3888 - val_loss: 1.0853 - val_accuracy: 0.3893\n",
      "Epoch 17/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0836 - accuracy: 0.3979 - val_loss: 1.0871 - val_accuracy: 0.3845\n",
      "Epoch 18/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0831 - accuracy: 0.3945 - val_loss: 1.0873 - val_accuracy: 0.3726\n",
      "Epoch 19/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0823 - accuracy: 0.3905 - val_loss: 1.0799 - val_accuracy: 0.4310\n",
      "Epoch 20/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0789 - accuracy: 0.3937 - val_loss: 1.0847 - val_accuracy: 0.3833\n",
      "Epoch 21/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0774 - accuracy: 0.3956 - val_loss: 1.0853 - val_accuracy: 0.3952\n",
      "Epoch 22/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0776 - accuracy: 0.3966 - val_loss: 1.0731 - val_accuracy: 0.4083\n",
      "Epoch 23/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0741 - accuracy: 0.3976 - val_loss: 1.0778 - val_accuracy: 0.4179\n",
      "Epoch 24/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0750 - accuracy: 0.3904 - val_loss: 1.0798 - val_accuracy: 0.4000\n",
      "Epoch 25/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0685 - accuracy: 0.4045 - val_loss: 1.0691 - val_accuracy: 0.3976\n",
      "Epoch 26/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0649 - accuracy: 0.4056 - val_loss: 1.0712 - val_accuracy: 0.3798\n",
      "Epoch 27/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0652 - accuracy: 0.4037 - val_loss: 1.0686 - val_accuracy: 0.4262\n",
      "Epoch 28/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0624 - accuracy: 0.4034 - val_loss: 1.0704 - val_accuracy: 0.4119\n",
      "Epoch 29/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0621 - accuracy: 0.4155 - val_loss: 1.0665 - val_accuracy: 0.3988\n",
      "Epoch 30/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0543 - accuracy: 0.4284 - val_loss: 1.0552 - val_accuracy: 0.4333\n",
      "Epoch 31/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0547 - accuracy: 0.4198 - val_loss: 1.0890 - val_accuracy: 0.3940\n",
      "Epoch 32/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0552 - accuracy: 0.4169 - val_loss: 1.0410 - val_accuracy: 0.4155\n",
      "Epoch 33/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0490 - accuracy: 0.4249 - val_loss: 1.0845 - val_accuracy: 0.3679\n",
      "Epoch 34/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0535 - accuracy: 0.4241 - val_loss: 1.0489 - val_accuracy: 0.4369\n",
      "Epoch 35/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0549 - accuracy: 0.4248 - val_loss: 1.0512 - val_accuracy: 0.4226\n",
      "Epoch 36/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0460 - accuracy: 0.4287 - val_loss: 1.0551 - val_accuracy: 0.4155\n",
      "Epoch 37/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0518 - accuracy: 0.4264 - val_loss: 1.0379 - val_accuracy: 0.4274\n",
      "Epoch 38/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0458 - accuracy: 0.4423 - val_loss: 1.0527 - val_accuracy: 0.4298\n",
      "Epoch 39/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0453 - accuracy: 0.4424 - val_loss: 1.0503 - val_accuracy: 0.4190\n",
      "Epoch 40/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0385 - accuracy: 0.4454 - val_loss: 1.0516 - val_accuracy: 0.4107\n",
      "Epoch 41/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0414 - accuracy: 0.4439 - val_loss: 1.0598 - val_accuracy: 0.4119\n",
      "Epoch 42/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0407 - accuracy: 0.4514 - val_loss: 1.0278 - val_accuracy: 0.4298\n",
      "Epoch 43/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0451 - accuracy: 0.4379 - val_loss: 1.0336 - val_accuracy: 0.4548\n",
      "Epoch 44/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0326 - accuracy: 0.4530 - val_loss: 1.0205 - val_accuracy: 0.4655\n",
      "Epoch 45/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0349 - accuracy: 0.4454 - val_loss: 1.0456 - val_accuracy: 0.4167\n",
      "Epoch 46/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0365 - accuracy: 0.4483 - val_loss: 1.0718 - val_accuracy: 0.4143\n",
      "Epoch 47/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0362 - accuracy: 0.4461 - val_loss: 1.0580 - val_accuracy: 0.4500\n",
      "Epoch 48/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0306 - accuracy: 0.4565 - val_loss: 1.0513 - val_accuracy: 0.4619\n",
      "Epoch 49/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0295 - accuracy: 0.4575 - val_loss: 1.0568 - val_accuracy: 0.4262\n",
      "Epoch 50/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0253 - accuracy: 0.4536 - val_loss: 1.0296 - val_accuracy: 0.4655\n",
      "Epoch 51/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0316 - accuracy: 0.4464 - val_loss: 1.0325 - val_accuracy: 0.4476\n",
      "Epoch 52/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0227 - accuracy: 0.4555 - val_loss: 1.0204 - val_accuracy: 0.4536\n",
      "Epoch 53/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0189 - accuracy: 0.4593 - val_loss: 1.0248 - val_accuracy: 0.4631\n",
      "Epoch 54/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0200 - accuracy: 0.4632 - val_loss: 1.0185 - val_accuracy: 0.4690\n",
      "Epoch 55/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0073 - accuracy: 0.4700 - val_loss: 1.0490 - val_accuracy: 0.4571\n",
      "Epoch 56/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0116 - accuracy: 0.4734 - val_loss: 1.0627 - val_accuracy: 0.4143\n",
      "Epoch 57/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0077 - accuracy: 0.4729 - val_loss: 1.0526 - val_accuracy: 0.4274\n",
      "Epoch 58/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0091 - accuracy: 0.4664 - val_loss: 1.0365 - val_accuracy: 0.4476\n",
      "Epoch 59/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0072 - accuracy: 0.4752 - val_loss: 1.0260 - val_accuracy: 0.4238\n",
      "Epoch 60/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0041 - accuracy: 0.4754 - val_loss: 1.0621 - val_accuracy: 0.4274\n",
      "Epoch 61/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9975 - accuracy: 0.4749 - val_loss: 1.0506 - val_accuracy: 0.4488\n",
      "Epoch 62/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0049 - accuracy: 0.4801 - val_loss: 1.0127 - val_accuracy: 0.4845\n",
      "Epoch 63/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9930 - accuracy: 0.4861 - val_loss: 0.9952 - val_accuracy: 0.4762\n",
      "Epoch 64/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0018 - accuracy: 0.4835 - val_loss: 1.0123 - val_accuracy: 0.4726\n",
      "Epoch 65/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9941 - accuracy: 0.4813 - val_loss: 0.9917 - val_accuracy: 0.4714\n",
      "Epoch 66/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9911 - accuracy: 0.4925 - val_loss: 1.0158 - val_accuracy: 0.4631\n",
      "Epoch 67/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9857 - accuracy: 0.4918 - val_loss: 1.0283 - val_accuracy: 0.4595\n",
      "Epoch 68/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9793 - accuracy: 0.5001 - val_loss: 1.0521 - val_accuracy: 0.4583\n",
      "Epoch 69/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9872 - accuracy: 0.4965 - val_loss: 1.0323 - val_accuracy: 0.4464\n",
      "Epoch 70/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9853 - accuracy: 0.4923 - val_loss: 1.0003 - val_accuracy: 0.4940\n",
      "Epoch 71/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9716 - accuracy: 0.5078 - val_loss: 0.9821 - val_accuracy: 0.4810\n",
      "Epoch 72/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9640 - accuracy: 0.5102 - val_loss: 1.0371 - val_accuracy: 0.4690\n",
      "Epoch 73/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9695 - accuracy: 0.5093 - val_loss: 1.0138 - val_accuracy: 0.4583\n",
      "Epoch 74/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9687 - accuracy: 0.5129 - val_loss: 1.0544 - val_accuracy: 0.4393\n",
      "Epoch 75/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9663 - accuracy: 0.5167 - val_loss: 1.0001 - val_accuracy: 0.4667\n",
      "Epoch 76/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9691 - accuracy: 0.5066 - val_loss: 1.0030 - val_accuracy: 0.4762\n",
      "Epoch 77/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9637 - accuracy: 0.5085 - val_loss: 0.9900 - val_accuracy: 0.4964\n",
      "Epoch 78/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9574 - accuracy: 0.5075 - val_loss: 1.0144 - val_accuracy: 0.4821\n",
      "Epoch 79/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9566 - accuracy: 0.5104 - val_loss: 1.0339 - val_accuracy: 0.4500\n",
      "Epoch 80/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9589 - accuracy: 0.5091 - val_loss: 1.0036 - val_accuracy: 0.4643\n",
      "Epoch 81/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9556 - accuracy: 0.5083 - val_loss: 1.0004 - val_accuracy: 0.4786\n",
      "Epoch 82/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9547 - accuracy: 0.5179 - val_loss: 0.9960 - val_accuracy: 0.4976\n",
      "Epoch 83/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9417 - accuracy: 0.5266 - val_loss: 0.9887 - val_accuracy: 0.4857\n",
      "Epoch 84/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9418 - accuracy: 0.5265 - val_loss: 1.0082 - val_accuracy: 0.4905\n",
      "Epoch 85/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9482 - accuracy: 0.5269 - val_loss: 1.0083 - val_accuracy: 0.4845\n",
      "Epoch 86/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9485 - accuracy: 0.5189 - val_loss: 0.9794 - val_accuracy: 0.5095\n",
      "Epoch 87/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9396 - accuracy: 0.5281 - val_loss: 1.0100 - val_accuracy: 0.4702\n",
      "Epoch 88/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9471 - accuracy: 0.5179 - val_loss: 1.0320 - val_accuracy: 0.4262\n",
      "Epoch 89/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9408 - accuracy: 0.5199 - val_loss: 0.9660 - val_accuracy: 0.5321\n",
      "Epoch 90/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9343 - accuracy: 0.5338 - val_loss: 1.0146 - val_accuracy: 0.4500\n",
      "Epoch 91/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9340 - accuracy: 0.5330 - val_loss: 0.9615 - val_accuracy: 0.5143\n",
      "Epoch 92/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9278 - accuracy: 0.5383 - val_loss: 1.0197 - val_accuracy: 0.4905\n",
      "Epoch 93/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9362 - accuracy: 0.5403 - val_loss: 0.9796 - val_accuracy: 0.5107\n",
      "Epoch 94/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9262 - accuracy: 0.5367 - val_loss: 0.9782 - val_accuracy: 0.5012\n",
      "Epoch 95/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9202 - accuracy: 0.5478 - val_loss: 1.0053 - val_accuracy: 0.4893\n",
      "Epoch 96/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9183 - accuracy: 0.5449 - val_loss: 0.9877 - val_accuracy: 0.4893\n",
      "Epoch 97/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9153 - accuracy: 0.5459 - val_loss: 0.9843 - val_accuracy: 0.4881\n",
      "Epoch 98/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9191 - accuracy: 0.5377 - val_loss: 1.0509 - val_accuracy: 0.4548\n",
      "Epoch 99/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9158 - accuracy: 0.5393 - val_loss: 0.9884 - val_accuracy: 0.4905\n",
      "Epoch 100/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9176 - accuracy: 0.5433 - val_loss: 1.0018 - val_accuracy: 0.4833\n",
      "Epoch 101/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9106 - accuracy: 0.5439 - val_loss: 1.0127 - val_accuracy: 0.5083\n",
      "Epoch 102/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9206 - accuracy: 0.5453 - val_loss: 1.0079 - val_accuracy: 0.4524\n",
      "Epoch 103/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9120 - accuracy: 0.5468 - val_loss: 1.0407 - val_accuracy: 0.4440\n",
      "Epoch 104/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8936 - accuracy: 0.5544 - val_loss: 0.9587 - val_accuracy: 0.5060\n",
      "Epoch 105/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9057 - accuracy: 0.5485 - val_loss: 0.9572 - val_accuracy: 0.5119\n",
      "Epoch 106/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9028 - accuracy: 0.5526 - val_loss: 1.0134 - val_accuracy: 0.4738\n",
      "Epoch 107/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8999 - accuracy: 0.5517 - val_loss: 1.0022 - val_accuracy: 0.4798\n",
      "Epoch 108/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8939 - accuracy: 0.5650 - val_loss: 1.0486 - val_accuracy: 0.4274\n",
      "Epoch 109/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8883 - accuracy: 0.5558 - val_loss: 1.0142 - val_accuracy: 0.4869\n",
      "Epoch 110/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8955 - accuracy: 0.5509 - val_loss: 1.0072 - val_accuracy: 0.4595\n",
      "Epoch 111/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8904 - accuracy: 0.5580 - val_loss: 0.9515 - val_accuracy: 0.5250\n",
      "Epoch 112/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9009 - accuracy: 0.5527 - val_loss: 0.9669 - val_accuracy: 0.4905\n",
      "Epoch 113/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8848 - accuracy: 0.5708 - val_loss: 0.9776 - val_accuracy: 0.4881\n",
      "Epoch 114/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8840 - accuracy: 0.5683 - val_loss: 0.9423 - val_accuracy: 0.5190\n",
      "Epoch 115/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8806 - accuracy: 0.5642 - val_loss: 0.9722 - val_accuracy: 0.4833\n",
      "Epoch 116/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8866 - accuracy: 0.5628 - val_loss: 0.9527 - val_accuracy: 0.4762\n",
      "Epoch 117/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8824 - accuracy: 0.5629 - val_loss: 0.9500 - val_accuracy: 0.5071\n",
      "Epoch 118/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8802 - accuracy: 0.5622 - val_loss: 0.9359 - val_accuracy: 0.4964\n",
      "Epoch 119/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8938 - accuracy: 0.5622 - val_loss: 1.0012 - val_accuracy: 0.4714\n",
      "Epoch 120/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8895 - accuracy: 0.5622 - val_loss: 0.9867 - val_accuracy: 0.4762\n",
      "Epoch 121/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8857 - accuracy: 0.5602 - val_loss: 0.9718 - val_accuracy: 0.4833\n",
      "Epoch 122/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8731 - accuracy: 0.5738 - val_loss: 0.9684 - val_accuracy: 0.4917\n",
      "Epoch 123/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8741 - accuracy: 0.5776 - val_loss: 0.9278 - val_accuracy: 0.5262\n",
      "Epoch 124/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8631 - accuracy: 0.5787 - val_loss: 1.0133 - val_accuracy: 0.4595\n",
      "Epoch 125/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8645 - accuracy: 0.5815 - val_loss: 0.9903 - val_accuracy: 0.4857\n",
      "Epoch 126/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8601 - accuracy: 0.5842 - val_loss: 0.9879 - val_accuracy: 0.5048\n",
      "Epoch 127/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8537 - accuracy: 0.5863 - val_loss: 0.9965 - val_accuracy: 0.4929\n",
      "Epoch 128/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8732 - accuracy: 0.5743 - val_loss: 1.0214 - val_accuracy: 0.4548\n",
      "Epoch 129/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8604 - accuracy: 0.5827 - val_loss: 1.0038 - val_accuracy: 0.4810\n",
      "Epoch 130/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8587 - accuracy: 0.5928 - val_loss: 0.9573 - val_accuracy: 0.5000\n",
      "Epoch 131/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8417 - accuracy: 0.6001 - val_loss: 0.9950 - val_accuracy: 0.4726\n",
      "Epoch 132/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8586 - accuracy: 0.5910 - val_loss: 1.0098 - val_accuracy: 0.4607\n",
      "Epoch 133/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8504 - accuracy: 0.5993 - val_loss: 0.9576 - val_accuracy: 0.5464\n",
      "Epoch 134/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8434 - accuracy: 0.6026 - val_loss: 0.9648 - val_accuracy: 0.5107\n",
      "Epoch 135/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8583 - accuracy: 0.5858 - val_loss: 0.9329 - val_accuracy: 0.5298\n",
      "Epoch 136/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8312 - accuracy: 0.6044 - val_loss: 0.9737 - val_accuracy: 0.5036\n",
      "Epoch 137/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8472 - accuracy: 0.5939 - val_loss: 1.0003 - val_accuracy: 0.4893\n",
      "Epoch 138/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8340 - accuracy: 0.6006 - val_loss: 0.9712 - val_accuracy: 0.5000\n",
      "Epoch 139/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8270 - accuracy: 0.6063 - val_loss: 0.9876 - val_accuracy: 0.5214\n",
      "Epoch 140/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8309 - accuracy: 0.6032 - val_loss: 0.9847 - val_accuracy: 0.5012\n",
      "Epoch 141/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8292 - accuracy: 0.6078 - val_loss: 1.0080 - val_accuracy: 0.4750\n",
      "Epoch 142/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8328 - accuracy: 0.6067 - val_loss: 0.9306 - val_accuracy: 0.5167\n",
      "Epoch 143/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8197 - accuracy: 0.6184 - val_loss: 0.9638 - val_accuracy: 0.5143\n",
      "Epoch 144/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8148 - accuracy: 0.6200 - val_loss: 0.9734 - val_accuracy: 0.4905\n",
      "Epoch 145/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8197 - accuracy: 0.6143 - val_loss: 0.9381 - val_accuracy: 0.5167\n",
      "Epoch 146/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8629 - accuracy: 0.6017 - val_loss: 0.9420 - val_accuracy: 0.5321\n",
      "Epoch 147/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8501 - accuracy: 0.6075 - val_loss: 0.9571 - val_accuracy: 0.5452\n",
      "Epoch 148/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8442 - accuracy: 0.6063 - val_loss: 0.9296 - val_accuracy: 0.5238\n",
      "Epoch 149/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8450 - accuracy: 0.6127 - val_loss: 0.9062 - val_accuracy: 0.5560\n",
      "Epoch 150/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8341 - accuracy: 0.6066 - val_loss: 0.9750 - val_accuracy: 0.5452\n",
      "Epoch 151/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8280 - accuracy: 0.6141 - val_loss: 0.9525 - val_accuracy: 0.5333\n",
      "Epoch 152/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8352 - accuracy: 0.6081 - val_loss: 0.9788 - val_accuracy: 0.5012\n",
      "Epoch 153/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7997 - accuracy: 0.6285 - val_loss: 0.9518 - val_accuracy: 0.5298\n",
      "Epoch 154/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8191 - accuracy: 0.6119 - val_loss: 0.9291 - val_accuracy: 0.5262\n",
      "Epoch 155/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8095 - accuracy: 0.6081 - val_loss: 0.9085 - val_accuracy: 0.5667\n",
      "Epoch 156/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8191 - accuracy: 0.6049 - val_loss: 1.0044 - val_accuracy: 0.5060\n",
      "Epoch 157/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8072 - accuracy: 0.6172 - val_loss: 0.9610 - val_accuracy: 0.4976\n",
      "Epoch 158/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7983 - accuracy: 0.6214 - val_loss: 0.8869 - val_accuracy: 0.5786\n",
      "Epoch 159/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8095 - accuracy: 0.6160 - val_loss: 0.9013 - val_accuracy: 0.5250\n",
      "Epoch 160/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7860 - accuracy: 0.6345 - val_loss: 0.9132 - val_accuracy: 0.5500\n",
      "Epoch 161/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7890 - accuracy: 0.6228 - val_loss: 0.9011 - val_accuracy: 0.5940\n",
      "Epoch 162/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7918 - accuracy: 0.6243 - val_loss: 0.9053 - val_accuracy: 0.5405\n",
      "Epoch 163/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7986 - accuracy: 0.6230 - val_loss: 0.8554 - val_accuracy: 0.6060\n",
      "Epoch 164/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7788 - accuracy: 0.6285 - val_loss: 0.8481 - val_accuracy: 0.5786\n",
      "Epoch 165/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7854 - accuracy: 0.6336 - val_loss: 0.9147 - val_accuracy: 0.5345\n",
      "Epoch 166/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7680 - accuracy: 0.6348 - val_loss: 0.8693 - val_accuracy: 0.5667\n",
      "Epoch 167/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7767 - accuracy: 0.6267 - val_loss: 0.9046 - val_accuracy: 0.5190\n",
      "Epoch 168/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7619 - accuracy: 0.6450 - val_loss: 0.8382 - val_accuracy: 0.5952\n",
      "Epoch 169/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7614 - accuracy: 0.6343 - val_loss: 0.9106 - val_accuracy: 0.5345\n",
      "Epoch 170/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7678 - accuracy: 0.6394 - val_loss: 0.9047 - val_accuracy: 0.5881\n",
      "Epoch 171/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7698 - accuracy: 0.6346 - val_loss: 0.8847 - val_accuracy: 0.5595\n",
      "Epoch 172/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7641 - accuracy: 0.6373 - val_loss: 0.9082 - val_accuracy: 0.5452\n",
      "Epoch 173/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7546 - accuracy: 0.6442 - val_loss: 0.8974 - val_accuracy: 0.5369\n",
      "Epoch 174/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7739 - accuracy: 0.6347 - val_loss: 0.8716 - val_accuracy: 0.5476\n",
      "Epoch 175/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7510 - accuracy: 0.6532 - val_loss: 0.8795 - val_accuracy: 0.5560\n",
      "Epoch 176/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7861 - accuracy: 0.6285 - val_loss: 0.9088 - val_accuracy: 0.5560\n",
      "Epoch 177/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7958 - accuracy: 0.6205 - val_loss: 0.8388 - val_accuracy: 0.5810\n",
      "Epoch 178/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7946 - accuracy: 0.6226 - val_loss: 0.8762 - val_accuracy: 0.5667\n",
      "Epoch 179/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7679 - accuracy: 0.6409 - val_loss: 0.8772 - val_accuracy: 0.5583\n",
      "Epoch 180/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7475 - accuracy: 0.6539 - val_loss: 0.8658 - val_accuracy: 0.5548\n",
      "Epoch 181/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7602 - accuracy: 0.6495 - val_loss: 0.9000 - val_accuracy: 0.5226\n",
      "Epoch 182/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7421 - accuracy: 0.6494 - val_loss: 0.8130 - val_accuracy: 0.6155\n",
      "Epoch 183/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7448 - accuracy: 0.6522 - val_loss: 0.8037 - val_accuracy: 0.6060\n",
      "Epoch 184/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7582 - accuracy: 0.6438 - val_loss: 0.9181 - val_accuracy: 0.5214\n",
      "Epoch 185/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7321 - accuracy: 0.6562 - val_loss: 0.9462 - val_accuracy: 0.5500\n",
      "Epoch 186/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7296 - accuracy: 0.6591 - val_loss: 0.8203 - val_accuracy: 0.6262\n",
      "Epoch 187/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7367 - accuracy: 0.6566 - val_loss: 0.8716 - val_accuracy: 0.5536\n",
      "Epoch 188/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7397 - accuracy: 0.6552 - val_loss: 0.8920 - val_accuracy: 0.5738\n",
      "Epoch 189/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7336 - accuracy: 0.6562 - val_loss: 0.8556 - val_accuracy: 0.5845\n",
      "Epoch 190/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7204 - accuracy: 0.6603 - val_loss: 0.8591 - val_accuracy: 0.5619\n",
      "Epoch 191/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7488 - accuracy: 0.6520 - val_loss: 0.7652 - val_accuracy: 0.6286\n",
      "Epoch 192/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7153 - accuracy: 0.6699 - val_loss: 0.8445 - val_accuracy: 0.5869\n",
      "Epoch 193/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7158 - accuracy: 0.6655 - val_loss: 0.8167 - val_accuracy: 0.6048\n",
      "Epoch 194/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7124 - accuracy: 0.6746 - val_loss: 0.8827 - val_accuracy: 0.5643\n",
      "Epoch 195/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7157 - accuracy: 0.6704 - val_loss: 0.8601 - val_accuracy: 0.6024\n",
      "Epoch 196/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7067 - accuracy: 0.6738 - val_loss: 0.8767 - val_accuracy: 0.5762\n",
      "Epoch 197/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7221 - accuracy: 0.6689 - val_loss: 0.9147 - val_accuracy: 0.5238\n",
      "Epoch 198/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7114 - accuracy: 0.6720 - val_loss: 0.8047 - val_accuracy: 0.5988\n",
      "Epoch 199/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7202 - accuracy: 0.6650 - val_loss: 0.8671 - val_accuracy: 0.5619\n",
      "Epoch 200/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6835 - accuracy: 0.6889 - val_loss: 0.8934 - val_accuracy: 0.5750\n",
      "Epoch 201/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7208 - accuracy: 0.6641 - val_loss: 0.7799 - val_accuracy: 0.6500\n",
      "Epoch 202/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6927 - accuracy: 0.6806 - val_loss: 0.9843 - val_accuracy: 0.5012\n",
      "Epoch 203/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7047 - accuracy: 0.6796 - val_loss: 0.8546 - val_accuracy: 0.5571\n",
      "Epoch 204/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6940 - accuracy: 0.6882 - val_loss: 0.8392 - val_accuracy: 0.5845\n",
      "Epoch 205/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6848 - accuracy: 0.6884 - val_loss: 0.8635 - val_accuracy: 0.5762\n",
      "Epoch 206/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6884 - accuracy: 0.6812 - val_loss: 0.8328 - val_accuracy: 0.5952\n",
      "Epoch 207/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7095 - accuracy: 0.6733 - val_loss: 0.8100 - val_accuracy: 0.5929\n",
      "Epoch 208/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6896 - accuracy: 0.6820 - val_loss: 0.8410 - val_accuracy: 0.5940\n",
      "Epoch 209/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6810 - accuracy: 0.6930 - val_loss: 0.7905 - val_accuracy: 0.6417\n",
      "Epoch 210/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6980 - accuracy: 0.6801 - val_loss: 0.8618 - val_accuracy: 0.5810\n",
      "Epoch 211/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6842 - accuracy: 0.6918 - val_loss: 0.8181 - val_accuracy: 0.5762\n",
      "Epoch 212/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6926 - accuracy: 0.6857 - val_loss: 0.7819 - val_accuracy: 0.6286\n",
      "Epoch 213/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6818 - accuracy: 0.6881 - val_loss: 0.8777 - val_accuracy: 0.5714\n",
      "Epoch 214/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6638 - accuracy: 0.6985 - val_loss: 0.8138 - val_accuracy: 0.6226\n",
      "Epoch 215/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6702 - accuracy: 0.6925 - val_loss: 0.8990 - val_accuracy: 0.5655\n",
      "Epoch 216/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6811 - accuracy: 0.6899 - val_loss: 0.8372 - val_accuracy: 0.5702\n",
      "Epoch 217/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6739 - accuracy: 0.6944 - val_loss: 0.8235 - val_accuracy: 0.6095\n",
      "Epoch 218/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6696 - accuracy: 0.6965 - val_loss: 0.8117 - val_accuracy: 0.6083\n",
      "Epoch 219/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6654 - accuracy: 0.6956 - val_loss: 0.7777 - val_accuracy: 0.6262\n",
      "Epoch 220/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6533 - accuracy: 0.7098 - val_loss: 0.7794 - val_accuracy: 0.6190\n",
      "Epoch 221/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6685 - accuracy: 0.6944 - val_loss: 0.9052 - val_accuracy: 0.5786\n",
      "Epoch 222/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6573 - accuracy: 0.7052 - val_loss: 0.8536 - val_accuracy: 0.6119\n",
      "Epoch 223/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6675 - accuracy: 0.6954 - val_loss: 0.8024 - val_accuracy: 0.5976\n",
      "Epoch 224/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6501 - accuracy: 0.7083 - val_loss: 0.7989 - val_accuracy: 0.6202\n",
      "Epoch 225/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6594 - accuracy: 0.7045 - val_loss: 0.8344 - val_accuracy: 0.6000\n",
      "Epoch 226/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6628 - accuracy: 0.7000 - val_loss: 0.8071 - val_accuracy: 0.6071\n",
      "Epoch 227/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6503 - accuracy: 0.7114 - val_loss: 0.8364 - val_accuracy: 0.5893\n",
      "Epoch 228/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6454 - accuracy: 0.7152 - val_loss: 0.9288 - val_accuracy: 0.5583\n",
      "Epoch 229/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6623 - accuracy: 0.7052 - val_loss: 0.7675 - val_accuracy: 0.6607\n",
      "Epoch 230/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6549 - accuracy: 0.7056 - val_loss: 0.7594 - val_accuracy: 0.6393\n",
      "Epoch 231/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6476 - accuracy: 0.7080 - val_loss: 0.7842 - val_accuracy: 0.6357\n",
      "Epoch 232/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6447 - accuracy: 0.7068 - val_loss: 0.9393 - val_accuracy: 0.5274\n",
      "Epoch 233/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6276 - accuracy: 0.7231 - val_loss: 0.8393 - val_accuracy: 0.6119\n",
      "Epoch 234/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6446 - accuracy: 0.7042 - val_loss: 0.8622 - val_accuracy: 0.6083\n",
      "Epoch 235/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6461 - accuracy: 0.7113 - val_loss: 0.8405 - val_accuracy: 0.5988\n",
      "Epoch 236/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6377 - accuracy: 0.7133 - val_loss: 0.7758 - val_accuracy: 0.6000\n",
      "Epoch 237/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6442 - accuracy: 0.7111 - val_loss: 0.8141 - val_accuracy: 0.5976\n",
      "Epoch 238/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6155 - accuracy: 0.7265 - val_loss: 0.8743 - val_accuracy: 0.6226\n",
      "Epoch 239/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6367 - accuracy: 0.7149 - val_loss: 0.8241 - val_accuracy: 0.6298\n",
      "Epoch 240/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6211 - accuracy: 0.7279 - val_loss: 0.8060 - val_accuracy: 0.6107\n",
      "Epoch 241/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6240 - accuracy: 0.7240 - val_loss: 0.8583 - val_accuracy: 0.6226\n",
      "Epoch 242/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6496 - accuracy: 0.7055 - val_loss: 0.7937 - val_accuracy: 0.6274\n",
      "Epoch 243/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6133 - accuracy: 0.7279 - val_loss: 0.7863 - val_accuracy: 0.6190\n",
      "Epoch 244/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6252 - accuracy: 0.7226 - val_loss: 0.8155 - val_accuracy: 0.6202\n",
      "Epoch 245/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6212 - accuracy: 0.7262 - val_loss: 0.8816 - val_accuracy: 0.5786\n",
      "Epoch 246/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6176 - accuracy: 0.7327 - val_loss: 0.8090 - val_accuracy: 0.5988\n",
      "Epoch 247/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6064 - accuracy: 0.7257 - val_loss: 0.7495 - val_accuracy: 0.6488\n",
      "Epoch 248/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6238 - accuracy: 0.7204 - val_loss: 0.9132 - val_accuracy: 0.5679\n",
      "Epoch 249/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6303 - accuracy: 0.7209 - val_loss: 0.7679 - val_accuracy: 0.6690\n",
      "Epoch 250/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6112 - accuracy: 0.7316 - val_loss: 0.9078 - val_accuracy: 0.5619\n",
      "Epoch 251/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6324 - accuracy: 0.7284 - val_loss: 0.9223 - val_accuracy: 0.5214\n",
      "Epoch 252/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6563 - accuracy: 0.7049 - val_loss: 0.8186 - val_accuracy: 0.6357\n",
      "Epoch 253/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6266 - accuracy: 0.7188 - val_loss: 0.8108 - val_accuracy: 0.6095\n",
      "Epoch 254/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6058 - accuracy: 0.7267 - val_loss: 0.8622 - val_accuracy: 0.6655\n",
      "Epoch 255/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6064 - accuracy: 0.7289 - val_loss: 0.8470 - val_accuracy: 0.6071\n",
      "Epoch 256/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6239 - accuracy: 0.7266 - val_loss: 0.7934 - val_accuracy: 0.6286\n",
      "Epoch 257/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6011 - accuracy: 0.7323 - val_loss: 0.7647 - val_accuracy: 0.6583\n",
      "Epoch 258/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6132 - accuracy: 0.7311 - val_loss: 0.7836 - val_accuracy: 0.6452\n",
      "Epoch 259/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5975 - accuracy: 0.7379 - val_loss: 0.9127 - val_accuracy: 0.5619\n",
      "Epoch 260/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5990 - accuracy: 0.7389 - val_loss: 0.8480 - val_accuracy: 0.6393\n",
      "Epoch 261/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5908 - accuracy: 0.7343 - val_loss: 0.7954 - val_accuracy: 0.6417\n",
      "Epoch 262/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6039 - accuracy: 0.7353 - val_loss: 0.8955 - val_accuracy: 0.5643\n",
      "Epoch 263/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5787 - accuracy: 0.7422 - val_loss: 0.7989 - val_accuracy: 0.6476\n",
      "Epoch 264/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6109 - accuracy: 0.7318 - val_loss: 0.8619 - val_accuracy: 0.5905\n",
      "Epoch 265/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6238 - accuracy: 0.7177 - val_loss: 0.8080 - val_accuracy: 0.6369\n",
      "Epoch 266/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5780 - accuracy: 0.7384 - val_loss: 0.7883 - val_accuracy: 0.6357\n",
      "Epoch 267/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5853 - accuracy: 0.7410 - val_loss: 0.7782 - val_accuracy: 0.6607\n",
      "Epoch 268/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5901 - accuracy: 0.7454 - val_loss: 0.7655 - val_accuracy: 0.6738\n",
      "Epoch 269/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5794 - accuracy: 0.7476 - val_loss: 0.7780 - val_accuracy: 0.6369\n",
      "Epoch 270/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5790 - accuracy: 0.7484 - val_loss: 0.7492 - val_accuracy: 0.6595\n",
      "Epoch 271/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5929 - accuracy: 0.7405 - val_loss: 0.7892 - val_accuracy: 0.6429\n",
      "Epoch 272/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6003 - accuracy: 0.7364 - val_loss: 0.8029 - val_accuracy: 0.6500\n",
      "Epoch 273/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5712 - accuracy: 0.7526 - val_loss: 0.7887 - val_accuracy: 0.6560\n",
      "Epoch 274/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5717 - accuracy: 0.7489 - val_loss: 0.7418 - val_accuracy: 0.6702\n",
      "Epoch 275/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5670 - accuracy: 0.7448 - val_loss: 0.7367 - val_accuracy: 0.6738\n",
      "Epoch 276/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5768 - accuracy: 0.7502 - val_loss: 0.7251 - val_accuracy: 0.6643\n",
      "Epoch 277/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5603 - accuracy: 0.7566 - val_loss: 0.7828 - val_accuracy: 0.6774\n",
      "Epoch 278/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5668 - accuracy: 0.7521 - val_loss: 0.7389 - val_accuracy: 0.6548\n",
      "Epoch 279/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5497 - accuracy: 0.7637 - val_loss: 0.7768 - val_accuracy: 0.6560\n",
      "Epoch 280/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5466 - accuracy: 0.7617 - val_loss: 0.7707 - val_accuracy: 0.6571\n",
      "Epoch 281/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5593 - accuracy: 0.7563 - val_loss: 0.7401 - val_accuracy: 0.6679\n",
      "Epoch 282/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5668 - accuracy: 0.7539 - val_loss: 0.7418 - val_accuracy: 0.6524\n",
      "Epoch 283/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5318 - accuracy: 0.7710 - val_loss: 0.7650 - val_accuracy: 0.6667\n",
      "Epoch 284/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5362 - accuracy: 0.7667 - val_loss: 0.7437 - val_accuracy: 0.6440\n",
      "Epoch 285/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5654 - accuracy: 0.7526 - val_loss: 0.7966 - val_accuracy: 0.6583\n",
      "Epoch 286/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5362 - accuracy: 0.7660 - val_loss: 0.7300 - val_accuracy: 0.6798\n",
      "Epoch 287/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5806 - accuracy: 0.7484 - val_loss: 0.7682 - val_accuracy: 0.6524\n",
      "Epoch 288/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5554 - accuracy: 0.7591 - val_loss: 0.8827 - val_accuracy: 0.6202\n",
      "Epoch 289/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5790 - accuracy: 0.7514 - val_loss: 0.7341 - val_accuracy: 0.6500\n",
      "Epoch 290/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5400 - accuracy: 0.7638 - val_loss: 0.7068 - val_accuracy: 0.6917\n",
      "Epoch 291/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5349 - accuracy: 0.7602 - val_loss: 0.6679 - val_accuracy: 0.7131\n",
      "Epoch 292/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5365 - accuracy: 0.7687 - val_loss: 0.6917 - val_accuracy: 0.6690\n",
      "Epoch 293/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5438 - accuracy: 0.7650 - val_loss: 0.8055 - val_accuracy: 0.6036\n",
      "Epoch 294/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5204 - accuracy: 0.7749 - val_loss: 0.6606 - val_accuracy: 0.6988\n",
      "Epoch 295/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5202 - accuracy: 0.7703 - val_loss: 0.6906 - val_accuracy: 0.6762\n",
      "Epoch 296/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5243 - accuracy: 0.7739 - val_loss: 0.6817 - val_accuracy: 0.7048\n",
      "Epoch 297/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5099 - accuracy: 0.7799 - val_loss: 0.7020 - val_accuracy: 0.6952\n",
      "Epoch 298/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5156 - accuracy: 0.7812 - val_loss: 0.7534 - val_accuracy: 0.6369\n",
      "Epoch 299/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5402 - accuracy: 0.7684 - val_loss: 0.7326 - val_accuracy: 0.6536\n",
      "Epoch 300/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5153 - accuracy: 0.7799 - val_loss: 0.6656 - val_accuracy: 0.6952\n",
      "Epoch 301/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5272 - accuracy: 0.7739 - val_loss: 0.6914 - val_accuracy: 0.6798\n",
      "Epoch 302/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5229 - accuracy: 0.7771 - val_loss: 0.7235 - val_accuracy: 0.6750\n",
      "Epoch 303/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5061 - accuracy: 0.7810 - val_loss: 0.6735 - val_accuracy: 0.6976\n",
      "Epoch 304/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5517 - accuracy: 0.7629 - val_loss: 0.7672 - val_accuracy: 0.6452\n",
      "Epoch 305/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5093 - accuracy: 0.7838 - val_loss: 0.6838 - val_accuracy: 0.6726\n",
      "Epoch 306/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5127 - accuracy: 0.7808 - val_loss: 0.6962 - val_accuracy: 0.6988\n",
      "Epoch 307/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5047 - accuracy: 0.7889 - val_loss: 0.7408 - val_accuracy: 0.6667\n",
      "Epoch 308/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5043 - accuracy: 0.7899 - val_loss: 0.6806 - val_accuracy: 0.6917\n",
      "Epoch 309/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4931 - accuracy: 0.7881 - val_loss: 0.7490 - val_accuracy: 0.6750\n",
      "Epoch 310/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4934 - accuracy: 0.7862 - val_loss: 0.7442 - val_accuracy: 0.6595\n",
      "Epoch 311/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5127 - accuracy: 0.7780 - val_loss: 0.7016 - val_accuracy: 0.7286\n",
      "Epoch 312/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4942 - accuracy: 0.7848 - val_loss: 0.7931 - val_accuracy: 0.6405\n",
      "Epoch 313/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5042 - accuracy: 0.7888 - val_loss: 0.7501 - val_accuracy: 0.6667\n",
      "Epoch 314/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5070 - accuracy: 0.7806 - val_loss: 0.8596 - val_accuracy: 0.6274\n",
      "Epoch 315/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4810 - accuracy: 0.7996 - val_loss: 0.7639 - val_accuracy: 0.6857\n",
      "Epoch 316/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5077 - accuracy: 0.7838 - val_loss: 0.8119 - val_accuracy: 0.6310\n",
      "Epoch 317/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5099 - accuracy: 0.7811 - val_loss: 0.7143 - val_accuracy: 0.6357\n",
      "Epoch 318/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5058 - accuracy: 0.7806 - val_loss: 0.7372 - val_accuracy: 0.6655\n",
      "Epoch 319/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5168 - accuracy: 0.7808 - val_loss: 0.7198 - val_accuracy: 0.6643\n",
      "Epoch 320/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4920 - accuracy: 0.7958 - val_loss: 0.7423 - val_accuracy: 0.6452\n",
      "Epoch 321/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4693 - accuracy: 0.7983 - val_loss: 0.6823 - val_accuracy: 0.7107\n",
      "Epoch 322/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4904 - accuracy: 0.7973 - val_loss: 0.6906 - val_accuracy: 0.7024\n",
      "Epoch 323/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5121 - accuracy: 0.7846 - val_loss: 0.7104 - val_accuracy: 0.6869\n",
      "Epoch 324/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4853 - accuracy: 0.7919 - val_loss: 0.6648 - val_accuracy: 0.6810\n",
      "Epoch 325/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4843 - accuracy: 0.7954 - val_loss: 0.6560 - val_accuracy: 0.7060\n",
      "Epoch 326/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4763 - accuracy: 0.7951 - val_loss: 0.6519 - val_accuracy: 0.7012\n",
      "Epoch 327/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4881 - accuracy: 0.7925 - val_loss: 0.6899 - val_accuracy: 0.6655\n",
      "Epoch 328/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4635 - accuracy: 0.8031 - val_loss: 0.6341 - val_accuracy: 0.7464\n",
      "Epoch 329/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4580 - accuracy: 0.8082 - val_loss: 0.6928 - val_accuracy: 0.6798\n",
      "Epoch 330/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4720 - accuracy: 0.7966 - val_loss: 0.6667 - val_accuracy: 0.7179\n",
      "Epoch 331/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4754 - accuracy: 0.7968 - val_loss: 0.6406 - val_accuracy: 0.7167\n",
      "Epoch 332/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4899 - accuracy: 0.7943 - val_loss: 0.7028 - val_accuracy: 0.6524\n",
      "Epoch 333/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4926 - accuracy: 0.7925 - val_loss: 0.6699 - val_accuracy: 0.6893\n",
      "Epoch 334/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4534 - accuracy: 0.8080 - val_loss: 0.6435 - val_accuracy: 0.7024\n",
      "Epoch 335/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4529 - accuracy: 0.8111 - val_loss: 0.7962 - val_accuracy: 0.6560\n",
      "Epoch 336/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4568 - accuracy: 0.8039 - val_loss: 0.7114 - val_accuracy: 0.6917\n",
      "Epoch 337/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4754 - accuracy: 0.8019 - val_loss: 0.7659 - val_accuracy: 0.6440\n",
      "Epoch 338/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4792 - accuracy: 0.7969 - val_loss: 0.6260 - val_accuracy: 0.7060\n",
      "Epoch 339/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4474 - accuracy: 0.8146 - val_loss: 0.6273 - val_accuracy: 0.7274\n",
      "Epoch 340/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4619 - accuracy: 0.8040 - val_loss: 0.6672 - val_accuracy: 0.6881\n",
      "Epoch 341/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4647 - accuracy: 0.8051 - val_loss: 0.7297 - val_accuracy: 0.6726\n",
      "Epoch 342/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4468 - accuracy: 0.8119 - val_loss: 0.6376 - val_accuracy: 0.7226\n",
      "Epoch 343/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4633 - accuracy: 0.8050 - val_loss: 0.7150 - val_accuracy: 0.6595\n",
      "Epoch 344/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4425 - accuracy: 0.8129 - val_loss: 0.6571 - val_accuracy: 0.7238\n",
      "Epoch 345/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4616 - accuracy: 0.8017 - val_loss: 0.6092 - val_accuracy: 0.7155\n",
      "Epoch 346/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4806 - accuracy: 0.7925 - val_loss: 0.6937 - val_accuracy: 0.6893\n",
      "Epoch 347/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5113 - accuracy: 0.7825 - val_loss: 0.7973 - val_accuracy: 0.6369\n",
      "Epoch 348/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5543 - accuracy: 0.7443 - val_loss: 0.7089 - val_accuracy: 0.6845\n",
      "Epoch 349/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4596 - accuracy: 0.8085 - val_loss: 0.6477 - val_accuracy: 0.6964\n",
      "Epoch 350/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4494 - accuracy: 0.8155 - val_loss: 0.7098 - val_accuracy: 0.6845\n",
      "Epoch 351/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4374 - accuracy: 0.8141 - val_loss: 0.8637 - val_accuracy: 0.6250\n",
      "Epoch 352/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4268 - accuracy: 0.8206 - val_loss: 0.6819 - val_accuracy: 0.6821\n",
      "Epoch 353/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4475 - accuracy: 0.8184 - val_loss: 0.6111 - val_accuracy: 0.7238\n",
      "Epoch 354/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4436 - accuracy: 0.8131 - val_loss: 0.7645 - val_accuracy: 0.6893\n",
      "Epoch 355/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4410 - accuracy: 0.8154 - val_loss: 0.5846 - val_accuracy: 0.7298\n",
      "Epoch 356/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4547 - accuracy: 0.8134 - val_loss: 0.8367 - val_accuracy: 0.6405\n",
      "Epoch 357/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4314 - accuracy: 0.8173 - val_loss: 0.6773 - val_accuracy: 0.6810\n",
      "Epoch 358/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4133 - accuracy: 0.8275 - val_loss: 0.6910 - val_accuracy: 0.7083\n",
      "Epoch 359/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4401 - accuracy: 0.8157 - val_loss: 0.6403 - val_accuracy: 0.6952\n",
      "Epoch 360/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4349 - accuracy: 0.8169 - val_loss: 0.6812 - val_accuracy: 0.7167\n",
      "Epoch 361/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4181 - accuracy: 0.8264 - val_loss: 0.7471 - val_accuracy: 0.6821\n",
      "Epoch 362/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4129 - accuracy: 0.8269 - val_loss: 0.8634 - val_accuracy: 0.6202\n",
      "Epoch 363/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4159 - accuracy: 0.8292 - val_loss: 0.7733 - val_accuracy: 0.7060\n",
      "Epoch 364/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4077 - accuracy: 0.8274 - val_loss: 0.8005 - val_accuracy: 0.6417\n",
      "Epoch 365/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4304 - accuracy: 0.8223 - val_loss: 0.7048 - val_accuracy: 0.7321\n",
      "Epoch 366/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4153 - accuracy: 0.8303 - val_loss: 0.6801 - val_accuracy: 0.7012\n",
      "Epoch 367/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4402 - accuracy: 0.8236 - val_loss: 0.6776 - val_accuracy: 0.7274\n",
      "Epoch 368/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4206 - accuracy: 0.8252 - val_loss: 0.6879 - val_accuracy: 0.6964\n",
      "Epoch 369/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3950 - accuracy: 0.8374 - val_loss: 0.7146 - val_accuracy: 0.6833\n",
      "Epoch 370/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3930 - accuracy: 0.8372 - val_loss: 0.6473 - val_accuracy: 0.7321\n",
      "Epoch 371/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4161 - accuracy: 0.8305 - val_loss: 0.6068 - val_accuracy: 0.7238\n",
      "Epoch 372/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4286 - accuracy: 0.8244 - val_loss: 0.6961 - val_accuracy: 0.6905\n",
      "Epoch 373/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4167 - accuracy: 0.8276 - val_loss: 0.6083 - val_accuracy: 0.7452\n",
      "Epoch 374/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4103 - accuracy: 0.8294 - val_loss: 0.6747 - val_accuracy: 0.6583\n",
      "Epoch 375/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4355 - accuracy: 0.8187 - val_loss: 0.6737 - val_accuracy: 0.6917\n",
      "Epoch 376/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3940 - accuracy: 0.8379 - val_loss: 0.6541 - val_accuracy: 0.7060\n",
      "Epoch 377/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4020 - accuracy: 0.8315 - val_loss: 0.6698 - val_accuracy: 0.6964\n",
      "Epoch 378/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3910 - accuracy: 0.8367 - val_loss: 0.6171 - val_accuracy: 0.7024\n",
      "Epoch 379/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3983 - accuracy: 0.8335 - val_loss: 0.6457 - val_accuracy: 0.7345\n",
      "Epoch 380/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4229 - accuracy: 0.8236 - val_loss: 0.7445 - val_accuracy: 0.6619\n",
      "Epoch 381/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4108 - accuracy: 0.8260 - val_loss: 0.5446 - val_accuracy: 0.7488\n",
      "Epoch 382/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4238 - accuracy: 0.8238 - val_loss: 0.7175 - val_accuracy: 0.6798\n",
      "Epoch 383/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4114 - accuracy: 0.8311 - val_loss: 0.6546 - val_accuracy: 0.6940\n",
      "Epoch 384/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4257 - accuracy: 0.8291 - val_loss: 0.8281 - val_accuracy: 0.6440\n",
      "Epoch 385/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4211 - accuracy: 0.8259 - val_loss: 0.5726 - val_accuracy: 0.7333\n",
      "Epoch 386/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4301 - accuracy: 0.8211 - val_loss: 0.6005 - val_accuracy: 0.7238\n",
      "Epoch 387/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4064 - accuracy: 0.8292 - val_loss: 0.6746 - val_accuracy: 0.6762\n",
      "Epoch 388/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3949 - accuracy: 0.8361 - val_loss: 0.6746 - val_accuracy: 0.7179\n",
      "Epoch 389/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4150 - accuracy: 0.8230 - val_loss: 0.6113 - val_accuracy: 0.7464\n",
      "Epoch 390/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.4094 - accuracy: 0.8342 - val_loss: 0.6804 - val_accuracy: 0.6929\n",
      "Epoch 391/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3879 - accuracy: 0.8381 - val_loss: 1.0465 - val_accuracy: 0.5798\n",
      "Epoch 392/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3953 - accuracy: 0.8358 - val_loss: 0.5946 - val_accuracy: 0.7286\n",
      "Epoch 393/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4013 - accuracy: 0.8372 - val_loss: 0.6551 - val_accuracy: 0.7274\n",
      "Epoch 394/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3838 - accuracy: 0.8422 - val_loss: 0.5720 - val_accuracy: 0.7500\n",
      "Epoch 395/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3795 - accuracy: 0.8394 - val_loss: 0.5916 - val_accuracy: 0.7250\n",
      "Epoch 396/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4071 - accuracy: 0.8302 - val_loss: 0.5507 - val_accuracy: 0.7631\n",
      "Epoch 397/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3619 - accuracy: 0.8456 - val_loss: 0.6953 - val_accuracy: 0.6798\n",
      "Epoch 398/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3699 - accuracy: 0.8415 - val_loss: 0.6167 - val_accuracy: 0.7369\n",
      "Epoch 399/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3925 - accuracy: 0.8356 - val_loss: 0.6318 - val_accuracy: 0.7357\n",
      "Epoch 400/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4015 - accuracy: 0.8328 - val_loss: 0.5903 - val_accuracy: 0.7488\n",
      "Epoch 401/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3932 - accuracy: 0.8404 - val_loss: 0.6642 - val_accuracy: 0.7048\n",
      "Epoch 402/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3774 - accuracy: 0.8410 - val_loss: 0.7001 - val_accuracy: 0.7274\n",
      "Epoch 403/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3695 - accuracy: 0.8447 - val_loss: 0.7476 - val_accuracy: 0.7190\n",
      "Epoch 404/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3786 - accuracy: 0.8399 - val_loss: 0.5469 - val_accuracy: 0.7619\n",
      "Epoch 405/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3842 - accuracy: 0.8432 - val_loss: 0.6570 - val_accuracy: 0.7310\n",
      "Epoch 406/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3434 - accuracy: 0.8555 - val_loss: 0.6150 - val_accuracy: 0.7310\n",
      "Epoch 407/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3758 - accuracy: 0.8387 - val_loss: 0.5570 - val_accuracy: 0.7810\n",
      "Epoch 408/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3592 - accuracy: 0.8515 - val_loss: 0.6415 - val_accuracy: 0.7357\n",
      "Epoch 409/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3455 - accuracy: 0.8590 - val_loss: 0.6290 - val_accuracy: 0.7286\n",
      "Epoch 410/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3913 - accuracy: 0.8373 - val_loss: 0.5260 - val_accuracy: 0.7821\n",
      "Epoch 411/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3641 - accuracy: 0.8532 - val_loss: 0.7408 - val_accuracy: 0.6905\n",
      "Epoch 412/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3793 - accuracy: 0.8470 - val_loss: 0.5884 - val_accuracy: 0.7440\n",
      "Epoch 413/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3597 - accuracy: 0.8490 - val_loss: 0.5974 - val_accuracy: 0.7310\n",
      "Epoch 414/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3382 - accuracy: 0.8609 - val_loss: 0.6590 - val_accuracy: 0.7071\n",
      "Epoch 415/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3534 - accuracy: 0.8529 - val_loss: 0.6356 - val_accuracy: 0.7226\n",
      "Epoch 416/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3992 - accuracy: 0.8342 - val_loss: 0.7620 - val_accuracy: 0.6762\n",
      "Epoch 417/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4339 - accuracy: 0.8144 - val_loss: 0.7817 - val_accuracy: 0.6679\n",
      "Epoch 418/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3911 - accuracy: 0.8379 - val_loss: 0.9601 - val_accuracy: 0.6012\n",
      "Epoch 419/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3980 - accuracy: 0.8373 - val_loss: 0.5350 - val_accuracy: 0.7655\n",
      "Epoch 420/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3338 - accuracy: 0.8602 - val_loss: 0.5949 - val_accuracy: 0.7464\n",
      "Epoch 421/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3645 - accuracy: 0.8525 - val_loss: 0.6492 - val_accuracy: 0.7345\n",
      "Epoch 422/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3585 - accuracy: 0.8526 - val_loss: 0.7727 - val_accuracy: 0.6476\n",
      "Epoch 423/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3472 - accuracy: 0.8556 - val_loss: 0.6770 - val_accuracy: 0.7298\n",
      "Epoch 424/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3451 - accuracy: 0.8570 - val_loss: 0.6254 - val_accuracy: 0.7214\n",
      "Epoch 425/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3566 - accuracy: 0.8541 - val_loss: 0.7653 - val_accuracy: 0.6917\n",
      "Epoch 426/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3607 - accuracy: 0.8509 - val_loss: 0.5789 - val_accuracy: 0.7738\n",
      "Epoch 427/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4292 - accuracy: 0.8313 - val_loss: 0.6247 - val_accuracy: 0.7238\n",
      "Epoch 428/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3351 - accuracy: 0.8623 - val_loss: 0.5662 - val_accuracy: 0.7774\n",
      "Epoch 429/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3453 - accuracy: 0.8606 - val_loss: 0.6084 - val_accuracy: 0.7476\n",
      "Epoch 430/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3398 - accuracy: 0.8650 - val_loss: 0.6477 - val_accuracy: 0.7167\n",
      "Epoch 431/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3341 - accuracy: 0.8606 - val_loss: 0.6162 - val_accuracy: 0.7452\n",
      "Epoch 432/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3384 - accuracy: 0.8572 - val_loss: 0.6474 - val_accuracy: 0.7298\n",
      "Epoch 433/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3439 - accuracy: 0.8616 - val_loss: 0.5939 - val_accuracy: 0.7381\n",
      "Epoch 434/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3530 - accuracy: 0.8512 - val_loss: 0.5989 - val_accuracy: 0.7702\n",
      "Epoch 435/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3248 - accuracy: 0.8672 - val_loss: 0.5272 - val_accuracy: 0.7786\n",
      "Epoch 436/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3669 - accuracy: 0.8510 - val_loss: 0.6090 - val_accuracy: 0.7298\n",
      "Epoch 437/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3196 - accuracy: 0.8650 - val_loss: 0.5600 - val_accuracy: 0.7464\n",
      "Epoch 438/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3428 - accuracy: 0.8588 - val_loss: 0.6675 - val_accuracy: 0.7202\n",
      "Epoch 439/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3598 - accuracy: 0.8530 - val_loss: 0.6052 - val_accuracy: 0.7452\n",
      "Epoch 440/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3530 - accuracy: 0.8556 - val_loss: 0.7405 - val_accuracy: 0.6595\n",
      "Epoch 441/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3830 - accuracy: 0.8404 - val_loss: 0.5887 - val_accuracy: 0.7619\n",
      "Epoch 442/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3308 - accuracy: 0.8638 - val_loss: 0.5944 - val_accuracy: 0.7274\n",
      "Epoch 443/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3310 - accuracy: 0.8624 - val_loss: 0.6043 - val_accuracy: 0.7345\n",
      "Epoch 444/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3686 - accuracy: 0.8499 - val_loss: 0.5869 - val_accuracy: 0.7429\n",
      "Epoch 445/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3533 - accuracy: 0.8546 - val_loss: 0.6347 - val_accuracy: 0.7107\n",
      "Epoch 446/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3086 - accuracy: 0.8741 - val_loss: 0.8980 - val_accuracy: 0.6512\n",
      "Epoch 447/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3640 - accuracy: 0.8501 - val_loss: 0.6529 - val_accuracy: 0.7226\n",
      "Epoch 448/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3245 - accuracy: 0.8647 - val_loss: 0.5869 - val_accuracy: 0.7512\n",
      "Epoch 449/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3617 - accuracy: 0.8557 - val_loss: 0.6382 - val_accuracy: 0.7417\n",
      "Epoch 450/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3378 - accuracy: 0.8622 - val_loss: 0.7595 - val_accuracy: 0.7036\n",
      "Epoch 451/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3857 - accuracy: 0.8444 - val_loss: 0.6765 - val_accuracy: 0.7048\n",
      "Epoch 452/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3434 - accuracy: 0.8539 - val_loss: 0.6564 - val_accuracy: 0.7393\n",
      "Epoch 453/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3362 - accuracy: 0.8619 - val_loss: 0.5883 - val_accuracy: 0.7571\n",
      "Epoch 454/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3333 - accuracy: 0.8609 - val_loss: 0.5470 - val_accuracy: 0.7679\n",
      "Epoch 455/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3348 - accuracy: 0.8608 - val_loss: 0.7074 - val_accuracy: 0.7024\n",
      "Epoch 456/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3286 - accuracy: 0.8648 - val_loss: 0.5787 - val_accuracy: 0.7690\n",
      "Epoch 457/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3357 - accuracy: 0.8647 - val_loss: 0.6750 - val_accuracy: 0.6964\n",
      "Epoch 458/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3305 - accuracy: 0.8700 - val_loss: 0.5697 - val_accuracy: 0.7833\n",
      "Epoch 459/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3090 - accuracy: 0.8752 - val_loss: 0.7247 - val_accuracy: 0.7274\n",
      "Epoch 460/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3155 - accuracy: 0.8703 - val_loss: 0.6591 - val_accuracy: 0.7345\n",
      "Epoch 461/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3124 - accuracy: 0.8698 - val_loss: 0.5902 - val_accuracy: 0.7631\n",
      "Epoch 462/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3022 - accuracy: 0.8767 - val_loss: 0.6034 - val_accuracy: 0.7321\n",
      "Epoch 463/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3293 - accuracy: 0.8648 - val_loss: 0.7292 - val_accuracy: 0.6881\n",
      "Epoch 464/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3114 - accuracy: 0.8730 - val_loss: 0.5627 - val_accuracy: 0.7524\n",
      "Epoch 465/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3297 - accuracy: 0.8622 - val_loss: 0.5058 - val_accuracy: 0.7786\n",
      "Epoch 466/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2935 - accuracy: 0.8797 - val_loss: 0.9124 - val_accuracy: 0.6393\n",
      "Epoch 467/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3191 - accuracy: 0.8683 - val_loss: 0.6089 - val_accuracy: 0.7476\n",
      "Epoch 468/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3048 - accuracy: 0.8731 - val_loss: 0.5881 - val_accuracy: 0.7560\n",
      "Epoch 469/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3177 - accuracy: 0.8716 - val_loss: 0.5578 - val_accuracy: 0.7821\n",
      "Epoch 470/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3201 - accuracy: 0.8687 - val_loss: 0.5604 - val_accuracy: 0.7857\n",
      "Epoch 471/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3070 - accuracy: 0.8738 - val_loss: 0.5459 - val_accuracy: 0.7798\n",
      "Epoch 472/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4298 - accuracy: 0.8313 - val_loss: 0.6003 - val_accuracy: 0.7321\n",
      "Epoch 473/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3127 - accuracy: 0.8706 - val_loss: 0.6405 - val_accuracy: 0.7405\n",
      "Epoch 474/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4269 - accuracy: 0.8368 - val_loss: 0.5755 - val_accuracy: 0.7607\n",
      "Epoch 475/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3175 - accuracy: 0.8690 - val_loss: 0.6083 - val_accuracy: 0.7202\n",
      "Epoch 476/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3350 - accuracy: 0.8646 - val_loss: 0.6203 - val_accuracy: 0.7333\n",
      "Epoch 477/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3095 - accuracy: 0.8704 - val_loss: 0.5250 - val_accuracy: 0.7762\n",
      "Epoch 478/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3101 - accuracy: 0.8726 - val_loss: 0.5684 - val_accuracy: 0.7690\n",
      "Epoch 479/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3202 - accuracy: 0.8633 - val_loss: 0.5850 - val_accuracy: 0.7512\n",
      "Epoch 480/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3299 - accuracy: 0.8629 - val_loss: 0.8513 - val_accuracy: 0.6631\n",
      "Epoch 481/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3274 - accuracy: 0.8613 - val_loss: 0.6537 - val_accuracy: 0.7369\n",
      "Epoch 482/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3085 - accuracy: 0.8697 - val_loss: 0.6839 - val_accuracy: 0.7417\n",
      "Epoch 483/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3159 - accuracy: 0.8664 - val_loss: 0.5476 - val_accuracy: 0.7536\n",
      "Epoch 484/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3034 - accuracy: 0.8760 - val_loss: 0.6302 - val_accuracy: 0.7524\n",
      "Epoch 485/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3076 - accuracy: 0.8725 - val_loss: 0.6468 - val_accuracy: 0.7250\n",
      "Epoch 486/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2882 - accuracy: 0.8805 - val_loss: 0.6133 - val_accuracy: 0.7440\n",
      "Epoch 487/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2988 - accuracy: 0.8746 - val_loss: 0.7344 - val_accuracy: 0.7405\n",
      "Epoch 488/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3006 - accuracy: 0.8765 - val_loss: 0.6052 - val_accuracy: 0.7369\n",
      "Epoch 489/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3153 - accuracy: 0.8706 - val_loss: 0.7095 - val_accuracy: 0.7071\n",
      "Epoch 490/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2859 - accuracy: 0.8853 - val_loss: 0.5545 - val_accuracy: 0.7583\n",
      "Epoch 491/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3087 - accuracy: 0.8764 - val_loss: 0.6721 - val_accuracy: 0.7143\n",
      "Epoch 492/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2771 - accuracy: 0.8866 - val_loss: 0.6362 - val_accuracy: 0.7440\n",
      "Epoch 493/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2777 - accuracy: 0.8867 - val_loss: 0.6084 - val_accuracy: 0.7595\n",
      "Epoch 494/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2637 - accuracy: 0.8924 - val_loss: 0.5913 - val_accuracy: 0.7619\n",
      "Epoch 495/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2895 - accuracy: 0.8815 - val_loss: 0.5421 - val_accuracy: 0.7714\n",
      "Epoch 496/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2873 - accuracy: 0.8852 - val_loss: 1.1173 - val_accuracy: 0.6226\n",
      "Epoch 497/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3022 - accuracy: 0.8772 - val_loss: 0.5686 - val_accuracy: 0.7643\n",
      "Epoch 498/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2704 - accuracy: 0.8900 - val_loss: 0.7372 - val_accuracy: 0.7107\n",
      "Epoch 499/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3273 - accuracy: 0.8631 - val_loss: 0.5177 - val_accuracy: 0.7667\n",
      "Epoch 500/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2619 - accuracy: 0.8938 - val_loss: 0.5340 - val_accuracy: 0.7845\n",
      "Epoch 501/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2883 - accuracy: 0.8831 - val_loss: 0.6503 - val_accuracy: 0.7357\n",
      "Epoch 502/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2824 - accuracy: 0.8832 - val_loss: 0.5632 - val_accuracy: 0.7631\n",
      "Epoch 503/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2749 - accuracy: 0.8867 - val_loss: 0.6304 - val_accuracy: 0.7321\n",
      "Epoch 504/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3142 - accuracy: 0.8720 - val_loss: 0.6791 - val_accuracy: 0.7143\n",
      "Epoch 505/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3204 - accuracy: 0.8728 - val_loss: 0.6854 - val_accuracy: 0.7321\n",
      "Epoch 506/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2898 - accuracy: 0.8803 - val_loss: 0.6090 - val_accuracy: 0.7655\n",
      "Epoch 507/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2677 - accuracy: 0.8927 - val_loss: 0.5250 - val_accuracy: 0.7750\n",
      "Epoch 508/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2623 - accuracy: 0.8909 - val_loss: 0.5132 - val_accuracy: 0.7964\n",
      "Epoch 509/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2929 - accuracy: 0.8770 - val_loss: 0.5486 - val_accuracy: 0.7464\n",
      "Epoch 510/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2982 - accuracy: 0.8805 - val_loss: 0.6286 - val_accuracy: 0.7571\n",
      "Epoch 511/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2915 - accuracy: 0.8845 - val_loss: 0.5980 - val_accuracy: 0.7607\n",
      "Epoch 512/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2938 - accuracy: 0.8823 - val_loss: 0.6041 - val_accuracy: 0.7512\n",
      "Epoch 513/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2652 - accuracy: 0.8905 - val_loss: 0.6477 - val_accuracy: 0.7429\n",
      "Epoch 514/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2890 - accuracy: 0.8837 - val_loss: 0.5131 - val_accuracy: 0.7607\n",
      "Epoch 515/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2476 - accuracy: 0.9012 - val_loss: 0.5383 - val_accuracy: 0.7738\n",
      "Epoch 516/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2714 - accuracy: 0.8893 - val_loss: 0.7157 - val_accuracy: 0.7298\n",
      "Epoch 517/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3119 - accuracy: 0.8745 - val_loss: 0.5454 - val_accuracy: 0.7714\n",
      "Epoch 518/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5472 - accuracy: 0.7684 - val_loss: 0.8130 - val_accuracy: 0.6298\n",
      "Epoch 519/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5572 - accuracy: 0.7490 - val_loss: 0.7923 - val_accuracy: 0.6524\n",
      "Epoch 520/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5256 - accuracy: 0.7669 - val_loss: 0.7264 - val_accuracy: 0.6964\n",
      "Epoch 521/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4573 - accuracy: 0.8009 - val_loss: 0.7643 - val_accuracy: 0.6893\n",
      "Epoch 522/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4147 - accuracy: 0.8200 - val_loss: 0.7662 - val_accuracy: 0.6964\n",
      "Epoch 523/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4514 - accuracy: 0.8056 - val_loss: 0.7271 - val_accuracy: 0.6821\n",
      "Epoch 524/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4201 - accuracy: 0.8254 - val_loss: 0.7177 - val_accuracy: 0.6726\n",
      "Epoch 525/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3737 - accuracy: 0.8413 - val_loss: 0.6371 - val_accuracy: 0.7369\n",
      "Epoch 526/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3503 - accuracy: 0.8501 - val_loss: 0.7011 - val_accuracy: 0.7226\n",
      "Epoch 527/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3447 - accuracy: 0.8478 - val_loss: 0.7231 - val_accuracy: 0.6988\n",
      "Epoch 528/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3342 - accuracy: 0.8586 - val_loss: 0.6099 - val_accuracy: 0.7321\n",
      "Epoch 529/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3411 - accuracy: 0.8558 - val_loss: 0.6519 - val_accuracy: 0.7262\n",
      "Epoch 530/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3878 - accuracy: 0.8392 - val_loss: 0.6570 - val_accuracy: 0.7274\n",
      "Epoch 531/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3275 - accuracy: 0.8595 - val_loss: 0.6042 - val_accuracy: 0.7393\n",
      "Epoch 532/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3176 - accuracy: 0.8588 - val_loss: 0.6698 - val_accuracy: 0.7131\n",
      "Epoch 533/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3182 - accuracy: 0.8641 - val_loss: 0.7775 - val_accuracy: 0.6976\n",
      "Epoch 534/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3301 - accuracy: 0.8626 - val_loss: 0.5842 - val_accuracy: 0.7333\n",
      "Epoch 535/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3311 - accuracy: 0.8527 - val_loss: 0.6321 - val_accuracy: 0.7524\n",
      "Epoch 536/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3264 - accuracy: 0.8609 - val_loss: 0.6008 - val_accuracy: 0.7333\n",
      "Epoch 537/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2896 - accuracy: 0.8733 - val_loss: 0.6146 - val_accuracy: 0.7143\n",
      "Epoch 538/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3228 - accuracy: 0.8609 - val_loss: 0.6639 - val_accuracy: 0.7607\n",
      "Epoch 539/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3193 - accuracy: 0.8641 - val_loss: 0.5625 - val_accuracy: 0.7607\n",
      "Epoch 540/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3042 - accuracy: 0.8762 - val_loss: 0.5569 - val_accuracy: 0.7405\n",
      "Epoch 541/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3123 - accuracy: 0.8752 - val_loss: 0.5287 - val_accuracy: 0.7631\n",
      "Epoch 542/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2854 - accuracy: 0.8845 - val_loss: 0.8778 - val_accuracy: 0.6571\n",
      "Epoch 543/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3054 - accuracy: 0.8748 - val_loss: 0.5786 - val_accuracy: 0.7595\n",
      "Epoch 544/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3932 - accuracy: 0.8520 - val_loss: 0.6827 - val_accuracy: 0.7179\n",
      "Epoch 545/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3962 - accuracy: 0.8398 - val_loss: 0.6894 - val_accuracy: 0.7345\n",
      "Epoch 546/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3583 - accuracy: 0.8525 - val_loss: 0.7024 - val_accuracy: 0.7155\n",
      "Epoch 547/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3529 - accuracy: 0.8586 - val_loss: 0.6997 - val_accuracy: 0.7238\n",
      "Epoch 548/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3240 - accuracy: 0.8626 - val_loss: 0.5799 - val_accuracy: 0.7452\n",
      "Epoch 549/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3178 - accuracy: 0.8693 - val_loss: 0.5855 - val_accuracy: 0.7774\n",
      "Epoch 550/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3003 - accuracy: 0.8709 - val_loss: 0.6229 - val_accuracy: 0.7321\n",
      "Epoch 551/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3251 - accuracy: 0.8611 - val_loss: 0.5591 - val_accuracy: 0.7607\n",
      "Epoch 552/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3387 - accuracy: 0.8580 - val_loss: 0.7140 - val_accuracy: 0.6833\n",
      "Epoch 553/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3041 - accuracy: 0.8769 - val_loss: 0.4850 - val_accuracy: 0.8083\n",
      "Epoch 554/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3116 - accuracy: 0.8683 - val_loss: 0.6278 - val_accuracy: 0.7536\n",
      "Epoch 555/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2934 - accuracy: 0.8750 - val_loss: 0.5381 - val_accuracy: 0.7786\n",
      "Epoch 556/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2916 - accuracy: 0.8764 - val_loss: 0.6306 - val_accuracy: 0.7476\n",
      "Epoch 557/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2771 - accuracy: 0.8806 - val_loss: 0.6065 - val_accuracy: 0.7369\n",
      "Epoch 558/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2796 - accuracy: 0.8751 - val_loss: 0.5680 - val_accuracy: 0.7512\n",
      "Epoch 559/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3170 - accuracy: 0.8659 - val_loss: 0.5839 - val_accuracy: 0.7631\n",
      "Epoch 560/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3202 - accuracy: 0.8639 - val_loss: 0.5754 - val_accuracy: 0.7655\n",
      "Epoch 561/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3497 - accuracy: 0.8571 - val_loss: 0.6381 - val_accuracy: 0.7560\n",
      "Epoch 562/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2711 - accuracy: 0.8856 - val_loss: 0.5980 - val_accuracy: 0.7726\n",
      "Epoch 563/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3066 - accuracy: 0.8703 - val_loss: 0.5240 - val_accuracy: 0.7786\n",
      "Epoch 564/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2854 - accuracy: 0.8807 - val_loss: 0.5268 - val_accuracy: 0.8143\n",
      "Epoch 565/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3251 - accuracy: 0.8637 - val_loss: 0.6077 - val_accuracy: 0.7643\n",
      "Epoch 566/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2972 - accuracy: 0.8766 - val_loss: 0.6858 - val_accuracy: 0.7179\n",
      "Epoch 567/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2931 - accuracy: 0.8750 - val_loss: 0.5982 - val_accuracy: 0.7786\n",
      "Epoch 568/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2906 - accuracy: 0.8756 - val_loss: 0.5826 - val_accuracy: 0.7810\n",
      "Epoch 569/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2837 - accuracy: 0.8736 - val_loss: 0.5719 - val_accuracy: 0.7929\n",
      "Epoch 570/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2693 - accuracy: 0.8847 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
      "Epoch 571/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2867 - accuracy: 0.8799 - val_loss: 0.6433 - val_accuracy: 0.7345\n",
      "Epoch 572/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3082 - accuracy: 0.8678 - val_loss: 0.5756 - val_accuracy: 0.7345\n",
      "Epoch 573/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2625 - accuracy: 0.8874 - val_loss: 0.5819 - val_accuracy: 0.7643\n",
      "Epoch 574/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3075 - accuracy: 0.8744 - val_loss: 0.7676 - val_accuracy: 0.6940\n",
      "Epoch 575/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2525 - accuracy: 0.8920 - val_loss: 0.5360 - val_accuracy: 0.8131\n",
      "Epoch 576/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2725 - accuracy: 0.8818 - val_loss: 0.5469 - val_accuracy: 0.7810\n",
      "Epoch 577/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3130 - accuracy: 0.8706 - val_loss: 0.7286 - val_accuracy: 0.7214\n",
      "Epoch 578/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2895 - accuracy: 0.8789 - val_loss: 0.5879 - val_accuracy: 0.7536\n",
      "Epoch 579/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2842 - accuracy: 0.8802 - val_loss: 0.5890 - val_accuracy: 0.7429\n",
      "Epoch 580/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2752 - accuracy: 0.8811 - val_loss: 0.6195 - val_accuracy: 0.7440\n",
      "Epoch 581/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2597 - accuracy: 0.8883 - val_loss: 0.6147 - val_accuracy: 0.7488\n",
      "Epoch 582/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2684 - accuracy: 0.8891 - val_loss: 0.6573 - val_accuracy: 0.7512\n",
      "Epoch 583/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2905 - accuracy: 0.8820 - val_loss: 0.5532 - val_accuracy: 0.7786\n",
      "Epoch 584/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2804 - accuracy: 0.8851 - val_loss: 0.6177 - val_accuracy: 0.7548\n",
      "Epoch 585/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2825 - accuracy: 0.8853 - val_loss: 0.5330 - val_accuracy: 0.7750\n",
      "Epoch 586/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2745 - accuracy: 0.8887 - val_loss: 0.6124 - val_accuracy: 0.7488\n",
      "Epoch 587/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2705 - accuracy: 0.8850 - val_loss: 0.5044 - val_accuracy: 0.7869\n",
      "Epoch 588/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2730 - accuracy: 0.8858 - val_loss: 0.5087 - val_accuracy: 0.7667\n",
      "Epoch 589/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3017 - accuracy: 0.8735 - val_loss: 0.5479 - val_accuracy: 0.7750\n",
      "Epoch 590/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2519 - accuracy: 0.8925 - val_loss: 0.6670 - val_accuracy: 0.7583\n",
      "Epoch 591/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2672 - accuracy: 0.8887 - val_loss: 0.5546 - val_accuracy: 0.7845\n",
      "Epoch 592/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2646 - accuracy: 0.8900 - val_loss: 0.6279 - val_accuracy: 0.7690\n",
      "Epoch 593/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2573 - accuracy: 0.8942 - val_loss: 0.6008 - val_accuracy: 0.7690\n",
      "Epoch 594/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2770 - accuracy: 0.8859 - val_loss: 0.5930 - val_accuracy: 0.7655\n",
      "Epoch 595/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2874 - accuracy: 0.8841 - val_loss: 0.4765 - val_accuracy: 0.8143\n",
      "Epoch 596/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2785 - accuracy: 0.8828 - val_loss: 0.5006 - val_accuracy: 0.7976\n",
      "Epoch 597/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2501 - accuracy: 0.8927 - val_loss: 0.5879 - val_accuracy: 0.7500\n",
      "Epoch 598/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2392 - accuracy: 0.8959 - val_loss: 0.6073 - val_accuracy: 0.7405\n",
      "Epoch 599/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2582 - accuracy: 0.8898 - val_loss: 0.6188 - val_accuracy: 0.7643\n",
      "Epoch 600/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2832 - accuracy: 0.8886 - val_loss: 0.5996 - val_accuracy: 0.7726\n",
      "Epoch 1/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0987 - accuracy: 0.3415 - val_loss: 1.0984 - val_accuracy: 0.3381\n",
      "Epoch 2/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0977 - accuracy: 0.3562 - val_loss: 1.0973 - val_accuracy: 0.3381\n",
      "Epoch 3/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0956 - accuracy: 0.3816 - val_loss: 1.0953 - val_accuracy: 0.3488\n",
      "Epoch 4/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0958 - accuracy: 0.3743 - val_loss: 1.0941 - val_accuracy: 0.3476\n",
      "Epoch 5/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0940 - accuracy: 0.3842 - val_loss: 1.0945 - val_accuracy: 0.3345\n",
      "Epoch 6/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0925 - accuracy: 0.3858 - val_loss: 1.0945 - val_accuracy: 0.3202\n",
      "Epoch 7/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0950 - accuracy: 0.3649 - val_loss: 1.0931 - val_accuracy: 0.3524\n",
      "Epoch 8/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0938 - accuracy: 0.3755 - val_loss: 1.0914 - val_accuracy: 0.3714\n",
      "Epoch 9/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0925 - accuracy: 0.3730 - val_loss: 1.0867 - val_accuracy: 0.3631\n",
      "Epoch 10/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0903 - accuracy: 0.3877 - val_loss: 1.0863 - val_accuracy: 0.4048\n",
      "Epoch 11/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0899 - accuracy: 0.3820 - val_loss: 1.0872 - val_accuracy: 0.3548\n",
      "Epoch 12/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0885 - accuracy: 0.3767 - val_loss: 1.0892 - val_accuracy: 0.3798\n",
      "Epoch 13/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0836 - accuracy: 0.3959 - val_loss: 1.0758 - val_accuracy: 0.3988\n",
      "Epoch 14/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0831 - accuracy: 0.3848 - val_loss: 1.0723 - val_accuracy: 0.4333\n",
      "Epoch 15/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0809 - accuracy: 0.3879 - val_loss: 1.0793 - val_accuracy: 0.3964\n",
      "Epoch 16/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0753 - accuracy: 0.3947 - val_loss: 1.0716 - val_accuracy: 0.3988\n",
      "Epoch 17/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0729 - accuracy: 0.4007 - val_loss: 1.0505 - val_accuracy: 0.4214\n",
      "Epoch 18/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0725 - accuracy: 0.4098 - val_loss: 1.0616 - val_accuracy: 0.4250\n",
      "Epoch 19/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0703 - accuracy: 0.4128 - val_loss: 1.0516 - val_accuracy: 0.4476\n",
      "Epoch 20/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0679 - accuracy: 0.4076 - val_loss: 1.0544 - val_accuracy: 0.4274\n",
      "Epoch 21/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0667 - accuracy: 0.4087 - val_loss: 1.0519 - val_accuracy: 0.4321\n",
      "Epoch 22/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0588 - accuracy: 0.4199 - val_loss: 1.0449 - val_accuracy: 0.4321\n",
      "Epoch 23/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0556 - accuracy: 0.4255 - val_loss: 1.0352 - val_accuracy: 0.4571\n",
      "Epoch 24/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0569 - accuracy: 0.4128 - val_loss: 1.0610 - val_accuracy: 0.4214\n",
      "Epoch 25/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0563 - accuracy: 0.4146 - val_loss: 1.0415 - val_accuracy: 0.4512\n",
      "Epoch 26/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0570 - accuracy: 0.4157 - val_loss: 1.0477 - val_accuracy: 0.4214\n",
      "Epoch 27/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0494 - accuracy: 0.4246 - val_loss: 1.0335 - val_accuracy: 0.4500\n",
      "Epoch 28/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0496 - accuracy: 0.4240 - val_loss: 1.0627 - val_accuracy: 0.4179\n",
      "Epoch 29/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0549 - accuracy: 0.4158 - val_loss: 1.0311 - val_accuracy: 0.3976\n",
      "Epoch 30/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0427 - accuracy: 0.4264 - val_loss: 1.0314 - val_accuracy: 0.4369\n",
      "Epoch 31/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0374 - accuracy: 0.4315 - val_loss: 1.0293 - val_accuracy: 0.4310\n",
      "Epoch 32/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0424 - accuracy: 0.4266 - val_loss: 1.0394 - val_accuracy: 0.4333\n",
      "Epoch 33/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0358 - accuracy: 0.4415 - val_loss: 1.0148 - val_accuracy: 0.4583\n",
      "Epoch 34/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0344 - accuracy: 0.4363 - val_loss: 1.0083 - val_accuracy: 0.5083\n",
      "Epoch 35/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0275 - accuracy: 0.4356 - val_loss: 1.0367 - val_accuracy: 0.4274\n",
      "Epoch 36/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0295 - accuracy: 0.4438 - val_loss: 1.0093 - val_accuracy: 0.4845\n",
      "Epoch 37/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0328 - accuracy: 0.4432 - val_loss: 1.0052 - val_accuracy: 0.4881\n",
      "Epoch 38/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0214 - accuracy: 0.4547 - val_loss: 0.9983 - val_accuracy: 0.4774\n",
      "Epoch 39/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0228 - accuracy: 0.4546 - val_loss: 1.0418 - val_accuracy: 0.4452\n",
      "Epoch 40/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0209 - accuracy: 0.4531 - val_loss: 1.0590 - val_accuracy: 0.4476\n",
      "Epoch 41/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0157 - accuracy: 0.4571 - val_loss: 0.9921 - val_accuracy: 0.4798\n",
      "Epoch 42/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0180 - accuracy: 0.4561 - val_loss: 0.9861 - val_accuracy: 0.4726\n",
      "Epoch 43/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0145 - accuracy: 0.4498 - val_loss: 1.0006 - val_accuracy: 0.4595\n",
      "Epoch 44/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0068 - accuracy: 0.4653 - val_loss: 1.0063 - val_accuracy: 0.4738\n",
      "Epoch 45/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0062 - accuracy: 0.4647 - val_loss: 0.9992 - val_accuracy: 0.4893\n",
      "Epoch 46/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0107 - accuracy: 0.4617 - val_loss: 1.0117 - val_accuracy: 0.4500\n",
      "Epoch 47/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0060 - accuracy: 0.4726 - val_loss: 0.9936 - val_accuracy: 0.4786\n",
      "Epoch 48/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0001 - accuracy: 0.4714 - val_loss: 0.9750 - val_accuracy: 0.5036\n",
      "Epoch 49/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0041 - accuracy: 0.4693 - val_loss: 0.9678 - val_accuracy: 0.4893\n",
      "Epoch 50/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0123 - accuracy: 0.4540 - val_loss: 1.0134 - val_accuracy: 0.4702\n",
      "Epoch 51/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0046 - accuracy: 0.4766 - val_loss: 0.9784 - val_accuracy: 0.5202\n",
      "Epoch 52/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9951 - accuracy: 0.4817 - val_loss: 0.9896 - val_accuracy: 0.4821\n",
      "Epoch 53/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9889 - accuracy: 0.4767 - val_loss: 1.0123 - val_accuracy: 0.4417\n",
      "Epoch 54/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9960 - accuracy: 0.4843 - val_loss: 0.9827 - val_accuracy: 0.4869\n",
      "Epoch 55/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9981 - accuracy: 0.4805 - val_loss: 0.9433 - val_accuracy: 0.4952\n",
      "Epoch 56/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9883 - accuracy: 0.4850 - val_loss: 0.9737 - val_accuracy: 0.4500\n",
      "Epoch 57/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9836 - accuracy: 0.4877 - val_loss: 0.9749 - val_accuracy: 0.4893\n",
      "Epoch 58/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9831 - accuracy: 0.4862 - val_loss: 0.9661 - val_accuracy: 0.4988\n",
      "Epoch 59/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9817 - accuracy: 0.4838 - val_loss: 0.9489 - val_accuracy: 0.5107\n",
      "Epoch 60/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9828 - accuracy: 0.4905 - val_loss: 0.9437 - val_accuracy: 0.5238\n",
      "Epoch 61/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9767 - accuracy: 0.5002 - val_loss: 0.9754 - val_accuracy: 0.5012\n",
      "Epoch 62/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9671 - accuracy: 0.5091 - val_loss: 0.9674 - val_accuracy: 0.5155\n",
      "Epoch 63/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9660 - accuracy: 0.5077 - val_loss: 0.9445 - val_accuracy: 0.5643\n",
      "Epoch 64/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9689 - accuracy: 0.5146 - val_loss: 0.9442 - val_accuracy: 0.5167\n",
      "Epoch 65/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9731 - accuracy: 0.5025 - val_loss: 0.9439 - val_accuracy: 0.5060\n",
      "Epoch 66/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9634 - accuracy: 0.5058 - val_loss: 0.9525 - val_accuracy: 0.5048\n",
      "Epoch 67/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9609 - accuracy: 0.5142 - val_loss: 0.9393 - val_accuracy: 0.5214\n",
      "Epoch 68/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9732 - accuracy: 0.5044 - val_loss: 0.9388 - val_accuracy: 0.5357\n",
      "Epoch 69/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9600 - accuracy: 0.5174 - val_loss: 0.9398 - val_accuracy: 0.5381\n",
      "Epoch 70/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9599 - accuracy: 0.5090 - val_loss: 0.9563 - val_accuracy: 0.5155\n",
      "Epoch 71/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9482 - accuracy: 0.5266 - val_loss: 0.9711 - val_accuracy: 0.4881\n",
      "Epoch 72/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9595 - accuracy: 0.5170 - val_loss: 0.9570 - val_accuracy: 0.5476\n",
      "Epoch 73/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9606 - accuracy: 0.5234 - val_loss: 0.9433 - val_accuracy: 0.5452\n",
      "Epoch 74/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9482 - accuracy: 0.5291 - val_loss: 0.9307 - val_accuracy: 0.5536\n",
      "Epoch 75/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9392 - accuracy: 0.5345 - val_loss: 0.9579 - val_accuracy: 0.5155\n",
      "Epoch 76/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9500 - accuracy: 0.5216 - val_loss: 0.9317 - val_accuracy: 0.5262\n",
      "Epoch 77/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9306 - accuracy: 0.5373 - val_loss: 0.8912 - val_accuracy: 0.5619\n",
      "Epoch 78/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9281 - accuracy: 0.5321 - val_loss: 0.9680 - val_accuracy: 0.5202\n",
      "Epoch 79/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9315 - accuracy: 0.5260 - val_loss: 0.9324 - val_accuracy: 0.5226\n",
      "Epoch 80/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9323 - accuracy: 0.5326 - val_loss: 0.9466 - val_accuracy: 0.5083\n",
      "Epoch 81/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9324 - accuracy: 0.5389 - val_loss: 0.9024 - val_accuracy: 0.5286\n",
      "Epoch 82/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9259 - accuracy: 0.5358 - val_loss: 0.9480 - val_accuracy: 0.5310\n",
      "Epoch 83/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9270 - accuracy: 0.5374 - val_loss: 0.9383 - val_accuracy: 0.4929\n",
      "Epoch 84/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9209 - accuracy: 0.5407 - val_loss: 0.9080 - val_accuracy: 0.5381\n",
      "Epoch 85/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9164 - accuracy: 0.5460 - val_loss: 0.9245 - val_accuracy: 0.5464\n",
      "Epoch 86/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9017 - accuracy: 0.5560 - val_loss: 0.8897 - val_accuracy: 0.5524\n",
      "Epoch 87/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9119 - accuracy: 0.5483 - val_loss: 0.9128 - val_accuracy: 0.5083\n",
      "Epoch 88/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9125 - accuracy: 0.5511 - val_loss: 0.9148 - val_accuracy: 0.5464\n",
      "Epoch 89/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9042 - accuracy: 0.5479 - val_loss: 0.9500 - val_accuracy: 0.5083\n",
      "Epoch 90/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9133 - accuracy: 0.5425 - val_loss: 0.8658 - val_accuracy: 0.5631\n",
      "Epoch 91/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8981 - accuracy: 0.5577 - val_loss: 0.9324 - val_accuracy: 0.5179\n",
      "Epoch 92/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9000 - accuracy: 0.5639 - val_loss: 0.9118 - val_accuracy: 0.5393\n",
      "Epoch 93/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8969 - accuracy: 0.5609 - val_loss: 0.8955 - val_accuracy: 0.5298\n",
      "Epoch 94/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9027 - accuracy: 0.5505 - val_loss: 0.9269 - val_accuracy: 0.5274\n",
      "Epoch 95/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8903 - accuracy: 0.5617 - val_loss: 0.8786 - val_accuracy: 0.5571\n",
      "Epoch 96/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8833 - accuracy: 0.5628 - val_loss: 0.8736 - val_accuracy: 0.5595\n",
      "Epoch 97/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8891 - accuracy: 0.5669 - val_loss: 0.8965 - val_accuracy: 0.5357\n",
      "Epoch 98/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8750 - accuracy: 0.5748 - val_loss: 0.8795 - val_accuracy: 0.5548\n",
      "Epoch 99/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8775 - accuracy: 0.5748 - val_loss: 0.8553 - val_accuracy: 0.5631\n",
      "Epoch 100/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8848 - accuracy: 0.5664 - val_loss: 0.9425 - val_accuracy: 0.5060\n",
      "Epoch 101/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8935 - accuracy: 0.5682 - val_loss: 0.9285 - val_accuracy: 0.5345\n",
      "Epoch 102/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8850 - accuracy: 0.5715 - val_loss: 0.9467 - val_accuracy: 0.5119\n",
      "Epoch 103/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8839 - accuracy: 0.5797 - val_loss: 0.9130 - val_accuracy: 0.5417\n",
      "Epoch 104/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8711 - accuracy: 0.5771 - val_loss: 0.9024 - val_accuracy: 0.5405\n",
      "Epoch 105/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8771 - accuracy: 0.5767 - val_loss: 0.8725 - val_accuracy: 0.5750\n",
      "Epoch 106/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8732 - accuracy: 0.5791 - val_loss: 0.9213 - val_accuracy: 0.5357\n",
      "Epoch 107/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8629 - accuracy: 0.5789 - val_loss: 0.8607 - val_accuracy: 0.5583\n",
      "Epoch 108/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8635 - accuracy: 0.5808 - val_loss: 0.8653 - val_accuracy: 0.5607\n",
      "Epoch 109/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8607 - accuracy: 0.5833 - val_loss: 0.8780 - val_accuracy: 0.5464\n",
      "Epoch 110/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8568 - accuracy: 0.5833 - val_loss: 0.8750 - val_accuracy: 0.5679\n",
      "Epoch 111/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8584 - accuracy: 0.5845 - val_loss: 0.8851 - val_accuracy: 0.5619\n",
      "Epoch 112/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8594 - accuracy: 0.5746 - val_loss: 0.8447 - val_accuracy: 0.5595\n",
      "Epoch 113/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8506 - accuracy: 0.5908 - val_loss: 0.8777 - val_accuracy: 0.5571\n",
      "Epoch 114/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8409 - accuracy: 0.5922 - val_loss: 0.8069 - val_accuracy: 0.5869\n",
      "Epoch 115/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8400 - accuracy: 0.5928 - val_loss: 0.8497 - val_accuracy: 0.5726\n",
      "Epoch 116/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8377 - accuracy: 0.5873 - val_loss: 0.8674 - val_accuracy: 0.5714\n",
      "Epoch 117/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8462 - accuracy: 0.5818 - val_loss: 0.9170 - val_accuracy: 0.5333\n",
      "Epoch 118/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8283 - accuracy: 0.5915 - val_loss: 0.8785 - val_accuracy: 0.5369\n",
      "Epoch 119/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8203 - accuracy: 0.6026 - val_loss: 0.8410 - val_accuracy: 0.5619\n",
      "Epoch 120/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8355 - accuracy: 0.5854 - val_loss: 0.8366 - val_accuracy: 0.5548\n",
      "Epoch 121/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8269 - accuracy: 0.5984 - val_loss: 0.8791 - val_accuracy: 0.5512\n",
      "Epoch 122/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8341 - accuracy: 0.6022 - val_loss: 0.8700 - val_accuracy: 0.5786\n",
      "Epoch 123/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8204 - accuracy: 0.6053 - val_loss: 0.8467 - val_accuracy: 0.5560\n",
      "Epoch 124/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8184 - accuracy: 0.6071 - val_loss: 0.8818 - val_accuracy: 0.5548\n",
      "Epoch 125/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8246 - accuracy: 0.6049 - val_loss: 0.9136 - val_accuracy: 0.5393\n",
      "Epoch 126/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8085 - accuracy: 0.6116 - val_loss: 0.8264 - val_accuracy: 0.6405\n",
      "Epoch 127/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8019 - accuracy: 0.6193 - val_loss: 0.8417 - val_accuracy: 0.5881\n",
      "Epoch 128/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8069 - accuracy: 0.6163 - val_loss: 0.8509 - val_accuracy: 0.5750\n",
      "Epoch 129/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7989 - accuracy: 0.6201 - val_loss: 0.8467 - val_accuracy: 0.5786\n",
      "Epoch 130/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8053 - accuracy: 0.6136 - val_loss: 0.9055 - val_accuracy: 0.5476\n",
      "Epoch 131/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7920 - accuracy: 0.6262 - val_loss: 0.8249 - val_accuracy: 0.5869\n",
      "Epoch 132/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7962 - accuracy: 0.6197 - val_loss: 0.8108 - val_accuracy: 0.5738\n",
      "Epoch 133/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7875 - accuracy: 0.6229 - val_loss: 0.8930 - val_accuracy: 0.5905\n",
      "Epoch 134/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7821 - accuracy: 0.6272 - val_loss: 0.8315 - val_accuracy: 0.5845\n",
      "Epoch 135/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7912 - accuracy: 0.6201 - val_loss: 0.8267 - val_accuracy: 0.5607\n",
      "Epoch 136/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7680 - accuracy: 0.6280 - val_loss: 0.8419 - val_accuracy: 0.5714\n",
      "Epoch 137/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7881 - accuracy: 0.6233 - val_loss: 0.8225 - val_accuracy: 0.5679\n",
      "Epoch 138/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7775 - accuracy: 0.6325 - val_loss: 0.8450 - val_accuracy: 0.5833\n",
      "Epoch 139/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7736 - accuracy: 0.6276 - val_loss: 0.8386 - val_accuracy: 0.5881\n",
      "Epoch 140/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7725 - accuracy: 0.6333 - val_loss: 0.8325 - val_accuracy: 0.5798\n",
      "Epoch 141/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7747 - accuracy: 0.6322 - val_loss: 0.8053 - val_accuracy: 0.6167\n",
      "Epoch 142/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7675 - accuracy: 0.6300 - val_loss: 0.7803 - val_accuracy: 0.5940\n",
      "Epoch 143/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7742 - accuracy: 0.6346 - val_loss: 0.7780 - val_accuracy: 0.6107\n",
      "Epoch 144/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7625 - accuracy: 0.6408 - val_loss: 0.7891 - val_accuracy: 0.6155\n",
      "Epoch 145/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7726 - accuracy: 0.6276 - val_loss: 0.8672 - val_accuracy: 0.5571\n",
      "Epoch 146/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7611 - accuracy: 0.6398 - val_loss: 0.8543 - val_accuracy: 0.5583\n",
      "Epoch 147/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7679 - accuracy: 0.6306 - val_loss: 0.8297 - val_accuracy: 0.6071\n",
      "Epoch 148/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7564 - accuracy: 0.6346 - val_loss: 0.8553 - val_accuracy: 0.6131\n",
      "Epoch 149/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7590 - accuracy: 0.6289 - val_loss: 0.8443 - val_accuracy: 0.5786\n",
      "Epoch 150/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7435 - accuracy: 0.6374 - val_loss: 0.8450 - val_accuracy: 0.5762\n",
      "Epoch 151/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7573 - accuracy: 0.6359 - val_loss: 0.8244 - val_accuracy: 0.5571\n",
      "Epoch 152/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7457 - accuracy: 0.6372 - val_loss: 0.8370 - val_accuracy: 0.5631\n",
      "Epoch 153/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7336 - accuracy: 0.6506 - val_loss: 0.8187 - val_accuracy: 0.6000\n",
      "Epoch 154/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7359 - accuracy: 0.6478 - val_loss: 0.8578 - val_accuracy: 0.6012\n",
      "Epoch 155/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7548 - accuracy: 0.6389 - val_loss: 0.8208 - val_accuracy: 0.5869\n",
      "Epoch 156/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7410 - accuracy: 0.6468 - val_loss: 0.7905 - val_accuracy: 0.6131\n",
      "Epoch 157/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7386 - accuracy: 0.6544 - val_loss: 0.8392 - val_accuracy: 0.5714\n",
      "Epoch 158/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7252 - accuracy: 0.6641 - val_loss: 0.8071 - val_accuracy: 0.6155\n",
      "Epoch 159/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7250 - accuracy: 0.6595 - val_loss: 0.8538 - val_accuracy: 0.5810\n",
      "Epoch 160/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7411 - accuracy: 0.6557 - val_loss: 0.8809 - val_accuracy: 0.5583\n",
      "Epoch 161/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7248 - accuracy: 0.6619 - val_loss: 0.7439 - val_accuracy: 0.6357\n",
      "Epoch 162/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7336 - accuracy: 0.6501 - val_loss: 0.7659 - val_accuracy: 0.6655\n",
      "Epoch 163/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7288 - accuracy: 0.6541 - val_loss: 0.7848 - val_accuracy: 0.6107\n",
      "Epoch 164/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7150 - accuracy: 0.6580 - val_loss: 0.8285 - val_accuracy: 0.6036\n",
      "Epoch 165/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7327 - accuracy: 0.6567 - val_loss: 0.7518 - val_accuracy: 0.6619\n",
      "Epoch 166/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7179 - accuracy: 0.6597 - val_loss: 0.9943 - val_accuracy: 0.5238\n",
      "Epoch 167/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7171 - accuracy: 0.6644 - val_loss: 0.9498 - val_accuracy: 0.5726\n",
      "Epoch 168/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7118 - accuracy: 0.6631 - val_loss: 0.7755 - val_accuracy: 0.6202\n",
      "Epoch 169/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7066 - accuracy: 0.6680 - val_loss: 0.8507 - val_accuracy: 0.5774\n",
      "Epoch 170/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7186 - accuracy: 0.6652 - val_loss: 0.7886 - val_accuracy: 0.6083\n",
      "Epoch 171/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7052 - accuracy: 0.6644 - val_loss: 0.7859 - val_accuracy: 0.6321\n",
      "Epoch 172/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7149 - accuracy: 0.6675 - val_loss: 0.9077 - val_accuracy: 0.5429\n",
      "Epoch 173/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7366 - accuracy: 0.6587 - val_loss: 0.8857 - val_accuracy: 0.5714\n",
      "Epoch 174/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7220 - accuracy: 0.6577 - val_loss: 0.8707 - val_accuracy: 0.5655\n",
      "Epoch 175/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6980 - accuracy: 0.6764 - val_loss: 0.8135 - val_accuracy: 0.5726\n",
      "Epoch 176/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6970 - accuracy: 0.6692 - val_loss: 0.8135 - val_accuracy: 0.6071\n",
      "Epoch 177/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7063 - accuracy: 0.6746 - val_loss: 0.8220 - val_accuracy: 0.5976\n",
      "Epoch 178/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6849 - accuracy: 0.6797 - val_loss: 0.8394 - val_accuracy: 0.6048\n",
      "Epoch 179/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7028 - accuracy: 0.6692 - val_loss: 0.7995 - val_accuracy: 0.6214\n",
      "Epoch 180/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7008 - accuracy: 0.6692 - val_loss: 0.7659 - val_accuracy: 0.6345\n",
      "Epoch 181/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6658 - accuracy: 0.6903 - val_loss: 0.7781 - val_accuracy: 0.6250\n",
      "Epoch 182/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7016 - accuracy: 0.6764 - val_loss: 0.9025 - val_accuracy: 0.5786\n",
      "Epoch 183/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6849 - accuracy: 0.6784 - val_loss: 0.8239 - val_accuracy: 0.6155\n",
      "Epoch 184/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6902 - accuracy: 0.6719 - val_loss: 0.7800 - val_accuracy: 0.6310\n",
      "Epoch 185/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6850 - accuracy: 0.6781 - val_loss: 0.8432 - val_accuracy: 0.5929\n",
      "Epoch 186/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6884 - accuracy: 0.6754 - val_loss: 0.7653 - val_accuracy: 0.6393\n",
      "Epoch 187/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6682 - accuracy: 0.6945 - val_loss: 0.7284 - val_accuracy: 0.6571\n",
      "Epoch 188/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6684 - accuracy: 0.6867 - val_loss: 0.8477 - val_accuracy: 0.5857\n",
      "Epoch 189/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6792 - accuracy: 0.6927 - val_loss: 0.7804 - val_accuracy: 0.6393\n",
      "Epoch 190/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6671 - accuracy: 0.6851 - val_loss: 0.8573 - val_accuracy: 0.5679\n",
      "Epoch 191/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6701 - accuracy: 0.6813 - val_loss: 0.8287 - val_accuracy: 0.5833\n",
      "Epoch 192/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6745 - accuracy: 0.6907 - val_loss: 0.8381 - val_accuracy: 0.6119\n",
      "Epoch 193/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6805 - accuracy: 0.6905 - val_loss: 0.8492 - val_accuracy: 0.6107\n",
      "Epoch 194/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6596 - accuracy: 0.6968 - val_loss: 0.8345 - val_accuracy: 0.5964\n",
      "Epoch 195/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6566 - accuracy: 0.6965 - val_loss: 0.7725 - val_accuracy: 0.6393\n",
      "Epoch 196/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6676 - accuracy: 0.6917 - val_loss: 0.9311 - val_accuracy: 0.5738\n",
      "Epoch 197/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6593 - accuracy: 0.7009 - val_loss: 0.7526 - val_accuracy: 0.6512\n",
      "Epoch 198/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6594 - accuracy: 0.6965 - val_loss: 0.8135 - val_accuracy: 0.6179\n",
      "Epoch 199/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6711 - accuracy: 0.6892 - val_loss: 0.8590 - val_accuracy: 0.5810\n",
      "Epoch 200/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6748 - accuracy: 0.6918 - val_loss: 0.8496 - val_accuracy: 0.5845\n",
      "Epoch 201/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6718 - accuracy: 0.6933 - val_loss: 0.9888 - val_accuracy: 0.5321\n",
      "Epoch 202/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6730 - accuracy: 0.7009 - val_loss: 0.8015 - val_accuracy: 0.6202\n",
      "Epoch 203/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6654 - accuracy: 0.7009 - val_loss: 0.8718 - val_accuracy: 0.6083\n",
      "Epoch 204/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6570 - accuracy: 0.6960 - val_loss: 0.8909 - val_accuracy: 0.5738\n",
      "Epoch 205/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6639 - accuracy: 0.7001 - val_loss: 0.8245 - val_accuracy: 0.5869\n",
      "Epoch 206/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6533 - accuracy: 0.7040 - val_loss: 0.8282 - val_accuracy: 0.6274\n",
      "Epoch 207/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6537 - accuracy: 0.7066 - val_loss: 0.7891 - val_accuracy: 0.6464\n",
      "Epoch 208/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6465 - accuracy: 0.7106 - val_loss: 0.8672 - val_accuracy: 0.6024\n",
      "Epoch 209/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6520 - accuracy: 0.7062 - val_loss: 0.7511 - val_accuracy: 0.6869\n",
      "Epoch 210/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6582 - accuracy: 0.7065 - val_loss: 0.8061 - val_accuracy: 0.6190\n",
      "Epoch 211/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6482 - accuracy: 0.7063 - val_loss: 0.8495 - val_accuracy: 0.5988\n",
      "Epoch 212/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6172 - accuracy: 0.7238 - val_loss: 0.8312 - val_accuracy: 0.5726\n",
      "Epoch 213/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6169 - accuracy: 0.7198 - val_loss: 0.7915 - val_accuracy: 0.6119\n",
      "Epoch 214/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6515 - accuracy: 0.7093 - val_loss: 0.8300 - val_accuracy: 0.6155\n",
      "Epoch 215/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6430 - accuracy: 0.7138 - val_loss: 0.8110 - val_accuracy: 0.6000\n",
      "Epoch 216/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6386 - accuracy: 0.7133 - val_loss: 0.7419 - val_accuracy: 0.6548\n",
      "Epoch 217/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6264 - accuracy: 0.7244 - val_loss: 0.7619 - val_accuracy: 0.6560\n",
      "Epoch 218/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6251 - accuracy: 0.7229 - val_loss: 0.7614 - val_accuracy: 0.6607\n",
      "Epoch 219/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6349 - accuracy: 0.7184 - val_loss: 0.7871 - val_accuracy: 0.6357\n",
      "Epoch 220/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6060 - accuracy: 0.7264 - val_loss: 0.7465 - val_accuracy: 0.6381\n",
      "Epoch 221/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6270 - accuracy: 0.7185 - val_loss: 0.7821 - val_accuracy: 0.6250\n",
      "Epoch 222/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6064 - accuracy: 0.7313 - val_loss: 0.8205 - val_accuracy: 0.6429\n",
      "Epoch 223/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6154 - accuracy: 0.7233 - val_loss: 0.7738 - val_accuracy: 0.6548\n",
      "Epoch 224/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6061 - accuracy: 0.7341 - val_loss: 0.7664 - val_accuracy: 0.6369\n",
      "Epoch 225/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6010 - accuracy: 0.7356 - val_loss: 0.7833 - val_accuracy: 0.6393\n",
      "Epoch 226/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6114 - accuracy: 0.7266 - val_loss: 0.8282 - val_accuracy: 0.6369\n",
      "Epoch 227/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6146 - accuracy: 0.7275 - val_loss: 0.7808 - val_accuracy: 0.6321\n",
      "Epoch 228/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5848 - accuracy: 0.7438 - val_loss: 0.7433 - val_accuracy: 0.6476\n",
      "Epoch 229/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6188 - accuracy: 0.7290 - val_loss: 0.6993 - val_accuracy: 0.6571\n",
      "Epoch 230/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5780 - accuracy: 0.7450 - val_loss: 0.8193 - val_accuracy: 0.5940\n",
      "Epoch 231/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5915 - accuracy: 0.7408 - val_loss: 0.7822 - val_accuracy: 0.6321\n",
      "Epoch 232/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5960 - accuracy: 0.7410 - val_loss: 0.8412 - val_accuracy: 0.5976\n",
      "Epoch 233/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6116 - accuracy: 0.7249 - val_loss: 0.7268 - val_accuracy: 0.6631\n",
      "Epoch 234/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5593 - accuracy: 0.7593 - val_loss: 0.9113 - val_accuracy: 0.5964\n",
      "Epoch 235/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5959 - accuracy: 0.7379 - val_loss: 0.8084 - val_accuracy: 0.6310\n",
      "Epoch 236/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5974 - accuracy: 0.7336 - val_loss: 0.7358 - val_accuracy: 0.6631\n",
      "Epoch 237/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5754 - accuracy: 0.7491 - val_loss: 0.6965 - val_accuracy: 0.6833\n",
      "Epoch 238/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5617 - accuracy: 0.7535 - val_loss: 0.7654 - val_accuracy: 0.6417\n",
      "Epoch 239/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5988 - accuracy: 0.7281 - val_loss: 0.8211 - val_accuracy: 0.6262\n",
      "Epoch 240/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5813 - accuracy: 0.7494 - val_loss: 0.7941 - val_accuracy: 0.6548\n",
      "Epoch 241/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5768 - accuracy: 0.7464 - val_loss: 0.7826 - val_accuracy: 0.6702\n",
      "Epoch 242/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5813 - accuracy: 0.7451 - val_loss: 0.7651 - val_accuracy: 0.6690\n",
      "Epoch 243/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5590 - accuracy: 0.7587 - val_loss: 0.7810 - val_accuracy: 0.6500\n",
      "Epoch 244/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5681 - accuracy: 0.7532 - val_loss: 0.7407 - val_accuracy: 0.6702\n",
      "Epoch 245/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5698 - accuracy: 0.7501 - val_loss: 0.7476 - val_accuracy: 0.6679\n",
      "Epoch 246/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5718 - accuracy: 0.7516 - val_loss: 0.7819 - val_accuracy: 0.6631\n",
      "Epoch 247/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5700 - accuracy: 0.7489 - val_loss: 0.6665 - val_accuracy: 0.6869\n",
      "Epoch 248/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5622 - accuracy: 0.7545 - val_loss: 0.7465 - val_accuracy: 0.6893\n",
      "Epoch 249/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5550 - accuracy: 0.7536 - val_loss: 0.7881 - val_accuracy: 0.6381\n",
      "Epoch 250/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5809 - accuracy: 0.7592 - val_loss: 0.7518 - val_accuracy: 0.6238\n",
      "Epoch 251/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5375 - accuracy: 0.7706 - val_loss: 0.7785 - val_accuracy: 0.6643\n",
      "Epoch 252/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5661 - accuracy: 0.7551 - val_loss: 0.7614 - val_accuracy: 0.6536\n",
      "Epoch 253/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5666 - accuracy: 0.7592 - val_loss: 0.6736 - val_accuracy: 0.6869\n",
      "Epoch 254/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5552 - accuracy: 0.7600 - val_loss: 0.7863 - val_accuracy: 0.6560\n",
      "Epoch 255/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5319 - accuracy: 0.7662 - val_loss: 0.6590 - val_accuracy: 0.7345\n",
      "Epoch 256/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5558 - accuracy: 0.7592 - val_loss: 0.8932 - val_accuracy: 0.5964\n",
      "Epoch 257/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5356 - accuracy: 0.7692 - val_loss: 0.6609 - val_accuracy: 0.6893\n",
      "Epoch 258/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5526 - accuracy: 0.7658 - val_loss: 0.7001 - val_accuracy: 0.6786\n",
      "Epoch 259/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5266 - accuracy: 0.7714 - val_loss: 0.7942 - val_accuracy: 0.6536\n",
      "Epoch 260/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5384 - accuracy: 0.7689 - val_loss: 0.6969 - val_accuracy: 0.6869\n",
      "Epoch 261/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5535 - accuracy: 0.7603 - val_loss: 0.6966 - val_accuracy: 0.6845\n",
      "Epoch 262/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5537 - accuracy: 0.7673 - val_loss: 0.7859 - val_accuracy: 0.6083\n",
      "Epoch 263/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5405 - accuracy: 0.7660 - val_loss: 0.6389 - val_accuracy: 0.7060\n",
      "Epoch 264/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5463 - accuracy: 0.7674 - val_loss: 0.6713 - val_accuracy: 0.6738\n",
      "Epoch 265/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5175 - accuracy: 0.7764 - val_loss: 0.7197 - val_accuracy: 0.6679\n",
      "Epoch 266/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5456 - accuracy: 0.7602 - val_loss: 0.8838 - val_accuracy: 0.6238\n",
      "Epoch 267/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5183 - accuracy: 0.7736 - val_loss: 0.6866 - val_accuracy: 0.7000\n",
      "Epoch 268/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5302 - accuracy: 0.7776 - val_loss: 0.7307 - val_accuracy: 0.6726\n",
      "Epoch 269/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5077 - accuracy: 0.7833 - val_loss: 0.8047 - val_accuracy: 0.6452\n",
      "Epoch 270/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5336 - accuracy: 0.7801 - val_loss: 0.7286 - val_accuracy: 0.6964\n",
      "Epoch 271/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5308 - accuracy: 0.7739 - val_loss: 0.7167 - val_accuracy: 0.6702\n",
      "Epoch 272/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5209 - accuracy: 0.7790 - val_loss: 0.7473 - val_accuracy: 0.6357\n",
      "Epoch 273/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5087 - accuracy: 0.7831 - val_loss: 0.7285 - val_accuracy: 0.6762\n",
      "Epoch 274/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5292 - accuracy: 0.7757 - val_loss: 0.7455 - val_accuracy: 0.6464\n",
      "Epoch 275/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5061 - accuracy: 0.7841 - val_loss: 0.7009 - val_accuracy: 0.6786\n",
      "Epoch 276/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4888 - accuracy: 0.7943 - val_loss: 0.7446 - val_accuracy: 0.6762\n",
      "Epoch 277/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5136 - accuracy: 0.7835 - val_loss: 0.6608 - val_accuracy: 0.6893\n",
      "Epoch 278/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5043 - accuracy: 0.7877 - val_loss: 0.6515 - val_accuracy: 0.6976\n",
      "Epoch 279/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5273 - accuracy: 0.7688 - val_loss: 0.6319 - val_accuracy: 0.7000\n",
      "Epoch 280/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5059 - accuracy: 0.7835 - val_loss: 0.6800 - val_accuracy: 0.7000\n",
      "Epoch 281/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5201 - accuracy: 0.7848 - val_loss: 0.7362 - val_accuracy: 0.6643\n",
      "Epoch 282/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5088 - accuracy: 0.7847 - val_loss: 0.7002 - val_accuracy: 0.6667\n",
      "Epoch 283/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4941 - accuracy: 0.7954 - val_loss: 0.7366 - val_accuracy: 0.6440\n",
      "Epoch 284/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5204 - accuracy: 0.7822 - val_loss: 0.7310 - val_accuracy: 0.6655\n",
      "Epoch 285/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4917 - accuracy: 0.7965 - val_loss: 0.6467 - val_accuracy: 0.6952\n",
      "Epoch 286/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4815 - accuracy: 0.8017 - val_loss: 0.6519 - val_accuracy: 0.7262\n",
      "Epoch 287/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4858 - accuracy: 0.7951 - val_loss: 0.7644 - val_accuracy: 0.6679\n",
      "Epoch 288/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4949 - accuracy: 0.7932 - val_loss: 0.7768 - val_accuracy: 0.6500\n",
      "Epoch 289/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4856 - accuracy: 0.7959 - val_loss: 0.6736 - val_accuracy: 0.7179\n",
      "Epoch 290/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4831 - accuracy: 0.7935 - val_loss: 0.6892 - val_accuracy: 0.7155\n",
      "Epoch 291/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4880 - accuracy: 0.7902 - val_loss: 0.6923 - val_accuracy: 0.7107\n",
      "Epoch 292/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4629 - accuracy: 0.8026 - val_loss: 0.6363 - val_accuracy: 0.7214\n",
      "Epoch 293/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4709 - accuracy: 0.7993 - val_loss: 0.6630 - val_accuracy: 0.7226\n",
      "Epoch 294/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4767 - accuracy: 0.7976 - val_loss: 0.6311 - val_accuracy: 0.7631\n",
      "Epoch 295/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4992 - accuracy: 0.7868 - val_loss: 0.7378 - val_accuracy: 0.6679\n",
      "Epoch 296/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5246 - accuracy: 0.7837 - val_loss: 0.7634 - val_accuracy: 0.6702\n",
      "Epoch 297/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4881 - accuracy: 0.7943 - val_loss: 0.7067 - val_accuracy: 0.7143\n",
      "Epoch 298/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4741 - accuracy: 0.8051 - val_loss: 0.7204 - val_accuracy: 0.7095\n",
      "Epoch 299/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4938 - accuracy: 0.7898 - val_loss: 0.7787 - val_accuracy: 0.6774\n",
      "Epoch 300/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4657 - accuracy: 0.8035 - val_loss: 0.6950 - val_accuracy: 0.7095\n",
      "Epoch 301/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4608 - accuracy: 0.8092 - val_loss: 0.7072 - val_accuracy: 0.7202\n",
      "Epoch 302/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4737 - accuracy: 0.8032 - val_loss: 0.7586 - val_accuracy: 0.6893\n",
      "Epoch 303/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4988 - accuracy: 0.7925 - val_loss: 0.6828 - val_accuracy: 0.6810\n",
      "Epoch 304/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4581 - accuracy: 0.8090 - val_loss: 0.6582 - val_accuracy: 0.7131\n",
      "Epoch 305/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4808 - accuracy: 0.7993 - val_loss: 0.6590 - val_accuracy: 0.7321\n",
      "Epoch 306/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4461 - accuracy: 0.8106 - val_loss: 0.7484 - val_accuracy: 0.6762\n",
      "Epoch 307/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4603 - accuracy: 0.8098 - val_loss: 0.7349 - val_accuracy: 0.6679\n",
      "Epoch 308/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4850 - accuracy: 0.8058 - val_loss: 0.7068 - val_accuracy: 0.6940\n",
      "Epoch 309/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4682 - accuracy: 0.8004 - val_loss: 0.6506 - val_accuracy: 0.7060\n",
      "Epoch 310/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4714 - accuracy: 0.8046 - val_loss: 0.6068 - val_accuracy: 0.7583\n",
      "Epoch 311/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4319 - accuracy: 0.8210 - val_loss: 0.5593 - val_accuracy: 0.7476\n",
      "Epoch 312/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4646 - accuracy: 0.8053 - val_loss: 0.6864 - val_accuracy: 0.7095\n",
      "Epoch 313/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4393 - accuracy: 0.8204 - val_loss: 0.7268 - val_accuracy: 0.6643\n",
      "Epoch 314/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4683 - accuracy: 0.8088 - val_loss: 0.6938 - val_accuracy: 0.6893\n",
      "Epoch 315/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4343 - accuracy: 0.8174 - val_loss: 0.6262 - val_accuracy: 0.7226\n",
      "Epoch 316/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4395 - accuracy: 0.8187 - val_loss: 0.6578 - val_accuracy: 0.7262\n",
      "Epoch 317/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4579 - accuracy: 0.8100 - val_loss: 0.8099 - val_accuracy: 0.6452\n",
      "Epoch 318/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4514 - accuracy: 0.8131 - val_loss: 0.8101 - val_accuracy: 0.6524\n",
      "Epoch 319/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4389 - accuracy: 0.8199 - val_loss: 0.7043 - val_accuracy: 0.6833\n",
      "Epoch 320/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4480 - accuracy: 0.8167 - val_loss: 0.6866 - val_accuracy: 0.6857\n",
      "Epoch 321/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4368 - accuracy: 0.8235 - val_loss: 0.7342 - val_accuracy: 0.6952\n",
      "Epoch 322/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4449 - accuracy: 0.8199 - val_loss: 0.6876 - val_accuracy: 0.6833\n",
      "Epoch 323/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4231 - accuracy: 0.8229 - val_loss: 0.6435 - val_accuracy: 0.7321\n",
      "Epoch 324/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4125 - accuracy: 0.8292 - val_loss: 0.9116 - val_accuracy: 0.6012\n",
      "Epoch 325/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4358 - accuracy: 0.8244 - val_loss: 0.6746 - val_accuracy: 0.7357\n",
      "Epoch 326/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4274 - accuracy: 0.8265 - val_loss: 0.8646 - val_accuracy: 0.6595\n",
      "Epoch 327/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4314 - accuracy: 0.8290 - val_loss: 0.6222 - val_accuracy: 0.7179\n",
      "Epoch 328/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4287 - accuracy: 0.8201 - val_loss: 0.7370 - val_accuracy: 0.6940\n",
      "Epoch 329/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4298 - accuracy: 0.8266 - val_loss: 0.6069 - val_accuracy: 0.7345\n",
      "Epoch 330/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4274 - accuracy: 0.8243 - val_loss: 0.7002 - val_accuracy: 0.6988\n",
      "Epoch 331/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4387 - accuracy: 0.8199 - val_loss: 0.6519 - val_accuracy: 0.7250\n",
      "Epoch 332/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4169 - accuracy: 0.8326 - val_loss: 0.6568 - val_accuracy: 0.7190\n",
      "Epoch 333/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4471 - accuracy: 0.8175 - val_loss: 0.6123 - val_accuracy: 0.7357\n",
      "Epoch 334/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3957 - accuracy: 0.8398 - val_loss: 0.7048 - val_accuracy: 0.7167\n",
      "Epoch 335/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4380 - accuracy: 0.8220 - val_loss: 0.6734 - val_accuracy: 0.7036\n",
      "Epoch 336/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4173 - accuracy: 0.8346 - val_loss: 0.6313 - val_accuracy: 0.7452\n",
      "Epoch 337/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4304 - accuracy: 0.8225 - val_loss: 0.6944 - val_accuracy: 0.7036\n",
      "Epoch 338/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4284 - accuracy: 0.8277 - val_loss: 0.6266 - val_accuracy: 0.7083\n",
      "Epoch 339/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4324 - accuracy: 0.8250 - val_loss: 0.6460 - val_accuracy: 0.7202\n",
      "Epoch 340/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4072 - accuracy: 0.8374 - val_loss: 0.6413 - val_accuracy: 0.7190\n",
      "Epoch 341/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4067 - accuracy: 0.8327 - val_loss: 0.6210 - val_accuracy: 0.7333\n",
      "Epoch 342/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4097 - accuracy: 0.8295 - val_loss: 0.6752 - val_accuracy: 0.7155\n",
      "Epoch 343/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3962 - accuracy: 0.8398 - val_loss: 0.6065 - val_accuracy: 0.7571\n",
      "Epoch 344/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4122 - accuracy: 0.8313 - val_loss: 0.6680 - val_accuracy: 0.7131\n",
      "Epoch 345/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4229 - accuracy: 0.8195 - val_loss: 0.6570 - val_accuracy: 0.7048\n",
      "Epoch 346/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.4047 - accuracy: 0.8364 - val_loss: 0.6232 - val_accuracy: 0.7119\n",
      "Epoch 347/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4198 - accuracy: 0.8275 - val_loss: 0.7390 - val_accuracy: 0.6571\n",
      "Epoch 348/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4280 - accuracy: 0.8279 - val_loss: 0.6925 - val_accuracy: 0.7071\n",
      "Epoch 349/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3786 - accuracy: 0.8450 - val_loss: 0.6118 - val_accuracy: 0.7393\n",
      "Epoch 350/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4031 - accuracy: 0.8343 - val_loss: 0.7032 - val_accuracy: 0.6869\n",
      "Epoch 351/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4188 - accuracy: 0.8267 - val_loss: 0.6881 - val_accuracy: 0.6964\n",
      "Epoch 352/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4032 - accuracy: 0.8346 - val_loss: 0.6408 - val_accuracy: 0.7250\n",
      "Epoch 353/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3924 - accuracy: 0.8338 - val_loss: 0.6812 - val_accuracy: 0.7262\n",
      "Epoch 354/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3930 - accuracy: 0.8409 - val_loss: 0.6726 - val_accuracy: 0.7476\n",
      "Epoch 355/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4140 - accuracy: 0.8299 - val_loss: 0.6553 - val_accuracy: 0.7179\n",
      "Epoch 356/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3926 - accuracy: 0.8430 - val_loss: 0.7571 - val_accuracy: 0.6952\n",
      "Epoch 357/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4033 - accuracy: 0.8407 - val_loss: 0.6330 - val_accuracy: 0.7381\n",
      "Epoch 358/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4027 - accuracy: 0.8350 - val_loss: 0.7287 - val_accuracy: 0.7107\n",
      "Epoch 359/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3757 - accuracy: 0.8488 - val_loss: 0.5538 - val_accuracy: 0.7607\n",
      "Epoch 360/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4118 - accuracy: 0.8308 - val_loss: 0.5551 - val_accuracy: 0.7560\n",
      "Epoch 361/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4071 - accuracy: 0.8378 - val_loss: 0.6980 - val_accuracy: 0.6940\n",
      "Epoch 362/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4052 - accuracy: 0.8330 - val_loss: 0.6453 - val_accuracy: 0.7060\n",
      "Epoch 363/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3712 - accuracy: 0.8516 - val_loss: 0.6548 - val_accuracy: 0.7393\n",
      "Epoch 364/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4081 - accuracy: 0.8382 - val_loss: 0.7953 - val_accuracy: 0.6750\n",
      "Epoch 365/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3842 - accuracy: 0.8424 - val_loss: 0.6729 - val_accuracy: 0.7333\n",
      "Epoch 366/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3594 - accuracy: 0.8596 - val_loss: 0.6883 - val_accuracy: 0.6917\n",
      "Epoch 367/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3656 - accuracy: 0.8470 - val_loss: 0.5695 - val_accuracy: 0.7548\n",
      "Epoch 368/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4282 - accuracy: 0.8336 - val_loss: 0.6521 - val_accuracy: 0.7274\n",
      "Epoch 369/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3774 - accuracy: 0.8468 - val_loss: 0.7121 - val_accuracy: 0.6881\n",
      "Epoch 370/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3825 - accuracy: 0.8448 - val_loss: 0.6468 - val_accuracy: 0.7226\n",
      "Epoch 371/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3824 - accuracy: 0.8469 - val_loss: 0.6975 - val_accuracy: 0.7107\n",
      "Epoch 372/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4291 - accuracy: 0.8257 - val_loss: 0.7010 - val_accuracy: 0.6893\n",
      "Epoch 373/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3670 - accuracy: 0.8527 - val_loss: 0.6392 - val_accuracy: 0.7298\n",
      "Epoch 374/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3960 - accuracy: 0.8369 - val_loss: 0.6749 - val_accuracy: 0.7190\n",
      "Epoch 375/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3632 - accuracy: 0.8555 - val_loss: 0.8114 - val_accuracy: 0.6679\n",
      "Epoch 376/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3774 - accuracy: 0.8445 - val_loss: 0.6059 - val_accuracy: 0.7488\n",
      "Epoch 377/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3786 - accuracy: 0.8464 - val_loss: 0.5880 - val_accuracy: 0.7381\n",
      "Epoch 378/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3665 - accuracy: 0.8493 - val_loss: 0.5888 - val_accuracy: 0.7369\n",
      "Epoch 379/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3660 - accuracy: 0.8466 - val_loss: 0.5895 - val_accuracy: 0.7357\n",
      "Epoch 380/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3725 - accuracy: 0.8510 - val_loss: 0.6579 - val_accuracy: 0.7357\n",
      "Epoch 381/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4051 - accuracy: 0.8382 - val_loss: 0.6071 - val_accuracy: 0.7381\n",
      "Epoch 382/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3655 - accuracy: 0.8526 - val_loss: 0.6360 - val_accuracy: 0.7262\n",
      "Epoch 383/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4007 - accuracy: 0.8402 - val_loss: 0.5715 - val_accuracy: 0.7536\n",
      "Epoch 384/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3751 - accuracy: 0.8473 - val_loss: 0.6977 - val_accuracy: 0.7095\n",
      "Epoch 385/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3684 - accuracy: 0.8517 - val_loss: 0.5893 - val_accuracy: 0.7607\n",
      "Epoch 386/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3600 - accuracy: 0.8585 - val_loss: 0.6028 - val_accuracy: 0.7440\n",
      "Epoch 387/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3800 - accuracy: 0.8419 - val_loss: 0.6461 - val_accuracy: 0.7131\n",
      "Epoch 388/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3520 - accuracy: 0.8614 - val_loss: 0.6396 - val_accuracy: 0.7345\n",
      "Epoch 389/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3657 - accuracy: 0.8519 - val_loss: 0.5642 - val_accuracy: 0.7643\n",
      "Epoch 390/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3490 - accuracy: 0.8607 - val_loss: 0.6300 - val_accuracy: 0.7560\n",
      "Epoch 391/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3714 - accuracy: 0.8534 - val_loss: 0.5706 - val_accuracy: 0.7798\n",
      "Epoch 392/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3758 - accuracy: 0.8526 - val_loss: 0.7696 - val_accuracy: 0.6952\n",
      "Epoch 393/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3694 - accuracy: 0.8484 - val_loss: 0.6711 - val_accuracy: 0.7345\n",
      "Epoch 394/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3370 - accuracy: 0.8650 - val_loss: 0.6395 - val_accuracy: 0.7321\n",
      "Epoch 395/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4027 - accuracy: 0.8499 - val_loss: 0.6857 - val_accuracy: 0.6857\n",
      "Epoch 396/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4399 - accuracy: 0.8182 - val_loss: 0.7706 - val_accuracy: 0.6679\n",
      "Epoch 397/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4059 - accuracy: 0.8368 - val_loss: 0.7566 - val_accuracy: 0.7071\n",
      "Epoch 398/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4167 - accuracy: 0.8299 - val_loss: 0.6627 - val_accuracy: 0.7060\n",
      "Epoch 399/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3990 - accuracy: 0.8409 - val_loss: 0.6447 - val_accuracy: 0.7155\n",
      "Epoch 400/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4081 - accuracy: 0.8376 - val_loss: 0.7126 - val_accuracy: 0.7000\n",
      "Epoch 401/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4142 - accuracy: 0.8328 - val_loss: 0.7630 - val_accuracy: 0.6964\n",
      "Epoch 402/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4005 - accuracy: 0.8389 - val_loss: 0.9247 - val_accuracy: 0.6488\n",
      "Epoch 403/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3794 - accuracy: 0.8454 - val_loss: 0.6388 - val_accuracy: 0.7417\n",
      "Epoch 404/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4261 - accuracy: 0.8243 - val_loss: 0.7919 - val_accuracy: 0.6464\n",
      "Epoch 405/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3871 - accuracy: 0.8454 - val_loss: 0.7371 - val_accuracy: 0.7000\n",
      "Epoch 406/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3818 - accuracy: 0.8451 - val_loss: 0.6605 - val_accuracy: 0.7107\n",
      "Epoch 407/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3765 - accuracy: 0.8470 - val_loss: 0.7549 - val_accuracy: 0.6679\n",
      "Epoch 408/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3729 - accuracy: 0.8476 - val_loss: 0.7783 - val_accuracy: 0.6821\n",
      "Epoch 409/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3560 - accuracy: 0.8530 - val_loss: 0.6829 - val_accuracy: 0.7107\n",
      "Epoch 410/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3896 - accuracy: 0.8427 - val_loss: 0.6788 - val_accuracy: 0.7083\n",
      "Epoch 411/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3557 - accuracy: 0.8616 - val_loss: 0.7155 - val_accuracy: 0.7107\n",
      "Epoch 412/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3771 - accuracy: 0.8507 - val_loss: 0.7038 - val_accuracy: 0.7119\n",
      "Epoch 413/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3861 - accuracy: 0.8453 - val_loss: 0.6059 - val_accuracy: 0.7393\n",
      "Epoch 414/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3605 - accuracy: 0.8544 - val_loss: 0.7721 - val_accuracy: 0.6905\n",
      "Epoch 415/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4006 - accuracy: 0.8405 - val_loss: 0.7329 - val_accuracy: 0.6833\n",
      "Epoch 416/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3594 - accuracy: 0.8560 - val_loss: 0.7984 - val_accuracy: 0.6655\n",
      "Epoch 417/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3872 - accuracy: 0.8451 - val_loss: 0.7490 - val_accuracy: 0.6988\n",
      "Epoch 418/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3498 - accuracy: 0.8587 - val_loss: 0.6650 - val_accuracy: 0.7417\n",
      "Epoch 419/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3487 - accuracy: 0.8560 - val_loss: 0.6058 - val_accuracy: 0.7512\n",
      "Epoch 420/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3450 - accuracy: 0.8585 - val_loss: 0.7304 - val_accuracy: 0.6595\n",
      "Epoch 421/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3868 - accuracy: 0.8515 - val_loss: 0.6478 - val_accuracy: 0.7488\n",
      "Epoch 422/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3698 - accuracy: 0.8535 - val_loss: 0.7232 - val_accuracy: 0.6774\n",
      "Epoch 423/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3958 - accuracy: 0.8405 - val_loss: 0.6324 - val_accuracy: 0.7369\n",
      "Epoch 424/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3487 - accuracy: 0.8576 - val_loss: 0.6602 - val_accuracy: 0.7119\n",
      "Epoch 425/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3862 - accuracy: 0.8489 - val_loss: 0.6337 - val_accuracy: 0.7429\n",
      "Epoch 426/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3553 - accuracy: 0.8582 - val_loss: 0.5943 - val_accuracy: 0.7369\n",
      "Epoch 427/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3295 - accuracy: 0.8701 - val_loss: 0.6258 - val_accuracy: 0.7464\n",
      "Epoch 428/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3313 - accuracy: 0.8677 - val_loss: 0.7960 - val_accuracy: 0.6821\n",
      "Epoch 429/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3348 - accuracy: 0.8632 - val_loss: 0.6858 - val_accuracy: 0.7119\n",
      "Epoch 430/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3346 - accuracy: 0.8670 - val_loss: 0.6641 - val_accuracy: 0.7060\n",
      "Epoch 431/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3120 - accuracy: 0.8706 - val_loss: 0.6029 - val_accuracy: 0.7464\n",
      "Epoch 432/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3435 - accuracy: 0.8623 - val_loss: 0.6616 - val_accuracy: 0.7405\n",
      "Epoch 433/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3319 - accuracy: 0.8679 - val_loss: 0.6828 - val_accuracy: 0.7357\n",
      "Epoch 434/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3283 - accuracy: 0.8701 - val_loss: 0.6511 - val_accuracy: 0.7357\n",
      "Epoch 435/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3501 - accuracy: 0.8639 - val_loss: 0.5696 - val_accuracy: 0.7702\n",
      "Epoch 436/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3205 - accuracy: 0.8709 - val_loss: 0.6473 - val_accuracy: 0.7321\n",
      "Epoch 437/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3427 - accuracy: 0.8655 - val_loss: 0.6679 - val_accuracy: 0.7286\n",
      "Epoch 438/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3721 - accuracy: 0.8550 - val_loss: 0.5847 - val_accuracy: 0.7560\n",
      "Epoch 439/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3148 - accuracy: 0.8757 - val_loss: 0.7559 - val_accuracy: 0.6643\n",
      "Epoch 440/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3126 - accuracy: 0.8731 - val_loss: 0.6911 - val_accuracy: 0.7095\n",
      "Epoch 441/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3359 - accuracy: 0.8675 - val_loss: 0.5975 - val_accuracy: 0.7405\n",
      "Epoch 442/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3484 - accuracy: 0.8657 - val_loss: 0.5889 - val_accuracy: 0.7488\n",
      "Epoch 443/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3210 - accuracy: 0.8760 - val_loss: 0.6895 - val_accuracy: 0.7143\n",
      "Epoch 444/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3268 - accuracy: 0.8693 - val_loss: 0.6473 - val_accuracy: 0.7452\n",
      "Epoch 445/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3202 - accuracy: 0.8700 - val_loss: 0.6355 - val_accuracy: 0.7702\n",
      "Epoch 446/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3223 - accuracy: 0.8731 - val_loss: 0.6496 - val_accuracy: 0.7536\n",
      "Epoch 447/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3273 - accuracy: 0.8730 - val_loss: 0.6570 - val_accuracy: 0.7214\n",
      "Epoch 448/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3331 - accuracy: 0.8700 - val_loss: 0.6186 - val_accuracy: 0.7464\n",
      "Epoch 449/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3193 - accuracy: 0.8713 - val_loss: 0.6140 - val_accuracy: 0.7298\n",
      "Epoch 450/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3172 - accuracy: 0.8755 - val_loss: 0.6488 - val_accuracy: 0.7440\n",
      "Epoch 451/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3046 - accuracy: 0.8791 - val_loss: 0.6254 - val_accuracy: 0.7345\n",
      "Epoch 452/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3167 - accuracy: 0.8740 - val_loss: 0.6343 - val_accuracy: 0.7476\n",
      "Epoch 453/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3032 - accuracy: 0.8782 - val_loss: 0.5965 - val_accuracy: 0.7429\n",
      "Epoch 454/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3011 - accuracy: 0.8808 - val_loss: 0.7013 - val_accuracy: 0.7155\n",
      "Epoch 455/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3226 - accuracy: 0.8728 - val_loss: 0.5453 - val_accuracy: 0.7679\n",
      "Epoch 456/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3012 - accuracy: 0.8756 - val_loss: 0.6622 - val_accuracy: 0.7310\n",
      "Epoch 457/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3290 - accuracy: 0.8687 - val_loss: 0.7105 - val_accuracy: 0.7321\n",
      "Epoch 458/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3245 - accuracy: 0.8701 - val_loss: 0.5713 - val_accuracy: 0.7512\n",
      "Epoch 459/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3243 - accuracy: 0.8694 - val_loss: 0.6240 - val_accuracy: 0.7298\n",
      "Epoch 460/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3204 - accuracy: 0.8731 - val_loss: 0.6019 - val_accuracy: 0.7595\n",
      "Epoch 461/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3057 - accuracy: 0.8803 - val_loss: 0.5632 - val_accuracy: 0.7607\n",
      "Epoch 462/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3065 - accuracy: 0.8801 - val_loss: 0.5876 - val_accuracy: 0.7524\n",
      "Epoch 463/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2875 - accuracy: 0.8854 - val_loss: 0.5697 - val_accuracy: 0.7655\n",
      "Epoch 464/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3047 - accuracy: 0.8799 - val_loss: 0.5494 - val_accuracy: 0.7714\n",
      "Epoch 465/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2908 - accuracy: 0.8871 - val_loss: 0.6399 - val_accuracy: 0.7333\n",
      "Epoch 466/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2819 - accuracy: 0.8894 - val_loss: 0.6716 - val_accuracy: 0.7202\n",
      "Epoch 467/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3130 - accuracy: 0.8743 - val_loss: 0.5822 - val_accuracy: 0.7571\n",
      "Epoch 468/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3733 - accuracy: 0.8578 - val_loss: 0.5617 - val_accuracy: 0.7798\n",
      "Epoch 469/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2947 - accuracy: 0.8856 - val_loss: 0.7263 - val_accuracy: 0.6893\n",
      "Epoch 470/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3277 - accuracy: 0.8700 - val_loss: 0.5787 - val_accuracy: 0.7476\n",
      "Epoch 471/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2927 - accuracy: 0.8842 - val_loss: 0.6123 - val_accuracy: 0.7560\n",
      "Epoch 472/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2876 - accuracy: 0.8861 - val_loss: 0.5790 - val_accuracy: 0.7548\n",
      "Epoch 473/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2864 - accuracy: 0.8846 - val_loss: 0.6161 - val_accuracy: 0.7452\n",
      "Epoch 474/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2835 - accuracy: 0.8878 - val_loss: 0.5988 - val_accuracy: 0.7655\n",
      "Epoch 475/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3116 - accuracy: 0.8790 - val_loss: 0.5988 - val_accuracy: 0.7464\n",
      "Epoch 476/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3184 - accuracy: 0.8789 - val_loss: 0.5537 - val_accuracy: 0.7821\n",
      "Epoch 477/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2880 - accuracy: 0.8891 - val_loss: 0.5855 - val_accuracy: 0.7619\n",
      "Epoch 478/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2963 - accuracy: 0.8848 - val_loss: 0.5579 - val_accuracy: 0.7869\n",
      "Epoch 479/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2861 - accuracy: 0.8898 - val_loss: 0.6533 - val_accuracy: 0.7345\n",
      "Epoch 480/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3083 - accuracy: 0.8799 - val_loss: 0.6078 - val_accuracy: 0.7417\n",
      "Epoch 481/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2914 - accuracy: 0.8827 - val_loss: 0.6537 - val_accuracy: 0.7488\n",
      "Epoch 482/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2853 - accuracy: 0.8876 - val_loss: 0.6242 - val_accuracy: 0.7429\n",
      "Epoch 483/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2932 - accuracy: 0.8892 - val_loss: 0.5814 - val_accuracy: 0.7726\n",
      "Epoch 484/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2773 - accuracy: 0.8917 - val_loss: 0.6422 - val_accuracy: 0.7333\n",
      "Epoch 485/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2673 - accuracy: 0.8919 - val_loss: 0.5830 - val_accuracy: 0.7560\n",
      "Epoch 486/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2856 - accuracy: 0.8924 - val_loss: 0.6871 - val_accuracy: 0.7155\n",
      "Epoch 487/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2905 - accuracy: 0.8816 - val_loss: 0.6048 - val_accuracy: 0.7548\n",
      "Epoch 488/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3015 - accuracy: 0.8797 - val_loss: 0.6543 - val_accuracy: 0.7214\n",
      "Epoch 489/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2943 - accuracy: 0.8828 - val_loss: 0.5339 - val_accuracy: 0.7845\n",
      "Epoch 490/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2979 - accuracy: 0.8827 - val_loss: 0.5886 - val_accuracy: 0.7298\n",
      "Epoch 491/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2793 - accuracy: 0.8862 - val_loss: 0.6191 - val_accuracy: 0.7357\n",
      "Epoch 492/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2914 - accuracy: 0.8800 - val_loss: 0.5871 - val_accuracy: 0.7607\n",
      "Epoch 493/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3119 - accuracy: 0.8826 - val_loss: 0.6347 - val_accuracy: 0.7488\n",
      "Epoch 494/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2971 - accuracy: 0.8847 - val_loss: 0.7027 - val_accuracy: 0.7119\n",
      "Epoch 495/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2721 - accuracy: 0.8925 - val_loss: 0.6222 - val_accuracy: 0.7476\n",
      "Epoch 496/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2949 - accuracy: 0.8878 - val_loss: 0.6516 - val_accuracy: 0.7417\n",
      "Epoch 497/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3064 - accuracy: 0.8825 - val_loss: 0.6059 - val_accuracy: 0.7595\n",
      "Epoch 498/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2713 - accuracy: 0.8912 - val_loss: 0.5956 - val_accuracy: 0.7631\n",
      "Epoch 499/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2687 - accuracy: 0.8951 - val_loss: 0.5810 - val_accuracy: 0.7762\n",
      "Epoch 500/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2924 - accuracy: 0.8861 - val_loss: 0.6001 - val_accuracy: 0.7738\n",
      "Epoch 501/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2806 - accuracy: 0.8907 - val_loss: 0.5693 - val_accuracy: 0.7679\n",
      "Epoch 502/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2923 - accuracy: 0.8859 - val_loss: 0.6663 - val_accuracy: 0.7202\n",
      "Epoch 503/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2938 - accuracy: 0.8864 - val_loss: 0.6201 - val_accuracy: 0.7643\n",
      "Epoch 504/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2982 - accuracy: 0.8848 - val_loss: 0.6322 - val_accuracy: 0.7536\n",
      "Epoch 505/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2905 - accuracy: 0.8845 - val_loss: 0.6064 - val_accuracy: 0.7524\n",
      "Epoch 506/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2774 - accuracy: 0.8909 - val_loss: 0.6541 - val_accuracy: 0.7607\n",
      "Epoch 507/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2672 - accuracy: 0.8960 - val_loss: 0.7346 - val_accuracy: 0.6976\n",
      "Epoch 508/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3013 - accuracy: 0.8812 - val_loss: 0.5565 - val_accuracy: 0.7833\n",
      "Epoch 509/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2756 - accuracy: 0.8934 - val_loss: 0.6128 - val_accuracy: 0.7464\n",
      "Epoch 510/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2655 - accuracy: 0.8954 - val_loss: 0.5693 - val_accuracy: 0.7679\n",
      "Epoch 511/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2502 - accuracy: 0.9044 - val_loss: 0.6180 - val_accuracy: 0.7762\n",
      "Epoch 512/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2820 - accuracy: 0.8940 - val_loss: 0.5933 - val_accuracy: 0.7476\n",
      "Epoch 513/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2824 - accuracy: 0.8897 - val_loss: 0.5429 - val_accuracy: 0.7595\n",
      "Epoch 514/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2804 - accuracy: 0.8907 - val_loss: 0.6221 - val_accuracy: 0.7571\n",
      "Epoch 515/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2587 - accuracy: 0.9010 - val_loss: 0.5729 - val_accuracy: 0.7702\n",
      "Epoch 516/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2775 - accuracy: 0.8904 - val_loss: 0.6232 - val_accuracy: 0.7595\n",
      "Epoch 517/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2699 - accuracy: 0.8944 - val_loss: 0.5829 - val_accuracy: 0.7571\n",
      "Epoch 518/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2402 - accuracy: 0.9026 - val_loss: 0.6500 - val_accuracy: 0.7321\n",
      "Epoch 519/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2655 - accuracy: 0.8978 - val_loss: 0.5398 - val_accuracy: 0.7798\n",
      "Epoch 520/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2597 - accuracy: 0.9004 - val_loss: 0.5960 - val_accuracy: 0.7405\n",
      "Epoch 521/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2559 - accuracy: 0.9011 - val_loss: 0.7557 - val_accuracy: 0.7095\n",
      "Epoch 522/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2964 - accuracy: 0.8918 - val_loss: 0.7718 - val_accuracy: 0.6929\n",
      "Epoch 523/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2624 - accuracy: 0.8974 - val_loss: 0.6300 - val_accuracy: 0.7714\n",
      "Epoch 524/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2725 - accuracy: 0.8913 - val_loss: 0.5342 - val_accuracy: 0.7774\n",
      "Epoch 525/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2454 - accuracy: 0.9029 - val_loss: 0.7914 - val_accuracy: 0.7321\n",
      "Epoch 526/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2652 - accuracy: 0.8965 - val_loss: 0.7800 - val_accuracy: 0.7405\n",
      "Epoch 527/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2597 - accuracy: 0.8990 - val_loss: 0.6836 - val_accuracy: 0.7583\n",
      "Epoch 528/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2659 - accuracy: 0.8939 - val_loss: 0.6169 - val_accuracy: 0.7310\n",
      "Epoch 529/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2591 - accuracy: 0.8996 - val_loss: 0.6016 - val_accuracy: 0.7440\n",
      "Epoch 530/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2650 - accuracy: 0.8988 - val_loss: 0.6295 - val_accuracy: 0.7750\n",
      "Epoch 531/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2576 - accuracy: 0.9010 - val_loss: 0.6000 - val_accuracy: 0.7369\n",
      "Epoch 532/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2607 - accuracy: 0.8940 - val_loss: 0.6170 - val_accuracy: 0.7595\n",
      "Epoch 533/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2579 - accuracy: 0.8953 - val_loss: 0.6778 - val_accuracy: 0.7155\n",
      "Epoch 534/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2738 - accuracy: 0.8934 - val_loss: 0.5818 - val_accuracy: 0.7560\n",
      "Epoch 535/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2596 - accuracy: 0.8970 - val_loss: 0.6809 - val_accuracy: 0.7452\n",
      "Epoch 536/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2564 - accuracy: 0.8954 - val_loss: 0.6640 - val_accuracy: 0.7548\n",
      "Epoch 537/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2673 - accuracy: 0.8983 - val_loss: 0.5760 - val_accuracy: 0.7405\n",
      "Epoch 538/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2541 - accuracy: 0.9011 - val_loss: 0.6493 - val_accuracy: 0.7357\n",
      "Epoch 539/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4757 - accuracy: 0.8400 - val_loss: 0.7098 - val_accuracy: 0.7167\n",
      "Epoch 540/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3703 - accuracy: 0.8505 - val_loss: 0.6922 - val_accuracy: 0.7167\n",
      "Epoch 541/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3449 - accuracy: 0.8580 - val_loss: 0.7044 - val_accuracy: 0.7214\n",
      "Epoch 542/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3191 - accuracy: 0.8699 - val_loss: 0.5782 - val_accuracy: 0.7738\n",
      "Epoch 543/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2962 - accuracy: 0.8866 - val_loss: 0.5981 - val_accuracy: 0.7548\n",
      "Epoch 544/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2879 - accuracy: 0.8876 - val_loss: 0.7065 - val_accuracy: 0.7012\n",
      "Epoch 545/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3205 - accuracy: 0.8740 - val_loss: 0.5985 - val_accuracy: 0.7464\n",
      "Epoch 546/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2868 - accuracy: 0.8848 - val_loss: 0.6213 - val_accuracy: 0.7571\n",
      "Epoch 547/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2914 - accuracy: 0.8838 - val_loss: 0.6346 - val_accuracy: 0.7548\n",
      "Epoch 548/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2995 - accuracy: 0.8811 - val_loss: 0.6697 - val_accuracy: 0.7226\n",
      "Epoch 549/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3346 - accuracy: 0.8694 - val_loss: 0.6700 - val_accuracy: 0.7357\n",
      "Epoch 550/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2569 - accuracy: 0.8998 - val_loss: 0.8687 - val_accuracy: 0.6607\n",
      "Epoch 551/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2848 - accuracy: 0.8861 - val_loss: 0.7401 - val_accuracy: 0.7333\n",
      "Epoch 552/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2804 - accuracy: 0.8878 - val_loss: 0.7183 - val_accuracy: 0.7440\n",
      "Epoch 553/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2904 - accuracy: 0.8823 - val_loss: 0.7068 - val_accuracy: 0.7393\n",
      "Epoch 554/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2774 - accuracy: 0.8896 - val_loss: 0.6484 - val_accuracy: 0.7464\n",
      "Epoch 555/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2956 - accuracy: 0.8862 - val_loss: 0.6366 - val_accuracy: 0.7500\n",
      "Epoch 556/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2587 - accuracy: 0.9009 - val_loss: 0.6907 - val_accuracy: 0.7571\n",
      "Epoch 557/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2610 - accuracy: 0.8971 - val_loss: 0.6274 - val_accuracy: 0.7690\n",
      "Epoch 558/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2817 - accuracy: 0.8883 - val_loss: 0.6182 - val_accuracy: 0.7429\n",
      "Epoch 559/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2540 - accuracy: 0.8998 - val_loss: 0.7118 - val_accuracy: 0.7321\n",
      "Epoch 560/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2630 - accuracy: 0.8923 - val_loss: 0.6621 - val_accuracy: 0.7571\n",
      "Epoch 561/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2766 - accuracy: 0.8910 - val_loss: 0.6740 - val_accuracy: 0.7524\n",
      "Epoch 562/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2774 - accuracy: 0.8943 - val_loss: 0.7510 - val_accuracy: 0.7048\n",
      "Epoch 563/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2722 - accuracy: 0.8950 - val_loss: 0.6445 - val_accuracy: 0.7607\n",
      "Epoch 564/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2628 - accuracy: 0.9007 - val_loss: 0.7566 - val_accuracy: 0.7202\n",
      "Epoch 565/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2782 - accuracy: 0.8925 - val_loss: 0.6216 - val_accuracy: 0.7607\n",
      "Epoch 566/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2598 - accuracy: 0.8942 - val_loss: 0.6683 - val_accuracy: 0.7643\n",
      "Epoch 567/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2733 - accuracy: 0.8925 - val_loss: 0.7862 - val_accuracy: 0.7071\n",
      "Epoch 568/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3015 - accuracy: 0.8805 - val_loss: 0.6774 - val_accuracy: 0.7310\n",
      "Epoch 569/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2651 - accuracy: 0.8969 - val_loss: 0.5832 - val_accuracy: 0.7857\n",
      "Epoch 570/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2515 - accuracy: 0.9029 - val_loss: 0.6761 - val_accuracy: 0.7381\n",
      "Epoch 571/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2492 - accuracy: 0.9030 - val_loss: 0.5969 - val_accuracy: 0.7571\n",
      "Epoch 572/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2715 - accuracy: 0.8966 - val_loss: 0.6800 - val_accuracy: 0.7286\n",
      "Epoch 573/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2732 - accuracy: 0.8933 - val_loss: 0.6418 - val_accuracy: 0.7536\n",
      "Epoch 574/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2815 - accuracy: 0.8937 - val_loss: 0.9756 - val_accuracy: 0.6369\n",
      "Epoch 575/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2770 - accuracy: 0.8908 - val_loss: 0.6054 - val_accuracy: 0.7643\n",
      "Epoch 576/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3230 - accuracy: 0.8841 - val_loss: 0.7034 - val_accuracy: 0.7357\n",
      "Epoch 577/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3452 - accuracy: 0.8771 - val_loss: 0.7363 - val_accuracy: 0.6786\n",
      "Epoch 578/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3920 - accuracy: 0.8252 - val_loss: 0.7168 - val_accuracy: 0.7262\n",
      "Epoch 579/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3020 - accuracy: 0.8718 - val_loss: 0.7281 - val_accuracy: 0.7357\n",
      "Epoch 580/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2965 - accuracy: 0.8867 - val_loss: 0.5926 - val_accuracy: 0.7679\n",
      "Epoch 581/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2519 - accuracy: 0.8978 - val_loss: 0.5919 - val_accuracy: 0.7548\n",
      "Epoch 582/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2335 - accuracy: 0.9088 - val_loss: 0.6502 - val_accuracy: 0.7560\n",
      "Epoch 583/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2419 - accuracy: 0.9083 - val_loss: 0.6027 - val_accuracy: 0.7571\n",
      "Epoch 584/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2709 - accuracy: 0.8917 - val_loss: 0.6489 - val_accuracy: 0.7548\n",
      "Epoch 585/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2331 - accuracy: 0.9066 - val_loss: 0.6385 - val_accuracy: 0.7571\n",
      "Epoch 586/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2490 - accuracy: 0.9017 - val_loss: 0.6756 - val_accuracy: 0.7190\n",
      "Epoch 587/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2607 - accuracy: 0.9004 - val_loss: 0.7030 - val_accuracy: 0.7155\n",
      "Epoch 588/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2438 - accuracy: 0.9063 - val_loss: 0.6282 - val_accuracy: 0.7786\n",
      "Epoch 589/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2464 - accuracy: 0.9060 - val_loss: 0.7309 - val_accuracy: 0.7417\n",
      "Epoch 590/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2522 - accuracy: 0.9029 - val_loss: 0.5756 - val_accuracy: 0.7917\n",
      "Epoch 591/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2584 - accuracy: 0.9007 - val_loss: 0.6043 - val_accuracy: 0.7500\n",
      "Epoch 592/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2191 - accuracy: 0.9172 - val_loss: 0.6654 - val_accuracy: 0.7452\n",
      "Epoch 593/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2374 - accuracy: 0.9085 - val_loss: 0.6027 - val_accuracy: 0.7667\n",
      "Epoch 594/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2551 - accuracy: 0.9009 - val_loss: 0.6996 - val_accuracy: 0.7286\n",
      "Epoch 595/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2717 - accuracy: 0.8942 - val_loss: 0.6877 - val_accuracy: 0.6988\n",
      "Epoch 596/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2425 - accuracy: 0.9063 - val_loss: 0.6365 - val_accuracy: 0.7357\n",
      "Epoch 597/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2122 - accuracy: 0.9177 - val_loss: 0.5640 - val_accuracy: 0.7690\n",
      "Epoch 598/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2348 - accuracy: 0.9088 - val_loss: 0.6506 - val_accuracy: 0.7512\n",
      "Epoch 599/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2602 - accuracy: 0.8988 - val_loss: 0.6107 - val_accuracy: 0.7488\n",
      "Epoch 600/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2313 - accuracy: 0.9046 - val_loss: 0.6482 - val_accuracy: 0.7488\n",
      "Epoch 1/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0992 - accuracy: 0.3367 - val_loss: 1.0987 - val_accuracy: 0.3405\n",
      "Epoch 2/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0987 - accuracy: 0.3338 - val_loss: 1.0985 - val_accuracy: 0.3631\n",
      "Epoch 3/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0985 - accuracy: 0.3438 - val_loss: 1.0984 - val_accuracy: 0.3440\n",
      "Epoch 4/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0976 - accuracy: 0.3524 - val_loss: 1.0978 - val_accuracy: 0.3393\n",
      "Epoch 5/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0973 - accuracy: 0.3652 - val_loss: 1.0973 - val_accuracy: 0.3345\n",
      "Epoch 6/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0964 - accuracy: 0.3748 - val_loss: 1.0970 - val_accuracy: 0.3298\n",
      "Epoch 7/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0949 - accuracy: 0.3807 - val_loss: 1.0960 - val_accuracy: 0.3298\n",
      "Epoch 8/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0939 - accuracy: 0.3789 - val_loss: 1.0939 - val_accuracy: 0.3393\n",
      "Epoch 9/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0926 - accuracy: 0.3854 - val_loss: 1.0934 - val_accuracy: 0.3655\n",
      "Epoch 10/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0921 - accuracy: 0.3848 - val_loss: 1.0917 - val_accuracy: 0.3500\n",
      "Epoch 11/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0923 - accuracy: 0.3748 - val_loss: 1.0907 - val_accuracy: 0.3810\n",
      "Epoch 12/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0927 - accuracy: 0.3697 - val_loss: 1.0910 - val_accuracy: 0.3298\n",
      "Epoch 13/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0906 - accuracy: 0.3918 - val_loss: 1.0912 - val_accuracy: 0.3321\n",
      "Epoch 14/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0902 - accuracy: 0.3907 - val_loss: 1.0856 - val_accuracy: 0.3821\n",
      "Epoch 15/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0877 - accuracy: 0.3896 - val_loss: 1.0858 - val_accuracy: 0.3881\n",
      "Epoch 16/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0877 - accuracy: 0.3807 - val_loss: 1.0895 - val_accuracy: 0.3738\n",
      "Epoch 17/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0844 - accuracy: 0.3859 - val_loss: 1.0801 - val_accuracy: 0.3869\n",
      "Epoch 18/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0834 - accuracy: 0.3888 - val_loss: 1.0873 - val_accuracy: 0.3750\n",
      "Epoch 19/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0785 - accuracy: 0.3956 - val_loss: 1.0738 - val_accuracy: 0.4060\n",
      "Epoch 20/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0809 - accuracy: 0.3851 - val_loss: 1.0778 - val_accuracy: 0.3964\n",
      "Epoch 21/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0725 - accuracy: 0.4049 - val_loss: 1.0814 - val_accuracy: 0.3988\n",
      "Epoch 22/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0731 - accuracy: 0.3907 - val_loss: 1.0548 - val_accuracy: 0.4357\n",
      "Epoch 23/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0668 - accuracy: 0.4080 - val_loss: 1.0613 - val_accuracy: 0.4083\n",
      "Epoch 24/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0647 - accuracy: 0.4096 - val_loss: 1.0546 - val_accuracy: 0.4440\n",
      "Epoch 25/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0663 - accuracy: 0.4060 - val_loss: 1.0841 - val_accuracy: 0.4060\n",
      "Epoch 26/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0613 - accuracy: 0.4083 - val_loss: 1.0579 - val_accuracy: 0.4262\n",
      "Epoch 27/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0591 - accuracy: 0.4108 - val_loss: 1.0732 - val_accuracy: 0.3905\n",
      "Epoch 28/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0564 - accuracy: 0.4189 - val_loss: 1.0690 - val_accuracy: 0.4179\n",
      "Epoch 29/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0580 - accuracy: 0.4148 - val_loss: 1.0495 - val_accuracy: 0.4155\n",
      "Epoch 30/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0550 - accuracy: 0.4187 - val_loss: 1.0491 - val_accuracy: 0.4321\n",
      "Epoch 31/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0529 - accuracy: 0.4203 - val_loss: 1.0402 - val_accuracy: 0.4524\n",
      "Epoch 32/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0536 - accuracy: 0.4103 - val_loss: 1.0781 - val_accuracy: 0.4179\n",
      "Epoch 33/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0448 - accuracy: 0.4277 - val_loss: 1.0249 - val_accuracy: 0.4619\n",
      "Epoch 34/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0527 - accuracy: 0.4141 - val_loss: 1.0398 - val_accuracy: 0.4583\n",
      "Epoch 35/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0482 - accuracy: 0.4204 - val_loss: 1.0634 - val_accuracy: 0.4238\n",
      "Epoch 36/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0503 - accuracy: 0.4226 - val_loss: 1.0400 - val_accuracy: 0.4429\n",
      "Epoch 37/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0435 - accuracy: 0.4203 - val_loss: 1.0330 - val_accuracy: 0.4298\n",
      "Epoch 38/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0450 - accuracy: 0.4249 - val_loss: 1.0488 - val_accuracy: 0.4298\n",
      "Epoch 39/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0434 - accuracy: 0.4239 - val_loss: 1.0347 - val_accuracy: 0.4607\n",
      "Epoch 40/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0358 - accuracy: 0.4297 - val_loss: 1.0440 - val_accuracy: 0.4369\n",
      "Epoch 41/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0404 - accuracy: 0.4230 - val_loss: 1.0322 - val_accuracy: 0.4488\n",
      "Epoch 42/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0384 - accuracy: 0.4285 - val_loss: 1.0429 - val_accuracy: 0.4488\n",
      "Epoch 43/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0378 - accuracy: 0.4271 - val_loss: 1.0498 - val_accuracy: 0.4143\n",
      "Epoch 44/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0361 - accuracy: 0.4310 - val_loss: 1.0403 - val_accuracy: 0.4250\n",
      "Epoch 45/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0303 - accuracy: 0.4322 - val_loss: 1.0812 - val_accuracy: 0.3774\n",
      "Epoch 46/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0295 - accuracy: 0.4327 - val_loss: 1.0439 - val_accuracy: 0.4274\n",
      "Epoch 47/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0334 - accuracy: 0.4266 - val_loss: 1.0432 - val_accuracy: 0.4155\n",
      "Epoch 48/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0332 - accuracy: 0.4292 - val_loss: 1.0361 - val_accuracy: 0.4226\n",
      "Epoch 49/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0188 - accuracy: 0.4369 - val_loss: 1.0526 - val_accuracy: 0.4155\n",
      "Epoch 50/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0163 - accuracy: 0.4445 - val_loss: 1.0442 - val_accuracy: 0.4131\n",
      "Epoch 51/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0219 - accuracy: 0.4341 - val_loss: 1.0190 - val_accuracy: 0.4583\n",
      "Epoch 52/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0183 - accuracy: 0.4383 - val_loss: 1.0269 - val_accuracy: 0.4548\n",
      "Epoch 53/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0193 - accuracy: 0.4437 - val_loss: 1.0182 - val_accuracy: 0.4345\n",
      "Epoch 54/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0233 - accuracy: 0.4338 - val_loss: 1.0447 - val_accuracy: 0.3905\n",
      "Epoch 55/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0183 - accuracy: 0.4376 - val_loss: 1.0360 - val_accuracy: 0.4036\n",
      "Epoch 56/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0246 - accuracy: 0.4335 - val_loss: 1.0546 - val_accuracy: 0.4131\n",
      "Epoch 57/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0151 - accuracy: 0.4367 - val_loss: 1.0517 - val_accuracy: 0.4024\n",
      "Epoch 58/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0127 - accuracy: 0.4435 - val_loss: 1.0714 - val_accuracy: 0.3595\n",
      "Epoch 59/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0107 - accuracy: 0.4368 - val_loss: 1.0205 - val_accuracy: 0.4321\n",
      "Epoch 60/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0061 - accuracy: 0.4455 - val_loss: 1.0431 - val_accuracy: 0.3917\n",
      "Epoch 61/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0033 - accuracy: 0.4454 - val_loss: 1.0255 - val_accuracy: 0.4238\n",
      "Epoch 62/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0029 - accuracy: 0.4392 - val_loss: 1.0408 - val_accuracy: 0.3964\n",
      "Epoch 63/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0120 - accuracy: 0.4468 - val_loss: 1.0341 - val_accuracy: 0.4369\n",
      "Epoch 64/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9939 - accuracy: 0.4587 - val_loss: 1.0008 - val_accuracy: 0.4476\n",
      "Epoch 65/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9997 - accuracy: 0.4525 - val_loss: 1.0075 - val_accuracy: 0.4357\n",
      "Epoch 66/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0061 - accuracy: 0.4519 - val_loss: 1.0130 - val_accuracy: 0.4393\n",
      "Epoch 67/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0022 - accuracy: 0.4570 - val_loss: 0.9829 - val_accuracy: 0.4869\n",
      "Epoch 68/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9924 - accuracy: 0.4624 - val_loss: 1.0069 - val_accuracy: 0.4131\n",
      "Epoch 69/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9940 - accuracy: 0.4637 - val_loss: 0.9927 - val_accuracy: 0.4250\n",
      "Epoch 70/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9949 - accuracy: 0.4519 - val_loss: 1.0035 - val_accuracy: 0.4310\n",
      "Epoch 71/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9876 - accuracy: 0.4592 - val_loss: 1.0097 - val_accuracy: 0.4440\n",
      "Epoch 72/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9931 - accuracy: 0.4604 - val_loss: 1.0422 - val_accuracy: 0.4095\n",
      "Epoch 73/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9874 - accuracy: 0.4660 - val_loss: 0.9912 - val_accuracy: 0.4429\n",
      "Epoch 74/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9826 - accuracy: 0.4578 - val_loss: 0.9747 - val_accuracy: 0.4476\n",
      "Epoch 75/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9844 - accuracy: 0.4592 - val_loss: 1.0298 - val_accuracy: 0.4357\n",
      "Epoch 76/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9919 - accuracy: 0.4614 - val_loss: 1.0063 - val_accuracy: 0.4274\n",
      "Epoch 77/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9836 - accuracy: 0.4662 - val_loss: 0.9889 - val_accuracy: 0.4667\n",
      "Epoch 78/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9737 - accuracy: 0.4784 - val_loss: 1.0178 - val_accuracy: 0.4702\n",
      "Epoch 79/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9708 - accuracy: 0.4777 - val_loss: 1.0069 - val_accuracy: 0.4274\n",
      "Epoch 80/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9769 - accuracy: 0.4710 - val_loss: 0.9988 - val_accuracy: 0.4726\n",
      "Epoch 81/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9855 - accuracy: 0.4728 - val_loss: 0.9848 - val_accuracy: 0.4774\n",
      "Epoch 82/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9790 - accuracy: 0.4731 - val_loss: 0.9763 - val_accuracy: 0.4857\n",
      "Epoch 83/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9791 - accuracy: 0.4841 - val_loss: 0.9893 - val_accuracy: 0.4643\n",
      "Epoch 84/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9661 - accuracy: 0.4896 - val_loss: 1.0294 - val_accuracy: 0.4452\n",
      "Epoch 85/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9676 - accuracy: 0.4853 - val_loss: 1.0208 - val_accuracy: 0.4679\n",
      "Epoch 86/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9589 - accuracy: 0.5016 - val_loss: 0.9563 - val_accuracy: 0.5155\n",
      "Epoch 87/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9529 - accuracy: 0.5044 - val_loss: 0.9649 - val_accuracy: 0.5107\n",
      "Epoch 88/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9588 - accuracy: 0.5080 - val_loss: 0.9500 - val_accuracy: 0.4964\n",
      "Epoch 89/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9635 - accuracy: 0.5024 - val_loss: 0.9625 - val_accuracy: 0.4964\n",
      "Epoch 90/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9460 - accuracy: 0.5137 - val_loss: 0.9378 - val_accuracy: 0.5274\n",
      "Epoch 91/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9425 - accuracy: 0.5129 - val_loss: 0.9463 - val_accuracy: 0.5083\n",
      "Epoch 92/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9474 - accuracy: 0.5152 - val_loss: 0.9428 - val_accuracy: 0.5298\n",
      "Epoch 93/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9451 - accuracy: 0.5139 - val_loss: 0.9693 - val_accuracy: 0.5048\n",
      "Epoch 94/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9347 - accuracy: 0.5250 - val_loss: 0.9310 - val_accuracy: 0.5321\n",
      "Epoch 95/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9346 - accuracy: 0.5173 - val_loss: 1.0049 - val_accuracy: 0.4262\n",
      "Epoch 96/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9410 - accuracy: 0.5203 - val_loss: 0.9370 - val_accuracy: 0.5250\n",
      "Epoch 97/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9367 - accuracy: 0.5236 - val_loss: 0.9533 - val_accuracy: 0.5095\n",
      "Epoch 98/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9250 - accuracy: 0.5294 - val_loss: 0.9202 - val_accuracy: 0.5262\n",
      "Epoch 99/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9276 - accuracy: 0.5235 - val_loss: 0.9428 - val_accuracy: 0.5298\n",
      "Epoch 100/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9341 - accuracy: 0.5187 - val_loss: 0.9335 - val_accuracy: 0.5357\n",
      "Epoch 101/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9287 - accuracy: 0.5261 - val_loss: 0.9533 - val_accuracy: 0.4940\n",
      "Epoch 102/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9317 - accuracy: 0.5289 - val_loss: 0.9586 - val_accuracy: 0.5214\n",
      "Epoch 103/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9479 - accuracy: 0.5179 - val_loss: 0.9397 - val_accuracy: 0.5393\n",
      "Epoch 104/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9470 - accuracy: 0.5210 - val_loss: 0.9399 - val_accuracy: 0.5060\n",
      "Epoch 105/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9340 - accuracy: 0.5276 - val_loss: 0.9530 - val_accuracy: 0.5190\n",
      "Epoch 106/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9268 - accuracy: 0.5325 - val_loss: 0.9582 - val_accuracy: 0.4976\n",
      "Epoch 107/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9192 - accuracy: 0.5403 - val_loss: 0.9242 - val_accuracy: 0.5238\n",
      "Epoch 108/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9160 - accuracy: 0.5362 - val_loss: 0.9176 - val_accuracy: 0.5190\n",
      "Epoch 109/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9127 - accuracy: 0.5432 - val_loss: 0.9630 - val_accuracy: 0.4940\n",
      "Epoch 110/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9181 - accuracy: 0.5289 - val_loss: 0.8900 - val_accuracy: 0.5667\n",
      "Epoch 111/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9078 - accuracy: 0.5333 - val_loss: 0.8877 - val_accuracy: 0.5333\n",
      "Epoch 112/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9138 - accuracy: 0.5475 - val_loss: 0.8832 - val_accuracy: 0.5702\n",
      "Epoch 113/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9057 - accuracy: 0.5507 - val_loss: 0.9090 - val_accuracy: 0.5714\n",
      "Epoch 114/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9134 - accuracy: 0.5323 - val_loss: 0.9113 - val_accuracy: 0.5583\n",
      "Epoch 115/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9024 - accuracy: 0.5481 - val_loss: 0.9297 - val_accuracy: 0.5310\n",
      "Epoch 116/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9020 - accuracy: 0.5424 - val_loss: 0.9336 - val_accuracy: 0.5250\n",
      "Epoch 117/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8909 - accuracy: 0.5566 - val_loss: 0.9532 - val_accuracy: 0.5500\n",
      "Epoch 118/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8860 - accuracy: 0.5546 - val_loss: 0.9023 - val_accuracy: 0.5393\n",
      "Epoch 119/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9016 - accuracy: 0.5488 - val_loss: 0.9511 - val_accuracy: 0.5167\n",
      "Epoch 120/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8912 - accuracy: 0.5553 - val_loss: 0.8875 - val_accuracy: 0.5810\n",
      "Epoch 121/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8779 - accuracy: 0.5606 - val_loss: 0.9165 - val_accuracy: 0.5702\n",
      "Epoch 122/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8898 - accuracy: 0.5540 - val_loss: 0.8868 - val_accuracy: 0.5619\n",
      "Epoch 123/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8758 - accuracy: 0.5657 - val_loss: 0.9131 - val_accuracy: 0.5560\n",
      "Epoch 124/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8771 - accuracy: 0.5646 - val_loss: 0.8965 - val_accuracy: 0.5571\n",
      "Epoch 125/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8858 - accuracy: 0.5546 - val_loss: 0.8612 - val_accuracy: 0.5786\n",
      "Epoch 126/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8740 - accuracy: 0.5627 - val_loss: 0.9105 - val_accuracy: 0.5452\n",
      "Epoch 127/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8772 - accuracy: 0.5659 - val_loss: 0.8981 - val_accuracy: 0.5524\n",
      "Epoch 128/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8852 - accuracy: 0.5607 - val_loss: 0.9115 - val_accuracy: 0.5488\n",
      "Epoch 129/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8694 - accuracy: 0.5664 - val_loss: 0.9543 - val_accuracy: 0.4917\n",
      "Epoch 130/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9089 - accuracy: 0.5346 - val_loss: 0.9408 - val_accuracy: 0.5071\n",
      "Epoch 131/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9005 - accuracy: 0.5455 - val_loss: 0.8698 - val_accuracy: 0.5690\n",
      "Epoch 132/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8581 - accuracy: 0.5723 - val_loss: 0.9097 - val_accuracy: 0.5321\n",
      "Epoch 133/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8600 - accuracy: 0.5724 - val_loss: 0.8487 - val_accuracy: 0.5940\n",
      "Epoch 134/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8497 - accuracy: 0.5837 - val_loss: 0.8807 - val_accuracy: 0.5417\n",
      "Epoch 135/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8512 - accuracy: 0.5786 - val_loss: 0.8695 - val_accuracy: 0.5905\n",
      "Epoch 136/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8441 - accuracy: 0.5838 - val_loss: 0.8680 - val_accuracy: 0.5726\n",
      "Epoch 137/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8435 - accuracy: 0.5842 - val_loss: 0.9110 - val_accuracy: 0.5143\n",
      "Epoch 138/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8589 - accuracy: 0.5799 - val_loss: 0.8748 - val_accuracy: 0.5857\n",
      "Epoch 139/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8539 - accuracy: 0.5802 - val_loss: 0.9019 - val_accuracy: 0.5631\n",
      "Epoch 140/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8381 - accuracy: 0.5918 - val_loss: 0.8782 - val_accuracy: 0.6071\n",
      "Epoch 141/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8400 - accuracy: 0.5915 - val_loss: 0.8651 - val_accuracy: 0.5833\n",
      "Epoch 142/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8406 - accuracy: 0.5859 - val_loss: 0.9151 - val_accuracy: 0.5667\n",
      "Epoch 143/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8416 - accuracy: 0.5945 - val_loss: 0.8361 - val_accuracy: 0.6131\n",
      "Epoch 144/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8388 - accuracy: 0.5935 - val_loss: 0.9147 - val_accuracy: 0.5690\n",
      "Epoch 145/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8228 - accuracy: 0.5942 - val_loss: 0.8374 - val_accuracy: 0.6131\n",
      "Epoch 146/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8239 - accuracy: 0.6068 - val_loss: 0.8835 - val_accuracy: 0.5940\n",
      "Epoch 147/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8346 - accuracy: 0.5981 - val_loss: 0.9024 - val_accuracy: 0.5583\n",
      "Epoch 148/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8106 - accuracy: 0.6096 - val_loss: 0.8669 - val_accuracy: 0.5869\n",
      "Epoch 149/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8129 - accuracy: 0.6096 - val_loss: 0.8897 - val_accuracy: 0.5774\n",
      "Epoch 150/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8171 - accuracy: 0.6063 - val_loss: 0.9061 - val_accuracy: 0.5714\n",
      "Epoch 151/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8212 - accuracy: 0.6014 - val_loss: 0.9213 - val_accuracy: 0.5536\n",
      "Epoch 152/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8148 - accuracy: 0.6098 - val_loss: 0.9041 - val_accuracy: 0.5667\n",
      "Epoch 153/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8155 - accuracy: 0.6058 - val_loss: 0.8954 - val_accuracy: 0.5619\n",
      "Epoch 154/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8110 - accuracy: 0.6083 - val_loss: 0.8874 - val_accuracy: 0.5702\n",
      "Epoch 155/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8172 - accuracy: 0.6024 - val_loss: 0.8649 - val_accuracy: 0.5595\n",
      "Epoch 156/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7992 - accuracy: 0.6153 - val_loss: 0.9076 - val_accuracy: 0.5488\n",
      "Epoch 157/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7996 - accuracy: 0.6163 - val_loss: 0.9298 - val_accuracy: 0.6107\n",
      "Epoch 158/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8095 - accuracy: 0.6113 - val_loss: 0.8420 - val_accuracy: 0.5702\n",
      "Epoch 159/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7859 - accuracy: 0.6221 - val_loss: 0.8973 - val_accuracy: 0.5774\n",
      "Epoch 160/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8045 - accuracy: 0.6121 - val_loss: 0.8651 - val_accuracy: 0.5905\n",
      "Epoch 161/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7844 - accuracy: 0.6209 - val_loss: 0.8502 - val_accuracy: 0.5905\n",
      "Epoch 162/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8024 - accuracy: 0.6132 - val_loss: 0.8616 - val_accuracy: 0.6083\n",
      "Epoch 163/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7886 - accuracy: 0.6250 - val_loss: 0.8736 - val_accuracy: 0.5917\n",
      "Epoch 164/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8059 - accuracy: 0.6082 - val_loss: 0.8858 - val_accuracy: 0.5714\n",
      "Epoch 165/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8026 - accuracy: 0.6150 - val_loss: 0.8841 - val_accuracy: 0.5738\n",
      "Epoch 166/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8003 - accuracy: 0.6104 - val_loss: 0.8255 - val_accuracy: 0.6214\n",
      "Epoch 167/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7854 - accuracy: 0.6285 - val_loss: 0.8602 - val_accuracy: 0.5905\n",
      "Epoch 168/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7865 - accuracy: 0.6208 - val_loss: 0.9439 - val_accuracy: 0.5560\n",
      "Epoch 169/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7817 - accuracy: 0.6281 - val_loss: 0.9083 - val_accuracy: 0.5762\n",
      "Epoch 170/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7820 - accuracy: 0.6251 - val_loss: 0.8624 - val_accuracy: 0.5952\n",
      "Epoch 171/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7798 - accuracy: 0.6228 - val_loss: 0.9126 - val_accuracy: 0.6048\n",
      "Epoch 172/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7770 - accuracy: 0.6251 - val_loss: 0.8651 - val_accuracy: 0.6107\n",
      "Epoch 173/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7801 - accuracy: 0.6257 - val_loss: 0.9333 - val_accuracy: 0.5702\n",
      "Epoch 174/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7854 - accuracy: 0.6301 - val_loss: 0.8523 - val_accuracy: 0.6357\n",
      "Epoch 175/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7623 - accuracy: 0.6327 - val_loss: 0.9203 - val_accuracy: 0.5631\n",
      "Epoch 176/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7694 - accuracy: 0.6311 - val_loss: 0.8876 - val_accuracy: 0.5964\n",
      "Epoch 177/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7572 - accuracy: 0.6438 - val_loss: 0.9589 - val_accuracy: 0.5952\n",
      "Epoch 178/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7692 - accuracy: 0.6318 - val_loss: 0.9103 - val_accuracy: 0.5536\n",
      "Epoch 179/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7508 - accuracy: 0.6435 - val_loss: 0.9493 - val_accuracy: 0.6107\n",
      "Epoch 180/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7607 - accuracy: 0.6386 - val_loss: 0.8648 - val_accuracy: 0.5786\n",
      "Epoch 181/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7395 - accuracy: 0.6429 - val_loss: 0.8639 - val_accuracy: 0.6083\n",
      "Epoch 182/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7523 - accuracy: 0.6383 - val_loss: 0.8580 - val_accuracy: 0.6036\n",
      "Epoch 183/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7505 - accuracy: 0.6348 - val_loss: 0.8328 - val_accuracy: 0.6250\n",
      "Epoch 184/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7665 - accuracy: 0.6372 - val_loss: 0.8596 - val_accuracy: 0.5905\n",
      "Epoch 185/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7481 - accuracy: 0.6408 - val_loss: 0.8688 - val_accuracy: 0.6095\n",
      "Epoch 186/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7555 - accuracy: 0.6413 - val_loss: 0.8680 - val_accuracy: 0.6357\n",
      "Epoch 187/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7421 - accuracy: 0.6466 - val_loss: 0.9311 - val_accuracy: 0.6024\n",
      "Epoch 188/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7551 - accuracy: 0.6442 - val_loss: 0.9109 - val_accuracy: 0.5881\n",
      "Epoch 189/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7280 - accuracy: 0.6527 - val_loss: 0.9092 - val_accuracy: 0.5929\n",
      "Epoch 190/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7363 - accuracy: 0.6537 - val_loss: 0.9643 - val_accuracy: 0.5643\n",
      "Epoch 191/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7325 - accuracy: 0.6614 - val_loss: 1.0295 - val_accuracy: 0.5405\n",
      "Epoch 192/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7277 - accuracy: 0.6648 - val_loss: 0.9871 - val_accuracy: 0.5905\n",
      "Epoch 193/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7540 - accuracy: 0.6484 - val_loss: 0.8910 - val_accuracy: 0.5988\n",
      "Epoch 194/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7354 - accuracy: 0.6509 - val_loss: 0.8237 - val_accuracy: 0.6429\n",
      "Epoch 195/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7676 - accuracy: 0.6272 - val_loss: 1.0350 - val_accuracy: 0.5607\n",
      "Epoch 196/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7711 - accuracy: 0.6294 - val_loss: 0.8602 - val_accuracy: 0.5893\n",
      "Epoch 197/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7615 - accuracy: 0.6285 - val_loss: 1.0768 - val_accuracy: 0.5369\n",
      "Epoch 198/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7301 - accuracy: 0.6459 - val_loss: 1.0804 - val_accuracy: 0.5226\n",
      "Epoch 199/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7322 - accuracy: 0.6514 - val_loss: 0.8674 - val_accuracy: 0.5774\n",
      "Epoch 200/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7242 - accuracy: 0.6619 - val_loss: 0.9011 - val_accuracy: 0.5655\n",
      "Epoch 201/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7415 - accuracy: 0.6465 - val_loss: 0.9687 - val_accuracy: 0.5536\n",
      "Epoch 202/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7303 - accuracy: 0.6587 - val_loss: 0.8051 - val_accuracy: 0.6655\n",
      "Epoch 203/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7296 - accuracy: 0.6601 - val_loss: 0.9816 - val_accuracy: 0.5679\n",
      "Epoch 204/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7203 - accuracy: 0.6713 - val_loss: 1.0856 - val_accuracy: 0.5655\n",
      "Epoch 205/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7050 - accuracy: 0.6736 - val_loss: 0.9285 - val_accuracy: 0.5476\n",
      "Epoch 206/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7125 - accuracy: 0.6757 - val_loss: 0.8573 - val_accuracy: 0.6393\n",
      "Epoch 207/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7177 - accuracy: 0.6658 - val_loss: 0.8059 - val_accuracy: 0.6012\n",
      "Epoch 208/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7051 - accuracy: 0.6789 - val_loss: 0.9476 - val_accuracy: 0.5929\n",
      "Epoch 209/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6874 - accuracy: 0.6848 - val_loss: 0.9330 - val_accuracy: 0.5905\n",
      "Epoch 210/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6922 - accuracy: 0.6872 - val_loss: 0.8054 - val_accuracy: 0.6464\n",
      "Epoch 211/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6889 - accuracy: 0.6886 - val_loss: 0.9167 - val_accuracy: 0.6214\n",
      "Epoch 212/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6761 - accuracy: 0.6874 - val_loss: 1.0528 - val_accuracy: 0.5500\n",
      "Epoch 213/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6932 - accuracy: 0.6861 - val_loss: 0.7975 - val_accuracy: 0.6298\n",
      "Epoch 214/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6926 - accuracy: 0.6823 - val_loss: 0.9792 - val_accuracy: 0.6083\n",
      "Epoch 215/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6868 - accuracy: 0.6877 - val_loss: 0.9168 - val_accuracy: 0.6143\n",
      "Epoch 216/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7039 - accuracy: 0.6800 - val_loss: 0.8839 - val_accuracy: 0.5821\n",
      "Epoch 217/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6761 - accuracy: 0.6892 - val_loss: 0.8834 - val_accuracy: 0.6643\n",
      "Epoch 218/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6903 - accuracy: 0.6915 - val_loss: 0.8891 - val_accuracy: 0.6036\n",
      "Epoch 219/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6903 - accuracy: 0.6832 - val_loss: 0.8894 - val_accuracy: 0.5893\n",
      "Epoch 220/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6758 - accuracy: 0.6896 - val_loss: 0.8721 - val_accuracy: 0.6464\n",
      "Epoch 221/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6788 - accuracy: 0.6940 - val_loss: 0.8221 - val_accuracy: 0.6643\n",
      "Epoch 222/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6797 - accuracy: 0.6920 - val_loss: 0.8452 - val_accuracy: 0.6071\n",
      "Epoch 223/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6686 - accuracy: 0.6994 - val_loss: 0.9642 - val_accuracy: 0.6060\n",
      "Epoch 224/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6537 - accuracy: 0.6968 - val_loss: 0.8810 - val_accuracy: 0.6095\n",
      "Epoch 225/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6769 - accuracy: 0.6948 - val_loss: 0.8010 - val_accuracy: 0.6548\n",
      "Epoch 226/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6568 - accuracy: 0.6975 - val_loss: 0.8291 - val_accuracy: 0.6500\n",
      "Epoch 227/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6650 - accuracy: 0.6939 - val_loss: 1.0187 - val_accuracy: 0.5679\n",
      "Epoch 228/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6661 - accuracy: 0.6925 - val_loss: 0.7898 - val_accuracy: 0.6524\n",
      "Epoch 229/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6508 - accuracy: 0.7011 - val_loss: 0.8224 - val_accuracy: 0.6464\n",
      "Epoch 230/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6630 - accuracy: 0.7022 - val_loss: 0.7579 - val_accuracy: 0.6964\n",
      "Epoch 231/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6918 - accuracy: 0.6820 - val_loss: 0.9431 - val_accuracy: 0.5714\n",
      "Epoch 232/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6593 - accuracy: 0.7037 - val_loss: 1.0107 - val_accuracy: 0.6214\n",
      "Epoch 233/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6606 - accuracy: 0.7034 - val_loss: 0.9621 - val_accuracy: 0.6143\n",
      "Epoch 234/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6467 - accuracy: 0.7076 - val_loss: 0.9802 - val_accuracy: 0.5976\n",
      "Epoch 235/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6582 - accuracy: 0.7067 - val_loss: 0.8464 - val_accuracy: 0.6405\n",
      "Epoch 236/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6277 - accuracy: 0.7154 - val_loss: 0.8404 - val_accuracy: 0.6845\n",
      "Epoch 237/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6565 - accuracy: 0.7040 - val_loss: 0.7691 - val_accuracy: 0.6357\n",
      "Epoch 238/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6412 - accuracy: 0.7182 - val_loss: 0.8830 - val_accuracy: 0.6607\n",
      "Epoch 239/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6471 - accuracy: 0.7113 - val_loss: 0.9671 - val_accuracy: 0.6381\n",
      "Epoch 240/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6425 - accuracy: 0.7091 - val_loss: 0.8434 - val_accuracy: 0.6750\n",
      "Epoch 241/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6422 - accuracy: 0.7122 - val_loss: 0.7874 - val_accuracy: 0.6524\n",
      "Epoch 242/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6260 - accuracy: 0.7235 - val_loss: 0.8102 - val_accuracy: 0.6833\n",
      "Epoch 243/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6162 - accuracy: 0.7311 - val_loss: 0.8696 - val_accuracy: 0.6357\n",
      "Epoch 244/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6186 - accuracy: 0.7224 - val_loss: 0.7656 - val_accuracy: 0.6607\n",
      "Epoch 245/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6356 - accuracy: 0.7229 - val_loss: 0.8270 - val_accuracy: 0.6250\n",
      "Epoch 246/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6307 - accuracy: 0.7236 - val_loss: 0.8308 - val_accuracy: 0.6595\n",
      "Epoch 247/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6106 - accuracy: 0.7328 - val_loss: 0.8959 - val_accuracy: 0.6095\n",
      "Epoch 248/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6126 - accuracy: 0.7255 - val_loss: 0.9145 - val_accuracy: 0.5857\n",
      "Epoch 249/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6236 - accuracy: 0.7249 - val_loss: 0.7672 - val_accuracy: 0.6583\n",
      "Epoch 250/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6115 - accuracy: 0.7231 - val_loss: 0.7757 - val_accuracy: 0.6619\n",
      "Epoch 251/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6101 - accuracy: 0.7307 - val_loss: 0.7841 - val_accuracy: 0.6357\n",
      "Epoch 252/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6172 - accuracy: 0.7256 - val_loss: 1.0960 - val_accuracy: 0.6167\n",
      "Epoch 253/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6250 - accuracy: 0.7216 - val_loss: 0.9525 - val_accuracy: 0.5952\n",
      "Epoch 254/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6032 - accuracy: 0.7316 - val_loss: 0.8253 - val_accuracy: 0.6452\n",
      "Epoch 255/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6215 - accuracy: 0.7280 - val_loss: 0.7641 - val_accuracy: 0.6286\n",
      "Epoch 256/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6110 - accuracy: 0.7255 - val_loss: 0.8021 - val_accuracy: 0.6774\n",
      "Epoch 257/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6166 - accuracy: 0.7240 - val_loss: 0.8651 - val_accuracy: 0.6298\n",
      "Epoch 258/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6018 - accuracy: 0.7287 - val_loss: 0.7613 - val_accuracy: 0.6690\n",
      "Epoch 259/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6126 - accuracy: 0.7296 - val_loss: 0.9875 - val_accuracy: 0.5607\n",
      "Epoch 260/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5912 - accuracy: 0.7438 - val_loss: 0.7785 - val_accuracy: 0.6500\n",
      "Epoch 261/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5962 - accuracy: 0.7363 - val_loss: 0.8981 - val_accuracy: 0.6381\n",
      "Epoch 262/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5982 - accuracy: 0.7442 - val_loss: 0.7315 - val_accuracy: 0.6643\n",
      "Epoch 263/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5886 - accuracy: 0.7350 - val_loss: 0.9081 - val_accuracy: 0.6238\n",
      "Epoch 264/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5874 - accuracy: 0.7381 - val_loss: 0.7553 - val_accuracy: 0.6298\n",
      "Epoch 265/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5893 - accuracy: 0.7364 - val_loss: 0.9216 - val_accuracy: 0.6250\n",
      "Epoch 266/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6079 - accuracy: 0.7330 - val_loss: 1.1330 - val_accuracy: 0.5476\n",
      "Epoch 267/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5928 - accuracy: 0.7425 - val_loss: 0.7889 - val_accuracy: 0.6821\n",
      "Epoch 268/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5912 - accuracy: 0.7373 - val_loss: 0.7883 - val_accuracy: 0.6702\n",
      "Epoch 269/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5719 - accuracy: 0.7476 - val_loss: 0.7272 - val_accuracy: 0.6679\n",
      "Epoch 270/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5690 - accuracy: 0.7479 - val_loss: 0.7633 - val_accuracy: 0.6667\n",
      "Epoch 271/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5697 - accuracy: 0.7496 - val_loss: 0.8795 - val_accuracy: 0.6250\n",
      "Epoch 272/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5852 - accuracy: 0.7425 - val_loss: 0.7932 - val_accuracy: 0.6274\n",
      "Epoch 273/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5645 - accuracy: 0.7536 - val_loss: 0.8120 - val_accuracy: 0.6405\n",
      "Epoch 274/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5680 - accuracy: 0.7480 - val_loss: 0.7299 - val_accuracy: 0.6750\n",
      "Epoch 275/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5790 - accuracy: 0.7453 - val_loss: 0.7411 - val_accuracy: 0.6762\n",
      "Epoch 276/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5609 - accuracy: 0.7567 - val_loss: 0.7553 - val_accuracy: 0.6798\n",
      "Epoch 277/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5563 - accuracy: 0.7542 - val_loss: 0.7304 - val_accuracy: 0.6738\n",
      "Epoch 278/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5537 - accuracy: 0.7549 - val_loss: 1.0960 - val_accuracy: 0.5690\n",
      "Epoch 279/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5542 - accuracy: 0.7607 - val_loss: 0.7220 - val_accuracy: 0.6762\n",
      "Epoch 280/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5500 - accuracy: 0.7573 - val_loss: 0.8491 - val_accuracy: 0.6679\n",
      "Epoch 281/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5950 - accuracy: 0.7378 - val_loss: 0.7957 - val_accuracy: 0.6607\n",
      "Epoch 282/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5334 - accuracy: 0.7720 - val_loss: 0.7682 - val_accuracy: 0.6881\n",
      "Epoch 283/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5696 - accuracy: 0.7502 - val_loss: 0.7965 - val_accuracy: 0.6714\n",
      "Epoch 284/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5438 - accuracy: 0.7575 - val_loss: 0.7301 - val_accuracy: 0.6881\n",
      "Epoch 285/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5457 - accuracy: 0.7553 - val_loss: 0.7328 - val_accuracy: 0.6881\n",
      "Epoch 286/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5525 - accuracy: 0.7669 - val_loss: 0.8400 - val_accuracy: 0.6357\n",
      "Epoch 287/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5606 - accuracy: 0.7509 - val_loss: 0.7560 - val_accuracy: 0.6798\n",
      "Epoch 288/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5567 - accuracy: 0.7558 - val_loss: 0.7439 - val_accuracy: 0.6893\n",
      "Epoch 289/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5550 - accuracy: 0.7606 - val_loss: 0.7766 - val_accuracy: 0.6726\n",
      "Epoch 290/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5352 - accuracy: 0.7644 - val_loss: 0.7605 - val_accuracy: 0.6429\n",
      "Epoch 291/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5407 - accuracy: 0.7672 - val_loss: 0.7916 - val_accuracy: 0.6369\n",
      "Epoch 292/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5400 - accuracy: 0.7622 - val_loss: 0.7801 - val_accuracy: 0.6393\n",
      "Epoch 293/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5520 - accuracy: 0.7634 - val_loss: 0.8209 - val_accuracy: 0.6179\n",
      "Epoch 294/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5581 - accuracy: 0.7539 - val_loss: 0.6638 - val_accuracy: 0.6964\n",
      "Epoch 295/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5386 - accuracy: 0.7655 - val_loss: 0.8218 - val_accuracy: 0.6179\n",
      "Epoch 296/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5311 - accuracy: 0.7642 - val_loss: 0.7506 - val_accuracy: 0.6726\n",
      "Epoch 297/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5366 - accuracy: 0.7688 - val_loss: 0.8397 - val_accuracy: 0.6679\n",
      "Epoch 298/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5256 - accuracy: 0.7678 - val_loss: 0.7242 - val_accuracy: 0.6738\n",
      "Epoch 299/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5120 - accuracy: 0.7789 - val_loss: 0.7443 - val_accuracy: 0.6726\n",
      "Epoch 300/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5317 - accuracy: 0.7653 - val_loss: 0.7795 - val_accuracy: 0.6905\n",
      "Epoch 301/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5094 - accuracy: 0.7765 - val_loss: 0.6903 - val_accuracy: 0.6964\n",
      "Epoch 302/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5036 - accuracy: 0.7821 - val_loss: 0.7513 - val_accuracy: 0.6571\n",
      "Epoch 303/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5340 - accuracy: 0.7662 - val_loss: 0.7563 - val_accuracy: 0.6845\n",
      "Epoch 304/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5270 - accuracy: 0.7718 - val_loss: 0.6947 - val_accuracy: 0.6940\n",
      "Epoch 305/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5302 - accuracy: 0.7683 - val_loss: 0.6911 - val_accuracy: 0.6964\n",
      "Epoch 306/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5229 - accuracy: 0.7755 - val_loss: 0.7777 - val_accuracy: 0.6536\n",
      "Epoch 307/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5112 - accuracy: 0.7733 - val_loss: 0.7479 - val_accuracy: 0.6774\n",
      "Epoch 308/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5140 - accuracy: 0.7748 - val_loss: 0.7881 - val_accuracy: 0.6429\n",
      "Epoch 309/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5195 - accuracy: 0.7724 - val_loss: 0.7923 - val_accuracy: 0.6940\n",
      "Epoch 310/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5085 - accuracy: 0.7786 - val_loss: 0.8467 - val_accuracy: 0.6762\n",
      "Epoch 311/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5010 - accuracy: 0.7887 - val_loss: 0.7094 - val_accuracy: 0.7274\n",
      "Epoch 312/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5137 - accuracy: 0.7772 - val_loss: 0.7378 - val_accuracy: 0.6714\n",
      "Epoch 313/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5250 - accuracy: 0.7667 - val_loss: 0.8272 - val_accuracy: 0.6167\n",
      "Epoch 314/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4877 - accuracy: 0.7881 - val_loss: 0.7177 - val_accuracy: 0.7119\n",
      "Epoch 315/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5055 - accuracy: 0.7838 - val_loss: 0.7664 - val_accuracy: 0.6595\n",
      "Epoch 316/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4873 - accuracy: 0.7878 - val_loss: 0.7288 - val_accuracy: 0.6845\n",
      "Epoch 317/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5036 - accuracy: 0.7879 - val_loss: 0.7077 - val_accuracy: 0.6881\n",
      "Epoch 318/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4948 - accuracy: 0.7881 - val_loss: 0.7950 - val_accuracy: 0.6940\n",
      "Epoch 319/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5020 - accuracy: 0.7800 - val_loss: 0.6514 - val_accuracy: 0.7214\n",
      "Epoch 320/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4964 - accuracy: 0.7797 - val_loss: 0.7773 - val_accuracy: 0.6857\n",
      "Epoch 321/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5222 - accuracy: 0.7779 - val_loss: 0.8537 - val_accuracy: 0.7036\n",
      "Epoch 322/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4980 - accuracy: 0.7864 - val_loss: 0.7600 - val_accuracy: 0.6714\n",
      "Epoch 323/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4819 - accuracy: 0.7923 - val_loss: 0.8075 - val_accuracy: 0.6845\n",
      "Epoch 324/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5058 - accuracy: 0.7816 - val_loss: 0.6907 - val_accuracy: 0.6905\n",
      "Epoch 325/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4753 - accuracy: 0.7954 - val_loss: 0.7032 - val_accuracy: 0.6940\n",
      "Epoch 326/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4605 - accuracy: 0.8011 - val_loss: 0.6820 - val_accuracy: 0.6774\n",
      "Epoch 327/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4789 - accuracy: 0.7918 - val_loss: 0.7760 - val_accuracy: 0.6321\n",
      "Epoch 328/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4777 - accuracy: 0.7864 - val_loss: 0.6866 - val_accuracy: 0.7119\n",
      "Epoch 329/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4847 - accuracy: 0.7935 - val_loss: 0.6772 - val_accuracy: 0.7060\n",
      "Epoch 330/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4714 - accuracy: 0.7932 - val_loss: 0.8571 - val_accuracy: 0.6929\n",
      "Epoch 331/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4797 - accuracy: 0.7981 - val_loss: 0.6609 - val_accuracy: 0.7143\n",
      "Epoch 332/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4698 - accuracy: 0.7951 - val_loss: 0.6648 - val_accuracy: 0.7345\n",
      "Epoch 333/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4880 - accuracy: 0.7879 - val_loss: 0.6520 - val_accuracy: 0.7060\n",
      "Epoch 334/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4604 - accuracy: 0.8030 - val_loss: 0.6935 - val_accuracy: 0.6988\n",
      "Epoch 335/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4537 - accuracy: 0.8029 - val_loss: 0.6733 - val_accuracy: 0.7179\n",
      "Epoch 336/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4685 - accuracy: 0.7970 - val_loss: 0.7952 - val_accuracy: 0.6333\n",
      "Epoch 337/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5108 - accuracy: 0.7832 - val_loss: 0.7337 - val_accuracy: 0.6619\n",
      "Epoch 338/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4807 - accuracy: 0.7937 - val_loss: 0.6758 - val_accuracy: 0.7119\n",
      "Epoch 339/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4529 - accuracy: 0.8093 - val_loss: 0.6071 - val_accuracy: 0.7333\n",
      "Epoch 340/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4406 - accuracy: 0.8087 - val_loss: 0.6356 - val_accuracy: 0.7024\n",
      "Epoch 341/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4581 - accuracy: 0.8041 - val_loss: 0.6466 - val_accuracy: 0.7214\n",
      "Epoch 342/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4647 - accuracy: 0.8000 - val_loss: 0.7510 - val_accuracy: 0.6726\n",
      "Epoch 343/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4787 - accuracy: 0.7937 - val_loss: 0.7088 - val_accuracy: 0.6810\n",
      "Epoch 344/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4550 - accuracy: 0.8024 - val_loss: 0.6623 - val_accuracy: 0.7143\n",
      "Epoch 345/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4460 - accuracy: 0.8052 - val_loss: 0.6938 - val_accuracy: 0.6881\n",
      "Epoch 346/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4636 - accuracy: 0.7998 - val_loss: 0.6709 - val_accuracy: 0.6964\n",
      "Epoch 347/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4567 - accuracy: 0.8032 - val_loss: 0.6527 - val_accuracy: 0.7393\n",
      "Epoch 348/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4456 - accuracy: 0.8100 - val_loss: 0.8804 - val_accuracy: 0.6214\n",
      "Epoch 349/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4356 - accuracy: 0.8204 - val_loss: 0.6657 - val_accuracy: 0.7310\n",
      "Epoch 350/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4641 - accuracy: 0.8070 - val_loss: 0.6968 - val_accuracy: 0.7131\n",
      "Epoch 351/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4544 - accuracy: 0.8072 - val_loss: 0.8054 - val_accuracy: 0.6381\n",
      "Epoch 352/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4373 - accuracy: 0.8107 - val_loss: 0.6256 - val_accuracy: 0.7345\n",
      "Epoch 353/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4553 - accuracy: 0.8030 - val_loss: 0.7590 - val_accuracy: 0.6690\n",
      "Epoch 354/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4254 - accuracy: 0.8138 - val_loss: 0.8485 - val_accuracy: 0.6476\n",
      "Epoch 355/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4507 - accuracy: 0.8097 - val_loss: 0.7238 - val_accuracy: 0.7262\n",
      "Epoch 356/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4578 - accuracy: 0.8098 - val_loss: 0.8099 - val_accuracy: 0.6655\n",
      "Epoch 357/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4559 - accuracy: 0.8055 - val_loss: 0.8824 - val_accuracy: 0.6857\n",
      "Epoch 358/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4195 - accuracy: 0.8198 - val_loss: 0.8795 - val_accuracy: 0.7036\n",
      "Epoch 359/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4559 - accuracy: 0.7975 - val_loss: 0.8523 - val_accuracy: 0.6690\n",
      "Epoch 360/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4372 - accuracy: 0.8138 - val_loss: 0.7800 - val_accuracy: 0.6845\n",
      "Epoch 361/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4417 - accuracy: 0.8113 - val_loss: 0.7465 - val_accuracy: 0.6845\n",
      "Epoch 362/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4319 - accuracy: 0.8134 - val_loss: 0.6742 - val_accuracy: 0.7190\n",
      "Epoch 363/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4167 - accuracy: 0.8226 - val_loss: 0.5943 - val_accuracy: 0.7238\n",
      "Epoch 364/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4436 - accuracy: 0.8088 - val_loss: 0.7026 - val_accuracy: 0.7179\n",
      "Epoch 365/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4309 - accuracy: 0.8155 - val_loss: 0.9028 - val_accuracy: 0.6560\n",
      "Epoch 366/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4333 - accuracy: 0.8158 - val_loss: 0.7092 - val_accuracy: 0.7202\n",
      "Epoch 367/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.4153 - accuracy: 0.8225 - val_loss: 0.6503 - val_accuracy: 0.7119\n",
      "Epoch 368/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4372 - accuracy: 0.8092 - val_loss: 0.6657 - val_accuracy: 0.7381\n",
      "Epoch 369/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4258 - accuracy: 0.8162 - val_loss: 0.7037 - val_accuracy: 0.7488\n",
      "Epoch 370/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4232 - accuracy: 0.8192 - val_loss: 0.6893 - val_accuracy: 0.7131\n",
      "Epoch 371/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4071 - accuracy: 0.8231 - val_loss: 0.7682 - val_accuracy: 0.6857\n",
      "Epoch 372/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4083 - accuracy: 0.8264 - val_loss: 0.6395 - val_accuracy: 0.7143\n",
      "Epoch 373/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4344 - accuracy: 0.8122 - val_loss: 0.6401 - val_accuracy: 0.7357\n",
      "Epoch 374/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4316 - accuracy: 0.8199 - val_loss: 0.8000 - val_accuracy: 0.7107\n",
      "Epoch 375/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4227 - accuracy: 0.8219 - val_loss: 0.6558 - val_accuracy: 0.7286\n",
      "Epoch 376/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4137 - accuracy: 0.8218 - val_loss: 0.6635 - val_accuracy: 0.7405\n",
      "Epoch 377/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4233 - accuracy: 0.8187 - val_loss: 0.7754 - val_accuracy: 0.6857\n",
      "Epoch 378/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4047 - accuracy: 0.8236 - val_loss: 0.6841 - val_accuracy: 0.7226\n",
      "Epoch 379/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3988 - accuracy: 0.8282 - val_loss: 0.7607 - val_accuracy: 0.7000\n",
      "Epoch 380/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4395 - accuracy: 0.8168 - val_loss: 0.6587 - val_accuracy: 0.7500\n",
      "Epoch 381/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4074 - accuracy: 0.8259 - val_loss: 0.6603 - val_accuracy: 0.7238\n",
      "Epoch 382/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4066 - accuracy: 0.8183 - val_loss: 0.6945 - val_accuracy: 0.7357\n",
      "Epoch 383/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4145 - accuracy: 0.8233 - val_loss: 0.6960 - val_accuracy: 0.7012\n",
      "Epoch 384/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3942 - accuracy: 0.8300 - val_loss: 0.7710 - val_accuracy: 0.6952\n",
      "Epoch 385/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3878 - accuracy: 0.8316 - val_loss: 0.6548 - val_accuracy: 0.7512\n",
      "Epoch 386/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3997 - accuracy: 0.8303 - val_loss: 0.7036 - val_accuracy: 0.7405\n",
      "Epoch 387/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3954 - accuracy: 0.8246 - val_loss: 0.7139 - val_accuracy: 0.7131\n",
      "Epoch 388/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3944 - accuracy: 0.8290 - val_loss: 0.7483 - val_accuracy: 0.7119\n",
      "Epoch 389/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4245 - accuracy: 0.8265 - val_loss: 0.6829 - val_accuracy: 0.7095\n",
      "Epoch 390/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4118 - accuracy: 0.8239 - val_loss: 0.7771 - val_accuracy: 0.6524\n",
      "Epoch 391/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3923 - accuracy: 0.8294 - val_loss: 0.6463 - val_accuracy: 0.7488\n",
      "Epoch 392/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3978 - accuracy: 0.8315 - val_loss: 0.7559 - val_accuracy: 0.6631\n",
      "Epoch 393/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3776 - accuracy: 0.8361 - val_loss: 0.6718 - val_accuracy: 0.7345\n",
      "Epoch 394/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4094 - accuracy: 0.8245 - val_loss: 0.5912 - val_accuracy: 0.7655\n",
      "Epoch 395/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3976 - accuracy: 0.8373 - val_loss: 0.6395 - val_accuracy: 0.7429\n",
      "Epoch 396/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3636 - accuracy: 0.8488 - val_loss: 0.7148 - val_accuracy: 0.7381\n",
      "Epoch 397/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3967 - accuracy: 0.8350 - val_loss: 0.6929 - val_accuracy: 0.7131\n",
      "Epoch 398/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3772 - accuracy: 0.8405 - val_loss: 0.7777 - val_accuracy: 0.6964\n",
      "Epoch 399/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3892 - accuracy: 0.8386 - val_loss: 0.6996 - val_accuracy: 0.7190\n",
      "Epoch 400/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4067 - accuracy: 0.8302 - val_loss: 0.8106 - val_accuracy: 0.7036\n",
      "Epoch 401/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3924 - accuracy: 0.8325 - val_loss: 0.6866 - val_accuracy: 0.7238\n",
      "Epoch 402/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3777 - accuracy: 0.8399 - val_loss: 0.6470 - val_accuracy: 0.7190\n",
      "Epoch 403/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3774 - accuracy: 0.8465 - val_loss: 0.6938 - val_accuracy: 0.7119\n",
      "Epoch 404/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3784 - accuracy: 0.8415 - val_loss: 0.6741 - val_accuracy: 0.7643\n",
      "Epoch 405/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3637 - accuracy: 0.8495 - val_loss: 0.6278 - val_accuracy: 0.7143\n",
      "Epoch 406/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3918 - accuracy: 0.8423 - val_loss: 0.6300 - val_accuracy: 0.7214\n",
      "Epoch 407/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3913 - accuracy: 0.8351 - val_loss: 0.6434 - val_accuracy: 0.7190\n",
      "Epoch 408/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3739 - accuracy: 0.8417 - val_loss: 0.6393 - val_accuracy: 0.7143\n",
      "Epoch 409/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3797 - accuracy: 0.8428 - val_loss: 0.6432 - val_accuracy: 0.7238\n",
      "Epoch 410/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3949 - accuracy: 0.8343 - val_loss: 0.6299 - val_accuracy: 0.7548\n",
      "Epoch 411/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3740 - accuracy: 0.8439 - val_loss: 0.6217 - val_accuracy: 0.7310\n",
      "Epoch 412/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3700 - accuracy: 0.8510 - val_loss: 0.7646 - val_accuracy: 0.7036\n",
      "Epoch 413/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3677 - accuracy: 0.8429 - val_loss: 0.6613 - val_accuracy: 0.7310\n",
      "Epoch 414/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3909 - accuracy: 0.8357 - val_loss: 0.6621 - val_accuracy: 0.7238\n",
      "Epoch 415/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3775 - accuracy: 0.8413 - val_loss: 0.7153 - val_accuracy: 0.6810\n",
      "Epoch 416/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3660 - accuracy: 0.8422 - val_loss: 0.7376 - val_accuracy: 0.6821\n",
      "Epoch 417/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4071 - accuracy: 0.8337 - val_loss: 0.6878 - val_accuracy: 0.7167\n",
      "Epoch 418/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3766 - accuracy: 0.8392 - val_loss: 0.7261 - val_accuracy: 0.7000\n",
      "Epoch 419/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3550 - accuracy: 0.8519 - val_loss: 0.5621 - val_accuracy: 0.7488\n",
      "Epoch 420/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4083 - accuracy: 0.8248 - val_loss: 0.6764 - val_accuracy: 0.7048\n",
      "Epoch 421/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3784 - accuracy: 0.8432 - val_loss: 0.7931 - val_accuracy: 0.6452\n",
      "Epoch 422/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3780 - accuracy: 0.8405 - val_loss: 0.6266 - val_accuracy: 0.7512\n",
      "Epoch 423/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3498 - accuracy: 0.8512 - val_loss: 0.6728 - val_accuracy: 0.7179\n",
      "Epoch 424/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3522 - accuracy: 0.8498 - val_loss: 0.5621 - val_accuracy: 0.7595\n",
      "Epoch 425/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3641 - accuracy: 0.8493 - val_loss: 0.6315 - val_accuracy: 0.7286\n",
      "Epoch 426/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3568 - accuracy: 0.8473 - val_loss: 0.5970 - val_accuracy: 0.7345\n",
      "Epoch 427/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3603 - accuracy: 0.8509 - val_loss: 0.6144 - val_accuracy: 0.7595\n",
      "Epoch 428/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3673 - accuracy: 0.8449 - val_loss: 0.6199 - val_accuracy: 0.7381\n",
      "Epoch 429/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3849 - accuracy: 0.8342 - val_loss: 0.6052 - val_accuracy: 0.7429\n",
      "Epoch 430/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3521 - accuracy: 0.8522 - val_loss: 0.6666 - val_accuracy: 0.7238\n",
      "Epoch 431/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3660 - accuracy: 0.8456 - val_loss: 0.6794 - val_accuracy: 0.7310\n",
      "Epoch 432/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3512 - accuracy: 0.8509 - val_loss: 0.6112 - val_accuracy: 0.7488\n",
      "Epoch 433/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3422 - accuracy: 0.8624 - val_loss: 0.7544 - val_accuracy: 0.6595\n",
      "Epoch 434/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4097 - accuracy: 0.8296 - val_loss: 0.6755 - val_accuracy: 0.7071\n",
      "Epoch 435/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3427 - accuracy: 0.8576 - val_loss: 0.6041 - val_accuracy: 0.7321\n",
      "Epoch 436/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3811 - accuracy: 0.8410 - val_loss: 0.7151 - val_accuracy: 0.6905\n",
      "Epoch 437/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3500 - accuracy: 0.8500 - val_loss: 0.7200 - val_accuracy: 0.7155\n",
      "Epoch 438/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3490 - accuracy: 0.8522 - val_loss: 0.6224 - val_accuracy: 0.7393\n",
      "Epoch 439/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3507 - accuracy: 0.8488 - val_loss: 0.6802 - val_accuracy: 0.7238\n",
      "Epoch 440/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3797 - accuracy: 0.8448 - val_loss: 0.6907 - val_accuracy: 0.6810\n",
      "Epoch 441/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3918 - accuracy: 0.8320 - val_loss: 0.5426 - val_accuracy: 0.7583\n",
      "Epoch 442/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3275 - accuracy: 0.8597 - val_loss: 0.6028 - val_accuracy: 0.7500\n",
      "Epoch 443/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3638 - accuracy: 0.8473 - val_loss: 0.7247 - val_accuracy: 0.6607\n",
      "Epoch 444/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3405 - accuracy: 0.8606 - val_loss: 0.6220 - val_accuracy: 0.7440\n",
      "Epoch 445/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3382 - accuracy: 0.8562 - val_loss: 0.7645 - val_accuracy: 0.6333\n",
      "Epoch 446/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3552 - accuracy: 0.8546 - val_loss: 0.6346 - val_accuracy: 0.7452\n",
      "Epoch 447/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3494 - accuracy: 0.8535 - val_loss: 0.8299 - val_accuracy: 0.6333\n",
      "Epoch 448/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3294 - accuracy: 0.8624 - val_loss: 0.6509 - val_accuracy: 0.7464\n",
      "Epoch 449/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3473 - accuracy: 0.8600 - val_loss: 0.7473 - val_accuracy: 0.7071\n",
      "Epoch 450/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3513 - accuracy: 0.8556 - val_loss: 0.6399 - val_accuracy: 0.7476\n",
      "Epoch 451/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3376 - accuracy: 0.8586 - val_loss: 0.5959 - val_accuracy: 0.7381\n",
      "Epoch 452/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3230 - accuracy: 0.8667 - val_loss: 0.6913 - val_accuracy: 0.7131\n",
      "Epoch 453/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3683 - accuracy: 0.8484 - val_loss: 0.6866 - val_accuracy: 0.6940\n",
      "Epoch 454/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3169 - accuracy: 0.8683 - val_loss: 0.7210 - val_accuracy: 0.7250\n",
      "Epoch 455/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3228 - accuracy: 0.8655 - val_loss: 0.6931 - val_accuracy: 0.7048\n",
      "Epoch 456/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3535 - accuracy: 0.8519 - val_loss: 0.6022 - val_accuracy: 0.7310\n",
      "Epoch 457/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3378 - accuracy: 0.8613 - val_loss: 0.8661 - val_accuracy: 0.6583\n",
      "Epoch 458/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3298 - accuracy: 0.8612 - val_loss: 0.5697 - val_accuracy: 0.7429\n",
      "Epoch 459/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3343 - accuracy: 0.8577 - val_loss: 0.6646 - val_accuracy: 0.6976\n",
      "Epoch 460/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3020 - accuracy: 0.8709 - val_loss: 0.6398 - val_accuracy: 0.7310\n",
      "Epoch 461/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3300 - accuracy: 0.8632 - val_loss: 0.6450 - val_accuracy: 0.7417\n",
      "Epoch 462/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3215 - accuracy: 0.8646 - val_loss: 0.5962 - val_accuracy: 0.7643\n",
      "Epoch 463/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2975 - accuracy: 0.8744 - val_loss: 0.7766 - val_accuracy: 0.6929\n",
      "Epoch 464/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3062 - accuracy: 0.8739 - val_loss: 0.6497 - val_accuracy: 0.6917\n",
      "Epoch 465/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3291 - accuracy: 0.8617 - val_loss: 0.6857 - val_accuracy: 0.7167\n",
      "Epoch 466/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3113 - accuracy: 0.8740 - val_loss: 0.5970 - val_accuracy: 0.7500\n",
      "Epoch 467/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3258 - accuracy: 0.8678 - val_loss: 0.6171 - val_accuracy: 0.7512\n",
      "Epoch 468/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3195 - accuracy: 0.8731 - val_loss: 0.6470 - val_accuracy: 0.7345\n",
      "Epoch 469/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3392 - accuracy: 0.8581 - val_loss: 0.7082 - val_accuracy: 0.7167\n",
      "Epoch 470/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3123 - accuracy: 0.8733 - val_loss: 0.6188 - val_accuracy: 0.7274\n",
      "Epoch 471/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3125 - accuracy: 0.8695 - val_loss: 0.6289 - val_accuracy: 0.7167\n",
      "Epoch 472/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3208 - accuracy: 0.8606 - val_loss: 0.7282 - val_accuracy: 0.6869\n",
      "Epoch 473/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2856 - accuracy: 0.8873 - val_loss: 0.6484 - val_accuracy: 0.7548\n",
      "Epoch 474/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3415 - accuracy: 0.8614 - val_loss: 0.6571 - val_accuracy: 0.7071\n",
      "Epoch 475/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3344 - accuracy: 0.8644 - val_loss: 0.6752 - val_accuracy: 0.6869\n",
      "Epoch 476/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3277 - accuracy: 0.8698 - val_loss: 0.6232 - val_accuracy: 0.7083\n",
      "Epoch 477/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3439 - accuracy: 0.8623 - val_loss: 0.6706 - val_accuracy: 0.7179\n",
      "Epoch 478/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3026 - accuracy: 0.8743 - val_loss: 0.7555 - val_accuracy: 0.7071\n",
      "Epoch 479/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3427 - accuracy: 0.8598 - val_loss: 0.6780 - val_accuracy: 0.7250\n",
      "Epoch 480/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3148 - accuracy: 0.8718 - val_loss: 0.5772 - val_accuracy: 0.7202\n",
      "Epoch 481/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3017 - accuracy: 0.8745 - val_loss: 0.5964 - val_accuracy: 0.7381\n",
      "Epoch 482/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3110 - accuracy: 0.8752 - val_loss: 0.7162 - val_accuracy: 0.6667\n",
      "Epoch 483/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3077 - accuracy: 0.8810 - val_loss: 0.6926 - val_accuracy: 0.7310\n",
      "Epoch 484/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3137 - accuracy: 0.8673 - val_loss: 0.6522 - val_accuracy: 0.7012\n",
      "Epoch 485/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3503 - accuracy: 0.8621 - val_loss: 0.6405 - val_accuracy: 0.7333\n",
      "Epoch 486/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3104 - accuracy: 0.8776 - val_loss: 0.5879 - val_accuracy: 0.7571\n",
      "Epoch 487/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2944 - accuracy: 0.8801 - val_loss: 0.5706 - val_accuracy: 0.7738\n",
      "Epoch 488/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3108 - accuracy: 0.8796 - val_loss: 0.5938 - val_accuracy: 0.7321\n",
      "Epoch 489/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2845 - accuracy: 0.8832 - val_loss: 0.5935 - val_accuracy: 0.7393\n",
      "Epoch 490/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3406 - accuracy: 0.8632 - val_loss: 0.7269 - val_accuracy: 0.7321\n",
      "Epoch 491/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3035 - accuracy: 0.8734 - val_loss: 0.5497 - val_accuracy: 0.7821\n",
      "Epoch 492/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2968 - accuracy: 0.8806 - val_loss: 0.6173 - val_accuracy: 0.7202\n",
      "Epoch 493/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3090 - accuracy: 0.8729 - val_loss: 0.6475 - val_accuracy: 0.7214\n",
      "Epoch 494/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3044 - accuracy: 0.8733 - val_loss: 0.6021 - val_accuracy: 0.7417\n",
      "Epoch 495/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2971 - accuracy: 0.8741 - val_loss: 0.6252 - val_accuracy: 0.7500\n",
      "Epoch 496/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3205 - accuracy: 0.8685 - val_loss: 0.6152 - val_accuracy: 0.7190\n",
      "Epoch 497/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2826 - accuracy: 0.8842 - val_loss: 0.5456 - val_accuracy: 0.7714\n",
      "Epoch 498/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3053 - accuracy: 0.8787 - val_loss: 0.6137 - val_accuracy: 0.7250\n",
      "Epoch 499/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2929 - accuracy: 0.8841 - val_loss: 0.6558 - val_accuracy: 0.7202\n",
      "Epoch 500/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2807 - accuracy: 0.8859 - val_loss: 0.6604 - val_accuracy: 0.7357\n",
      "Epoch 501/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2870 - accuracy: 0.8846 - val_loss: 0.6477 - val_accuracy: 0.7298\n",
      "Epoch 502/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3081 - accuracy: 0.8731 - val_loss: 0.6111 - val_accuracy: 0.7357\n",
      "Epoch 503/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3309 - accuracy: 0.8675 - val_loss: 0.5682 - val_accuracy: 0.7476\n",
      "Epoch 504/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2897 - accuracy: 0.8794 - val_loss: 0.5452 - val_accuracy: 0.7726\n",
      "Epoch 505/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2844 - accuracy: 0.8878 - val_loss: 0.6363 - val_accuracy: 0.7321\n",
      "Epoch 506/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2669 - accuracy: 0.8888 - val_loss: 0.7809 - val_accuracy: 0.7274\n",
      "Epoch 507/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3140 - accuracy: 0.8748 - val_loss: 0.6410 - val_accuracy: 0.7143\n",
      "Epoch 508/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2654 - accuracy: 0.8879 - val_loss: 0.6168 - val_accuracy: 0.7798\n",
      "Epoch 509/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2728 - accuracy: 0.8889 - val_loss: 0.5711 - val_accuracy: 0.7667\n",
      "Epoch 510/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2754 - accuracy: 0.8878 - val_loss: 0.5998 - val_accuracy: 0.7476\n",
      "Epoch 511/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2866 - accuracy: 0.8827 - val_loss: 0.6094 - val_accuracy: 0.7333\n",
      "Epoch 512/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3039 - accuracy: 0.8820 - val_loss: 0.6265 - val_accuracy: 0.7381\n",
      "Epoch 513/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2873 - accuracy: 0.8845 - val_loss: 0.6693 - val_accuracy: 0.7607\n",
      "Epoch 514/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3141 - accuracy: 0.8761 - val_loss: 0.6290 - val_accuracy: 0.7452\n",
      "Epoch 515/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2709 - accuracy: 0.8942 - val_loss: 0.8013 - val_accuracy: 0.7012\n",
      "Epoch 516/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2766 - accuracy: 0.8884 - val_loss: 0.7323 - val_accuracy: 0.6845\n",
      "Epoch 517/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2704 - accuracy: 0.8910 - val_loss: 0.6556 - val_accuracy: 0.7274\n",
      "Epoch 518/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2944 - accuracy: 0.8818 - val_loss: 0.6899 - val_accuracy: 0.7214\n",
      "Epoch 519/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2952 - accuracy: 0.8789 - val_loss: 0.6588 - val_accuracy: 0.7214\n",
      "Epoch 520/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2822 - accuracy: 0.8813 - val_loss: 0.5677 - val_accuracy: 0.7452\n",
      "Epoch 521/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2618 - accuracy: 0.8954 - val_loss: 0.6345 - val_accuracy: 0.7238\n",
      "Epoch 522/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2953 - accuracy: 0.8841 - val_loss: 0.6812 - val_accuracy: 0.7286\n",
      "Epoch 523/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2855 - accuracy: 0.8828 - val_loss: 0.5922 - val_accuracy: 0.7560\n",
      "Epoch 524/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2591 - accuracy: 0.8919 - val_loss: 0.5345 - val_accuracy: 0.7631\n",
      "Epoch 525/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3220 - accuracy: 0.8720 - val_loss: 0.5700 - val_accuracy: 0.7798\n",
      "Epoch 526/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3026 - accuracy: 0.8811 - val_loss: 0.6500 - val_accuracy: 0.7500\n",
      "Epoch 527/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2905 - accuracy: 0.8818 - val_loss: 0.6766 - val_accuracy: 0.7143\n",
      "Epoch 528/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2560 - accuracy: 0.8950 - val_loss: 0.6492 - val_accuracy: 0.7548\n",
      "Epoch 529/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2891 - accuracy: 0.8873 - val_loss: 0.6727 - val_accuracy: 0.7060\n",
      "Epoch 530/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3044 - accuracy: 0.8699 - val_loss: 0.7529 - val_accuracy: 0.7393\n",
      "Epoch 531/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3001 - accuracy: 0.8812 - val_loss: 0.6490 - val_accuracy: 0.7286\n",
      "Epoch 532/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2729 - accuracy: 0.8937 - val_loss: 0.6252 - val_accuracy: 0.7679\n",
      "Epoch 533/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2743 - accuracy: 0.8868 - val_loss: 0.6087 - val_accuracy: 0.7345\n",
      "Epoch 534/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2781 - accuracy: 0.8851 - val_loss: 0.6089 - val_accuracy: 0.7595\n",
      "Epoch 535/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3025 - accuracy: 0.8710 - val_loss: 0.5795 - val_accuracy: 0.7452\n",
      "Epoch 536/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2724 - accuracy: 0.8900 - val_loss: 0.8124 - val_accuracy: 0.6940\n",
      "Epoch 537/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2622 - accuracy: 0.8886 - val_loss: 0.5958 - val_accuracy: 0.7583\n",
      "Epoch 538/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2767 - accuracy: 0.8853 - val_loss: 0.6249 - val_accuracy: 0.7452\n",
      "Epoch 539/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2882 - accuracy: 0.8843 - val_loss: 0.6746 - val_accuracy: 0.7036\n",
      "Epoch 540/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2873 - accuracy: 0.8818 - val_loss: 0.6019 - val_accuracy: 0.7631\n",
      "Epoch 541/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2595 - accuracy: 0.8937 - val_loss: 0.7698 - val_accuracy: 0.7333\n",
      "Epoch 542/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2706 - accuracy: 0.8909 - val_loss: 0.6567 - val_accuracy: 0.7452\n",
      "Epoch 543/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2449 - accuracy: 0.9024 - val_loss: 0.6433 - val_accuracy: 0.7357\n",
      "Epoch 544/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3168 - accuracy: 0.8653 - val_loss: 0.6006 - val_accuracy: 0.7298\n",
      "Epoch 545/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2551 - accuracy: 0.8955 - val_loss: 0.5910 - val_accuracy: 0.7500\n",
      "Epoch 546/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3281 - accuracy: 0.8675 - val_loss: 0.6559 - val_accuracy: 0.7310\n",
      "Epoch 547/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2666 - accuracy: 0.8922 - val_loss: 0.6217 - val_accuracy: 0.7548\n",
      "Epoch 548/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2729 - accuracy: 0.8937 - val_loss: 0.6060 - val_accuracy: 0.7548\n",
      "Epoch 549/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2503 - accuracy: 0.9012 - val_loss: 0.6394 - val_accuracy: 0.7500\n",
      "Epoch 550/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2658 - accuracy: 0.8930 - val_loss: 0.6176 - val_accuracy: 0.7524\n",
      "Epoch 551/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2719 - accuracy: 0.8925 - val_loss: 0.6069 - val_accuracy: 0.7333\n",
      "Epoch 552/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2463 - accuracy: 0.9006 - val_loss: 0.6689 - val_accuracy: 0.7250\n",
      "Epoch 553/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2599 - accuracy: 0.8968 - val_loss: 0.6714 - val_accuracy: 0.7262\n",
      "Epoch 554/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3161 - accuracy: 0.8790 - val_loss: 0.6564 - val_accuracy: 0.7190\n",
      "Epoch 555/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2719 - accuracy: 0.8908 - val_loss: 0.6203 - val_accuracy: 0.7429\n",
      "Epoch 556/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2429 - accuracy: 0.9076 - val_loss: 0.6477 - val_accuracy: 0.7262\n",
      "Epoch 557/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2350 - accuracy: 0.9073 - val_loss: 0.7146 - val_accuracy: 0.7012\n",
      "Epoch 558/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3834 - accuracy: 0.8525 - val_loss: 0.6835 - val_accuracy: 0.7333\n",
      "Epoch 559/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2875 - accuracy: 0.8878 - val_loss: 0.7595 - val_accuracy: 0.7095\n",
      "Epoch 560/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2709 - accuracy: 0.8913 - val_loss: 0.5946 - val_accuracy: 0.7167\n",
      "Epoch 561/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2597 - accuracy: 0.8960 - val_loss: 0.6336 - val_accuracy: 0.7429\n",
      "Epoch 562/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2703 - accuracy: 0.8928 - val_loss: 0.5063 - val_accuracy: 0.7869\n",
      "Epoch 563/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2502 - accuracy: 0.9006 - val_loss: 0.6241 - val_accuracy: 0.7512\n",
      "Epoch 564/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2450 - accuracy: 0.8975 - val_loss: 0.6330 - val_accuracy: 0.7607\n",
      "Epoch 565/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2857 - accuracy: 0.8864 - val_loss: 0.6617 - val_accuracy: 0.7476\n",
      "Epoch 566/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2376 - accuracy: 0.9044 - val_loss: 0.5920 - val_accuracy: 0.7500\n",
      "Epoch 567/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3356 - accuracy: 0.8553 - val_loss: 0.7247 - val_accuracy: 0.6917\n",
      "Epoch 568/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2582 - accuracy: 0.8949 - val_loss: 0.6726 - val_accuracy: 0.7357\n",
      "Epoch 569/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2111 - accuracy: 0.9159 - val_loss: 0.6538 - val_accuracy: 0.7690\n",
      "Epoch 570/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2309 - accuracy: 0.9047 - val_loss: 0.6362 - val_accuracy: 0.7619\n",
      "Epoch 571/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2557 - accuracy: 0.8984 - val_loss: 0.6750 - val_accuracy: 0.7393\n",
      "Epoch 572/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2611 - accuracy: 0.8986 - val_loss: 0.6474 - val_accuracy: 0.7488\n",
      "Epoch 573/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2534 - accuracy: 0.9004 - val_loss: 0.6292 - val_accuracy: 0.7607\n",
      "Epoch 574/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2492 - accuracy: 0.9017 - val_loss: 0.7364 - val_accuracy: 0.7333\n",
      "Epoch 575/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2776 - accuracy: 0.8872 - val_loss: 0.6518 - val_accuracy: 0.7417\n",
      "Epoch 576/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2533 - accuracy: 0.9051 - val_loss: 0.6166 - val_accuracy: 0.7714\n",
      "Epoch 577/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2213 - accuracy: 0.9101 - val_loss: 0.6228 - val_accuracy: 0.7429\n",
      "Epoch 578/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3052 - accuracy: 0.8884 - val_loss: 0.7703 - val_accuracy: 0.6976\n",
      "Epoch 579/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2570 - accuracy: 0.9031 - val_loss: 0.7932 - val_accuracy: 0.7048\n",
      "Epoch 580/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2537 - accuracy: 0.8995 - val_loss: 0.6100 - val_accuracy: 0.7631\n",
      "Epoch 581/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2412 - accuracy: 0.9056 - val_loss: 0.5590 - val_accuracy: 0.7857\n",
      "Epoch 582/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2387 - accuracy: 0.9042 - val_loss: 0.7504 - val_accuracy: 0.7429\n",
      "Epoch 583/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2288 - accuracy: 0.9090 - val_loss: 0.5678 - val_accuracy: 0.7631\n",
      "Epoch 584/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2805 - accuracy: 0.8833 - val_loss: 0.5792 - val_accuracy: 0.7917\n",
      "Epoch 585/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2311 - accuracy: 0.9078 - val_loss: 0.7042 - val_accuracy: 0.7119\n",
      "Epoch 586/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2371 - accuracy: 0.9111 - val_loss: 0.6463 - val_accuracy: 0.7548\n",
      "Epoch 587/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3449 - accuracy: 0.8728 - val_loss: 0.6670 - val_accuracy: 0.7107\n",
      "Epoch 588/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2840 - accuracy: 0.8831 - val_loss: 0.6304 - val_accuracy: 0.7286\n",
      "Epoch 589/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2857 - accuracy: 0.8852 - val_loss: 0.7465 - val_accuracy: 0.7226\n",
      "Epoch 590/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2908 - accuracy: 0.8817 - val_loss: 0.9494 - val_accuracy: 0.6274\n",
      "Epoch 591/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2516 - accuracy: 0.9004 - val_loss: 0.5643 - val_accuracy: 0.7548\n",
      "Epoch 592/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2579 - accuracy: 0.8976 - val_loss: 0.6590 - val_accuracy: 0.7583\n",
      "Epoch 593/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2549 - accuracy: 0.8973 - val_loss: 0.6449 - val_accuracy: 0.7655\n",
      "Epoch 594/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2698 - accuracy: 0.8965 - val_loss: 0.6377 - val_accuracy: 0.7321\n",
      "Epoch 595/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2773 - accuracy: 0.9011 - val_loss: 0.6592 - val_accuracy: 0.7631\n",
      "Epoch 596/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2688 - accuracy: 0.8975 - val_loss: 0.6233 - val_accuracy: 0.7500\n",
      "Epoch 597/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2327 - accuracy: 0.9100 - val_loss: 0.5979 - val_accuracy: 0.7583\n",
      "Epoch 598/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2321 - accuracy: 0.9095 - val_loss: 0.6978 - val_accuracy: 0.7381\n",
      "Epoch 599/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2191 - accuracy: 0.9138 - val_loss: 0.8663 - val_accuracy: 0.6512\n",
      "Epoch 600/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2464 - accuracy: 0.9076 - val_loss: 0.7006 - val_accuracy: 0.7417\n",
      "Epoch 1/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0984 - accuracy: 0.3466 - val_loss: 1.0974 - val_accuracy: 0.3857\n",
      "Epoch 2/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0982 - accuracy: 0.3501 - val_loss: 1.0971 - val_accuracy: 0.3714\n",
      "Epoch 3/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0970 - accuracy: 0.3614 - val_loss: 1.0943 - val_accuracy: 0.3869\n",
      "Epoch 4/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0979 - accuracy: 0.3516 - val_loss: 1.0952 - val_accuracy: 0.3810\n",
      "Epoch 5/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0957 - accuracy: 0.3714 - val_loss: 1.0910 - val_accuracy: 0.4083\n",
      "Epoch 6/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0952 - accuracy: 0.3822 - val_loss: 1.0899 - val_accuracy: 0.4167\n",
      "Epoch 7/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0913 - accuracy: 0.3846 - val_loss: 1.0870 - val_accuracy: 0.4107\n",
      "Epoch 8/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0915 - accuracy: 0.3863 - val_loss: 1.0828 - val_accuracy: 0.4310\n",
      "Epoch 9/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0902 - accuracy: 0.3897 - val_loss: 1.0872 - val_accuracy: 0.3762\n",
      "Epoch 10/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0883 - accuracy: 0.3847 - val_loss: 1.0780 - val_accuracy: 0.4012\n",
      "Epoch 11/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0875 - accuracy: 0.3887 - val_loss: 1.0810 - val_accuracy: 0.3548\n",
      "Epoch 12/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0844 - accuracy: 0.3847 - val_loss: 1.0745 - val_accuracy: 0.3905\n",
      "Epoch 13/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0813 - accuracy: 0.3882 - val_loss: 1.0740 - val_accuracy: 0.4071\n",
      "Epoch 14/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0778 - accuracy: 0.3932 - val_loss: 1.0700 - val_accuracy: 0.4060\n",
      "Epoch 15/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0709 - accuracy: 0.3988 - val_loss: 1.0680 - val_accuracy: 0.4286\n",
      "Epoch 16/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0746 - accuracy: 0.3966 - val_loss: 1.0623 - val_accuracy: 0.4095\n",
      "Epoch 17/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0709 - accuracy: 0.4167 - val_loss: 1.0668 - val_accuracy: 0.4083\n",
      "Epoch 18/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0655 - accuracy: 0.4113 - val_loss: 1.0605 - val_accuracy: 0.4250\n",
      "Epoch 19/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0624 - accuracy: 0.4179 - val_loss: 1.0543 - val_accuracy: 0.4369\n",
      "Epoch 20/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0602 - accuracy: 0.4147 - val_loss: 1.0479 - val_accuracy: 0.4369\n",
      "Epoch 21/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0560 - accuracy: 0.4235 - val_loss: 1.0409 - val_accuracy: 0.4643\n",
      "Epoch 22/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0584 - accuracy: 0.4215 - val_loss: 1.0446 - val_accuracy: 0.4488\n",
      "Epoch 23/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0563 - accuracy: 0.4272 - val_loss: 1.0381 - val_accuracy: 0.4452\n",
      "Epoch 24/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0588 - accuracy: 0.4203 - val_loss: 1.0677 - val_accuracy: 0.3988\n",
      "Epoch 25/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0570 - accuracy: 0.4159 - val_loss: 1.0330 - val_accuracy: 0.4726\n",
      "Epoch 26/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0496 - accuracy: 0.4327 - val_loss: 1.0341 - val_accuracy: 0.4655\n",
      "Epoch 27/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0475 - accuracy: 0.4256 - val_loss: 1.0483 - val_accuracy: 0.4262\n",
      "Epoch 28/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0462 - accuracy: 0.4274 - val_loss: 1.0486 - val_accuracy: 0.4250\n",
      "Epoch 29/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0430 - accuracy: 0.4308 - val_loss: 1.0861 - val_accuracy: 0.3810\n",
      "Epoch 30/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0426 - accuracy: 0.4345 - val_loss: 1.0378 - val_accuracy: 0.4345\n",
      "Epoch 31/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0437 - accuracy: 0.4259 - val_loss: 1.0597 - val_accuracy: 0.4024\n",
      "Epoch 32/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0416 - accuracy: 0.4342 - val_loss: 1.0336 - val_accuracy: 0.4440\n",
      "Epoch 33/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0383 - accuracy: 0.4412 - val_loss: 1.0376 - val_accuracy: 0.4214\n",
      "Epoch 34/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0400 - accuracy: 0.4377 - val_loss: 1.0088 - val_accuracy: 0.4571\n",
      "Epoch 35/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0349 - accuracy: 0.4366 - val_loss: 1.0443 - val_accuracy: 0.4238\n",
      "Epoch 36/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0336 - accuracy: 0.4327 - val_loss: 1.0316 - val_accuracy: 0.4500\n",
      "Epoch 37/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0368 - accuracy: 0.4448 - val_loss: 1.0306 - val_accuracy: 0.4488\n",
      "Epoch 38/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0255 - accuracy: 0.4490 - val_loss: 1.0243 - val_accuracy: 0.4583\n",
      "Epoch 39/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0196 - accuracy: 0.4476 - val_loss: 1.0198 - val_accuracy: 0.4595\n",
      "Epoch 40/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0182 - accuracy: 0.4500 - val_loss: 0.9980 - val_accuracy: 0.4655\n",
      "Epoch 41/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0187 - accuracy: 0.4483 - val_loss: 1.0001 - val_accuracy: 0.4845\n",
      "Epoch 42/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0235 - accuracy: 0.4544 - val_loss: 1.0057 - val_accuracy: 0.4869\n",
      "Epoch 43/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0210 - accuracy: 0.4530 - val_loss: 0.9947 - val_accuracy: 0.4940\n",
      "Epoch 44/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0144 - accuracy: 0.4614 - val_loss: 1.0380 - val_accuracy: 0.4190\n",
      "Epoch 45/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0127 - accuracy: 0.4552 - val_loss: 1.0406 - val_accuracy: 0.4405\n",
      "Epoch 46/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0094 - accuracy: 0.4590 - val_loss: 1.0006 - val_accuracy: 0.4774\n",
      "Epoch 47/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0064 - accuracy: 0.4624 - val_loss: 1.0340 - val_accuracy: 0.4607\n",
      "Epoch 48/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0047 - accuracy: 0.4570 - val_loss: 0.9836 - val_accuracy: 0.5155\n",
      "Epoch 49/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9961 - accuracy: 0.4739 - val_loss: 1.0160 - val_accuracy: 0.4524\n",
      "Epoch 50/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0009 - accuracy: 0.4649 - val_loss: 1.0272 - val_accuracy: 0.4393\n",
      "Epoch 51/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0075 - accuracy: 0.4598 - val_loss: 1.0416 - val_accuracy: 0.4381\n",
      "Epoch 52/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0008 - accuracy: 0.4668 - val_loss: 1.0031 - val_accuracy: 0.4631\n",
      "Epoch 53/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9918 - accuracy: 0.4719 - val_loss: 0.9739 - val_accuracy: 0.4667\n",
      "Epoch 54/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9913 - accuracy: 0.4761 - val_loss: 1.0550 - val_accuracy: 0.4417\n",
      "Epoch 55/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9954 - accuracy: 0.4692 - val_loss: 0.9947 - val_accuracy: 0.4786\n",
      "Epoch 56/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9916 - accuracy: 0.4740 - val_loss: 1.0204 - val_accuracy: 0.4595\n",
      "Epoch 57/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9927 - accuracy: 0.4771 - val_loss: 0.9865 - val_accuracy: 0.4905\n",
      "Epoch 58/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9940 - accuracy: 0.4787 - val_loss: 1.0101 - val_accuracy: 0.4417\n",
      "Epoch 59/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9875 - accuracy: 0.4790 - val_loss: 0.9828 - val_accuracy: 0.4714\n",
      "Epoch 60/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9775 - accuracy: 0.4841 - val_loss: 1.0017 - val_accuracy: 0.4560\n",
      "Epoch 61/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9814 - accuracy: 0.4876 - val_loss: 0.9566 - val_accuracy: 0.4845\n",
      "Epoch 62/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9776 - accuracy: 0.4832 - val_loss: 0.9747 - val_accuracy: 0.4762\n",
      "Epoch 63/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9848 - accuracy: 0.4715 - val_loss: 0.9827 - val_accuracy: 0.4821\n",
      "Epoch 64/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9898 - accuracy: 0.4701 - val_loss: 1.0053 - val_accuracy: 0.4702\n",
      "Epoch 65/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9750 - accuracy: 0.4917 - val_loss: 1.0098 - val_accuracy: 0.4750\n",
      "Epoch 66/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9837 - accuracy: 0.4767 - val_loss: 1.0031 - val_accuracy: 0.4643\n",
      "Epoch 67/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9768 - accuracy: 0.4856 - val_loss: 1.0031 - val_accuracy: 0.4595\n",
      "Epoch 68/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9691 - accuracy: 0.5044 - val_loss: 0.9645 - val_accuracy: 0.4798\n",
      "Epoch 69/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9769 - accuracy: 0.4893 - val_loss: 0.9608 - val_accuracy: 0.4893\n",
      "Epoch 70/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9633 - accuracy: 0.5016 - val_loss: 1.0194 - val_accuracy: 0.4655\n",
      "Epoch 71/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9564 - accuracy: 0.5095 - val_loss: 0.9518 - val_accuracy: 0.4845\n",
      "Epoch 72/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9649 - accuracy: 0.4902 - val_loss: 0.9430 - val_accuracy: 0.4857\n",
      "Epoch 73/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9551 - accuracy: 0.5025 - val_loss: 1.0015 - val_accuracy: 0.4512\n",
      "Epoch 74/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9639 - accuracy: 0.4965 - val_loss: 1.0028 - val_accuracy: 0.4488\n",
      "Epoch 75/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9683 - accuracy: 0.4959 - val_loss: 0.9498 - val_accuracy: 0.4714\n",
      "Epoch 76/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9586 - accuracy: 0.5042 - val_loss: 0.9879 - val_accuracy: 0.4893\n",
      "Epoch 77/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9477 - accuracy: 0.5187 - val_loss: 0.9732 - val_accuracy: 0.4536\n",
      "Epoch 78/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9527 - accuracy: 0.5025 - val_loss: 0.9648 - val_accuracy: 0.4810\n",
      "Epoch 79/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9549 - accuracy: 0.5019 - val_loss: 0.9734 - val_accuracy: 0.4976\n",
      "Epoch 80/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9418 - accuracy: 0.5137 - val_loss: 0.9445 - val_accuracy: 0.4929\n",
      "Epoch 81/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9430 - accuracy: 0.5174 - val_loss: 0.9415 - val_accuracy: 0.4810\n",
      "Epoch 82/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9416 - accuracy: 0.5209 - val_loss: 0.9248 - val_accuracy: 0.5167\n",
      "Epoch 83/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9401 - accuracy: 0.5215 - val_loss: 0.9999 - val_accuracy: 0.4655\n",
      "Epoch 84/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9371 - accuracy: 0.5201 - val_loss: 0.9281 - val_accuracy: 0.5119\n",
      "Epoch 85/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9310 - accuracy: 0.5210 - val_loss: 1.0242 - val_accuracy: 0.4631\n",
      "Epoch 86/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9302 - accuracy: 0.5259 - val_loss: 0.9082 - val_accuracy: 0.5131\n",
      "Epoch 87/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9313 - accuracy: 0.5194 - val_loss: 0.9367 - val_accuracy: 0.4690\n",
      "Epoch 88/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9475 - accuracy: 0.5165 - val_loss: 1.0220 - val_accuracy: 0.4524\n",
      "Epoch 89/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9292 - accuracy: 0.5336 - val_loss: 0.9991 - val_accuracy: 0.4583\n",
      "Epoch 90/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9289 - accuracy: 0.5326 - val_loss: 0.9801 - val_accuracy: 0.4929\n",
      "Epoch 91/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9180 - accuracy: 0.5351 - val_loss: 0.9061 - val_accuracy: 0.5560\n",
      "Epoch 92/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9180 - accuracy: 0.5364 - val_loss: 0.8957 - val_accuracy: 0.5417\n",
      "Epoch 93/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9186 - accuracy: 0.5336 - val_loss: 0.9973 - val_accuracy: 0.4869\n",
      "Epoch 94/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9089 - accuracy: 0.5367 - val_loss: 0.8923 - val_accuracy: 0.5274\n",
      "Epoch 95/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9160 - accuracy: 0.5386 - val_loss: 0.9432 - val_accuracy: 0.5083\n",
      "Epoch 96/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9087 - accuracy: 0.5447 - val_loss: 0.9255 - val_accuracy: 0.5071\n",
      "Epoch 97/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8983 - accuracy: 0.5461 - val_loss: 0.9653 - val_accuracy: 0.4857\n",
      "Epoch 98/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9072 - accuracy: 0.5391 - val_loss: 0.8564 - val_accuracy: 0.5345\n",
      "Epoch 99/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8951 - accuracy: 0.5444 - val_loss: 0.9275 - val_accuracy: 0.5036\n",
      "Epoch 100/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9083 - accuracy: 0.5371 - val_loss: 0.8689 - val_accuracy: 0.5536\n",
      "Epoch 101/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9032 - accuracy: 0.5488 - val_loss: 0.9301 - val_accuracy: 0.5143\n",
      "Epoch 102/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8961 - accuracy: 0.5476 - val_loss: 0.9296 - val_accuracy: 0.5000\n",
      "Epoch 103/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8969 - accuracy: 0.5511 - val_loss: 0.9258 - val_accuracy: 0.5214\n",
      "Epoch 104/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8851 - accuracy: 0.5568 - val_loss: 0.9675 - val_accuracy: 0.4679\n",
      "Epoch 105/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8838 - accuracy: 0.5601 - val_loss: 0.8718 - val_accuracy: 0.5583\n",
      "Epoch 106/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8906 - accuracy: 0.5529 - val_loss: 0.9202 - val_accuracy: 0.5238\n",
      "Epoch 107/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8899 - accuracy: 0.5586 - val_loss: 0.9487 - val_accuracy: 0.5060\n",
      "Epoch 108/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8824 - accuracy: 0.5544 - val_loss: 0.9011 - val_accuracy: 0.5536\n",
      "Epoch 109/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8870 - accuracy: 0.5596 - val_loss: 0.9194 - val_accuracy: 0.5226\n",
      "Epoch 110/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8720 - accuracy: 0.5701 - val_loss: 0.8875 - val_accuracy: 0.5298\n",
      "Epoch 111/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8803 - accuracy: 0.5644 - val_loss: 0.8926 - val_accuracy: 0.5274\n",
      "Epoch 112/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8702 - accuracy: 0.5709 - val_loss: 0.9817 - val_accuracy: 0.5024\n",
      "Epoch 113/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8719 - accuracy: 0.5637 - val_loss: 0.8892 - val_accuracy: 0.5452\n",
      "Epoch 114/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8637 - accuracy: 0.5779 - val_loss: 0.8389 - val_accuracy: 0.5881\n",
      "Epoch 115/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8755 - accuracy: 0.5648 - val_loss: 0.9499 - val_accuracy: 0.5250\n",
      "Epoch 116/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8624 - accuracy: 0.5791 - val_loss: 0.8865 - val_accuracy: 0.5369\n",
      "Epoch 117/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8599 - accuracy: 0.5714 - val_loss: 0.8446 - val_accuracy: 0.5952\n",
      "Epoch 118/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8486 - accuracy: 0.5831 - val_loss: 0.9517 - val_accuracy: 0.5167\n",
      "Epoch 119/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8517 - accuracy: 0.5813 - val_loss: 0.8295 - val_accuracy: 0.5750\n",
      "Epoch 120/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8535 - accuracy: 0.5813 - val_loss: 0.9502 - val_accuracy: 0.5298\n",
      "Epoch 121/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8365 - accuracy: 0.5945 - val_loss: 0.9614 - val_accuracy: 0.5000\n",
      "Epoch 122/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8514 - accuracy: 0.5765 - val_loss: 0.9848 - val_accuracy: 0.5286\n",
      "Epoch 123/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8532 - accuracy: 0.5835 - val_loss: 0.9380 - val_accuracy: 0.5500\n",
      "Epoch 124/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8435 - accuracy: 0.5919 - val_loss: 0.9453 - val_accuracy: 0.5012\n",
      "Epoch 125/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8446 - accuracy: 0.5898 - val_loss: 0.9075 - val_accuracy: 0.5429\n",
      "Epoch 126/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8354 - accuracy: 0.5947 - val_loss: 0.9892 - val_accuracy: 0.5238\n",
      "Epoch 127/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8394 - accuracy: 0.5955 - val_loss: 0.9913 - val_accuracy: 0.5060\n",
      "Epoch 128/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8373 - accuracy: 0.5959 - val_loss: 0.9019 - val_accuracy: 0.5500\n",
      "Epoch 129/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8361 - accuracy: 0.5934 - val_loss: 0.9188 - val_accuracy: 0.5190\n",
      "Epoch 130/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8150 - accuracy: 0.5969 - val_loss: 0.9197 - val_accuracy: 0.5452\n",
      "Epoch 131/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8240 - accuracy: 0.6027 - val_loss: 0.8612 - val_accuracy: 0.5964\n",
      "Epoch 132/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8237 - accuracy: 0.5939 - val_loss: 0.9578 - val_accuracy: 0.5190\n",
      "Epoch 133/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8107 - accuracy: 0.6097 - val_loss: 0.8711 - val_accuracy: 0.5750\n",
      "Epoch 134/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8108 - accuracy: 0.6113 - val_loss: 0.8779 - val_accuracy: 0.5690\n",
      "Epoch 135/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8036 - accuracy: 0.6159 - val_loss: 0.9319 - val_accuracy: 0.5857\n",
      "Epoch 136/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8107 - accuracy: 0.6102 - val_loss: 0.8782 - val_accuracy: 0.5619\n",
      "Epoch 137/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8218 - accuracy: 0.6046 - val_loss: 0.9046 - val_accuracy: 0.5262\n",
      "Epoch 138/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8036 - accuracy: 0.6101 - val_loss: 0.9468 - val_accuracy: 0.5250\n",
      "Epoch 139/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7964 - accuracy: 0.6182 - val_loss: 0.8634 - val_accuracy: 0.5798\n",
      "Epoch 140/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8118 - accuracy: 0.6051 - val_loss: 1.0680 - val_accuracy: 0.4917\n",
      "Epoch 141/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7990 - accuracy: 0.6158 - val_loss: 0.9810 - val_accuracy: 0.5226\n",
      "Epoch 142/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7999 - accuracy: 0.6162 - val_loss: 0.9334 - val_accuracy: 0.5238\n",
      "Epoch 143/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7907 - accuracy: 0.6187 - val_loss: 0.9928 - val_accuracy: 0.5143\n",
      "Epoch 144/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7922 - accuracy: 0.6246 - val_loss: 0.9652 - val_accuracy: 0.5381\n",
      "Epoch 145/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7841 - accuracy: 0.6244 - val_loss: 0.9043 - val_accuracy: 0.5560\n",
      "Epoch 146/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7847 - accuracy: 0.6206 - val_loss: 0.8841 - val_accuracy: 0.5845\n",
      "Epoch 147/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7780 - accuracy: 0.6359 - val_loss: 0.9682 - val_accuracy: 0.5226\n",
      "Epoch 148/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7807 - accuracy: 0.6284 - val_loss: 0.8276 - val_accuracy: 0.5952\n",
      "Epoch 149/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7879 - accuracy: 0.6303 - val_loss: 0.9597 - val_accuracy: 0.5274\n",
      "Epoch 150/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7530 - accuracy: 0.6382 - val_loss: 0.9017 - val_accuracy: 0.5429\n",
      "Epoch 151/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7790 - accuracy: 0.6279 - val_loss: 0.9247 - val_accuracy: 0.5512\n",
      "Epoch 152/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7798 - accuracy: 0.6301 - val_loss: 0.8754 - val_accuracy: 0.5583\n",
      "Epoch 153/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7640 - accuracy: 0.6351 - val_loss: 0.7570 - val_accuracy: 0.6214\n",
      "Epoch 154/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7752 - accuracy: 0.6338 - val_loss: 0.7727 - val_accuracy: 0.6333\n",
      "Epoch 155/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7482 - accuracy: 0.6498 - val_loss: 0.8450 - val_accuracy: 0.5905\n",
      "Epoch 156/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7704 - accuracy: 0.6405 - val_loss: 0.9420 - val_accuracy: 0.5464\n",
      "Epoch 157/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7531 - accuracy: 0.6515 - val_loss: 0.8769 - val_accuracy: 0.5655\n",
      "Epoch 158/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7670 - accuracy: 0.6420 - val_loss: 0.8010 - val_accuracy: 0.6131\n",
      "Epoch 159/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7651 - accuracy: 0.6418 - val_loss: 0.8546 - val_accuracy: 0.6048\n",
      "Epoch 160/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7536 - accuracy: 0.6465 - val_loss: 0.8995 - val_accuracy: 0.5821\n",
      "Epoch 161/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7465 - accuracy: 0.6515 - val_loss: 0.9121 - val_accuracy: 0.5798\n",
      "Epoch 162/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7608 - accuracy: 0.6453 - val_loss: 0.9757 - val_accuracy: 0.5726\n",
      "Epoch 163/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7424 - accuracy: 0.6430 - val_loss: 1.0340 - val_accuracy: 0.5679\n",
      "Epoch 164/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7438 - accuracy: 0.6549 - val_loss: 0.9872 - val_accuracy: 0.5071\n",
      "Epoch 165/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7418 - accuracy: 0.6571 - val_loss: 0.8522 - val_accuracy: 0.5976\n",
      "Epoch 166/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7505 - accuracy: 0.6498 - val_loss: 0.9715 - val_accuracy: 0.5512\n",
      "Epoch 167/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7315 - accuracy: 0.6532 - val_loss: 0.9007 - val_accuracy: 0.5429\n",
      "Epoch 168/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7391 - accuracy: 0.6568 - val_loss: 0.9262 - val_accuracy: 0.5750\n",
      "Epoch 169/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7406 - accuracy: 0.6558 - val_loss: 0.8387 - val_accuracy: 0.5881\n",
      "Epoch 170/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7317 - accuracy: 0.6618 - val_loss: 0.9143 - val_accuracy: 0.5833\n",
      "Epoch 171/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7343 - accuracy: 0.6578 - val_loss: 0.9565 - val_accuracy: 0.5500\n",
      "Epoch 172/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7461 - accuracy: 0.6567 - val_loss: 0.7952 - val_accuracy: 0.6024\n",
      "Epoch 173/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7213 - accuracy: 0.6621 - val_loss: 0.8366 - val_accuracy: 0.6071\n",
      "Epoch 174/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7151 - accuracy: 0.6682 - val_loss: 0.8142 - val_accuracy: 0.6024\n",
      "Epoch 175/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7332 - accuracy: 0.6595 - val_loss: 0.9420 - val_accuracy: 0.5369\n",
      "Epoch 176/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7255 - accuracy: 0.6657 - val_loss: 1.0071 - val_accuracy: 0.5476\n",
      "Epoch 177/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7052 - accuracy: 0.6781 - val_loss: 0.8378 - val_accuracy: 0.5917\n",
      "Epoch 178/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7319 - accuracy: 0.6603 - val_loss: 0.8005 - val_accuracy: 0.6369\n",
      "Epoch 179/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7154 - accuracy: 0.6693 - val_loss: 0.8584 - val_accuracy: 0.5690\n",
      "Epoch 180/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7238 - accuracy: 0.6638 - val_loss: 0.8169 - val_accuracy: 0.6155\n",
      "Epoch 181/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7187 - accuracy: 0.6660 - val_loss: 0.8210 - val_accuracy: 0.6131\n",
      "Epoch 182/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6906 - accuracy: 0.6833 - val_loss: 0.9395 - val_accuracy: 0.5357\n",
      "Epoch 183/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7050 - accuracy: 0.6755 - val_loss: 0.8371 - val_accuracy: 0.6000\n",
      "Epoch 184/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7017 - accuracy: 0.6743 - val_loss: 0.9467 - val_accuracy: 0.6190\n",
      "Epoch 185/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6956 - accuracy: 0.6842 - val_loss: 0.7526 - val_accuracy: 0.6202\n",
      "Epoch 186/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7128 - accuracy: 0.6670 - val_loss: 0.7787 - val_accuracy: 0.6298\n",
      "Epoch 187/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6974 - accuracy: 0.6803 - val_loss: 0.8164 - val_accuracy: 0.5940\n",
      "Epoch 188/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6915 - accuracy: 0.6795 - val_loss: 0.7594 - val_accuracy: 0.6226\n",
      "Epoch 189/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7050 - accuracy: 0.6766 - val_loss: 0.9945 - val_accuracy: 0.5500\n",
      "Epoch 190/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6986 - accuracy: 0.6762 - val_loss: 0.7850 - val_accuracy: 0.6179\n",
      "Epoch 191/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6851 - accuracy: 0.6826 - val_loss: 0.7829 - val_accuracy: 0.6083\n",
      "Epoch 192/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7168 - accuracy: 0.6695 - val_loss: 0.7691 - val_accuracy: 0.6417\n",
      "Epoch 193/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6803 - accuracy: 0.6852 - val_loss: 0.8397 - val_accuracy: 0.6012\n",
      "Epoch 194/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7069 - accuracy: 0.6735 - val_loss: 0.7801 - val_accuracy: 0.6345\n",
      "Epoch 195/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6876 - accuracy: 0.6823 - val_loss: 0.7743 - val_accuracy: 0.6321\n",
      "Epoch 196/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6767 - accuracy: 0.6929 - val_loss: 0.7762 - val_accuracy: 0.6083\n",
      "Epoch 197/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6736 - accuracy: 0.6979 - val_loss: 0.7974 - val_accuracy: 0.6238\n",
      "Epoch 198/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6692 - accuracy: 0.6960 - val_loss: 0.7856 - val_accuracy: 0.6417\n",
      "Epoch 199/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6962 - accuracy: 0.6851 - val_loss: 0.8431 - val_accuracy: 0.6143\n",
      "Epoch 200/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6949 - accuracy: 0.6861 - val_loss: 0.7218 - val_accuracy: 0.6369\n",
      "Epoch 201/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6631 - accuracy: 0.7032 - val_loss: 0.8382 - val_accuracy: 0.6036\n",
      "Epoch 202/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6647 - accuracy: 0.6953 - val_loss: 0.7414 - val_accuracy: 0.6798\n",
      "Epoch 203/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6604 - accuracy: 0.6994 - val_loss: 0.7921 - val_accuracy: 0.6429\n",
      "Epoch 204/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6592 - accuracy: 0.7021 - val_loss: 0.8706 - val_accuracy: 0.6071\n",
      "Epoch 205/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6397 - accuracy: 0.7124 - val_loss: 0.8531 - val_accuracy: 0.6357\n",
      "Epoch 206/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.6553 - accuracy: 0.7062 - val_loss: 0.9904 - val_accuracy: 0.6274\n",
      "Epoch 207/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6554 - accuracy: 0.6979 - val_loss: 0.7245 - val_accuracy: 0.6607\n",
      "Epoch 208/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6620 - accuracy: 0.7056 - val_loss: 0.8175 - val_accuracy: 0.6048\n",
      "Epoch 209/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6615 - accuracy: 0.6990 - val_loss: 0.7343 - val_accuracy: 0.6440\n",
      "Epoch 210/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6647 - accuracy: 0.6980 - val_loss: 0.7655 - val_accuracy: 0.6333\n",
      "Epoch 211/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6535 - accuracy: 0.7068 - val_loss: 0.7474 - val_accuracy: 0.6821\n",
      "Epoch 212/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6431 - accuracy: 0.7088 - val_loss: 0.7857 - val_accuracy: 0.6762\n",
      "Epoch 213/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6309 - accuracy: 0.7160 - val_loss: 0.7891 - val_accuracy: 0.6250\n",
      "Epoch 214/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6374 - accuracy: 0.7119 - val_loss: 0.7644 - val_accuracy: 0.6440\n",
      "Epoch 215/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6355 - accuracy: 0.7098 - val_loss: 0.7017 - val_accuracy: 0.6845\n",
      "Epoch 216/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6408 - accuracy: 0.7136 - val_loss: 0.7113 - val_accuracy: 0.7167\n",
      "Epoch 217/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6384 - accuracy: 0.7108 - val_loss: 0.6897 - val_accuracy: 0.6452\n",
      "Epoch 218/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6590 - accuracy: 0.6975 - val_loss: 0.7889 - val_accuracy: 0.6274\n",
      "Epoch 219/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6313 - accuracy: 0.7107 - val_loss: 0.7782 - val_accuracy: 0.6845\n",
      "Epoch 220/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6077 - accuracy: 0.7248 - val_loss: 0.8757 - val_accuracy: 0.6738\n",
      "Epoch 221/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6277 - accuracy: 0.7193 - val_loss: 0.7213 - val_accuracy: 0.6393\n",
      "Epoch 222/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6222 - accuracy: 0.7225 - val_loss: 0.7202 - val_accuracy: 0.6738\n",
      "Epoch 223/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6169 - accuracy: 0.7270 - val_loss: 0.8823 - val_accuracy: 0.6250\n",
      "Epoch 224/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6332 - accuracy: 0.7096 - val_loss: 0.6593 - val_accuracy: 0.7131\n",
      "Epoch 225/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6275 - accuracy: 0.7148 - val_loss: 0.7114 - val_accuracy: 0.6845\n",
      "Epoch 226/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6438 - accuracy: 0.7092 - val_loss: 0.7145 - val_accuracy: 0.6714\n",
      "Epoch 227/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6113 - accuracy: 0.7215 - val_loss: 0.9210 - val_accuracy: 0.6000\n",
      "Epoch 228/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6049 - accuracy: 0.7320 - val_loss: 0.7362 - val_accuracy: 0.6917\n",
      "Epoch 229/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6147 - accuracy: 0.7233 - val_loss: 0.9358 - val_accuracy: 0.6929\n",
      "Epoch 230/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6180 - accuracy: 0.7262 - val_loss: 0.8445 - val_accuracy: 0.6155\n",
      "Epoch 231/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5882 - accuracy: 0.7333 - val_loss: 0.7290 - val_accuracy: 0.6750\n",
      "Epoch 232/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6090 - accuracy: 0.7266 - val_loss: 0.8313 - val_accuracy: 0.6476\n",
      "Epoch 233/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6026 - accuracy: 0.7301 - val_loss: 0.7746 - val_accuracy: 0.7155\n",
      "Epoch 234/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6050 - accuracy: 0.7292 - val_loss: 0.8299 - val_accuracy: 0.6679\n",
      "Epoch 235/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5948 - accuracy: 0.7353 - val_loss: 0.7011 - val_accuracy: 0.7024\n",
      "Epoch 236/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5772 - accuracy: 0.7516 - val_loss: 0.7771 - val_accuracy: 0.7274\n",
      "Epoch 237/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6004 - accuracy: 0.7285 - val_loss: 0.7038 - val_accuracy: 0.6952\n",
      "Epoch 238/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5983 - accuracy: 0.7342 - val_loss: 0.6292 - val_accuracy: 0.7250\n",
      "Epoch 239/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5801 - accuracy: 0.7418 - val_loss: 0.8273 - val_accuracy: 0.6179\n",
      "Epoch 240/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6013 - accuracy: 0.7270 - val_loss: 0.6748 - val_accuracy: 0.6929\n",
      "Epoch 241/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5594 - accuracy: 0.7544 - val_loss: 0.6890 - val_accuracy: 0.6964\n",
      "Epoch 242/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5820 - accuracy: 0.7371 - val_loss: 0.8506 - val_accuracy: 0.6012\n",
      "Epoch 243/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5854 - accuracy: 0.7415 - val_loss: 0.6978 - val_accuracy: 0.6762\n",
      "Epoch 244/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5706 - accuracy: 0.7466 - val_loss: 0.7282 - val_accuracy: 0.6774\n",
      "Epoch 245/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5703 - accuracy: 0.7517 - val_loss: 0.6564 - val_accuracy: 0.7381\n",
      "Epoch 246/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5788 - accuracy: 0.7418 - val_loss: 0.8844 - val_accuracy: 0.6571\n",
      "Epoch 247/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5525 - accuracy: 0.7576 - val_loss: 0.7087 - val_accuracy: 0.7060\n",
      "Epoch 248/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5583 - accuracy: 0.7541 - val_loss: 0.6366 - val_accuracy: 0.7488\n",
      "Epoch 249/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5644 - accuracy: 0.7545 - val_loss: 0.8191 - val_accuracy: 0.7119\n",
      "Epoch 250/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5648 - accuracy: 0.7536 - val_loss: 0.7708 - val_accuracy: 0.6833\n",
      "Epoch 251/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5468 - accuracy: 0.7613 - val_loss: 0.6321 - val_accuracy: 0.7524\n",
      "Epoch 252/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5471 - accuracy: 0.7621 - val_loss: 0.7959 - val_accuracy: 0.6976\n",
      "Epoch 253/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5614 - accuracy: 0.7515 - val_loss: 0.6914 - val_accuracy: 0.7167\n",
      "Epoch 254/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5437 - accuracy: 0.7602 - val_loss: 0.6999 - val_accuracy: 0.7024\n",
      "Epoch 255/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5406 - accuracy: 0.7639 - val_loss: 0.7091 - val_accuracy: 0.7119\n",
      "Epoch 256/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5488 - accuracy: 0.7608 - val_loss: 0.6817 - val_accuracy: 0.7179\n",
      "Epoch 257/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5219 - accuracy: 0.7740 - val_loss: 0.6781 - val_accuracy: 0.7214\n",
      "Epoch 258/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5842 - accuracy: 0.7415 - val_loss: 0.7130 - val_accuracy: 0.6667\n",
      "Epoch 259/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5202 - accuracy: 0.7719 - val_loss: 0.6873 - val_accuracy: 0.7048\n",
      "Epoch 260/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5647 - accuracy: 0.7562 - val_loss: 0.8884 - val_accuracy: 0.6690\n",
      "Epoch 261/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5394 - accuracy: 0.7672 - val_loss: 0.6122 - val_accuracy: 0.7583\n",
      "Epoch 262/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5197 - accuracy: 0.7736 - val_loss: 0.6490 - val_accuracy: 0.7262\n",
      "Epoch 263/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5249 - accuracy: 0.7660 - val_loss: 0.8369 - val_accuracy: 0.6655\n",
      "Epoch 264/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5476 - accuracy: 0.7626 - val_loss: 0.6170 - val_accuracy: 0.7262\n",
      "Epoch 265/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5326 - accuracy: 0.7628 - val_loss: 0.8016 - val_accuracy: 0.7238\n",
      "Epoch 266/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5348 - accuracy: 0.7673 - val_loss: 0.6668 - val_accuracy: 0.7381\n",
      "Epoch 267/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5258 - accuracy: 0.7706 - val_loss: 0.7606 - val_accuracy: 0.6893\n",
      "Epoch 268/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5217 - accuracy: 0.7708 - val_loss: 0.6570 - val_accuracy: 0.7107\n",
      "Epoch 269/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5256 - accuracy: 0.7767 - val_loss: 0.6225 - val_accuracy: 0.7381\n",
      "Epoch 270/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5485 - accuracy: 0.7675 - val_loss: 0.6640 - val_accuracy: 0.7024\n",
      "Epoch 271/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5791 - accuracy: 0.7500 - val_loss: 0.6860 - val_accuracy: 0.6881\n",
      "Epoch 272/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5060 - accuracy: 0.7786 - val_loss: 0.6268 - val_accuracy: 0.7286\n",
      "Epoch 273/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5334 - accuracy: 0.7677 - val_loss: 0.7958 - val_accuracy: 0.6524\n",
      "Epoch 274/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5179 - accuracy: 0.7755 - val_loss: 0.6404 - val_accuracy: 0.7298\n",
      "Epoch 275/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5030 - accuracy: 0.7838 - val_loss: 0.6933 - val_accuracy: 0.7095\n",
      "Epoch 276/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5355 - accuracy: 0.7748 - val_loss: 0.6726 - val_accuracy: 0.7333\n",
      "Epoch 277/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4955 - accuracy: 0.7888 - val_loss: 0.9787 - val_accuracy: 0.5988\n",
      "Epoch 278/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5015 - accuracy: 0.7841 - val_loss: 0.7742 - val_accuracy: 0.7119\n",
      "Epoch 279/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5005 - accuracy: 0.7862 - val_loss: 0.8069 - val_accuracy: 0.7143\n",
      "Epoch 280/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5125 - accuracy: 0.7781 - val_loss: 0.7331 - val_accuracy: 0.7155\n",
      "Epoch 281/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5094 - accuracy: 0.7791 - val_loss: 0.9053 - val_accuracy: 0.6667\n",
      "Epoch 282/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4889 - accuracy: 0.7905 - val_loss: 0.9200 - val_accuracy: 0.7250\n",
      "Epoch 283/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4835 - accuracy: 0.7897 - val_loss: 0.7897 - val_accuracy: 0.7131\n",
      "Epoch 284/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4892 - accuracy: 0.7903 - val_loss: 0.8487 - val_accuracy: 0.6917\n",
      "Epoch 285/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4947 - accuracy: 0.7854 - val_loss: 0.9602 - val_accuracy: 0.6167\n",
      "Epoch 286/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4801 - accuracy: 0.7951 - val_loss: 0.9316 - val_accuracy: 0.6405\n",
      "Epoch 287/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4777 - accuracy: 0.7933 - val_loss: 0.6305 - val_accuracy: 0.7286\n",
      "Epoch 288/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5082 - accuracy: 0.7871 - val_loss: 0.6447 - val_accuracy: 0.7274\n",
      "Epoch 289/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4760 - accuracy: 0.8004 - val_loss: 0.8619 - val_accuracy: 0.6286\n",
      "Epoch 290/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5041 - accuracy: 0.7874 - val_loss: 0.7380 - val_accuracy: 0.7381\n",
      "Epoch 291/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5116 - accuracy: 0.7826 - val_loss: 0.9806 - val_accuracy: 0.6071\n",
      "Epoch 292/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4725 - accuracy: 0.7979 - val_loss: 0.6943 - val_accuracy: 0.6988\n",
      "Epoch 293/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4671 - accuracy: 0.7989 - val_loss: 0.7950 - val_accuracy: 0.6845\n",
      "Epoch 294/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4619 - accuracy: 0.7979 - val_loss: 0.7412 - val_accuracy: 0.6774\n",
      "Epoch 295/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4849 - accuracy: 0.7928 - val_loss: 0.9098 - val_accuracy: 0.6286\n",
      "Epoch 296/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4698 - accuracy: 0.8029 - val_loss: 0.9491 - val_accuracy: 0.6274\n",
      "Epoch 297/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4763 - accuracy: 0.7984 - val_loss: 0.7074 - val_accuracy: 0.7167\n",
      "Epoch 298/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4596 - accuracy: 0.8014 - val_loss: 0.7153 - val_accuracy: 0.7202\n",
      "Epoch 299/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4904 - accuracy: 0.7899 - val_loss: 0.7082 - val_accuracy: 0.7429\n",
      "Epoch 300/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4481 - accuracy: 0.8082 - val_loss: 0.6520 - val_accuracy: 0.7381\n",
      "Epoch 301/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4730 - accuracy: 0.7956 - val_loss: 0.5877 - val_accuracy: 0.7476\n",
      "Epoch 302/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4586 - accuracy: 0.8042 - val_loss: 0.6390 - val_accuracy: 0.7381\n",
      "Epoch 303/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4581 - accuracy: 0.8071 - val_loss: 0.6905 - val_accuracy: 0.7190\n",
      "Epoch 304/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4569 - accuracy: 0.8082 - val_loss: 0.6706 - val_accuracy: 0.7155\n",
      "Epoch 305/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4640 - accuracy: 0.8002 - val_loss: 0.6049 - val_accuracy: 0.7500\n",
      "Epoch 306/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4516 - accuracy: 0.8078 - val_loss: 0.6861 - val_accuracy: 0.7060\n",
      "Epoch 307/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4729 - accuracy: 0.7979 - val_loss: 0.7174 - val_accuracy: 0.7071\n",
      "Epoch 308/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4410 - accuracy: 0.8144 - val_loss: 0.6462 - val_accuracy: 0.7393\n",
      "Epoch 309/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4621 - accuracy: 0.8076 - val_loss: 0.6681 - val_accuracy: 0.7393\n",
      "Epoch 310/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4630 - accuracy: 0.8106 - val_loss: 0.6457 - val_accuracy: 0.7262\n",
      "Epoch 311/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4385 - accuracy: 0.8100 - val_loss: 0.6275 - val_accuracy: 0.7095\n",
      "Epoch 312/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4348 - accuracy: 0.8136 - val_loss: 0.6900 - val_accuracy: 0.7345\n",
      "Epoch 313/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4608 - accuracy: 0.8031 - val_loss: 0.7816 - val_accuracy: 0.7048\n",
      "Epoch 314/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4360 - accuracy: 0.8146 - val_loss: 0.7861 - val_accuracy: 0.6810\n",
      "Epoch 315/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4693 - accuracy: 0.8019 - val_loss: 0.7351 - val_accuracy: 0.7167\n",
      "Epoch 316/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4240 - accuracy: 0.8183 - val_loss: 0.6927 - val_accuracy: 0.6857\n",
      "Epoch 317/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4424 - accuracy: 0.8128 - val_loss: 0.7203 - val_accuracy: 0.7214\n",
      "Epoch 318/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4207 - accuracy: 0.8251 - val_loss: 0.7389 - val_accuracy: 0.7119\n",
      "Epoch 319/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4451 - accuracy: 0.8159 - val_loss: 0.8006 - val_accuracy: 0.6869\n",
      "Epoch 320/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4407 - accuracy: 0.8106 - val_loss: 0.5688 - val_accuracy: 0.7440\n",
      "Epoch 321/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4419 - accuracy: 0.8195 - val_loss: 0.7719 - val_accuracy: 0.6667\n",
      "Epoch 322/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4508 - accuracy: 0.8143 - val_loss: 0.6657 - val_accuracy: 0.7607\n",
      "Epoch 323/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4167 - accuracy: 0.8259 - val_loss: 0.7403 - val_accuracy: 0.7250\n",
      "Epoch 324/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4307 - accuracy: 0.8132 - val_loss: 0.7275 - val_accuracy: 0.6893\n",
      "Epoch 325/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4272 - accuracy: 0.8250 - val_loss: 0.7274 - val_accuracy: 0.7083\n",
      "Epoch 326/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4352 - accuracy: 0.8159 - val_loss: 0.7049 - val_accuracy: 0.7083\n",
      "Epoch 327/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4129 - accuracy: 0.8274 - val_loss: 0.8330 - val_accuracy: 0.6917\n",
      "Epoch 328/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4177 - accuracy: 0.8245 - val_loss: 0.8065 - val_accuracy: 0.7060\n",
      "Epoch 329/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4253 - accuracy: 0.8260 - val_loss: 0.7780 - val_accuracy: 0.6774\n",
      "Epoch 330/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4280 - accuracy: 0.8194 - val_loss: 0.7105 - val_accuracy: 0.6833\n",
      "Epoch 331/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4227 - accuracy: 0.8208 - val_loss: 0.6238 - val_accuracy: 0.7440\n",
      "Epoch 332/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4199 - accuracy: 0.8308 - val_loss: 0.7033 - val_accuracy: 0.7226\n",
      "Epoch 333/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4305 - accuracy: 0.8211 - val_loss: 0.7190 - val_accuracy: 0.7238\n",
      "Epoch 334/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3954 - accuracy: 0.8402 - val_loss: 0.7433 - val_accuracy: 0.7238\n",
      "Epoch 335/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4158 - accuracy: 0.8236 - val_loss: 0.8110 - val_accuracy: 0.6845\n",
      "Epoch 336/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4152 - accuracy: 0.8252 - val_loss: 0.6292 - val_accuracy: 0.7369\n",
      "Epoch 337/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4438 - accuracy: 0.8143 - val_loss: 0.6604 - val_accuracy: 0.7060\n",
      "Epoch 338/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4162 - accuracy: 0.8279 - val_loss: 0.6479 - val_accuracy: 0.6940\n",
      "Epoch 339/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3994 - accuracy: 0.8372 - val_loss: 0.8347 - val_accuracy: 0.6798\n",
      "Epoch 340/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4004 - accuracy: 0.8325 - val_loss: 0.8662 - val_accuracy: 0.7179\n",
      "Epoch 341/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3983 - accuracy: 0.8350 - val_loss: 0.6330 - val_accuracy: 0.7476\n",
      "Epoch 342/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3840 - accuracy: 0.8376 - val_loss: 0.6542 - val_accuracy: 0.6976\n",
      "Epoch 343/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3908 - accuracy: 0.8359 - val_loss: 0.7841 - val_accuracy: 0.7024\n",
      "Epoch 344/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4353 - accuracy: 0.8172 - val_loss: 0.6103 - val_accuracy: 0.7286\n",
      "Epoch 345/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4171 - accuracy: 0.8284 - val_loss: 0.8763 - val_accuracy: 0.6750\n",
      "Epoch 346/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4162 - accuracy: 0.8333 - val_loss: 0.5918 - val_accuracy: 0.7524\n",
      "Epoch 347/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3945 - accuracy: 0.8376 - val_loss: 0.8256 - val_accuracy: 0.6714\n",
      "Epoch 348/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3742 - accuracy: 0.8459 - val_loss: 0.7365 - val_accuracy: 0.6988\n",
      "Epoch 349/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4341 - accuracy: 0.8280 - val_loss: 0.7240 - val_accuracy: 0.7381\n",
      "Epoch 350/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3793 - accuracy: 0.8430 - val_loss: 0.6757 - val_accuracy: 0.7238\n",
      "Epoch 351/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4045 - accuracy: 0.8333 - val_loss: 0.6838 - val_accuracy: 0.7071\n",
      "Epoch 352/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4065 - accuracy: 0.8317 - val_loss: 0.6766 - val_accuracy: 0.7083\n",
      "Epoch 353/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3950 - accuracy: 0.8383 - val_loss: 0.6797 - val_accuracy: 0.7226\n",
      "Epoch 354/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3728 - accuracy: 0.8466 - val_loss: 0.6833 - val_accuracy: 0.7131\n",
      "Epoch 355/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3875 - accuracy: 0.8356 - val_loss: 0.7752 - val_accuracy: 0.7274\n",
      "Epoch 356/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3747 - accuracy: 0.8468 - val_loss: 0.6950 - val_accuracy: 0.7488\n",
      "Epoch 357/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4212 - accuracy: 0.8274 - val_loss: 0.7235 - val_accuracy: 0.7202\n",
      "Epoch 358/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3607 - accuracy: 0.8535 - val_loss: 0.6262 - val_accuracy: 0.7464\n",
      "Epoch 359/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3898 - accuracy: 0.8414 - val_loss: 0.7422 - val_accuracy: 0.6869\n",
      "Epoch 360/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3684 - accuracy: 0.8504 - val_loss: 0.7536 - val_accuracy: 0.7119\n",
      "Epoch 361/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3942 - accuracy: 0.8376 - val_loss: 0.7339 - val_accuracy: 0.7000\n",
      "Epoch 362/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3701 - accuracy: 0.8437 - val_loss: 0.7549 - val_accuracy: 0.7083\n",
      "Epoch 363/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3790 - accuracy: 0.8415 - val_loss: 0.8051 - val_accuracy: 0.6905\n",
      "Epoch 364/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3768 - accuracy: 0.8470 - val_loss: 0.6703 - val_accuracy: 0.7274\n",
      "Epoch 365/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4084 - accuracy: 0.8358 - val_loss: 0.7077 - val_accuracy: 0.7095\n",
      "Epoch 366/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3444 - accuracy: 0.8604 - val_loss: 0.5657 - val_accuracy: 0.7833\n",
      "Epoch 367/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3670 - accuracy: 0.8536 - val_loss: 0.6140 - val_accuracy: 0.7190\n",
      "Epoch 368/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3817 - accuracy: 0.8428 - val_loss: 0.6470 - val_accuracy: 0.7345\n",
      "Epoch 369/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3803 - accuracy: 0.8428 - val_loss: 0.7505 - val_accuracy: 0.7012\n",
      "Epoch 370/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3670 - accuracy: 0.8470 - val_loss: 0.7424 - val_accuracy: 0.6988\n",
      "Epoch 371/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3885 - accuracy: 0.8433 - val_loss: 0.5951 - val_accuracy: 0.7560\n",
      "Epoch 372/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3811 - accuracy: 0.8479 - val_loss: 0.8050 - val_accuracy: 0.6667\n",
      "Epoch 373/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3763 - accuracy: 0.8447 - val_loss: 0.6677 - val_accuracy: 0.7262\n",
      "Epoch 374/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3772 - accuracy: 0.8511 - val_loss: 0.6316 - val_accuracy: 0.7345\n",
      "Epoch 375/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3893 - accuracy: 0.8443 - val_loss: 0.6847 - val_accuracy: 0.7190\n",
      "Epoch 376/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3693 - accuracy: 0.8530 - val_loss: 0.6598 - val_accuracy: 0.7155\n",
      "Epoch 377/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3356 - accuracy: 0.8598 - val_loss: 0.6562 - val_accuracy: 0.7131\n",
      "Epoch 378/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3595 - accuracy: 0.8524 - val_loss: 0.6524 - val_accuracy: 0.7369\n",
      "Epoch 379/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3678 - accuracy: 0.8520 - val_loss: 0.6014 - val_accuracy: 0.7536\n",
      "Epoch 380/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3562 - accuracy: 0.8537 - val_loss: 0.7365 - val_accuracy: 0.7048\n",
      "Epoch 381/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3721 - accuracy: 0.8501 - val_loss: 0.7593 - val_accuracy: 0.7357\n",
      "Epoch 382/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3463 - accuracy: 0.8608 - val_loss: 0.8576 - val_accuracy: 0.6917\n",
      "Epoch 383/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4160 - accuracy: 0.8350 - val_loss: 0.6700 - val_accuracy: 0.6929\n",
      "Epoch 384/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4299 - accuracy: 0.7956 - val_loss: 0.6000 - val_accuracy: 0.7417\n",
      "Epoch 385/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4217 - accuracy: 0.8149 - val_loss: 0.7461 - val_accuracy: 0.7012\n",
      "Epoch 386/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4063 - accuracy: 0.8183 - val_loss: 0.5688 - val_accuracy: 0.7488\n",
      "Epoch 387/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3884 - accuracy: 0.8357 - val_loss: 0.5879 - val_accuracy: 0.7583\n",
      "Epoch 388/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3783 - accuracy: 0.8400 - val_loss: 0.5637 - val_accuracy: 0.7548\n",
      "Epoch 389/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3539 - accuracy: 0.8562 - val_loss: 0.6850 - val_accuracy: 0.7429\n",
      "Epoch 390/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3232 - accuracy: 0.8665 - val_loss: 0.5410 - val_accuracy: 0.7750\n",
      "Epoch 391/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3960 - accuracy: 0.8373 - val_loss: 0.6041 - val_accuracy: 0.7500\n",
      "Epoch 392/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3371 - accuracy: 0.8650 - val_loss: 0.6634 - val_accuracy: 0.7321\n",
      "Epoch 393/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3714 - accuracy: 0.8481 - val_loss: 0.5849 - val_accuracy: 0.7548\n",
      "Epoch 394/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3542 - accuracy: 0.8592 - val_loss: 0.8008 - val_accuracy: 0.6940\n",
      "Epoch 395/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3394 - accuracy: 0.8657 - val_loss: 0.7088 - val_accuracy: 0.7214\n",
      "Epoch 396/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3698 - accuracy: 0.8481 - val_loss: 0.6252 - val_accuracy: 0.7274\n",
      "Epoch 397/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3580 - accuracy: 0.8568 - val_loss: 0.6456 - val_accuracy: 0.7190\n",
      "Epoch 398/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3557 - accuracy: 0.8565 - val_loss: 0.6845 - val_accuracy: 0.7262\n",
      "Epoch 399/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3390 - accuracy: 0.8636 - val_loss: 0.6962 - val_accuracy: 0.7440\n",
      "Epoch 400/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3343 - accuracy: 0.8587 - val_loss: 0.9279 - val_accuracy: 0.6595\n",
      "Epoch 401/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3587 - accuracy: 0.8536 - val_loss: 0.8932 - val_accuracy: 0.6702\n",
      "Epoch 402/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3434 - accuracy: 0.8602 - val_loss: 0.8417 - val_accuracy: 0.7024\n",
      "Epoch 403/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3462 - accuracy: 0.8612 - val_loss: 0.5725 - val_accuracy: 0.7571\n",
      "Epoch 404/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3561 - accuracy: 0.8566 - val_loss: 0.6836 - val_accuracy: 0.7321\n",
      "Epoch 405/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3444 - accuracy: 0.8567 - val_loss: 0.6526 - val_accuracy: 0.7357\n",
      "Epoch 406/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3325 - accuracy: 0.8692 - val_loss: 0.6610 - val_accuracy: 0.7286\n",
      "Epoch 407/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3423 - accuracy: 0.8607 - val_loss: 0.6458 - val_accuracy: 0.7274\n",
      "Epoch 408/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3025 - accuracy: 0.8764 - val_loss: 0.6928 - val_accuracy: 0.7238\n",
      "Epoch 409/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3373 - accuracy: 0.8648 - val_loss: 0.5772 - val_accuracy: 0.7738\n",
      "Epoch 410/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3327 - accuracy: 0.8648 - val_loss: 0.6693 - val_accuracy: 0.7321\n",
      "Epoch 411/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3115 - accuracy: 0.8708 - val_loss: 0.6613 - val_accuracy: 0.7190\n",
      "Epoch 412/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3275 - accuracy: 0.8652 - val_loss: 0.6020 - val_accuracy: 0.7679\n",
      "Epoch 413/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3623 - accuracy: 0.8557 - val_loss: 0.5902 - val_accuracy: 0.7750\n",
      "Epoch 414/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3206 - accuracy: 0.8694 - val_loss: 0.5883 - val_accuracy: 0.7500\n",
      "Epoch 415/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3253 - accuracy: 0.8724 - val_loss: 0.8098 - val_accuracy: 0.6905\n",
      "Epoch 416/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3447 - accuracy: 0.8653 - val_loss: 0.5932 - val_accuracy: 0.7512\n",
      "Epoch 417/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2954 - accuracy: 0.8780 - val_loss: 0.7453 - val_accuracy: 0.7226\n",
      "Epoch 418/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3434 - accuracy: 0.8613 - val_loss: 0.7917 - val_accuracy: 0.7119\n",
      "Epoch 419/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2986 - accuracy: 0.8806 - val_loss: 0.6630 - val_accuracy: 0.7381\n",
      "Epoch 420/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3345 - accuracy: 0.8683 - val_loss: 0.8933 - val_accuracy: 0.7060\n",
      "Epoch 421/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3196 - accuracy: 0.8697 - val_loss: 0.6526 - val_accuracy: 0.7512\n",
      "Epoch 422/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3201 - accuracy: 0.8700 - val_loss: 0.6682 - val_accuracy: 0.7381\n",
      "Epoch 423/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3220 - accuracy: 0.8704 - val_loss: 0.6670 - val_accuracy: 0.7440\n",
      "Epoch 424/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2918 - accuracy: 0.8846 - val_loss: 0.6235 - val_accuracy: 0.7369\n",
      "Epoch 425/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3455 - accuracy: 0.8687 - val_loss: 0.7166 - val_accuracy: 0.7262\n",
      "Epoch 426/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3150 - accuracy: 0.8792 - val_loss: 0.7556 - val_accuracy: 0.7131\n",
      "Epoch 427/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3049 - accuracy: 0.8794 - val_loss: 0.7081 - val_accuracy: 0.7190\n",
      "Epoch 428/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3030 - accuracy: 0.8789 - val_loss: 0.6345 - val_accuracy: 0.7381\n",
      "Epoch 429/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3079 - accuracy: 0.8750 - val_loss: 0.7263 - val_accuracy: 0.7310\n",
      "Epoch 430/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3158 - accuracy: 0.8733 - val_loss: 0.6384 - val_accuracy: 0.7226\n",
      "Epoch 431/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3393 - accuracy: 0.8633 - val_loss: 0.6596 - val_accuracy: 0.7107\n",
      "Epoch 432/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3024 - accuracy: 0.8774 - val_loss: 0.6241 - val_accuracy: 0.7655\n",
      "Epoch 433/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3059 - accuracy: 0.8703 - val_loss: 0.6883 - val_accuracy: 0.7095\n",
      "Epoch 434/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3155 - accuracy: 0.8711 - val_loss: 0.6749 - val_accuracy: 0.7417\n",
      "Epoch 435/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3178 - accuracy: 0.8715 - val_loss: 0.6409 - val_accuracy: 0.7464\n",
      "Epoch 436/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3202 - accuracy: 0.8777 - val_loss: 1.6103 - val_accuracy: 0.4917\n",
      "Epoch 437/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3225 - accuracy: 0.8728 - val_loss: 0.6660 - val_accuracy: 0.7286\n",
      "Epoch 438/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3168 - accuracy: 0.8706 - val_loss: 0.6534 - val_accuracy: 0.7369\n",
      "Epoch 439/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3100 - accuracy: 0.8776 - val_loss: 0.7737 - val_accuracy: 0.6774\n",
      "Epoch 440/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3126 - accuracy: 0.8744 - val_loss: 0.7018 - val_accuracy: 0.7119\n",
      "Epoch 441/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2969 - accuracy: 0.8766 - val_loss: 0.7175 - val_accuracy: 0.7262\n",
      "Epoch 442/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3186 - accuracy: 0.8740 - val_loss: 0.6422 - val_accuracy: 0.7679\n",
      "Epoch 443/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3219 - accuracy: 0.8688 - val_loss: 0.6713 - val_accuracy: 0.7321\n",
      "Epoch 444/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2818 - accuracy: 0.8850 - val_loss: 0.7712 - val_accuracy: 0.7250\n",
      "Epoch 445/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3134 - accuracy: 0.8746 - val_loss: 0.6607 - val_accuracy: 0.7429\n",
      "Epoch 446/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2840 - accuracy: 0.8848 - val_loss: 0.6491 - val_accuracy: 0.7500\n",
      "Epoch 447/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3273 - accuracy: 0.8697 - val_loss: 0.6193 - val_accuracy: 0.7536\n",
      "Epoch 448/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2985 - accuracy: 0.8790 - val_loss: 0.6370 - val_accuracy: 0.7476\n",
      "Epoch 449/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3083 - accuracy: 0.8772 - val_loss: 0.7221 - val_accuracy: 0.7119\n",
      "Epoch 450/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2709 - accuracy: 0.8915 - val_loss: 0.6981 - val_accuracy: 0.7345\n",
      "Epoch 451/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3255 - accuracy: 0.8749 - val_loss: 0.6479 - val_accuracy: 0.7512\n",
      "Epoch 452/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2941 - accuracy: 0.8818 - val_loss: 0.8135 - val_accuracy: 0.7071\n",
      "Epoch 453/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3021 - accuracy: 0.8757 - val_loss: 0.6128 - val_accuracy: 0.7524\n",
      "Epoch 454/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2759 - accuracy: 0.8902 - val_loss: 0.7260 - val_accuracy: 0.7071\n",
      "Epoch 455/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3283 - accuracy: 0.8683 - val_loss: 0.6105 - val_accuracy: 0.7726\n",
      "Epoch 456/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3278 - accuracy: 0.8774 - val_loss: 0.7138 - val_accuracy: 0.7155\n",
      "Epoch 457/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3155 - accuracy: 0.8745 - val_loss: 0.6941 - val_accuracy: 0.7250\n",
      "Epoch 458/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2717 - accuracy: 0.8898 - val_loss: 0.7269 - val_accuracy: 0.7060\n",
      "Epoch 459/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2903 - accuracy: 0.8812 - val_loss: 0.6590 - val_accuracy: 0.7512\n",
      "Epoch 460/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2907 - accuracy: 0.8816 - val_loss: 0.6457 - val_accuracy: 0.7762\n",
      "Epoch 461/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2778 - accuracy: 0.8933 - val_loss: 0.6828 - val_accuracy: 0.7298\n",
      "Epoch 462/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3068 - accuracy: 0.8769 - val_loss: 0.7824 - val_accuracy: 0.6952\n",
      "Epoch 463/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3217 - accuracy: 0.8662 - val_loss: 0.6923 - val_accuracy: 0.7155\n",
      "Epoch 464/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2979 - accuracy: 0.8776 - val_loss: 0.7083 - val_accuracy: 0.7286\n",
      "Epoch 465/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2849 - accuracy: 0.8833 - val_loss: 0.7324 - val_accuracy: 0.6976\n",
      "Epoch 466/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3183 - accuracy: 0.8693 - val_loss: 0.7607 - val_accuracy: 0.6905\n",
      "Epoch 467/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2879 - accuracy: 0.8850 - val_loss: 0.6580 - val_accuracy: 0.7464\n",
      "Epoch 468/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2792 - accuracy: 0.8877 - val_loss: 0.6927 - val_accuracy: 0.7500\n",
      "Epoch 469/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2948 - accuracy: 0.8850 - val_loss: 0.7112 - val_accuracy: 0.7190\n",
      "Epoch 470/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2944 - accuracy: 0.8781 - val_loss: 0.6405 - val_accuracy: 0.7488\n",
      "Epoch 471/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2912 - accuracy: 0.8857 - val_loss: 0.6819 - val_accuracy: 0.7429\n",
      "Epoch 472/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3060 - accuracy: 0.8812 - val_loss: 0.9354 - val_accuracy: 0.6714\n",
      "Epoch 473/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2956 - accuracy: 0.8836 - val_loss: 0.6614 - val_accuracy: 0.7393\n",
      "Epoch 474/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3075 - accuracy: 0.8756 - val_loss: 0.7926 - val_accuracy: 0.7560\n",
      "Epoch 475/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2554 - accuracy: 0.8965 - val_loss: 0.5996 - val_accuracy: 0.7619\n",
      "Epoch 476/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2723 - accuracy: 0.8910 - val_loss: 0.6667 - val_accuracy: 0.7429\n",
      "Epoch 477/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2644 - accuracy: 0.8943 - val_loss: 0.6766 - val_accuracy: 0.7357\n",
      "Epoch 478/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2701 - accuracy: 0.8877 - val_loss: 0.6752 - val_accuracy: 0.7321\n",
      "Epoch 479/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2683 - accuracy: 0.8947 - val_loss: 0.7275 - val_accuracy: 0.7417\n",
      "Epoch 480/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3071 - accuracy: 0.8818 - val_loss: 0.5954 - val_accuracy: 0.7524\n",
      "Epoch 481/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3410 - accuracy: 0.8745 - val_loss: 0.6475 - val_accuracy: 0.7274\n",
      "Epoch 482/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2973 - accuracy: 0.8820 - val_loss: 0.7331 - val_accuracy: 0.7214\n",
      "Epoch 483/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2731 - accuracy: 0.8942 - val_loss: 0.7272 - val_accuracy: 0.7214\n",
      "Epoch 484/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2590 - accuracy: 0.9001 - val_loss: 0.5927 - val_accuracy: 0.7738\n",
      "Epoch 485/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2479 - accuracy: 0.9035 - val_loss: 0.5988 - val_accuracy: 0.7845\n",
      "Epoch 486/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2622 - accuracy: 0.8980 - val_loss: 0.7313 - val_accuracy: 0.7238\n",
      "Epoch 487/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2723 - accuracy: 0.8898 - val_loss: 0.6797 - val_accuracy: 0.7369\n",
      "Epoch 488/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2547 - accuracy: 0.8989 - val_loss: 0.7496 - val_accuracy: 0.7464\n",
      "Epoch 489/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2714 - accuracy: 0.8940 - val_loss: 0.7133 - val_accuracy: 0.7393\n",
      "Epoch 490/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2987 - accuracy: 0.8841 - val_loss: 0.5897 - val_accuracy: 0.7643\n",
      "Epoch 491/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2490 - accuracy: 0.8969 - val_loss: 0.7481 - val_accuracy: 0.7179\n",
      "Epoch 492/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2798 - accuracy: 0.8852 - val_loss: 0.6862 - val_accuracy: 0.7381\n",
      "Epoch 493/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2569 - accuracy: 0.9000 - val_loss: 0.8888 - val_accuracy: 0.6821\n",
      "Epoch 494/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2620 - accuracy: 0.8988 - val_loss: 0.6401 - val_accuracy: 0.7357\n",
      "Epoch 495/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2608 - accuracy: 0.8978 - val_loss: 0.6752 - val_accuracy: 0.7452\n",
      "Epoch 496/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2573 - accuracy: 0.8951 - val_loss: 0.6366 - val_accuracy: 0.8024\n",
      "Epoch 497/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2639 - accuracy: 0.8929 - val_loss: 0.7828 - val_accuracy: 0.7155\n",
      "Epoch 498/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2423 - accuracy: 0.9046 - val_loss: 0.7258 - val_accuracy: 0.7619\n",
      "Epoch 499/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2738 - accuracy: 0.8925 - val_loss: 0.7410 - val_accuracy: 0.7583\n",
      "Epoch 500/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2860 - accuracy: 0.8842 - val_loss: 0.7573 - val_accuracy: 0.7226\n",
      "Epoch 501/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2530 - accuracy: 0.9010 - val_loss: 0.6649 - val_accuracy: 0.7595\n",
      "Epoch 502/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2847 - accuracy: 0.8874 - val_loss: 0.6277 - val_accuracy: 0.7667\n",
      "Epoch 503/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2464 - accuracy: 0.9030 - val_loss: 0.6759 - val_accuracy: 0.7607\n",
      "Epoch 504/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2696 - accuracy: 0.8927 - val_loss: 0.6363 - val_accuracy: 0.7988\n",
      "Epoch 505/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2415 - accuracy: 0.9015 - val_loss: 0.6818 - val_accuracy: 0.7548\n",
      "Epoch 506/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2856 - accuracy: 0.8888 - val_loss: 0.6458 - val_accuracy: 0.7571\n",
      "Epoch 507/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2872 - accuracy: 0.8877 - val_loss: 0.6502 - val_accuracy: 0.7536\n",
      "Epoch 508/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2647 - accuracy: 0.8933 - val_loss: 0.6942 - val_accuracy: 0.7440\n",
      "Epoch 509/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2679 - accuracy: 0.8918 - val_loss: 0.5931 - val_accuracy: 0.7655\n",
      "Epoch 510/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2823 - accuracy: 0.8903 - val_loss: 0.6588 - val_accuracy: 0.7619\n",
      "Epoch 511/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2694 - accuracy: 0.8944 - val_loss: 0.7165 - val_accuracy: 0.7095\n",
      "Epoch 512/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.2791 - accuracy: 0.8915 - val_loss: 0.6723 - val_accuracy: 0.7381\n",
      "Epoch 513/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2508 - accuracy: 0.8994 - val_loss: 0.6756 - val_accuracy: 0.7405\n",
      "Epoch 514/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2771 - accuracy: 0.8908 - val_loss: 0.6569 - val_accuracy: 0.7643\n",
      "Epoch 515/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2311 - accuracy: 0.9091 - val_loss: 0.7995 - val_accuracy: 0.7107\n",
      "Epoch 516/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2654 - accuracy: 0.9006 - val_loss: 0.6281 - val_accuracy: 0.7548\n",
      "Epoch 517/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3440 - accuracy: 0.8719 - val_loss: 0.6810 - val_accuracy: 0.7440\n",
      "Epoch 518/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2794 - accuracy: 0.8898 - val_loss: 0.7249 - val_accuracy: 0.7071\n",
      "Epoch 519/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2446 - accuracy: 0.9040 - val_loss: 0.6694 - val_accuracy: 0.7583\n",
      "Epoch 520/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2412 - accuracy: 0.9036 - val_loss: 0.7172 - val_accuracy: 0.7321\n",
      "Epoch 521/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2816 - accuracy: 0.8910 - val_loss: 0.7581 - val_accuracy: 0.6798\n",
      "Epoch 522/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2669 - accuracy: 0.8980 - val_loss: 0.7218 - val_accuracy: 0.7167\n",
      "Epoch 523/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2598 - accuracy: 0.8963 - val_loss: 0.6414 - val_accuracy: 0.7631\n",
      "Epoch 524/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2328 - accuracy: 0.9067 - val_loss: 0.7094 - val_accuracy: 0.7488\n",
      "Epoch 525/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2412 - accuracy: 0.9075 - val_loss: 0.6110 - val_accuracy: 0.7643\n",
      "Epoch 526/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2354 - accuracy: 0.9097 - val_loss: 0.8229 - val_accuracy: 0.7393\n",
      "Epoch 527/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2226 - accuracy: 0.9150 - val_loss: 0.7157 - val_accuracy: 0.7536\n",
      "Epoch 528/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2547 - accuracy: 0.9010 - val_loss: 0.7489 - val_accuracy: 0.7357\n",
      "Epoch 529/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2417 - accuracy: 0.9032 - val_loss: 0.6022 - val_accuracy: 0.7810\n",
      "Epoch 530/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2838 - accuracy: 0.8910 - val_loss: 0.6527 - val_accuracy: 0.7405\n",
      "Epoch 531/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2448 - accuracy: 0.9010 - val_loss: 0.6631 - val_accuracy: 0.7571\n",
      "Epoch 532/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2389 - accuracy: 0.9077 - val_loss: 0.7043 - val_accuracy: 0.7452\n",
      "Epoch 533/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2406 - accuracy: 0.9012 - val_loss: 0.7925 - val_accuracy: 0.7429\n",
      "Epoch 534/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2887 - accuracy: 0.8907 - val_loss: 0.6875 - val_accuracy: 0.7750\n",
      "Epoch 535/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2458 - accuracy: 0.9040 - val_loss: 0.6363 - val_accuracy: 0.7643\n",
      "Epoch 536/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2540 - accuracy: 0.8980 - val_loss: 0.7727 - val_accuracy: 0.7107\n",
      "Epoch 537/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2244 - accuracy: 0.9100 - val_loss: 0.6406 - val_accuracy: 0.7619\n",
      "Epoch 538/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2568 - accuracy: 0.9016 - val_loss: 0.9055 - val_accuracy: 0.6762\n",
      "Epoch 539/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2557 - accuracy: 0.8981 - val_loss: 0.6427 - val_accuracy: 0.7440\n",
      "Epoch 540/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2139 - accuracy: 0.9101 - val_loss: 0.8655 - val_accuracy: 0.7036\n",
      "Epoch 541/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2451 - accuracy: 0.8993 - val_loss: 0.8721 - val_accuracy: 0.7060\n",
      "Epoch 542/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3195 - accuracy: 0.8820 - val_loss: 0.6744 - val_accuracy: 0.7286\n",
      "Epoch 543/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2445 - accuracy: 0.8989 - val_loss: 0.6835 - val_accuracy: 0.7476\n",
      "Epoch 544/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2063 - accuracy: 0.9190 - val_loss: 0.8008 - val_accuracy: 0.7452\n",
      "Epoch 545/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2630 - accuracy: 0.8966 - val_loss: 0.6692 - val_accuracy: 0.7357\n",
      "Epoch 546/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2406 - accuracy: 0.9052 - val_loss: 0.6847 - val_accuracy: 0.7440\n",
      "Epoch 547/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2332 - accuracy: 0.9093 - val_loss: 0.6351 - val_accuracy: 0.7500\n",
      "Epoch 548/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2334 - accuracy: 0.9093 - val_loss: 0.6854 - val_accuracy: 0.7643\n",
      "Epoch 549/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2132 - accuracy: 0.9157 - val_loss: 0.6307 - val_accuracy: 0.7631\n",
      "Epoch 550/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2374 - accuracy: 0.9078 - val_loss: 0.8626 - val_accuracy: 0.7250\n",
      "Epoch 551/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2566 - accuracy: 0.9030 - val_loss: 0.7057 - val_accuracy: 0.7524\n",
      "Epoch 552/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2078 - accuracy: 0.9160 - val_loss: 0.6137 - val_accuracy: 0.7821\n",
      "Epoch 553/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2520 - accuracy: 0.8998 - val_loss: 0.7718 - val_accuracy: 0.7536\n",
      "Epoch 554/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2350 - accuracy: 0.9086 - val_loss: 0.6896 - val_accuracy: 0.7262\n",
      "Epoch 555/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2178 - accuracy: 0.9139 - val_loss: 0.6904 - val_accuracy: 0.7548\n",
      "Epoch 556/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2352 - accuracy: 0.9087 - val_loss: 0.8127 - val_accuracy: 0.7274\n",
      "Epoch 557/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2614 - accuracy: 0.8994 - val_loss: 0.6417 - val_accuracy: 0.7357\n",
      "Epoch 558/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2523 - accuracy: 0.9006 - val_loss: 0.6681 - val_accuracy: 0.7619\n",
      "Epoch 559/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2408 - accuracy: 0.9075 - val_loss: 0.6893 - val_accuracy: 0.7702\n",
      "Epoch 560/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2757 - accuracy: 0.8954 - val_loss: 0.6653 - val_accuracy: 0.7417\n",
      "Epoch 561/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2431 - accuracy: 0.9068 - val_loss: 0.6124 - val_accuracy: 0.7464\n",
      "Epoch 562/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2220 - accuracy: 0.9127 - val_loss: 0.5436 - val_accuracy: 0.7714\n",
      "Epoch 563/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2359 - accuracy: 0.9119 - val_loss: 0.6876 - val_accuracy: 0.7500\n",
      "Epoch 564/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2349 - accuracy: 0.9081 - val_loss: 0.6868 - val_accuracy: 0.7369\n",
      "Epoch 565/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2217 - accuracy: 0.9136 - val_loss: 0.6656 - val_accuracy: 0.7738\n",
      "Epoch 566/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2527 - accuracy: 0.9036 - val_loss: 0.6228 - val_accuracy: 0.7714\n",
      "Epoch 567/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2406 - accuracy: 0.9045 - val_loss: 0.7538 - val_accuracy: 0.7333\n",
      "Epoch 568/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2016 - accuracy: 0.9225 - val_loss: 0.7519 - val_accuracy: 0.7429\n",
      "Epoch 569/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2620 - accuracy: 0.8978 - val_loss: 0.6987 - val_accuracy: 0.7524\n",
      "Epoch 570/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2299 - accuracy: 0.9141 - val_loss: 0.7298 - val_accuracy: 0.7488\n",
      "Epoch 571/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2831 - accuracy: 0.8942 - val_loss: 0.6288 - val_accuracy: 0.7500\n",
      "Epoch 572/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2217 - accuracy: 0.9141 - val_loss: 0.8025 - val_accuracy: 0.7036\n",
      "Epoch 573/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2044 - accuracy: 0.9174 - val_loss: 0.7156 - val_accuracy: 0.7524\n",
      "Epoch 574/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2650 - accuracy: 0.9009 - val_loss: 0.6932 - val_accuracy: 0.7167\n",
      "Epoch 575/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.1992 - accuracy: 0.9226 - val_loss: 0.7221 - val_accuracy: 0.7500\n",
      "Epoch 576/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2229 - accuracy: 0.9146 - val_loss: 0.8074 - val_accuracy: 0.7131\n",
      "Epoch 577/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2677 - accuracy: 0.8927 - val_loss: 0.6012 - val_accuracy: 0.7869\n",
      "Epoch 578/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2115 - accuracy: 0.9199 - val_loss: 0.8258 - val_accuracy: 0.6762\n",
      "Epoch 579/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2252 - accuracy: 0.9126 - val_loss: 0.6834 - val_accuracy: 0.7500\n",
      "Epoch 580/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2250 - accuracy: 0.9127 - val_loss: 0.7422 - val_accuracy: 0.7333\n",
      "Epoch 581/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2332 - accuracy: 0.9119 - val_loss: 0.6373 - val_accuracy: 0.7643\n",
      "Epoch 582/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2248 - accuracy: 0.9081 - val_loss: 0.6712 - val_accuracy: 0.7667\n",
      "Epoch 583/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2097 - accuracy: 0.9179 - val_loss: 0.6975 - val_accuracy: 0.7333\n",
      "Epoch 584/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2145 - accuracy: 0.9139 - val_loss: 0.6060 - val_accuracy: 0.7607\n",
      "Epoch 585/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2308 - accuracy: 0.9090 - val_loss: 0.6766 - val_accuracy: 0.7298\n",
      "Epoch 586/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2214 - accuracy: 0.9116 - val_loss: 0.7551 - val_accuracy: 0.7167\n",
      "Epoch 587/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.1953 - accuracy: 0.9220 - val_loss: 0.7560 - val_accuracy: 0.7476\n",
      "Epoch 588/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2187 - accuracy: 0.9137 - val_loss: 0.7666 - val_accuracy: 0.7060\n",
      "Epoch 589/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.1836 - accuracy: 0.9257 - val_loss: 0.8303 - val_accuracy: 0.7405\n",
      "Epoch 590/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2457 - accuracy: 0.9041 - val_loss: 0.6436 - val_accuracy: 0.7643\n",
      "Epoch 591/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2256 - accuracy: 0.9111 - val_loss: 0.7383 - val_accuracy: 0.7429\n",
      "Epoch 592/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2165 - accuracy: 0.9126 - val_loss: 0.6890 - val_accuracy: 0.7512\n",
      "Epoch 593/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2109 - accuracy: 0.9197 - val_loss: 0.9089 - val_accuracy: 0.7214\n",
      "Epoch 594/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2250 - accuracy: 0.9180 - val_loss: 0.6915 - val_accuracy: 0.7762\n",
      "Epoch 595/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2242 - accuracy: 0.9143 - val_loss: 0.8724 - val_accuracy: 0.7071\n",
      "Epoch 596/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2219 - accuracy: 0.9108 - val_loss: 0.8908 - val_accuracy: 0.7238\n",
      "Epoch 597/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2093 - accuracy: 0.9211 - val_loss: 0.7326 - val_accuracy: 0.7500\n",
      "Epoch 598/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.1962 - accuracy: 0.9225 - val_loss: 0.6407 - val_accuracy: 0.7798\n",
      "Epoch 599/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2225 - accuracy: 0.9136 - val_loss: 0.7098 - val_accuracy: 0.7631\n",
      "Epoch 600/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2169 - accuracy: 0.9126 - val_loss: 0.7542 - val_accuracy: 0.7345\n",
      "Epoch 1/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0989 - accuracy: 0.3412 - val_loss: 1.0984 - val_accuracy: 0.3690\n",
      "Epoch 2/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0988 - accuracy: 0.3531 - val_loss: 1.0985 - val_accuracy: 0.3333\n",
      "Epoch 3/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0975 - accuracy: 0.3668 - val_loss: 1.0977 - val_accuracy: 0.3214\n",
      "Epoch 4/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0955 - accuracy: 0.3716 - val_loss: 1.0962 - val_accuracy: 0.3345\n",
      "Epoch 5/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0940 - accuracy: 0.3767 - val_loss: 1.0956 - val_accuracy: 0.3286\n",
      "Epoch 6/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0933 - accuracy: 0.3836 - val_loss: 1.0900 - val_accuracy: 0.3988\n",
      "Epoch 7/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0926 - accuracy: 0.3792 - val_loss: 1.0909 - val_accuracy: 0.3476\n",
      "Epoch 8/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0926 - accuracy: 0.3693 - val_loss: 1.0880 - val_accuracy: 0.3869\n",
      "Epoch 9/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0890 - accuracy: 0.3815 - val_loss: 1.0825 - val_accuracy: 0.3940\n",
      "Epoch 10/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0892 - accuracy: 0.3811 - val_loss: 1.0819 - val_accuracy: 0.3869\n",
      "Epoch 11/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0866 - accuracy: 0.3785 - val_loss: 1.0864 - val_accuracy: 0.3833\n",
      "Epoch 12/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0863 - accuracy: 0.3843 - val_loss: 1.0741 - val_accuracy: 0.4071\n",
      "Epoch 13/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0830 - accuracy: 0.3862 - val_loss: 1.0764 - val_accuracy: 0.4274\n",
      "Epoch 14/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0816 - accuracy: 0.3884 - val_loss: 1.0651 - val_accuracy: 0.4083\n",
      "Epoch 15/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0795 - accuracy: 0.3882 - val_loss: 1.0775 - val_accuracy: 0.4167\n",
      "Epoch 16/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0715 - accuracy: 0.4000 - val_loss: 1.0659 - val_accuracy: 0.3881\n",
      "Epoch 17/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0733 - accuracy: 0.3932 - val_loss: 1.0600 - val_accuracy: 0.4190\n",
      "Epoch 18/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0659 - accuracy: 0.4060 - val_loss: 1.0373 - val_accuracy: 0.4548\n",
      "Epoch 19/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0676 - accuracy: 0.4039 - val_loss: 1.0540 - val_accuracy: 0.4429\n",
      "Epoch 20/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0636 - accuracy: 0.4088 - val_loss: 1.0473 - val_accuracy: 0.4429\n",
      "Epoch 21/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0587 - accuracy: 0.4122 - val_loss: 1.0417 - val_accuracy: 0.4500\n",
      "Epoch 22/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0571 - accuracy: 0.4098 - val_loss: 1.0460 - val_accuracy: 0.4464\n",
      "Epoch 23/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0570 - accuracy: 0.4174 - val_loss: 1.0415 - val_accuracy: 0.4810\n",
      "Epoch 24/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0541 - accuracy: 0.4124 - val_loss: 1.0246 - val_accuracy: 0.4738\n",
      "Epoch 25/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0472 - accuracy: 0.4302 - val_loss: 1.0445 - val_accuracy: 0.4667\n",
      "Epoch 26/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0414 - accuracy: 0.4214 - val_loss: 1.0197 - val_accuracy: 0.4667\n",
      "Epoch 27/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0434 - accuracy: 0.4286 - val_loss: 1.0163 - val_accuracy: 0.4643\n",
      "Epoch 28/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0437 - accuracy: 0.4318 - val_loss: 1.0325 - val_accuracy: 0.4631\n",
      "Epoch 29/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0436 - accuracy: 0.4234 - val_loss: 1.0186 - val_accuracy: 0.4476\n",
      "Epoch 30/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0292 - accuracy: 0.4394 - val_loss: 1.0144 - val_accuracy: 0.4500\n",
      "Epoch 31/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0382 - accuracy: 0.4332 - val_loss: 0.9965 - val_accuracy: 0.4702\n",
      "Epoch 32/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0297 - accuracy: 0.4384 - val_loss: 1.0157 - val_accuracy: 0.4298\n",
      "Epoch 33/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0250 - accuracy: 0.4409 - val_loss: 1.0020 - val_accuracy: 0.4560\n",
      "Epoch 34/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0250 - accuracy: 0.4357 - val_loss: 1.0156 - val_accuracy: 0.4595\n",
      "Epoch 35/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0189 - accuracy: 0.4468 - val_loss: 1.0070 - val_accuracy: 0.4595\n",
      "Epoch 36/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0229 - accuracy: 0.4542 - val_loss: 1.0123 - val_accuracy: 0.4464\n",
      "Epoch 37/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0146 - accuracy: 0.4530 - val_loss: 1.0013 - val_accuracy: 0.4750\n",
      "Epoch 38/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0198 - accuracy: 0.4514 - val_loss: 0.9951 - val_accuracy: 0.4810\n",
      "Epoch 39/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0051 - accuracy: 0.4652 - val_loss: 1.0022 - val_accuracy: 0.4702\n",
      "Epoch 40/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 1.0072 - accuracy: 0.4659 - val_loss: 1.0053 - val_accuracy: 0.4714\n",
      "Epoch 41/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0015 - accuracy: 0.4725 - val_loss: 0.9553 - val_accuracy: 0.5071\n",
      "Epoch 42/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9996 - accuracy: 0.4812 - val_loss: 0.9857 - val_accuracy: 0.4893\n",
      "Epoch 43/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9946 - accuracy: 0.4782 - val_loss: 0.9875 - val_accuracy: 0.4881\n",
      "Epoch 44/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9913 - accuracy: 0.4852 - val_loss: 0.9750 - val_accuracy: 0.4679\n",
      "Epoch 45/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9983 - accuracy: 0.4761 - val_loss: 0.9707 - val_accuracy: 0.5024\n",
      "Epoch 46/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9793 - accuracy: 0.4998 - val_loss: 0.9596 - val_accuracy: 0.5333\n",
      "Epoch 47/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9838 - accuracy: 0.4888 - val_loss: 0.9460 - val_accuracy: 0.5405\n",
      "Epoch 48/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9905 - accuracy: 0.4822 - val_loss: 0.9458 - val_accuracy: 0.5226\n",
      "Epoch 49/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9772 - accuracy: 0.5046 - val_loss: 0.9377 - val_accuracy: 0.5298\n",
      "Epoch 50/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9723 - accuracy: 0.5087 - val_loss: 0.9501 - val_accuracy: 0.5119\n",
      "Epoch 51/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9747 - accuracy: 0.5071 - val_loss: 0.9480 - val_accuracy: 0.5012\n",
      "Epoch 52/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.9768 - accuracy: 0.5035 - val_loss: 0.9293 - val_accuracy: 0.5310\n",
      "Epoch 53/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9743 - accuracy: 0.5042 - val_loss: 1.0153 - val_accuracy: 0.4726\n",
      "Epoch 54/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9714 - accuracy: 0.5086 - val_loss: 0.9745 - val_accuracy: 0.4667\n",
      "Epoch 55/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9536 - accuracy: 0.5238 - val_loss: 0.9369 - val_accuracy: 0.4905\n",
      "Epoch 56/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9628 - accuracy: 0.5065 - val_loss: 0.9271 - val_accuracy: 0.5345\n",
      "Epoch 57/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9543 - accuracy: 0.5163 - val_loss: 0.9234 - val_accuracy: 0.5476\n",
      "Epoch 58/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9605 - accuracy: 0.5226 - val_loss: 0.9366 - val_accuracy: 0.5595\n",
      "Epoch 59/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9542 - accuracy: 0.5173 - val_loss: 0.9680 - val_accuracy: 0.5119\n",
      "Epoch 60/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9516 - accuracy: 0.5303 - val_loss: 0.9320 - val_accuracy: 0.5536\n",
      "Epoch 61/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9613 - accuracy: 0.5194 - val_loss: 0.9834 - val_accuracy: 0.4464\n",
      "Epoch 62/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9429 - accuracy: 0.5387 - val_loss: 0.9044 - val_accuracy: 0.5571\n",
      "Epoch 63/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9532 - accuracy: 0.5209 - val_loss: 0.9572 - val_accuracy: 0.5036\n",
      "Epoch 64/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9388 - accuracy: 0.5383 - val_loss: 1.0815 - val_accuracy: 0.4845\n",
      "Epoch 65/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9365 - accuracy: 0.5460 - val_loss: 0.9315 - val_accuracy: 0.5107\n",
      "Epoch 66/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9426 - accuracy: 0.5330 - val_loss: 0.9508 - val_accuracy: 0.5345\n",
      "Epoch 67/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9371 - accuracy: 0.5300 - val_loss: 0.9140 - val_accuracy: 0.5524\n",
      "Epoch 68/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9297 - accuracy: 0.5371 - val_loss: 0.9074 - val_accuracy: 0.5738\n",
      "Epoch 69/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9390 - accuracy: 0.5338 - val_loss: 0.9271 - val_accuracy: 0.5560\n",
      "Epoch 70/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9307 - accuracy: 0.5320 - val_loss: 0.9365 - val_accuracy: 0.5286\n",
      "Epoch 71/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9299 - accuracy: 0.5359 - val_loss: 0.9572 - val_accuracy: 0.5226\n",
      "Epoch 72/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9351 - accuracy: 0.5372 - val_loss: 0.9417 - val_accuracy: 0.5488\n",
      "Epoch 73/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9297 - accuracy: 0.5343 - val_loss: 0.9138 - val_accuracy: 0.5607\n",
      "Epoch 74/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9158 - accuracy: 0.5435 - val_loss: 0.9170 - val_accuracy: 0.5774\n",
      "Epoch 75/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9118 - accuracy: 0.5506 - val_loss: 0.8886 - val_accuracy: 0.5429\n",
      "Epoch 76/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9183 - accuracy: 0.5491 - val_loss: 0.9339 - val_accuracy: 0.5262\n",
      "Epoch 77/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9184 - accuracy: 0.5476 - val_loss: 0.9210 - val_accuracy: 0.5619\n",
      "Epoch 78/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9065 - accuracy: 0.5470 - val_loss: 0.8928 - val_accuracy: 0.5631\n",
      "Epoch 79/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9079 - accuracy: 0.5590 - val_loss: 0.9727 - val_accuracy: 0.4762\n",
      "Epoch 80/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9064 - accuracy: 0.5552 - val_loss: 0.9102 - val_accuracy: 0.5536\n",
      "Epoch 81/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9090 - accuracy: 0.5580 - val_loss: 0.9734 - val_accuracy: 0.4750\n",
      "Epoch 82/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.9032 - accuracy: 0.5475 - val_loss: 0.9170 - val_accuracy: 0.5619\n",
      "Epoch 83/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8963 - accuracy: 0.5602 - val_loss: 0.8702 - val_accuracy: 0.5845\n",
      "Epoch 84/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8994 - accuracy: 0.5600 - val_loss: 0.9091 - val_accuracy: 0.5631\n",
      "Epoch 85/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8877 - accuracy: 0.5659 - val_loss: 0.9273 - val_accuracy: 0.5643\n",
      "Epoch 86/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8853 - accuracy: 0.5673 - val_loss: 0.9647 - val_accuracy: 0.5250\n",
      "Epoch 87/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8824 - accuracy: 0.5688 - val_loss: 0.9585 - val_accuracy: 0.5321\n",
      "Epoch 88/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8842 - accuracy: 0.5642 - val_loss: 0.8798 - val_accuracy: 0.5643\n",
      "Epoch 89/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8795 - accuracy: 0.5701 - val_loss: 0.9039 - val_accuracy: 0.5655\n",
      "Epoch 90/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8850 - accuracy: 0.5724 - val_loss: 0.8886 - val_accuracy: 0.5595\n",
      "Epoch 91/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8781 - accuracy: 0.5785 - val_loss: 0.9157 - val_accuracy: 0.5726\n",
      "Epoch 92/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8710 - accuracy: 0.5780 - val_loss: 0.9018 - val_accuracy: 0.5917\n",
      "Epoch 93/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8648 - accuracy: 0.5762 - val_loss: 0.9189 - val_accuracy: 0.5762\n",
      "Epoch 94/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8699 - accuracy: 0.5731 - val_loss: 0.8944 - val_accuracy: 0.5488\n",
      "Epoch 95/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8726 - accuracy: 0.5789 - val_loss: 0.9083 - val_accuracy: 0.5798\n",
      "Epoch 96/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8650 - accuracy: 0.5760 - val_loss: 0.8881 - val_accuracy: 0.5869\n",
      "Epoch 97/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8596 - accuracy: 0.5792 - val_loss: 0.8799 - val_accuracy: 0.5810\n",
      "Epoch 98/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8609 - accuracy: 0.5852 - val_loss: 0.9013 - val_accuracy: 0.5560\n",
      "Epoch 99/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8907 - accuracy: 0.5689 - val_loss: 0.9277 - val_accuracy: 0.5429\n",
      "Epoch 100/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8779 - accuracy: 0.5699 - val_loss: 0.9592 - val_accuracy: 0.4750\n",
      "Epoch 101/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8764 - accuracy: 0.5738 - val_loss: 0.9105 - val_accuracy: 0.5595\n",
      "Epoch 102/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8803 - accuracy: 0.5730 - val_loss: 0.9271 - val_accuracy: 0.5607\n",
      "Epoch 103/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8581 - accuracy: 0.5776 - val_loss: 0.9919 - val_accuracy: 0.5536\n",
      "Epoch 104/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8680 - accuracy: 0.5750 - val_loss: 0.8858 - val_accuracy: 0.5643\n",
      "Epoch 105/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8620 - accuracy: 0.5746 - val_loss: 0.8513 - val_accuracy: 0.5988\n",
      "Epoch 106/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8633 - accuracy: 0.5802 - val_loss: 0.8467 - val_accuracy: 0.6048\n",
      "Epoch 107/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8472 - accuracy: 0.5928 - val_loss: 0.8861 - val_accuracy: 0.5821\n",
      "Epoch 108/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8453 - accuracy: 0.5919 - val_loss: 0.9587 - val_accuracy: 0.5000\n",
      "Epoch 109/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8372 - accuracy: 0.5944 - val_loss: 0.8590 - val_accuracy: 0.5988\n",
      "Epoch 110/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8377 - accuracy: 0.5993 - val_loss: 0.8886 - val_accuracy: 0.5631\n",
      "Epoch 111/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8308 - accuracy: 0.5979 - val_loss: 0.8511 - val_accuracy: 0.5893\n",
      "Epoch 112/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8444 - accuracy: 0.5858 - val_loss: 0.8771 - val_accuracy: 0.5905\n",
      "Epoch 113/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8276 - accuracy: 0.5960 - val_loss: 0.8899 - val_accuracy: 0.5774\n",
      "Epoch 114/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8222 - accuracy: 0.5989 - val_loss: 0.8572 - val_accuracy: 0.6262\n",
      "Epoch 115/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8277 - accuracy: 0.5932 - val_loss: 0.8575 - val_accuracy: 0.6298\n",
      "Epoch 116/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8228 - accuracy: 0.6002 - val_loss: 0.9577 - val_accuracy: 0.5631\n",
      "Epoch 117/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8149 - accuracy: 0.6091 - val_loss: 0.9045 - val_accuracy: 0.5690\n",
      "Epoch 118/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8137 - accuracy: 0.6109 - val_loss: 0.8996 - val_accuracy: 0.5679\n",
      "Epoch 119/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8135 - accuracy: 0.6144 - val_loss: 0.8711 - val_accuracy: 0.6024\n",
      "Epoch 120/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8225 - accuracy: 0.6049 - val_loss: 0.8431 - val_accuracy: 0.6179\n",
      "Epoch 121/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8203 - accuracy: 0.6097 - val_loss: 0.9141 - val_accuracy: 0.5357\n",
      "Epoch 122/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8072 - accuracy: 0.6148 - val_loss: 0.8707 - val_accuracy: 0.6012\n",
      "Epoch 123/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7988 - accuracy: 0.6148 - val_loss: 0.8868 - val_accuracy: 0.5619\n",
      "Epoch 124/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8084 - accuracy: 0.6164 - val_loss: 0.8821 - val_accuracy: 0.6190\n",
      "Epoch 125/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8014 - accuracy: 0.6165 - val_loss: 0.8741 - val_accuracy: 0.5643\n",
      "Epoch 126/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.8003 - accuracy: 0.6144 - val_loss: 0.8695 - val_accuracy: 0.5881\n",
      "Epoch 127/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7921 - accuracy: 0.6257 - val_loss: 0.8641 - val_accuracy: 0.6107\n",
      "Epoch 128/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7748 - accuracy: 0.6313 - val_loss: 0.9436 - val_accuracy: 0.5369\n",
      "Epoch 129/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7936 - accuracy: 0.6255 - val_loss: 0.9298 - val_accuracy: 0.5464\n",
      "Epoch 130/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7789 - accuracy: 0.6286 - val_loss: 0.8632 - val_accuracy: 0.5833\n",
      "Epoch 131/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7772 - accuracy: 0.6335 - val_loss: 0.8504 - val_accuracy: 0.6226\n",
      "Epoch 132/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7854 - accuracy: 0.6299 - val_loss: 0.8405 - val_accuracy: 0.5964\n",
      "Epoch 133/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7827 - accuracy: 0.6261 - val_loss: 0.9267 - val_accuracy: 0.5726\n",
      "Epoch 134/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7778 - accuracy: 0.6272 - val_loss: 0.8413 - val_accuracy: 0.6048\n",
      "Epoch 135/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7959 - accuracy: 0.6188 - val_loss: 0.8517 - val_accuracy: 0.5762\n",
      "Epoch 136/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7912 - accuracy: 0.6225 - val_loss: 0.8732 - val_accuracy: 0.5631\n",
      "Epoch 137/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7747 - accuracy: 0.6299 - val_loss: 0.8234 - val_accuracy: 0.6321\n",
      "Epoch 138/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7724 - accuracy: 0.6315 - val_loss: 1.0564 - val_accuracy: 0.5179\n",
      "Epoch 139/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7610 - accuracy: 0.6405 - val_loss: 0.9183 - val_accuracy: 0.5500\n",
      "Epoch 140/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7708 - accuracy: 0.6347 - val_loss: 0.9146 - val_accuracy: 0.5690\n",
      "Epoch 141/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7605 - accuracy: 0.6381 - val_loss: 0.8399 - val_accuracy: 0.5940\n",
      "Epoch 142/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7657 - accuracy: 0.6359 - val_loss: 0.8934 - val_accuracy: 0.5810\n",
      "Epoch 143/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7614 - accuracy: 0.6382 - val_loss: 0.8391 - val_accuracy: 0.6202\n",
      "Epoch 144/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7639 - accuracy: 0.6377 - val_loss: 0.8886 - val_accuracy: 0.5750\n",
      "Epoch 145/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7405 - accuracy: 0.6512 - val_loss: 0.8589 - val_accuracy: 0.5750\n",
      "Epoch 146/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7549 - accuracy: 0.6442 - val_loss: 0.9658 - val_accuracy: 0.5548\n",
      "Epoch 147/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7454 - accuracy: 0.6512 - val_loss: 0.9318 - val_accuracy: 0.5583\n",
      "Epoch 148/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.7539 - accuracy: 0.6499 - val_loss: 0.9004 - val_accuracy: 0.5607\n",
      "Epoch 149/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7345 - accuracy: 0.6470 - val_loss: 0.8876 - val_accuracy: 0.5512\n",
      "Epoch 150/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7516 - accuracy: 0.6419 - val_loss: 0.8657 - val_accuracy: 0.5821\n",
      "Epoch 151/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7437 - accuracy: 0.6530 - val_loss: 0.8417 - val_accuracy: 0.5917\n",
      "Epoch 152/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7314 - accuracy: 0.6558 - val_loss: 0.7949 - val_accuracy: 0.6524\n",
      "Epoch 153/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7516 - accuracy: 0.6397 - val_loss: 0.8588 - val_accuracy: 0.5810\n",
      "Epoch 154/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7357 - accuracy: 0.6507 - val_loss: 0.8458 - val_accuracy: 0.6333\n",
      "Epoch 155/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7500 - accuracy: 0.6498 - val_loss: 0.7894 - val_accuracy: 0.6310\n",
      "Epoch 156/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7252 - accuracy: 0.6593 - val_loss: 0.8312 - val_accuracy: 0.6226\n",
      "Epoch 157/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7182 - accuracy: 0.6653 - val_loss: 0.8807 - val_accuracy: 0.5548\n",
      "Epoch 158/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7197 - accuracy: 0.6705 - val_loss: 0.8563 - val_accuracy: 0.6048\n",
      "Epoch 159/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7263 - accuracy: 0.6565 - val_loss: 0.7931 - val_accuracy: 0.6226\n",
      "Epoch 160/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7299 - accuracy: 0.6592 - val_loss: 0.9537 - val_accuracy: 0.5881\n",
      "Epoch 161/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7094 - accuracy: 0.6618 - val_loss: 0.7969 - val_accuracy: 0.6310\n",
      "Epoch 162/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.7233 - accuracy: 0.6699 - val_loss: 0.7979 - val_accuracy: 0.6071\n",
      "Epoch 163/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7652 - accuracy: 0.6458 - val_loss: 0.8736 - val_accuracy: 0.5762\n",
      "Epoch 164/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7358 - accuracy: 0.6618 - val_loss: 0.8072 - val_accuracy: 0.6357\n",
      "Epoch 165/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7047 - accuracy: 0.6796 - val_loss: 0.8216 - val_accuracy: 0.6119\n",
      "Epoch 166/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7114 - accuracy: 0.6682 - val_loss: 0.8787 - val_accuracy: 0.5940\n",
      "Epoch 167/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7125 - accuracy: 0.6692 - val_loss: 0.7917 - val_accuracy: 0.6179\n",
      "Epoch 168/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7086 - accuracy: 0.6719 - val_loss: 0.7830 - val_accuracy: 0.6560\n",
      "Epoch 169/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7035 - accuracy: 0.6750 - val_loss: 0.8184 - val_accuracy: 0.6250\n",
      "Epoch 170/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6950 - accuracy: 0.6808 - val_loss: 0.7976 - val_accuracy: 0.6369\n",
      "Epoch 171/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7044 - accuracy: 0.6755 - val_loss: 0.8582 - val_accuracy: 0.6036\n",
      "Epoch 172/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6906 - accuracy: 0.6818 - val_loss: 0.7684 - val_accuracy: 0.6488\n",
      "Epoch 173/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7037 - accuracy: 0.6755 - val_loss: 0.8319 - val_accuracy: 0.5988\n",
      "Epoch 174/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7541 - accuracy: 0.6546 - val_loss: 0.8248 - val_accuracy: 0.6226\n",
      "Epoch 175/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7410 - accuracy: 0.6514 - val_loss: 0.8049 - val_accuracy: 0.6179\n",
      "Epoch 176/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7049 - accuracy: 0.6715 - val_loss: 0.7847 - val_accuracy: 0.6310\n",
      "Epoch 177/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6726 - accuracy: 0.6930 - val_loss: 0.7886 - val_accuracy: 0.6405\n",
      "Epoch 178/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.7020 - accuracy: 0.6744 - val_loss: 0.8289 - val_accuracy: 0.6143\n",
      "Epoch 179/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6870 - accuracy: 0.6808 - val_loss: 0.8427 - val_accuracy: 0.6012\n",
      "Epoch 180/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6682 - accuracy: 0.6994 - val_loss: 0.8073 - val_accuracy: 0.6286\n",
      "Epoch 181/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6691 - accuracy: 0.6938 - val_loss: 0.8419 - val_accuracy: 0.6071\n",
      "Epoch 182/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.6833 - accuracy: 0.6851 - val_loss: 0.8007 - val_accuracy: 0.6333\n",
      "Epoch 183/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6727 - accuracy: 0.6928 - val_loss: 0.7730 - val_accuracy: 0.6202\n",
      "Epoch 184/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6770 - accuracy: 0.6896 - val_loss: 0.9020 - val_accuracy: 0.5857\n",
      "Epoch 185/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6631 - accuracy: 0.6943 - val_loss: 0.7800 - val_accuracy: 0.6417\n",
      "Epoch 186/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6887 - accuracy: 0.6837 - val_loss: 0.8415 - val_accuracy: 0.5917\n",
      "Epoch 187/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6480 - accuracy: 0.7025 - val_loss: 0.7415 - val_accuracy: 0.6524\n",
      "Epoch 188/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6584 - accuracy: 0.7007 - val_loss: 0.7325 - val_accuracy: 0.6643\n",
      "Epoch 189/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6722 - accuracy: 0.6888 - val_loss: 0.7988 - val_accuracy: 0.6298\n",
      "Epoch 190/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6828 - accuracy: 0.6869 - val_loss: 0.8032 - val_accuracy: 0.6214\n",
      "Epoch 191/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6730 - accuracy: 0.6934 - val_loss: 0.7761 - val_accuracy: 0.6655\n",
      "Epoch 192/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6700 - accuracy: 0.6963 - val_loss: 0.7883 - val_accuracy: 0.6429\n",
      "Epoch 193/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6412 - accuracy: 0.7116 - val_loss: 0.7951 - val_accuracy: 0.6476\n",
      "Epoch 194/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6628 - accuracy: 0.7027 - val_loss: 0.8240 - val_accuracy: 0.6202\n",
      "Epoch 195/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6468 - accuracy: 0.6985 - val_loss: 0.8454 - val_accuracy: 0.6310\n",
      "Epoch 196/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6569 - accuracy: 0.6991 - val_loss: 0.7432 - val_accuracy: 0.6607\n",
      "Epoch 197/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6422 - accuracy: 0.7107 - val_loss: 0.7720 - val_accuracy: 0.6488\n",
      "Epoch 198/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6704 - accuracy: 0.6934 - val_loss: 0.7900 - val_accuracy: 0.5857\n",
      "Epoch 199/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6390 - accuracy: 0.7109 - val_loss: 0.8603 - val_accuracy: 0.5667\n",
      "Epoch 200/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6324 - accuracy: 0.7179 - val_loss: 0.8169 - val_accuracy: 0.6107\n",
      "Epoch 201/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6526 - accuracy: 0.7080 - val_loss: 0.7816 - val_accuracy: 0.6190\n",
      "Epoch 202/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6279 - accuracy: 0.7214 - val_loss: 0.8243 - val_accuracy: 0.6083\n",
      "Epoch 203/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6326 - accuracy: 0.7131 - val_loss: 0.7814 - val_accuracy: 0.6393\n",
      "Epoch 204/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6368 - accuracy: 0.7072 - val_loss: 0.8291 - val_accuracy: 0.6107\n",
      "Epoch 205/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6195 - accuracy: 0.7241 - val_loss: 0.6930 - val_accuracy: 0.6738\n",
      "Epoch 206/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6363 - accuracy: 0.7097 - val_loss: 0.8134 - val_accuracy: 0.6179\n",
      "Epoch 207/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6770 - accuracy: 0.7014 - val_loss: 0.8297 - val_accuracy: 0.6131\n",
      "Epoch 208/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6626 - accuracy: 0.7058 - val_loss: 0.9112 - val_accuracy: 0.5762\n",
      "Epoch 209/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6462 - accuracy: 0.7107 - val_loss: 0.7818 - val_accuracy: 0.6381\n",
      "Epoch 210/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6265 - accuracy: 0.7203 - val_loss: 0.8010 - val_accuracy: 0.6405\n",
      "Epoch 211/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6195 - accuracy: 0.7182 - val_loss: 0.7352 - val_accuracy: 0.6631\n",
      "Epoch 212/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6130 - accuracy: 0.7249 - val_loss: 0.7385 - val_accuracy: 0.6286\n",
      "Epoch 213/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6020 - accuracy: 0.7303 - val_loss: 0.7573 - val_accuracy: 0.6274\n",
      "Epoch 214/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6200 - accuracy: 0.7190 - val_loss: 0.7119 - val_accuracy: 0.6607\n",
      "Epoch 215/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6121 - accuracy: 0.7277 - val_loss: 0.8144 - val_accuracy: 0.6155\n",
      "Epoch 216/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6291 - accuracy: 0.7167 - val_loss: 0.7932 - val_accuracy: 0.6274\n",
      "Epoch 217/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6140 - accuracy: 0.7274 - val_loss: 0.7700 - val_accuracy: 0.6774\n",
      "Epoch 218/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6041 - accuracy: 0.7331 - val_loss: 0.8366 - val_accuracy: 0.5940\n",
      "Epoch 219/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5995 - accuracy: 0.7378 - val_loss: 0.7960 - val_accuracy: 0.6286\n",
      "Epoch 220/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5979 - accuracy: 0.7377 - val_loss: 0.7929 - val_accuracy: 0.6143\n",
      "Epoch 221/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5968 - accuracy: 0.7316 - val_loss: 0.7250 - val_accuracy: 0.6702\n",
      "Epoch 222/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5960 - accuracy: 0.7376 - val_loss: 0.8255 - val_accuracy: 0.6238\n",
      "Epoch 223/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.6036 - accuracy: 0.7279 - val_loss: 0.8134 - val_accuracy: 0.6202\n",
      "Epoch 224/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.5978 - accuracy: 0.7345 - val_loss: 0.7337 - val_accuracy: 0.6488\n",
      "Epoch 225/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5913 - accuracy: 0.7303 - val_loss: 0.7643 - val_accuracy: 0.6548\n",
      "Epoch 226/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5896 - accuracy: 0.7379 - val_loss: 0.7874 - val_accuracy: 0.6417\n",
      "Epoch 227/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5940 - accuracy: 0.7317 - val_loss: 0.7183 - val_accuracy: 0.6595\n",
      "Epoch 228/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5826 - accuracy: 0.7483 - val_loss: 0.6769 - val_accuracy: 0.6976\n",
      "Epoch 229/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5871 - accuracy: 0.7335 - val_loss: 0.7984 - val_accuracy: 0.6190\n",
      "Epoch 230/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.6087 - accuracy: 0.7388 - val_loss: 0.8049 - val_accuracy: 0.6238\n",
      "Epoch 231/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5910 - accuracy: 0.7307 - val_loss: 0.7659 - val_accuracy: 0.6369\n",
      "Epoch 232/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5743 - accuracy: 0.7465 - val_loss: 0.7715 - val_accuracy: 0.6476\n",
      "Epoch 233/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5960 - accuracy: 0.7345 - val_loss: 0.6922 - val_accuracy: 0.6917\n",
      "Epoch 234/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5461 - accuracy: 0.7593 - val_loss: 0.6958 - val_accuracy: 0.6679\n",
      "Epoch 235/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5802 - accuracy: 0.7419 - val_loss: 0.7567 - val_accuracy: 0.6393\n",
      "Epoch 236/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5793 - accuracy: 0.7417 - val_loss: 0.7757 - val_accuracy: 0.6476\n",
      "Epoch 237/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5835 - accuracy: 0.7404 - val_loss: 0.6651 - val_accuracy: 0.7071\n",
      "Epoch 238/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5617 - accuracy: 0.7556 - val_loss: 0.6807 - val_accuracy: 0.7000\n",
      "Epoch 239/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5712 - accuracy: 0.7505 - val_loss: 0.7396 - val_accuracy: 0.6607\n",
      "Epoch 240/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5492 - accuracy: 0.7568 - val_loss: 0.7165 - val_accuracy: 0.6714\n",
      "Epoch 241/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5479 - accuracy: 0.7641 - val_loss: 0.7215 - val_accuracy: 0.6631\n",
      "Epoch 242/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5713 - accuracy: 0.7468 - val_loss: 0.7744 - val_accuracy: 0.6238\n",
      "Epoch 243/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5623 - accuracy: 0.7522 - val_loss: 0.8277 - val_accuracy: 0.6417\n",
      "Epoch 244/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5649 - accuracy: 0.7501 - val_loss: 0.6943 - val_accuracy: 0.7107\n",
      "Epoch 245/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5497 - accuracy: 0.7608 - val_loss: 0.7295 - val_accuracy: 0.6548\n",
      "Epoch 246/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5540 - accuracy: 0.7596 - val_loss: 0.8048 - val_accuracy: 0.6762\n",
      "Epoch 247/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5713 - accuracy: 0.7534 - val_loss: 0.7673 - val_accuracy: 0.6369\n",
      "Epoch 248/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5458 - accuracy: 0.7563 - val_loss: 0.7082 - val_accuracy: 0.6833\n",
      "Epoch 249/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5513 - accuracy: 0.7558 - val_loss: 0.7668 - val_accuracy: 0.6488\n",
      "Epoch 250/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5587 - accuracy: 0.7575 - val_loss: 0.7139 - val_accuracy: 0.6619\n",
      "Epoch 251/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5611 - accuracy: 0.7603 - val_loss: 0.7293 - val_accuracy: 0.6679\n",
      "Epoch 252/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5275 - accuracy: 0.7672 - val_loss: 0.7438 - val_accuracy: 0.6845\n",
      "Epoch 253/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5406 - accuracy: 0.7639 - val_loss: 0.6929 - val_accuracy: 0.6750\n",
      "Epoch 254/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5512 - accuracy: 0.7611 - val_loss: 0.7578 - val_accuracy: 0.6512\n",
      "Epoch 255/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5418 - accuracy: 0.7629 - val_loss: 0.7070 - val_accuracy: 0.6905\n",
      "Epoch 256/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5400 - accuracy: 0.7639 - val_loss: 0.7241 - val_accuracy: 0.6786\n",
      "Epoch 257/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5328 - accuracy: 0.7659 - val_loss: 0.7337 - val_accuracy: 0.6798\n",
      "Epoch 258/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5729 - accuracy: 0.7537 - val_loss: 0.7422 - val_accuracy: 0.6905\n",
      "Epoch 259/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5172 - accuracy: 0.7802 - val_loss: 0.8107 - val_accuracy: 0.6536\n",
      "Epoch 260/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5435 - accuracy: 0.7663 - val_loss: 0.7294 - val_accuracy: 0.6702\n",
      "Epoch 261/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5440 - accuracy: 0.7638 - val_loss: 0.7292 - val_accuracy: 0.6667\n",
      "Epoch 262/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5388 - accuracy: 0.7667 - val_loss: 0.7588 - val_accuracy: 0.6762\n",
      "Epoch 263/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5372 - accuracy: 0.7668 - val_loss: 0.7688 - val_accuracy: 0.6464\n",
      "Epoch 264/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5361 - accuracy: 0.7769 - val_loss: 0.7690 - val_accuracy: 0.6750\n",
      "Epoch 265/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5188 - accuracy: 0.7816 - val_loss: 0.8309 - val_accuracy: 0.6238\n",
      "Epoch 266/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5280 - accuracy: 0.7711 - val_loss: 0.7199 - val_accuracy: 0.6833\n",
      "Epoch 267/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5299 - accuracy: 0.7767 - val_loss: 0.7193 - val_accuracy: 0.6524\n",
      "Epoch 268/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5168 - accuracy: 0.7791 - val_loss: 0.6392 - val_accuracy: 0.7226\n",
      "Epoch 269/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5174 - accuracy: 0.7733 - val_loss: 0.7631 - val_accuracy: 0.6476\n",
      "Epoch 270/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4981 - accuracy: 0.7861 - val_loss: 0.7527 - val_accuracy: 0.6476\n",
      "Epoch 271/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.5198 - accuracy: 0.7782 - val_loss: 0.7221 - val_accuracy: 0.6405\n",
      "Epoch 272/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5010 - accuracy: 0.7848 - val_loss: 0.6681 - val_accuracy: 0.7024\n",
      "Epoch 273/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4830 - accuracy: 0.7919 - val_loss: 0.7785 - val_accuracy: 0.6214\n",
      "Epoch 274/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5042 - accuracy: 0.7832 - val_loss: 0.6676 - val_accuracy: 0.7238\n",
      "Epoch 275/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5165 - accuracy: 0.7811 - val_loss: 0.7124 - val_accuracy: 0.6786\n",
      "Epoch 276/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5350 - accuracy: 0.7699 - val_loss: 0.7378 - val_accuracy: 0.6952\n",
      "Epoch 277/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4941 - accuracy: 0.7914 - val_loss: 0.8378 - val_accuracy: 0.6250\n",
      "Epoch 278/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4914 - accuracy: 0.7886 - val_loss: 0.7024 - val_accuracy: 0.7060\n",
      "Epoch 279/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.5091 - accuracy: 0.7802 - val_loss: 0.6984 - val_accuracy: 0.6786\n",
      "Epoch 280/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4856 - accuracy: 0.7955 - val_loss: 0.8021 - val_accuracy: 0.6321\n",
      "Epoch 281/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4866 - accuracy: 0.7953 - val_loss: 0.7988 - val_accuracy: 0.6583\n",
      "Epoch 282/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4852 - accuracy: 0.7937 - val_loss: 0.8237 - val_accuracy: 0.6452\n",
      "Epoch 283/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5030 - accuracy: 0.7859 - val_loss: 0.8232 - val_accuracy: 0.6429\n",
      "Epoch 284/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4959 - accuracy: 0.7876 - val_loss: 0.7896 - val_accuracy: 0.6536\n",
      "Epoch 285/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4980 - accuracy: 0.7935 - val_loss: 0.7310 - val_accuracy: 0.6762\n",
      "Epoch 286/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4965 - accuracy: 0.7874 - val_loss: 0.7558 - val_accuracy: 0.6655\n",
      "Epoch 287/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4712 - accuracy: 0.8005 - val_loss: 0.7833 - val_accuracy: 0.6536\n",
      "Epoch 288/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4863 - accuracy: 0.7908 - val_loss: 0.8725 - val_accuracy: 0.6476\n",
      "Epoch 289/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4777 - accuracy: 0.7988 - val_loss: 0.7100 - val_accuracy: 0.6857\n",
      "Epoch 290/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4800 - accuracy: 0.7973 - val_loss: 0.8548 - val_accuracy: 0.6440\n",
      "Epoch 291/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.5023 - accuracy: 0.7882 - val_loss: 0.7358 - val_accuracy: 0.7048\n",
      "Epoch 292/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4941 - accuracy: 0.7907 - val_loss: 0.7249 - val_accuracy: 0.6738\n",
      "Epoch 293/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4630 - accuracy: 0.7996 - val_loss: 0.6995 - val_accuracy: 0.7060\n",
      "Epoch 294/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4712 - accuracy: 0.8001 - val_loss: 0.7931 - val_accuracy: 0.6536\n",
      "Epoch 295/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4886 - accuracy: 0.7947 - val_loss: 0.7962 - val_accuracy: 0.6929\n",
      "Epoch 296/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4669 - accuracy: 0.8067 - val_loss: 0.6817 - val_accuracy: 0.6940\n",
      "Epoch 297/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4859 - accuracy: 0.7940 - val_loss: 0.6665 - val_accuracy: 0.7274\n",
      "Epoch 298/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.4724 - accuracy: 0.8073 - val_loss: 0.7185 - val_accuracy: 0.6571\n",
      "Epoch 299/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4547 - accuracy: 0.8118 - val_loss: 0.7516 - val_accuracy: 0.6762\n",
      "Epoch 300/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4659 - accuracy: 0.8078 - val_loss: 0.7264 - val_accuracy: 0.6762\n",
      "Epoch 301/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4404 - accuracy: 0.8149 - val_loss: 0.7279 - val_accuracy: 0.6702\n",
      "Epoch 302/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4511 - accuracy: 0.8072 - val_loss: 0.9933 - val_accuracy: 0.5810\n",
      "Epoch 303/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4669 - accuracy: 0.7989 - val_loss: 0.7506 - val_accuracy: 0.6452\n",
      "Epoch 304/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4437 - accuracy: 0.8124 - val_loss: 0.7675 - val_accuracy: 0.6643\n",
      "Epoch 305/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4705 - accuracy: 0.8052 - val_loss: 0.6838 - val_accuracy: 0.7155\n",
      "Epoch 306/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4650 - accuracy: 0.8092 - val_loss: 0.7277 - val_accuracy: 0.6464\n",
      "Epoch 307/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4549 - accuracy: 0.8081 - val_loss: 0.7277 - val_accuracy: 0.6726\n",
      "Epoch 308/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4426 - accuracy: 0.8163 - val_loss: 0.7073 - val_accuracy: 0.6845\n",
      "Epoch 309/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4633 - accuracy: 0.8078 - val_loss: 0.6758 - val_accuracy: 0.7274\n",
      "Epoch 310/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4751 - accuracy: 0.8002 - val_loss: 0.8666 - val_accuracy: 0.6631\n",
      "Epoch 311/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4670 - accuracy: 0.8029 - val_loss: 0.7405 - val_accuracy: 0.6667\n",
      "Epoch 312/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4396 - accuracy: 0.8102 - val_loss: 0.7154 - val_accuracy: 0.6952\n",
      "Epoch 313/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4479 - accuracy: 0.8146 - val_loss: 0.7320 - val_accuracy: 0.6905\n",
      "Epoch 314/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4437 - accuracy: 0.8123 - val_loss: 0.7258 - val_accuracy: 0.7262\n",
      "Epoch 315/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4608 - accuracy: 0.8086 - val_loss: 0.6397 - val_accuracy: 0.7083\n",
      "Epoch 316/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4321 - accuracy: 0.8240 - val_loss: 0.6913 - val_accuracy: 0.6893\n",
      "Epoch 317/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4247 - accuracy: 0.8239 - val_loss: 0.7414 - val_accuracy: 0.7095\n",
      "Epoch 318/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4168 - accuracy: 0.8262 - val_loss: 0.7371 - val_accuracy: 0.6988\n",
      "Epoch 319/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4701 - accuracy: 0.8092 - val_loss: 0.8219 - val_accuracy: 0.6321\n",
      "Epoch 320/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4357 - accuracy: 0.8201 - val_loss: 0.7003 - val_accuracy: 0.6845\n",
      "Epoch 321/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4334 - accuracy: 0.8182 - val_loss: 0.7603 - val_accuracy: 0.6679\n",
      "Epoch 322/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4331 - accuracy: 0.8226 - val_loss: 0.7169 - val_accuracy: 0.6940\n",
      "Epoch 323/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4271 - accuracy: 0.8203 - val_loss: 0.7736 - val_accuracy: 0.7024\n",
      "Epoch 324/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4202 - accuracy: 0.8240 - val_loss: 0.7639 - val_accuracy: 0.6762\n",
      "Epoch 325/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4212 - accuracy: 0.8285 - val_loss: 0.7837 - val_accuracy: 0.6583\n",
      "Epoch 326/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4428 - accuracy: 0.8153 - val_loss: 0.7815 - val_accuracy: 0.6536\n",
      "Epoch 327/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4308 - accuracy: 0.8198 - val_loss: 0.7493 - val_accuracy: 0.6833\n",
      "Epoch 328/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4251 - accuracy: 0.8246 - val_loss: 0.7285 - val_accuracy: 0.6810\n",
      "Epoch 329/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4342 - accuracy: 0.8165 - val_loss: 0.7918 - val_accuracy: 0.6607\n",
      "Epoch 330/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4491 - accuracy: 0.8142 - val_loss: 0.6618 - val_accuracy: 0.7262\n",
      "Epoch 331/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4485 - accuracy: 0.8057 - val_loss: 0.7041 - val_accuracy: 0.6893\n",
      "Epoch 332/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4292 - accuracy: 0.8219 - val_loss: 0.8625 - val_accuracy: 0.5940\n",
      "Epoch 333/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4119 - accuracy: 0.8297 - val_loss: 0.7226 - val_accuracy: 0.7107\n",
      "Epoch 334/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.4180 - accuracy: 0.8224 - val_loss: 0.6652 - val_accuracy: 0.7143\n",
      "Epoch 335/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4228 - accuracy: 0.8246 - val_loss: 0.6276 - val_accuracy: 0.7345\n",
      "Epoch 336/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4363 - accuracy: 0.8216 - val_loss: 0.7251 - val_accuracy: 0.6893\n",
      "Epoch 337/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4060 - accuracy: 0.8303 - val_loss: 1.0857 - val_accuracy: 0.5762\n",
      "Epoch 338/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4313 - accuracy: 0.8226 - val_loss: 0.6390 - val_accuracy: 0.7190\n",
      "Epoch 339/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4203 - accuracy: 0.8336 - val_loss: 0.6870 - val_accuracy: 0.7167\n",
      "Epoch 340/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4051 - accuracy: 0.8366 - val_loss: 0.7065 - val_accuracy: 0.7012\n",
      "Epoch 341/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4072 - accuracy: 0.8337 - val_loss: 0.7585 - val_accuracy: 0.6631\n",
      "Epoch 342/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4148 - accuracy: 0.8254 - val_loss: 0.7097 - val_accuracy: 0.6690\n",
      "Epoch 343/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3997 - accuracy: 0.8359 - val_loss: 0.6677 - val_accuracy: 0.6940\n",
      "Epoch 344/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3994 - accuracy: 0.8356 - val_loss: 0.7127 - val_accuracy: 0.6702\n",
      "Epoch 345/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3949 - accuracy: 0.8414 - val_loss: 0.7284 - val_accuracy: 0.7000\n",
      "Epoch 346/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4082 - accuracy: 0.8358 - val_loss: 0.8407 - val_accuracy: 0.6560\n",
      "Epoch 347/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3852 - accuracy: 0.8387 - val_loss: 0.6795 - val_accuracy: 0.7262\n",
      "Epoch 348/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4036 - accuracy: 0.8332 - val_loss: 0.8134 - val_accuracy: 0.6429\n",
      "Epoch 349/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3986 - accuracy: 0.8394 - val_loss: 0.6643 - val_accuracy: 0.7119\n",
      "Epoch 350/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4106 - accuracy: 0.8318 - val_loss: 0.6361 - val_accuracy: 0.6976\n",
      "Epoch 351/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3951 - accuracy: 0.8327 - val_loss: 0.7851 - val_accuracy: 0.7036\n",
      "Epoch 352/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3919 - accuracy: 0.8392 - val_loss: 0.6821 - val_accuracy: 0.7417\n",
      "Epoch 353/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3805 - accuracy: 0.8427 - val_loss: 0.7933 - val_accuracy: 0.6857\n",
      "Epoch 354/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3905 - accuracy: 0.8402 - val_loss: 0.7926 - val_accuracy: 0.6821\n",
      "Epoch 355/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4006 - accuracy: 0.8371 - val_loss: 0.7096 - val_accuracy: 0.7071\n",
      "Epoch 356/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.4043 - accuracy: 0.8376 - val_loss: 0.6515 - val_accuracy: 0.7381\n",
      "Epoch 357/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4016 - accuracy: 0.8315 - val_loss: 0.7753 - val_accuracy: 0.6714\n",
      "Epoch 358/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.4008 - accuracy: 0.8348 - val_loss: 0.7953 - val_accuracy: 0.6643\n",
      "Epoch 359/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3797 - accuracy: 0.8471 - val_loss: 0.7470 - val_accuracy: 0.6988\n",
      "Epoch 360/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3762 - accuracy: 0.8489 - val_loss: 0.8809 - val_accuracy: 0.6690\n",
      "Epoch 361/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3919 - accuracy: 0.8391 - val_loss: 0.7740 - val_accuracy: 0.6655\n",
      "Epoch 362/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3918 - accuracy: 0.8422 - val_loss: 0.6857 - val_accuracy: 0.6976\n",
      "Epoch 363/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3696 - accuracy: 0.8445 - val_loss: 0.8432 - val_accuracy: 0.6643\n",
      "Epoch 364/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3883 - accuracy: 0.8389 - val_loss: 0.6943 - val_accuracy: 0.6905\n",
      "Epoch 365/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3720 - accuracy: 0.8473 - val_loss: 0.7940 - val_accuracy: 0.6893\n",
      "Epoch 366/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3678 - accuracy: 0.8494 - val_loss: 0.6305 - val_accuracy: 0.7500\n",
      "Epoch 367/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3808 - accuracy: 0.8447 - val_loss: 0.6822 - val_accuracy: 0.7167\n",
      "Epoch 368/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3738 - accuracy: 0.8511 - val_loss: 0.7962 - val_accuracy: 0.6702\n",
      "Epoch 369/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3775 - accuracy: 0.8445 - val_loss: 0.7064 - val_accuracy: 0.7095\n",
      "Epoch 370/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3665 - accuracy: 0.8522 - val_loss: 0.7141 - val_accuracy: 0.6905\n",
      "Epoch 371/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3544 - accuracy: 0.8540 - val_loss: 0.8209 - val_accuracy: 0.6810\n",
      "Epoch 372/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3750 - accuracy: 0.8460 - val_loss: 0.7909 - val_accuracy: 0.6595\n",
      "Epoch 373/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3809 - accuracy: 0.8434 - val_loss: 0.8023 - val_accuracy: 0.6810\n",
      "Epoch 374/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3941 - accuracy: 0.8383 - val_loss: 0.8638 - val_accuracy: 0.6726\n",
      "Epoch 375/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3736 - accuracy: 0.8469 - val_loss: 0.7883 - val_accuracy: 0.7048\n",
      "Epoch 376/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3621 - accuracy: 0.8547 - val_loss: 0.8083 - val_accuracy: 0.6881\n",
      "Epoch 377/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3573 - accuracy: 0.8557 - val_loss: 0.8806 - val_accuracy: 0.6667\n",
      "Epoch 378/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3757 - accuracy: 0.8526 - val_loss: 0.8236 - val_accuracy: 0.6845\n",
      "Epoch 379/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3825 - accuracy: 0.8456 - val_loss: 0.7246 - val_accuracy: 0.6690\n",
      "Epoch 380/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3611 - accuracy: 0.8577 - val_loss: 0.7145 - val_accuracy: 0.6726\n",
      "Epoch 381/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3713 - accuracy: 0.8440 - val_loss: 0.7506 - val_accuracy: 0.6857\n",
      "Epoch 382/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3500 - accuracy: 0.8565 - val_loss: 0.7703 - val_accuracy: 0.6679\n",
      "Epoch 383/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3450 - accuracy: 0.8614 - val_loss: 0.7314 - val_accuracy: 0.7310\n",
      "Epoch 384/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3687 - accuracy: 0.8496 - val_loss: 0.7190 - val_accuracy: 0.7000\n",
      "Epoch 385/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3401 - accuracy: 0.8632 - val_loss: 0.8282 - val_accuracy: 0.6726\n",
      "Epoch 386/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3542 - accuracy: 0.8585 - val_loss: 0.6532 - val_accuracy: 0.7060\n",
      "Epoch 387/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3589 - accuracy: 0.8540 - val_loss: 0.7819 - val_accuracy: 0.6798\n",
      "Epoch 388/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3575 - accuracy: 0.8550 - val_loss: 0.7801 - val_accuracy: 0.7060\n",
      "Epoch 389/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3493 - accuracy: 0.8573 - val_loss: 0.7457 - val_accuracy: 0.6786\n",
      "Epoch 390/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3639 - accuracy: 0.8550 - val_loss: 0.7687 - val_accuracy: 0.6679\n",
      "Epoch 391/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3536 - accuracy: 0.8573 - val_loss: 0.7689 - val_accuracy: 0.6869\n",
      "Epoch 392/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3506 - accuracy: 0.8602 - val_loss: 0.8961 - val_accuracy: 0.6488\n",
      "Epoch 393/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3346 - accuracy: 0.8649 - val_loss: 0.8580 - val_accuracy: 0.6500\n",
      "Epoch 394/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3556 - accuracy: 0.8585 - val_loss: 0.7450 - val_accuracy: 0.6917\n",
      "Epoch 395/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3734 - accuracy: 0.8490 - val_loss: 0.9366 - val_accuracy: 0.6298\n",
      "Epoch 396/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3459 - accuracy: 0.8611 - val_loss: 0.7933 - val_accuracy: 0.6833\n",
      "Epoch 397/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3446 - accuracy: 0.8580 - val_loss: 0.8093 - val_accuracy: 0.6869\n",
      "Epoch 398/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3397 - accuracy: 0.8683 - val_loss: 0.7822 - val_accuracy: 0.6607\n",
      "Epoch 399/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3271 - accuracy: 0.8679 - val_loss: 0.8008 - val_accuracy: 0.6643\n",
      "Epoch 400/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3512 - accuracy: 0.8604 - val_loss: 0.7812 - val_accuracy: 0.6893\n",
      "Epoch 401/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3446 - accuracy: 0.8627 - val_loss: 0.7888 - val_accuracy: 0.6774\n",
      "Epoch 402/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3669 - accuracy: 0.8582 - val_loss: 0.7466 - val_accuracy: 0.6738\n",
      "Epoch 403/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3282 - accuracy: 0.8708 - val_loss: 0.7539 - val_accuracy: 0.6952\n",
      "Epoch 404/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3103 - accuracy: 0.8740 - val_loss: 0.6438 - val_accuracy: 0.7679\n",
      "Epoch 405/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3504 - accuracy: 0.8585 - val_loss: 0.8240 - val_accuracy: 0.6595\n",
      "Epoch 406/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3310 - accuracy: 0.8653 - val_loss: 0.7909 - val_accuracy: 0.7071\n",
      "Epoch 407/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3296 - accuracy: 0.8657 - val_loss: 0.9786 - val_accuracy: 0.6179\n",
      "Epoch 408/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3150 - accuracy: 0.8756 - val_loss: 0.7625 - val_accuracy: 0.7167\n",
      "Epoch 409/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3363 - accuracy: 0.8663 - val_loss: 0.6992 - val_accuracy: 0.7083\n",
      "Epoch 410/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3388 - accuracy: 0.8684 - val_loss: 0.7576 - val_accuracy: 0.6857\n",
      "Epoch 411/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.3203 - accuracy: 0.8748 - val_loss: 0.9670 - val_accuracy: 0.6857\n",
      "Epoch 412/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3511 - accuracy: 0.8617 - val_loss: 0.8626 - val_accuracy: 0.6857\n",
      "Epoch 413/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3194 - accuracy: 0.8729 - val_loss: 0.7963 - val_accuracy: 0.6655\n",
      "Epoch 414/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3016 - accuracy: 0.8821 - val_loss: 0.7663 - val_accuracy: 0.6893\n",
      "Epoch 415/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3235 - accuracy: 0.8703 - val_loss: 0.7044 - val_accuracy: 0.7119\n",
      "Epoch 416/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3226 - accuracy: 0.8751 - val_loss: 0.8087 - val_accuracy: 0.6857\n",
      "Epoch 417/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3041 - accuracy: 0.8752 - val_loss: 0.8002 - val_accuracy: 0.6595\n",
      "Epoch 418/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3392 - accuracy: 0.8633 - val_loss: 0.7691 - val_accuracy: 0.6964\n",
      "Epoch 419/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3399 - accuracy: 0.8678 - val_loss: 0.8214 - val_accuracy: 0.6631\n",
      "Epoch 420/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.3153 - accuracy: 0.8764 - val_loss: 0.8160 - val_accuracy: 0.6762\n",
      "Epoch 421/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2999 - accuracy: 0.8831 - val_loss: 0.7524 - val_accuracy: 0.7024\n",
      "Epoch 422/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3190 - accuracy: 0.8745 - val_loss: 0.7579 - val_accuracy: 0.6952\n",
      "Epoch 423/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2984 - accuracy: 0.8820 - val_loss: 0.8449 - val_accuracy: 0.6548\n",
      "Epoch 424/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2913 - accuracy: 0.8850 - val_loss: 0.8554 - val_accuracy: 0.6881\n",
      "Epoch 425/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2973 - accuracy: 0.8836 - val_loss: 0.7390 - val_accuracy: 0.6750\n",
      "Epoch 426/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3054 - accuracy: 0.8799 - val_loss: 0.8142 - val_accuracy: 0.6857\n",
      "Epoch 427/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3407 - accuracy: 0.8718 - val_loss: 0.8219 - val_accuracy: 0.6738\n",
      "Epoch 428/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3140 - accuracy: 0.8800 - val_loss: 0.6710 - val_accuracy: 0.7321\n",
      "Epoch 429/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3137 - accuracy: 0.8769 - val_loss: 0.6863 - val_accuracy: 0.6833\n",
      "Epoch 430/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2979 - accuracy: 0.8815 - val_loss: 0.7826 - val_accuracy: 0.6929\n",
      "Epoch 431/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3306 - accuracy: 0.8716 - val_loss: 0.7884 - val_accuracy: 0.6595\n",
      "Epoch 432/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3198 - accuracy: 0.8710 - val_loss: 0.8374 - val_accuracy: 0.6536\n",
      "Epoch 433/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2918 - accuracy: 0.8841 - val_loss: 0.6738 - val_accuracy: 0.7381\n",
      "Epoch 434/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3057 - accuracy: 0.8746 - val_loss: 0.8070 - val_accuracy: 0.6655\n",
      "Epoch 435/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3051 - accuracy: 0.8799 - val_loss: 0.9436 - val_accuracy: 0.5964\n",
      "Epoch 436/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2955 - accuracy: 0.8840 - val_loss: 0.8020 - val_accuracy: 0.6786\n",
      "Epoch 437/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2921 - accuracy: 0.8802 - val_loss: 0.7324 - val_accuracy: 0.6976\n",
      "Epoch 438/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3261 - accuracy: 0.8729 - val_loss: 0.7584 - val_accuracy: 0.6500\n",
      "Epoch 439/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3006 - accuracy: 0.8790 - val_loss: 0.8085 - val_accuracy: 0.6655\n",
      "Epoch 440/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2929 - accuracy: 0.8840 - val_loss: 0.7091 - val_accuracy: 0.7131\n",
      "Epoch 441/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2956 - accuracy: 0.8853 - val_loss: 0.7143 - val_accuracy: 0.6964\n",
      "Epoch 442/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3028 - accuracy: 0.8803 - val_loss: 0.8114 - val_accuracy: 0.6988\n",
      "Epoch 443/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2880 - accuracy: 0.8837 - val_loss: 0.7560 - val_accuracy: 0.6750\n",
      "Epoch 444/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3139 - accuracy: 0.8779 - val_loss: 0.7265 - val_accuracy: 0.7250\n",
      "Epoch 445/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2837 - accuracy: 0.8888 - val_loss: 0.7679 - val_accuracy: 0.7190\n",
      "Epoch 446/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2898 - accuracy: 0.8847 - val_loss: 0.8090 - val_accuracy: 0.6893\n",
      "Epoch 447/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2943 - accuracy: 0.8847 - val_loss: 0.8673 - val_accuracy: 0.6476\n",
      "Epoch 448/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3065 - accuracy: 0.8774 - val_loss: 0.8211 - val_accuracy: 0.6667\n",
      "Epoch 449/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2984 - accuracy: 0.8811 - val_loss: 0.8374 - val_accuracy: 0.6702\n",
      "Epoch 450/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2884 - accuracy: 0.8878 - val_loss: 0.7833 - val_accuracy: 0.7036\n",
      "Epoch 451/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2949 - accuracy: 0.8837 - val_loss: 0.6715 - val_accuracy: 0.6964\n",
      "Epoch 452/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2530 - accuracy: 0.8978 - val_loss: 0.7784 - val_accuracy: 0.6833\n",
      "Epoch 453/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2976 - accuracy: 0.8845 - val_loss: 0.8506 - val_accuracy: 0.6905\n",
      "Epoch 454/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3146 - accuracy: 0.8802 - val_loss: 0.8519 - val_accuracy: 0.6500\n",
      "Epoch 455/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2702 - accuracy: 0.8945 - val_loss: 0.7511 - val_accuracy: 0.7071\n",
      "Epoch 456/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.3140 - accuracy: 0.8745 - val_loss: 0.7821 - val_accuracy: 0.6560\n",
      "Epoch 457/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2852 - accuracy: 0.8910 - val_loss: 0.9570 - val_accuracy: 0.6655\n",
      "Epoch 458/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2969 - accuracy: 0.8884 - val_loss: 0.7548 - val_accuracy: 0.6976\n",
      "Epoch 459/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2604 - accuracy: 0.8971 - val_loss: 0.6878 - val_accuracy: 0.7179\n",
      "Epoch 460/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2913 - accuracy: 0.8832 - val_loss: 0.7953 - val_accuracy: 0.6917\n",
      "Epoch 461/600\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.2934 - accuracy: 0.8822 - val_loss: 0.8651 - val_accuracy: 0.6655\n",
      "Epoch 462/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2724 - accuracy: 0.8938 - val_loss: 0.7424 - val_accuracy: 0.7048\n",
      "Epoch 463/600\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 0.2702 - accuracy: 0.8910 - val_loss: 0.9903 - val_accuracy: 0.6690\n",
      "Epoch 464/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 44ms/step - loss: 0.2983 - accuracy: 0.8830 - val_loss: 0.7483 - val_accuracy: 0.7012\n",
      "Epoch 465/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3008 - accuracy: 0.8790 - val_loss: 0.7282 - val_accuracy: 0.6940\n",
      "Epoch 466/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2865 - accuracy: 0.8851 - val_loss: 0.7406 - val_accuracy: 0.7286\n",
      "Epoch 467/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3056 - accuracy: 0.8785 - val_loss: 0.8518 - val_accuracy: 0.6655\n",
      "Epoch 468/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2928 - accuracy: 0.8867 - val_loss: 0.6873 - val_accuracy: 0.6929\n",
      "Epoch 469/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2729 - accuracy: 0.8910 - val_loss: 0.7041 - val_accuracy: 0.7298\n",
      "Epoch 470/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2806 - accuracy: 0.8943 - val_loss: 0.7848 - val_accuracy: 0.6714\n",
      "Epoch 471/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2484 - accuracy: 0.9026 - val_loss: 0.9494 - val_accuracy: 0.6690\n",
      "Epoch 472/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2970 - accuracy: 0.8851 - val_loss: 0.7983 - val_accuracy: 0.6774\n",
      "Epoch 473/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2627 - accuracy: 0.9006 - val_loss: 0.8107 - val_accuracy: 0.6964\n",
      "Epoch 474/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2894 - accuracy: 0.8869 - val_loss: 0.7341 - val_accuracy: 0.7155\n",
      "Epoch 475/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2776 - accuracy: 0.8919 - val_loss: 0.8300 - val_accuracy: 0.6798\n",
      "Epoch 476/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2820 - accuracy: 0.8917 - val_loss: 0.7634 - val_accuracy: 0.6857\n",
      "Epoch 477/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2781 - accuracy: 0.8884 - val_loss: 0.7943 - val_accuracy: 0.6845\n",
      "Epoch 478/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2473 - accuracy: 0.9032 - val_loss: 0.7874 - val_accuracy: 0.6738\n",
      "Epoch 479/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.3092 - accuracy: 0.8811 - val_loss: 0.8967 - val_accuracy: 0.6560\n",
      "Epoch 480/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2779 - accuracy: 0.8920 - val_loss: 0.8204 - val_accuracy: 0.6798\n",
      "Epoch 481/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2526 - accuracy: 0.9000 - val_loss: 0.8536 - val_accuracy: 0.6536\n",
      "Epoch 482/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2833 - accuracy: 0.8935 - val_loss: 0.7690 - val_accuracy: 0.7012\n",
      "Epoch 483/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2446 - accuracy: 0.9055 - val_loss: 0.7917 - val_accuracy: 0.6714\n",
      "Epoch 484/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2749 - accuracy: 0.8928 - val_loss: 0.7722 - val_accuracy: 0.7095\n",
      "Epoch 485/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2878 - accuracy: 0.8940 - val_loss: 0.7749 - val_accuracy: 0.6762\n",
      "Epoch 486/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2558 - accuracy: 0.8984 - val_loss: 0.6633 - val_accuracy: 0.7369\n",
      "Epoch 487/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2647 - accuracy: 0.8969 - val_loss: 0.8475 - val_accuracy: 0.6905\n",
      "Epoch 488/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2514 - accuracy: 0.9004 - val_loss: 0.8815 - val_accuracy: 0.6643\n",
      "Epoch 489/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2770 - accuracy: 0.8923 - val_loss: 0.8260 - val_accuracy: 0.6929\n",
      "Epoch 490/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2758 - accuracy: 0.8958 - val_loss: 0.7678 - val_accuracy: 0.7119\n",
      "Epoch 491/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2924 - accuracy: 0.8832 - val_loss: 0.7255 - val_accuracy: 0.6952\n",
      "Epoch 492/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2401 - accuracy: 0.9072 - val_loss: 0.8602 - val_accuracy: 0.7036\n",
      "Epoch 493/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2654 - accuracy: 0.8971 - val_loss: 0.8294 - val_accuracy: 0.6560\n",
      "Epoch 494/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2575 - accuracy: 0.9021 - val_loss: 0.7739 - val_accuracy: 0.6952\n",
      "Epoch 495/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2661 - accuracy: 0.8944 - val_loss: 0.7589 - val_accuracy: 0.7298\n",
      "Epoch 496/600\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.2909 - accuracy: 0.8887 - val_loss: 0.7884 - val_accuracy: 0.6833\n",
      "Epoch 497/600\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.2694 - accuracy: 0.8910 - val_loss: 0.7540 - val_accuracy: 0.6988\n",
      "Epoch 498/600\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.2457 - accuracy: 0.9053 - val_loss: 0.7386 - val_accuracy: 0.7190\n",
      "Epoch 499/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2347 - accuracy: 0.9087 - val_loss: 0.9279 - val_accuracy: 0.6905\n",
      "Epoch 500/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2484 - accuracy: 0.9026 - val_loss: 0.9165 - val_accuracy: 0.6940\n",
      "Epoch 501/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2930 - accuracy: 0.8898 - val_loss: 0.8892 - val_accuracy: 0.6571\n",
      "Epoch 502/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2667 - accuracy: 0.8932 - val_loss: 0.8400 - val_accuracy: 0.6988\n",
      "Epoch 503/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.2600 - accuracy: 0.9012 - val_loss: 0.7917 - val_accuracy: 0.6810\n",
      "Epoch 504/600\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.2398 - accuracy: 0.9052 - val_loss: 1.0340 - val_accuracy: 0.6274\n",
      "Epoch 505/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2517 - accuracy: 0.8994 - val_loss: 0.8972 - val_accuracy: 0.6690\n",
      "Epoch 506/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2461 - accuracy: 0.9014 - val_loss: 0.7282 - val_accuracy: 0.7155\n",
      "Epoch 507/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2582 - accuracy: 0.9009 - val_loss: 0.7910 - val_accuracy: 0.6940\n",
      "Epoch 508/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2440 - accuracy: 0.9042 - val_loss: 0.7810 - val_accuracy: 0.6964\n",
      "Epoch 509/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2430 - accuracy: 0.9062 - val_loss: 0.8305 - val_accuracy: 0.6726\n",
      "Epoch 510/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2429 - accuracy: 0.9058 - val_loss: 0.7432 - val_accuracy: 0.7119\n",
      "Epoch 511/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2326 - accuracy: 0.9087 - val_loss: 1.0078 - val_accuracy: 0.6560\n",
      "Epoch 512/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2464 - accuracy: 0.9007 - val_loss: 1.0335 - val_accuracy: 0.6440\n",
      "Epoch 513/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2716 - accuracy: 0.8939 - val_loss: 0.8303 - val_accuracy: 0.6964\n",
      "Epoch 514/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2558 - accuracy: 0.8968 - val_loss: 0.7189 - val_accuracy: 0.7214\n",
      "Epoch 515/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2555 - accuracy: 0.8989 - val_loss: 0.7447 - val_accuracy: 0.6810\n",
      "Epoch 516/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2544 - accuracy: 0.9051 - val_loss: 0.8418 - val_accuracy: 0.6988\n",
      "Epoch 517/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2676 - accuracy: 0.8978 - val_loss: 0.7229 - val_accuracy: 0.7167\n",
      "Epoch 518/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2194 - accuracy: 0.9121 - val_loss: 0.7252 - val_accuracy: 0.7060\n",
      "Epoch 519/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2485 - accuracy: 0.9056 - val_loss: 0.8274 - val_accuracy: 0.6952\n",
      "Epoch 520/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2550 - accuracy: 0.9002 - val_loss: 0.7674 - val_accuracy: 0.6917\n",
      "Epoch 521/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2469 - accuracy: 0.9081 - val_loss: 0.8316 - val_accuracy: 0.6571\n",
      "Epoch 522/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2611 - accuracy: 0.9000 - val_loss: 0.8324 - val_accuracy: 0.6333\n",
      "Epoch 523/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2469 - accuracy: 0.9078 - val_loss: 0.7212 - val_accuracy: 0.7083\n",
      "Epoch 524/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2412 - accuracy: 0.9040 - val_loss: 0.7233 - val_accuracy: 0.6833\n",
      "Epoch 525/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2340 - accuracy: 0.9078 - val_loss: 0.8193 - val_accuracy: 0.7060\n",
      "Epoch 526/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2250 - accuracy: 0.9142 - val_loss: 0.8648 - val_accuracy: 0.6738\n",
      "Epoch 527/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2276 - accuracy: 0.9133 - val_loss: 0.7614 - val_accuracy: 0.6833\n",
      "Epoch 528/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2259 - accuracy: 0.9147 - val_loss: 0.9366 - val_accuracy: 0.6452\n",
      "Epoch 529/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2500 - accuracy: 0.9030 - val_loss: 0.8480 - val_accuracy: 0.6607\n",
      "Epoch 530/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2340 - accuracy: 0.9101 - val_loss: 0.7514 - val_accuracy: 0.7119\n",
      "Epoch 531/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2108 - accuracy: 0.9144 - val_loss: 0.9146 - val_accuracy: 0.6643\n",
      "Epoch 532/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2447 - accuracy: 0.9082 - val_loss: 0.7383 - val_accuracy: 0.7048\n",
      "Epoch 533/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2192 - accuracy: 0.9143 - val_loss: 0.9481 - val_accuracy: 0.6679\n",
      "Epoch 534/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.2500 - accuracy: 0.9034 - val_loss: 0.8055 - val_accuracy: 0.6833\n",
      "Epoch 535/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2705 - accuracy: 0.8940 - val_loss: 0.6922 - val_accuracy: 0.7214\n",
      "Epoch 536/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2283 - accuracy: 0.9129 - val_loss: 0.8061 - val_accuracy: 0.6845\n",
      "Epoch 537/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2392 - accuracy: 0.9075 - val_loss: 0.6957 - val_accuracy: 0.7060\n",
      "Epoch 538/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2347 - accuracy: 0.9061 - val_loss: 0.6414 - val_accuracy: 0.7488\n",
      "Epoch 539/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.2271 - accuracy: 0.9104 - val_loss: 0.6439 - val_accuracy: 0.7417\n",
      "Epoch 540/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2088 - accuracy: 0.9170 - val_loss: 0.7044 - val_accuracy: 0.7381\n",
      "Epoch 541/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2175 - accuracy: 0.9136 - val_loss: 0.6634 - val_accuracy: 0.7286\n",
      "Epoch 542/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2429 - accuracy: 0.9065 - val_loss: 0.8455 - val_accuracy: 0.6726\n",
      "Epoch 543/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2285 - accuracy: 0.9143 - val_loss: 0.6936 - val_accuracy: 0.7226\n",
      "Epoch 544/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2478 - accuracy: 0.9047 - val_loss: 0.8070 - val_accuracy: 0.6881\n",
      "Epoch 545/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2008 - accuracy: 0.9228 - val_loss: 0.8189 - val_accuracy: 0.6690\n",
      "Epoch 546/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2426 - accuracy: 0.9062 - val_loss: 0.8290 - val_accuracy: 0.7024\n",
      "Epoch 547/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2293 - accuracy: 0.9121 - val_loss: 0.9367 - val_accuracy: 0.6643\n",
      "Epoch 548/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2376 - accuracy: 0.9088 - val_loss: 0.6948 - val_accuracy: 0.7321\n",
      "Epoch 549/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2250 - accuracy: 0.9152 - val_loss: 0.6735 - val_accuracy: 0.7393\n",
      "Epoch 550/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2270 - accuracy: 0.9137 - val_loss: 0.7646 - val_accuracy: 0.7012\n",
      "Epoch 551/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2460 - accuracy: 0.9070 - val_loss: 0.7089 - val_accuracy: 0.7107\n",
      "Epoch 552/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2074 - accuracy: 0.9223 - val_loss: 0.8041 - val_accuracy: 0.7048\n",
      "Epoch 553/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2355 - accuracy: 0.9106 - val_loss: 0.7671 - val_accuracy: 0.6929\n",
      "Epoch 554/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.2216 - accuracy: 0.9128 - val_loss: 0.9098 - val_accuracy: 0.6857\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00554: early stopping\n",
      "Epoch 1/600\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 1.0988 - accuracy: 0.3427 - val_loss: 1.0987 - val_accuracy: 0.3357\n",
      "Epoch 2/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0977 - accuracy: 0.3498 - val_loss: 1.0985 - val_accuracy: 0.3333\n",
      "Epoch 3/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0991 - accuracy: 0.3448 - val_loss: 1.0983 - val_accuracy: 0.3238\n",
      "Epoch 4/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0986 - accuracy: 0.3529 - val_loss: 1.0985 - val_accuracy: 0.3429\n",
      "Epoch 5/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0968 - accuracy: 0.3731 - val_loss: 1.0964 - val_accuracy: 0.3631\n",
      "Epoch 6/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0969 - accuracy: 0.3725 - val_loss: 1.0914 - val_accuracy: 0.4179\n",
      "Epoch 7/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0959 - accuracy: 0.3710 - val_loss: 1.0910 - val_accuracy: 0.3905\n",
      "Epoch 8/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0934 - accuracy: 0.3806 - val_loss: 1.0886 - val_accuracy: 0.3857\n",
      "Epoch 9/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0930 - accuracy: 0.3848 - val_loss: 1.0887 - val_accuracy: 0.3905\n",
      "Epoch 10/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0915 - accuracy: 0.3789 - val_loss: 1.0883 - val_accuracy: 0.3607\n",
      "Epoch 11/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0895 - accuracy: 0.3915 - val_loss: 1.0840 - val_accuracy: 0.3869\n",
      "Epoch 12/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0882 - accuracy: 0.3942 - val_loss: 1.0837 - val_accuracy: 0.3964\n",
      "Epoch 13/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0893 - accuracy: 0.3896 - val_loss: 1.0808 - val_accuracy: 0.4083\n",
      "Epoch 14/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0849 - accuracy: 0.4017 - val_loss: 1.0800 - val_accuracy: 0.4012\n",
      "Epoch 15/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0875 - accuracy: 0.3861 - val_loss: 1.0723 - val_accuracy: 0.4095\n",
      "Epoch 16/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0868 - accuracy: 0.3848 - val_loss: 1.0773 - val_accuracy: 0.3821\n",
      "Epoch 17/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0855 - accuracy: 0.3884 - val_loss: 1.0716 - val_accuracy: 0.3857\n",
      "Epoch 18/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0853 - accuracy: 0.3887 - val_loss: 1.0810 - val_accuracy: 0.3631\n",
      "Epoch 19/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0815 - accuracy: 0.3975 - val_loss: 1.0700 - val_accuracy: 0.3964\n",
      "Epoch 20/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0862 - accuracy: 0.3731 - val_loss: 1.0756 - val_accuracy: 0.3833\n",
      "Epoch 21/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0729 - accuracy: 0.4010 - val_loss: 1.0722 - val_accuracy: 0.4012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0729 - accuracy: 0.4007 - val_loss: 1.0717 - val_accuracy: 0.4143\n",
      "Epoch 23/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0712 - accuracy: 0.4022 - val_loss: 1.0699 - val_accuracy: 0.3917\n",
      "Epoch 24/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0708 - accuracy: 0.4000 - val_loss: 1.0507 - val_accuracy: 0.4321\n",
      "Epoch 25/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0663 - accuracy: 0.4107 - val_loss: 1.0612 - val_accuracy: 0.4024\n",
      "Epoch 26/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0696 - accuracy: 0.4080 - val_loss: 1.0493 - val_accuracy: 0.4310\n",
      "Epoch 27/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0647 - accuracy: 0.4075 - val_loss: 1.0536 - val_accuracy: 0.4238\n",
      "Epoch 28/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0646 - accuracy: 0.4102 - val_loss: 1.0598 - val_accuracy: 0.4226\n",
      "Epoch 29/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0631 - accuracy: 0.4052 - val_loss: 1.0313 - val_accuracy: 0.4357\n",
      "Epoch 30/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0616 - accuracy: 0.4160 - val_loss: 1.0447 - val_accuracy: 0.4179\n",
      "Epoch 31/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0521 - accuracy: 0.4291 - val_loss: 1.0724 - val_accuracy: 0.4012\n",
      "Epoch 32/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0536 - accuracy: 0.4226 - val_loss: 1.0454 - val_accuracy: 0.4310\n",
      "Epoch 33/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0487 - accuracy: 0.4261 - val_loss: 1.0404 - val_accuracy: 0.4536\n",
      "Epoch 34/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0472 - accuracy: 0.4340 - val_loss: 1.0324 - val_accuracy: 0.4452\n",
      "Epoch 35/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0462 - accuracy: 0.4231 - val_loss: 1.0707 - val_accuracy: 0.4464\n",
      "Epoch 36/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0494 - accuracy: 0.4262 - val_loss: 1.0279 - val_accuracy: 0.4357\n",
      "Epoch 37/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0359 - accuracy: 0.4404 - val_loss: 1.0591 - val_accuracy: 0.4333\n",
      "Epoch 38/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0429 - accuracy: 0.4312 - val_loss: 1.0070 - val_accuracy: 0.4774\n",
      "Epoch 39/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0386 - accuracy: 0.4338 - val_loss: 1.0238 - val_accuracy: 0.4452\n",
      "Epoch 40/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0337 - accuracy: 0.4287 - val_loss: 1.0170 - val_accuracy: 0.4464\n",
      "Epoch 41/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0413 - accuracy: 0.4350 - val_loss: 1.0353 - val_accuracy: 0.4452\n",
      "Epoch 42/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0294 - accuracy: 0.4412 - val_loss: 1.0265 - val_accuracy: 0.4786\n",
      "Epoch 43/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0418 - accuracy: 0.4287 - val_loss: 1.0246 - val_accuracy: 0.4321\n",
      "Epoch 44/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0274 - accuracy: 0.4387 - val_loss: 1.0521 - val_accuracy: 0.4012\n",
      "Epoch 45/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0267 - accuracy: 0.4386 - val_loss: 1.0485 - val_accuracy: 0.4321\n",
      "Epoch 46/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0223 - accuracy: 0.4413 - val_loss: 1.0046 - val_accuracy: 0.4702\n",
      "Epoch 47/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0314 - accuracy: 0.4414 - val_loss: 1.0133 - val_accuracy: 0.4571\n",
      "Epoch 48/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0192 - accuracy: 0.4425 - val_loss: 1.0042 - val_accuracy: 0.4833\n",
      "Epoch 49/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0097 - accuracy: 0.4512 - val_loss: 1.0007 - val_accuracy: 0.4786\n",
      "Epoch 50/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0191 - accuracy: 0.4439 - val_loss: 1.0058 - val_accuracy: 0.4786\n",
      "Epoch 51/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0227 - accuracy: 0.4387 - val_loss: 1.0259 - val_accuracy: 0.4679\n",
      "Epoch 52/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0089 - accuracy: 0.4486 - val_loss: 1.0016 - val_accuracy: 0.4571\n",
      "Epoch 53/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0093 - accuracy: 0.4481 - val_loss: 0.9924 - val_accuracy: 0.4821\n",
      "Epoch 54/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0102 - accuracy: 0.4509 - val_loss: 0.9876 - val_accuracy: 0.4476\n",
      "Epoch 55/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0232 - accuracy: 0.4383 - val_loss: 0.9780 - val_accuracy: 0.4774\n",
      "Epoch 56/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0201 - accuracy: 0.4423 - val_loss: 1.0029 - val_accuracy: 0.4583\n",
      "Epoch 57/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 1.0118 - accuracy: 0.4447 - val_loss: 0.9835 - val_accuracy: 0.4905\n",
      "Epoch 58/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0148 - accuracy: 0.4474 - val_loss: 1.0015 - val_accuracy: 0.4821\n",
      "Epoch 59/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0076 - accuracy: 0.4537 - val_loss: 0.9890 - val_accuracy: 0.4845\n",
      "Epoch 60/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0019 - accuracy: 0.4469 - val_loss: 0.9901 - val_accuracy: 0.4631\n",
      "Epoch 61/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 1.0003 - accuracy: 0.4544 - val_loss: 0.9890 - val_accuracy: 0.4917\n",
      "Epoch 62/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0121 - accuracy: 0.4521 - val_loss: 1.0011 - val_accuracy: 0.5060\n",
      "Epoch 63/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9970 - accuracy: 0.4516 - val_loss: 1.0252 - val_accuracy: 0.4417\n",
      "Epoch 64/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0106 - accuracy: 0.4499 - val_loss: 1.0375 - val_accuracy: 0.4440\n",
      "Epoch 65/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0052 - accuracy: 0.4453 - val_loss: 0.9634 - val_accuracy: 0.5107\n",
      "Epoch 66/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0006 - accuracy: 0.4500 - val_loss: 0.9431 - val_accuracy: 0.5262\n",
      "Epoch 67/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9988 - accuracy: 0.4526 - val_loss: 0.9856 - val_accuracy: 0.5000\n",
      "Epoch 68/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0074 - accuracy: 0.4474 - val_loss: 0.9892 - val_accuracy: 0.4667\n",
      "Epoch 69/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 1.0020 - accuracy: 0.4480 - val_loss: 1.0149 - val_accuracy: 0.4619\n",
      "Epoch 70/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9964 - accuracy: 0.4539 - val_loss: 0.9553 - val_accuracy: 0.4929\n",
      "Epoch 71/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9941 - accuracy: 0.4602 - val_loss: 0.9942 - val_accuracy: 0.4774\n",
      "Epoch 72/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9923 - accuracy: 0.4578 - val_loss: 0.9576 - val_accuracy: 0.4929\n",
      "Epoch 73/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9928 - accuracy: 0.4833 - val_loss: 1.0001 - val_accuracy: 0.4536\n",
      "Epoch 74/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9869 - accuracy: 0.4823 - val_loss: 0.9835 - val_accuracy: 0.4988\n",
      "Epoch 75/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9999 - accuracy: 0.4719 - val_loss: 0.9872 - val_accuracy: 0.4976\n",
      "Epoch 76/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9862 - accuracy: 0.4879 - val_loss: 0.9758 - val_accuracy: 0.4786\n",
      "Epoch 77/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9842 - accuracy: 0.4821 - val_loss: 0.9833 - val_accuracy: 0.4810\n",
      "Epoch 78/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9857 - accuracy: 0.4888 - val_loss: 0.9379 - val_accuracy: 0.5155\n",
      "Epoch 79/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9794 - accuracy: 0.4932 - val_loss: 0.9542 - val_accuracy: 0.5262\n",
      "Epoch 80/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.9725 - accuracy: 0.4976 - val_loss: 0.9733 - val_accuracy: 0.5107\n",
      "Epoch 81/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9906 - accuracy: 0.4813 - val_loss: 0.9734 - val_accuracy: 0.5095\n",
      "Epoch 82/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9869 - accuracy: 0.4833 - val_loss: 1.0028 - val_accuracy: 0.4440\n",
      "Epoch 83/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9730 - accuracy: 0.5002 - val_loss: 0.9636 - val_accuracy: 0.5083\n",
      "Epoch 84/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9713 - accuracy: 0.5017 - val_loss: 0.9351 - val_accuracy: 0.5619\n",
      "Epoch 85/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9686 - accuracy: 0.4944 - val_loss: 0.9448 - val_accuracy: 0.5488\n",
      "Epoch 86/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9739 - accuracy: 0.5027 - val_loss: 0.9897 - val_accuracy: 0.4845\n",
      "Epoch 87/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.9540 - accuracy: 0.5108 - val_loss: 0.9728 - val_accuracy: 0.5083\n",
      "Epoch 88/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9644 - accuracy: 0.5022 - val_loss: 0.9854 - val_accuracy: 0.4714\n",
      "Epoch 89/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9647 - accuracy: 0.5031 - val_loss: 0.9993 - val_accuracy: 0.4869\n",
      "Epoch 90/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9600 - accuracy: 0.5098 - val_loss: 0.9621 - val_accuracy: 0.4976\n",
      "Epoch 91/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9609 - accuracy: 0.5088 - val_loss: 0.9320 - val_accuracy: 0.5286\n",
      "Epoch 92/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9724 - accuracy: 0.5060 - val_loss: 0.9094 - val_accuracy: 0.5560\n",
      "Epoch 93/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9397 - accuracy: 0.5240 - val_loss: 0.9353 - val_accuracy: 0.5095\n",
      "Epoch 94/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9460 - accuracy: 0.5252 - val_loss: 0.9266 - val_accuracy: 0.5202\n",
      "Epoch 95/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9560 - accuracy: 0.5174 - val_loss: 0.9811 - val_accuracy: 0.4952\n",
      "Epoch 96/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9465 - accuracy: 0.5243 - val_loss: 0.9548 - val_accuracy: 0.5369\n",
      "Epoch 97/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9411 - accuracy: 0.5255 - val_loss: 0.9736 - val_accuracy: 0.4821\n",
      "Epoch 98/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9411 - accuracy: 0.5272 - val_loss: 0.9630 - val_accuracy: 0.5083\n",
      "Epoch 99/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9347 - accuracy: 0.5332 - val_loss: 0.9654 - val_accuracy: 0.5310\n",
      "Epoch 100/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9379 - accuracy: 0.5241 - val_loss: 0.9432 - val_accuracy: 0.5131\n",
      "Epoch 101/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9381 - accuracy: 0.5353 - val_loss: 0.9398 - val_accuracy: 0.5060\n",
      "Epoch 102/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9416 - accuracy: 0.5351 - val_loss: 1.0049 - val_accuracy: 0.4583\n",
      "Epoch 103/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9389 - accuracy: 0.5290 - val_loss: 0.9752 - val_accuracy: 0.4845\n",
      "Epoch 104/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9277 - accuracy: 0.5345 - val_loss: 0.9245 - val_accuracy: 0.5167\n",
      "Epoch 105/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9252 - accuracy: 0.5430 - val_loss: 0.9409 - val_accuracy: 0.5131\n",
      "Epoch 106/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9399 - accuracy: 0.5279 - val_loss: 0.9665 - val_accuracy: 0.5190\n",
      "Epoch 107/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9266 - accuracy: 0.5369 - val_loss: 0.9093 - val_accuracy: 0.5393\n",
      "Epoch 108/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.9173 - accuracy: 0.5435 - val_loss: 0.9739 - val_accuracy: 0.4940\n",
      "Epoch 109/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9131 - accuracy: 0.5450 - val_loss: 0.9650 - val_accuracy: 0.5071\n",
      "Epoch 110/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9171 - accuracy: 0.5499 - val_loss: 0.9163 - val_accuracy: 0.5226\n",
      "Epoch 111/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9154 - accuracy: 0.5429 - val_loss: 0.9623 - val_accuracy: 0.4845\n",
      "Epoch 112/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9147 - accuracy: 0.5486 - val_loss: 0.9346 - val_accuracy: 0.5214\n",
      "Epoch 113/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9018 - accuracy: 0.5510 - val_loss: 0.9354 - val_accuracy: 0.5119\n",
      "Epoch 114/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9024 - accuracy: 0.5566 - val_loss: 0.9102 - val_accuracy: 0.4988\n",
      "Epoch 115/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.9037 - accuracy: 0.5517 - val_loss: 0.9119 - val_accuracy: 0.5024\n",
      "Epoch 116/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.9009 - accuracy: 0.5570 - val_loss: 0.9210 - val_accuracy: 0.5214\n",
      "Epoch 117/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.9090 - accuracy: 0.5476 - val_loss: 0.9225 - val_accuracy: 0.5036\n",
      "Epoch 118/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8897 - accuracy: 0.5597 - val_loss: 0.9162 - val_accuracy: 0.5060\n",
      "Epoch 119/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8978 - accuracy: 0.5516 - val_loss: 0.9361 - val_accuracy: 0.4869\n",
      "Epoch 120/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8983 - accuracy: 0.5604 - val_loss: 0.9815 - val_accuracy: 0.4786\n",
      "Epoch 121/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8921 - accuracy: 0.5558 - val_loss: 0.9113 - val_accuracy: 0.5357\n",
      "Epoch 122/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8947 - accuracy: 0.5517 - val_loss: 0.9400 - val_accuracy: 0.5250\n",
      "Epoch 123/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8882 - accuracy: 0.5582 - val_loss: 0.9710 - val_accuracy: 0.5310\n",
      "Epoch 124/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8812 - accuracy: 0.5649 - val_loss: 0.8609 - val_accuracy: 0.5476\n",
      "Epoch 125/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8872 - accuracy: 0.5611 - val_loss: 1.0100 - val_accuracy: 0.4679\n",
      "Epoch 126/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8833 - accuracy: 0.5642 - val_loss: 0.9131 - val_accuracy: 0.5214\n",
      "Epoch 127/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8756 - accuracy: 0.5730 - val_loss: 0.9476 - val_accuracy: 0.5214\n",
      "Epoch 128/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8927 - accuracy: 0.5603 - val_loss: 0.9996 - val_accuracy: 0.4702\n",
      "Epoch 129/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8832 - accuracy: 0.5731 - val_loss: 0.9721 - val_accuracy: 0.4917\n",
      "Epoch 130/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8755 - accuracy: 0.5787 - val_loss: 0.9029 - val_accuracy: 0.5333\n",
      "Epoch 131/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8757 - accuracy: 0.5759 - val_loss: 0.9457 - val_accuracy: 0.4929\n",
      "Epoch 132/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8905 - accuracy: 0.5626 - val_loss: 0.9730 - val_accuracy: 0.4810\n",
      "Epoch 133/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8639 - accuracy: 0.5799 - val_loss: 0.9518 - val_accuracy: 0.4976\n",
      "Epoch 134/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8657 - accuracy: 0.5698 - val_loss: 0.9451 - val_accuracy: 0.5214\n",
      "Epoch 135/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8699 - accuracy: 0.5780 - val_loss: 0.9162 - val_accuracy: 0.5238\n",
      "Epoch 136/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8611 - accuracy: 0.5830 - val_loss: 0.9494 - val_accuracy: 0.5071\n",
      "Epoch 137/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8563 - accuracy: 0.5803 - val_loss: 0.9505 - val_accuracy: 0.5095\n",
      "Epoch 138/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8715 - accuracy: 0.5772 - val_loss: 1.0570 - val_accuracy: 0.4190\n",
      "Epoch 139/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8989 - accuracy: 0.5633 - val_loss: 0.9271 - val_accuracy: 0.5310\n",
      "Epoch 140/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8577 - accuracy: 0.5840 - val_loss: 0.9267 - val_accuracy: 0.4798\n",
      "Epoch 141/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8680 - accuracy: 0.5771 - val_loss: 0.9155 - val_accuracy: 0.5250\n",
      "Epoch 142/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8335 - accuracy: 0.5961 - val_loss: 0.9633 - val_accuracy: 0.5024\n",
      "Epoch 143/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8606 - accuracy: 0.5851 - val_loss: 0.9709 - val_accuracy: 0.5012\n",
      "Epoch 144/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8349 - accuracy: 0.5993 - val_loss: 0.9293 - val_accuracy: 0.5393\n",
      "Epoch 145/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8338 - accuracy: 0.5983 - val_loss: 0.9306 - val_accuracy: 0.5595\n",
      "Epoch 146/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8305 - accuracy: 0.6041 - val_loss: 0.8900 - val_accuracy: 0.5643\n",
      "Epoch 147/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8406 - accuracy: 0.5918 - val_loss: 0.9788 - val_accuracy: 0.4798\n",
      "Epoch 148/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8370 - accuracy: 0.5879 - val_loss: 0.8961 - val_accuracy: 0.5440\n",
      "Epoch 149/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8184 - accuracy: 0.6095 - val_loss: 0.9183 - val_accuracy: 0.5250\n",
      "Epoch 150/600\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.8377 - accuracy: 0.5947 - val_loss: 0.9002 - val_accuracy: 0.5238\n",
      "Epoch 151/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8221 - accuracy: 0.6065 - val_loss: 0.9046 - val_accuracy: 0.5238\n",
      "Epoch 152/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8258 - accuracy: 0.6006 - val_loss: 0.8829 - val_accuracy: 0.5512\n",
      "Epoch 153/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8111 - accuracy: 0.6096 - val_loss: 0.9725 - val_accuracy: 0.4762\n",
      "Epoch 154/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8223 - accuracy: 0.6036 - val_loss: 1.0119 - val_accuracy: 0.4881\n",
      "Epoch 155/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8143 - accuracy: 0.6137 - val_loss: 0.9152 - val_accuracy: 0.5655\n",
      "Epoch 156/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8111 - accuracy: 0.6025 - val_loss: 0.9225 - val_accuracy: 0.5429\n",
      "Epoch 157/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8217 - accuracy: 0.6093 - val_loss: 0.8747 - val_accuracy: 0.5714\n",
      "Epoch 158/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.7911 - accuracy: 0.6219 - val_loss: 0.8441 - val_accuracy: 0.5690\n",
      "Epoch 159/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8091 - accuracy: 0.6157 - val_loss: 0.8916 - val_accuracy: 0.5512\n",
      "Epoch 160/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7992 - accuracy: 0.6138 - val_loss: 0.9062 - val_accuracy: 0.5738\n",
      "Epoch 161/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8047 - accuracy: 0.6126 - val_loss: 0.8458 - val_accuracy: 0.5810\n",
      "Epoch 162/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.8046 - accuracy: 0.6124 - val_loss: 0.9250 - val_accuracy: 0.5607\n",
      "Epoch 163/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8186 - accuracy: 0.6030 - val_loss: 0.8844 - val_accuracy: 0.5524\n",
      "Epoch 164/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.8022 - accuracy: 0.6160 - val_loss: 0.9694 - val_accuracy: 0.5464\n",
      "Epoch 165/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.7977 - accuracy: 0.6189 - val_loss: 0.9066 - val_accuracy: 0.5690\n",
      "Epoch 166/600\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.7891 - accuracy: 0.6244 - val_loss: 0.8939 - val_accuracy: 0.5298\n",
      "Epoch 167/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.7967 - accuracy: 0.6250 - val_loss: 0.8000 - val_accuracy: 0.6262\n",
      "Epoch 168/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.7905 - accuracy: 0.6203 - val_loss: 0.8919 - val_accuracy: 0.5321\n",
      "Epoch 169/600\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.7833 - accuracy: 0.6279 - val_loss: 0.9271 - val_accuracy: 0.5607\n",
      "Epoch 170/600\n",
      " 16/134 [==>...........................] - ETA: 4s - loss: 0.7947 - accuracy: 0.6365"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-518-915ea825b2fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mstepValidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m tuner.search(loadTrain(trainData,sampleSize),steps_per_epoch=stepTrain,\n\u001b[0m\u001b[0;32m     26\u001b[0m              \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloadTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msampleSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstepValidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m              epochs=600, callbacks=cb)\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras_tuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"callbacks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"min\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \"\"\"\n\u001b[0;32m    146\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelName = 'rawLFP_v5n_tunning'\n",
    "cb = [tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,\n",
    "    patience=150,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)]\n",
    "\n",
    "EXECUTION_PER_TRIAL = 14\n",
    "SEED = 1\n",
    "\n",
    "tuner = kt.BayesianOptimization(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "#                      max_epochs=800,\n",
    "                     seed=SEED,\n",
    "                     max_trials = EXECUTION_PER_TRIAL,           \n",
    "                     executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "                     directory='tunning',\n",
    "                     project_name='hailMary_B')\n",
    "\n",
    "\n",
    "stepTrain=len(trainData)//batchSize\n",
    "stepValidate=len(validate)//batchSize\n",
    "\n",
    "tuner.search(loadTrain(trainData,sampleSize),steps_per_epoch=stepTrain,\n",
    "             validation_data=loadTrain(validate,sampleSize),validation_steps=stepValidate,\n",
    "             epochs=600, callbacks=cb)\n",
    "# tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "2f8eb65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in tunning\\hailMary_B\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filters: 12\n",
      "numFilters_1: 60\n",
      "kernalSize_1: 3\n",
      "dropout_1: 0.0\n",
      "numFilters_2: 64\n",
      "kernalSize_2: 83\n",
      "dropout_2: 0.15000000000000002\n",
      "numFilters_3: 36\n",
      "kernalSize_3: 5\n",
      "dropout_3: 0.5\n",
      "numFilters_4: 24\n",
      "kernalSize_4: 17\n",
      "dropout_4: 0.15000000000000002\n",
      "numFilters_5: 16\n",
      "kernalSize_5: 89\n",
      "dropout_5: 0.4\n",
      "numFilters_6: 16\n",
      "kernalSize_6: 3\n",
      "dropout_6: 0.5\n",
      "units: 30\n",
      "Score: 0.7854591820921216\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filters: 12\n",
      "numFilters_1: 60\n",
      "kernalSize_1: 23\n",
      "dropout_1: 0.1\n",
      "numFilters_2: 40\n",
      "kernalSize_2: 71\n",
      "dropout_2: 0.15000000000000002\n",
      "numFilters_3: 20\n",
      "kernalSize_3: 43\n",
      "dropout_3: 0.30000000000000004\n",
      "numFilters_4: 36\n",
      "kernalSize_4: 43\n",
      "dropout_4: 0.15000000000000002\n",
      "numFilters_5: 20\n",
      "kernalSize_5: 87\n",
      "dropout_5: 0.2\n",
      "numFilters_6: 40\n",
      "kernalSize_6: 19\n",
      "dropout_6: 0.35000000000000003\n",
      "units: 30\n",
      "Score: 0.7589285671710968\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filters: 12\n",
      "numFilters_1: 60\n",
      "kernalSize_1: 3\n",
      "dropout_1: 0.0\n",
      "numFilters_2: 64\n",
      "kernalSize_2: 79\n",
      "dropout_2: 0.0\n",
      "numFilters_3: 28\n",
      "kernalSize_3: 25\n",
      "dropout_3: 0.4\n",
      "numFilters_4: 64\n",
      "kernalSize_4: 89\n",
      "dropout_4: 0.0\n",
      "numFilters_5: 16\n",
      "kernalSize_5: 89\n",
      "dropout_5: 0.30000000000000004\n",
      "numFilters_6: 24\n",
      "kernalSize_6: 3\n",
      "dropout_6: 0.5\n",
      "units: 30\n",
      "Score: 0.7398809492588043\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filters: 12\n",
      "numFilters_1: 60\n",
      "kernalSize_1: 3\n",
      "dropout_1: 0.0\n",
      "numFilters_2: 8\n",
      "kernalSize_2: 61\n",
      "dropout_2: 0.0\n",
      "numFilters_3: 8\n",
      "kernalSize_3: 77\n",
      "dropout_3: 0.15000000000000002\n",
      "numFilters_4: 60\n",
      "kernalSize_4: 89\n",
      "dropout_4: 0.0\n",
      "numFilters_5: 16\n",
      "kernalSize_5: 89\n",
      "dropout_5: 0.05\n",
      "numFilters_6: 60\n",
      "kernalSize_6: 3\n",
      "dropout_6: 0.5\n",
      "units: 30\n",
      "Score: 0.6360544179167066\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filters: 12\n",
      "numFilters_1: 60\n",
      "kernalSize_1: 83\n",
      "dropout_1: 0.35000000000000003\n",
      "numFilters_2: 28\n",
      "kernalSize_2: 67\n",
      "dropout_2: 0.30000000000000004\n",
      "numFilters_3: 16\n",
      "kernalSize_3: 51\n",
      "dropout_3: 0.25\n",
      "numFilters_4: 16\n",
      "kernalSize_4: 9\n",
      "dropout_4: 0.30000000000000004\n",
      "numFilters_5: 40\n",
      "kernalSize_5: 51\n",
      "dropout_5: 0.15000000000000002\n",
      "numFilters_6: 48\n",
      "kernalSize_6: 57\n",
      "dropout_6: 0.1\n",
      "units: 15\n",
      "Score: 0.5958333313465118\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "filters: 12\n",
      "numFilters_1: 60\n",
      "kernalSize_1: 3\n",
      "dropout_1: 0.0\n",
      "numFilters_2: 64\n",
      "kernalSize_2: 89\n",
      "dropout_2: 0.5\n",
      "numFilters_3: 32\n",
      "kernalSize_3: 3\n",
      "dropout_3: 0.45\n",
      "numFilters_4: 40\n",
      "kernalSize_4: 67\n",
      "dropout_4: 0.5\n",
      "numFilters_5: 16\n",
      "kernalSize_5: 89\n",
      "dropout_5: 0.35000000000000003\n",
      "numFilters_6: 16\n",
      "kernalSize_6: 3\n",
      "dropout_6: 0.5\n",
      "units: 30\n",
      "Score: 0.5543367351804461\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "6faa93aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "b8471574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:\\rawLFP_v5n_tunning\\assets\n"
     ]
    }
   ],
   "source": [
    "## Saving the model\n",
    "##\n",
    "model.save('E:\\\\'+modelName)\n",
    "model.save_weights('E:\\\\'+modelName+'_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "3b370f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])# history.history\n",
    "plt.savefig(\"E:\\\\NN\\\\\"+modelName+\"_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "e2188920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.plot(history.history['val_loss'])# history.history\n",
    "plt.savefig(\"E:\\\\NN\\\\\"+modelName+\"_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "808e9d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      1/Unknown - 0s 159ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzemel\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# model =  tf.keras.models.load_model('E:\\\\caOnly_v1')\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "# model.load_weights(\"E:\\\\caOnly_v1_weights.h5\")\n",
    "\n",
    "# labels = (train_generator.class_indices)\n",
    "pred = model.predict_generator(loadTest(testData),verbose=1)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "print(np.unique(pred))\n",
    "\n",
    "y = []\n",
    "for ind,(dataP,label) in enumerate(loadTest(testData)):\n",
    "    y = y+list(np.argmax(label,axis=1))\n",
    "# print(pred[1:100],y[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "0ca3f6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.263582966226138\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes=['Healthy','Acute','Chronic']\n",
    "con_mat = tf.math.confusion_matrix(labels=y, predictions=pred).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = classes, \n",
    "                     columns = classes)\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.title(modelName +\"- on test dataset. Accuracy: {acc:f}\".format(acc=np.sum(y==pred)/len(y)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig(\"E:\\\\NN\\\\\"+modelName+\"_confusionOnTest_Test.png\")\n",
    "print(np.sum(y==pred)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "9e57a9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 6ms/step\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# model =  tf.keras.models.load_model('E:\\\\caOnly_v1')\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "# model.load_weights(\"E:\\\\caOnly_v1_weights.h5\")\n",
    "\n",
    "# labels = (train_generator.class_indices)\n",
    "pred = model.predict_generator(loadTest(validate),verbose=1)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "print(np.unique(pred))\n",
    "\n",
    "y = []\n",
    "for ind,(dataP,label) in enumerate(loadTest(validate)):\n",
    "    y = y+list(np.argmax(label,axis=1))\n",
    "# print(pred[1:100],y[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "ae1a25f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6811594202898551\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes=['Healthy','Acute','Chronic']\n",
    "con_mat = tf.math.confusion_matrix(labels=y, predictions=pred).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = classes, \n",
    "                     columns = classes)\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.title(modelName +\"- on test dataset. Accuracy: {acc:f}\".format(acc=np.sum(y==pred)/len(y)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig(\"E:\\\\NN\\\\\"+modelName+\"_confusionOnTest_val.png\")\n",
    "print(np.sum(y==pred)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "81545c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896/896 [==============================] - 5s 5ms/step\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# model =  tf.keras.models.load_model('E:\\\\caOnly_v1')\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "# model.load_weights(\"E:\\\\caOnly_v1_weights.h5\")\n",
    "\n",
    "# labels = (train_generator.class_indices)\n",
    "pred = model.predict_generator(loadTest(trainData),verbose=1)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "print(np.unique(pred))\n",
    "\n",
    "y = []\n",
    "for ind,(dataP,label) in enumerate(loadTest(trainData)):\n",
    "    y = y+list(np.argmax(label,axis=1))\n",
    "# print(pred[1:100],y[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "b831547c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7641369047619048\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes=['Healthy','Acute','Chronic']\n",
    "con_mat = tf.math.confusion_matrix(labels=y, predictions=pred).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = classes, \n",
    "                     columns = classes)\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.title(modelName +\"- on train dataset. Accuracy: {acc:f}\".format(acc=np.sum(y==pred)/len(y)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig(\"E:\\\\NN\\\\\"+modelName+\"_confusionOnTest_Train.png\")\n",
    "print(np.sum(y==pred)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b67399e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567/567 [==============================] - 89s 157ms/step\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# model =  tf.keras.models.load_model('E:\\\\caOnly_v1')\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "# model.load_weights(\"E:\\\\caOnly_v1_weights.h5\")\n",
    "\n",
    "# train_datagenT = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "# train_generatorT = train_datagenT.flow_from_directory(\n",
    "#     directory=\"E:\\\\data\\\\Train\\\\\",#'E:\\\\data\\\\imageTest\\\\training_set\\\\',#\n",
    "#     target_size=(300, 300),\n",
    "#     color_mode=\"grayscale\",\n",
    "#     batch_size=32,\n",
    "#     class_mode=\"categorical\",\n",
    "#     shuffle=False,\n",
    "#     seed=36\n",
    "# )\n",
    "\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "pred = model.predict_generator(train_generatorT,verbose=1)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "print(np.unique(pred))\n",
    "\n",
    "y = []\n",
    "for f in train_generatorT.filenames:\n",
    "    sess = f.split(\"_\")[1]\n",
    "    if sess[0] == 'B':\n",
    "        day = 0\n",
    "    else:\n",
    "        day = int(re.findall(r'\\d+',sess)[0])\n",
    "\n",
    "    # get data\n",
    "    period = periodCalc(day) \n",
    "    y.append(labels[period])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "71a07908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes=labels.keys()\n",
    "con_mat = tf.math.confusion_matrix(labels=y, predictions=pred).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = classes, \n",
    "                     columns = classes)\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.title(modelName +\"- on train dataset. Accuracy: {acc:f}\".format(acc=np.sum(y==pred)/len(y)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig(\"E:\\\\NN\\\\\"+modelName+\"_confusionOnTest_Train.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f88aa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567/567 [==============================] - 89s 157ms/step - loss: 3.5345e-04 - accuracy: 1.0000\n",
      "[0.00035344576463103294, 1.0]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(train_generatorT)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "823d27a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567/567 [==============================] - 89s 157ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18130, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_generator(train_generator,verbose=1)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f72b53ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9993336e-01, 6.6623645e-05, 2.0047966e-09],\n",
       "       [1.0000000e+00, 1.3673330e-08, 4.0443326e-10],\n",
       "       [3.7493074e-08, 1.0000000e+00, 1.9402356e-11],\n",
       "       [3.0466440e-04, 9.9913293e-01, 5.6242698e-04]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generatorT = train_datagen.flow_from_directory(\n",
    "    directory=\"E:\\\\data\\\\Train\\\\\",#'E:\\\\data\\\\imageTest\\\\training_set\\\\',#\n",
    "    target_size=(300, 300),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=36\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ec9f784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "for d,l in train_generator:\n",
    "    plt.imshow(d[16,:,:,0])\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
